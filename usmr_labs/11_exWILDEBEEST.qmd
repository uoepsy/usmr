---
title: "Week 11 Exercises: Tying up Loose Ends"
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
editor_options: 
  chunk_output_type: console
---


```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(xaringanExtra)
library(tidyverse)
library(patchwork)
xaringanExtra::use_panelset()
set.seed(nchar("everybody loves USMR"))
couchto5k <- read_csv("../../data/couchto5k.csv")
```


:::lo
__Please Note__  

This might look like a lot of stuff, but it is just writing, bit by bit, the stuff that we have covered through the course. This is not a "perfect" answer (I may well have made mistakes, or have written certain sections unclearly).  
With regards to the coursework report, there are marks available even if you don't get all of the "bits" -- most important is to think carefully about what the questions are really asking (and therefore what kind of test might be appropriate), and to explain your analytical process as clearly as you can, pulling out and interpreting the key information from the models that help to guide the reader to your conclusion.  

:::



# Couch to 5k

:::frame

__Background: Couch to 5k__  

[Couch to 5k](https://www.nhs.uk/live-well/exercise/get-running-with-couch-to-5k/) is an NHS-sponsored fitness programme which lasts 9 weeks, taking participants from a gentle start up to a half-hour run.  

The NHS wants to research some of the potential impact this programme has on wellbeing. They have conducted a small study of `r nrow(couchto5k)` people in 2 cities (Edinburgh and Glasgow), all of whom started the Couch to 5k programme, across the course of a year.  

The researchers' interests are two-fold: They are interested in the effects of taking the programme on psychological wellbeing, and also in the psychological factors that make people continue on the programme. 

__Methods__  

At Week 0, all participants completed a questionnaire measuring the psychometric factors of accountability and self-motivation.  
Upon either completing the programme (Week 9) or dropping out (< Week 9), participants completed a questionnaire which included a measure of their self-reported happiness, and a "health" measure derived from a number of physiological tests. Researchers also recorded the season in which participants started the programme, as evidence from previous research suggests that the probability of completing the couch to 5k programme varies substantially across the year. 

You can download the dataset from [https://uoepsy.github.io/data/couchto5k.csv](https://uoepsy.github.io/data/couchto5k.csv). Details of the variables can be found in the table below.    
  
_Please note that Couch to 5k is a real programme, but the data you will be analysing comes from our febrile minds._  
  
---

__Data Dictionary:__

Column    | Content
----------|-------------
`pptID`   | random ID code for participant
`age`     | age in years
`accountability` | psychometric measure of accountability (or 'responsibility') (Sum of 5 questions, each scored 1-7). 
`selfmot` | psychometric measure of self-motivation (Sum of 5 questions, each scored 1-7)
`health`  | multi-test health measure (0-100)
`happiness` | simple happiness scale (0-100)
`season`  | season of the year participants were interviewed in
`city`    | city participant was recruited in
`week_stopped` | week of programme participant stopped in (week 9 = completed the programme)


:::

`r qbegin("Clean and describe", qlabel=FALSE)`
Have a look at the data. Check for impossible values and deal with these in an appropriate manner. Describe the data, either in words or using suitable graphs (or a combination). Remember to detail the decisions you have made.  



::: {.callout-tip collapse="true"}
#### Hints

- to clean data, go through each variable in turn. If numeric, what is the min and max? If categorical, what are the possible levels?  
- to describe data, you might want to use tables and plots, or you might find describing in text can work too.  
- There's no right way to deal with missing values. 
  - one option is to cross-tabulate the _reasons for_ missingness, and then remove them from the dataset at this point. This means all your analyses are conducted on the same set of "complete cases". This can be the neat and tidy option, but if some variables have lots of missingness, you might end up needlessly limiting some of your analyses in terms of statistical power. 
  - another option is to leave all missing values in the dataset and let them be dealt with by each of your model(s) and test(s). The downside of this is that different tests end up being performed on different subsets of data, making it harder to describe (it also means you need to be very careful with model comparisons)
- There's no right way to deal with outliers.  
  - Some fields of research will identify at the outset any observations that are outlying by looking at each variable individually. These they will then remove, or scale back ([6A #outliers](06_wt.html#outliers){target="_blank"}) prior to any analysis. This should really only be done if you are sure that these observations are outlying because of either a) measurement error or b) not belonging to the target population of interest. If the outlyingness could well simply be natural variation in the variable, keep it in. You can always then examine its influence on subsequent analyses!  

:::

`r qend()`

`r solbegin("Explore", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
couchto5k <- read_csv("https://uoepsy.github.io/data/couchto5k.csv")
```


Going through each variable:  

- `age` is an integer variable, shouldn't have negative values **by definition of variable**. There are a couple of values $\geq 100$, which we should probably either exclude, or at the very least mention in our writing. 
```{r}
#| fig-height: 3
summary(couchto5k$age)
hist(couchto5k$age)
```


- `accountability` and `selfmot` are both integer variables should both be $5 \leq x \leq 35$ - **by definition**

We can see that `accountability` looks to be okay, but `selfmot` has a minimum value of -99, which we can't have.  

```{r}
couchto5k %>% 
  select(accountability, selfmot) %>%
  summary()
```


- `health` and `happiness` are both integer and should be $0 \leq x \leq 100$ - **by definition of variable**

both `health` and `happiness` variables are within the possible ranges  
```{r}
couchto5k %>% 
  select(health, happiness) %>%
  summary()
```


- `season` should be one of "spring", "summer", "autumn", "winter" 

We have some mis-spellings of "autumn" as "autunm" which we should fix  
(i'm adding in the `useNA="always"` bit just so i can also see if there are any that are already missing)
```{r}
table(couchto5k$season, useNA = "always")
```

- `city` should be one of "Edinburgh", "Glasgow"

This looks fine:  
```{r}
table(couchto5k$city, useNA = "always")
```

- `week_stopped` is an integer variable and should be $1 \leq x \leq 9$ - **by definition of variable**

We have an entry of 12, which we can't have. Could this be interpreted as someone doing the programme for an extra 5 weeks beyond the 9? In which case could we turn that 12 into a 9? It's just a possible that it's a typo, and it's supposed to be a 1. This ambiguity is probably going to be best dealt with by considering that datapoint to be missing.  
```{r}
table(couchto5k$week_stopped, useNA = "always")
```

`r solend()`
`r solbegin("Clean", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`

We'll do all of our cleaning inside one `mutate()`. 

```{r}
couchto5k <- 
  couchto5k %>% 
  mutate(
    # ages >100, make NA
    age = ifelse(age>100, NA, age),
    # selfmot scores <5, make NA
    selfmot = ifelse(selfmot < 5, NA, selfmot),
    # change autunm to autumn
    season = ifelse(season == "autunm","autumn",season),
    # and then make it a factor (lets set the levels too)
    season = factor(season, levels = c("spring","summer","autumn","winter")),
    # make city a factor
    city = factor(city),
    # weekstopped if >9, then NA
    week_stopped = ifelse(week_stopped > 9, NA, week_stopped)
  )
```

```{r}
summary(couchto5k)
```

Because we know that the resulting missingness is restricted to a relatively small proportion of the dataset, we'll just stick with the complete cases. 

```{r}
couchto5k <- na.omit(couchto5k)
```


`r solend()`
`r solbegin("Describe", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`


`r nrow(couchto5k)+5` participants were recruited to take part in the study. 
2 participants recorded ages exceeding 100, 2 participants recorded an impossible score on the self-motivation scale, and a further one participant recorded having stopped the programme 3 weeks after the defined maximum. These 5 participants were excluded from all analyses.  

The remaining `r nrow(couchto5k)` participants were all over 18 (Mean age `r round(mean(couchto5k$age))`, SD `r round(sd(couchto5k$age),1)`) and were recruited from Edinburgh (`r round(prop.table(table(couchto5k$city))[1]*100)`%) and Glasgow (`r round(prop.table(table(couchto5k$city))[2]*100)`%). 
The median number of weeks spent in the 'couch-to-5k' programme was `r median(couchto5k$week_stopped)`, with `r round(sum(couchto5k$week_stopped==9)/nrow(couchto5k)*100)`% successfully completing the 9 weeks. Spring and summer were the most common seasons for attempting the programme (`r round(prop.table(table(couchto5k$season))*100)[1]`% and `r round(prop.table(table(couchto5k$season))*100)[2]`% of participants respectively), with `r round(prop.table(table(couchto5k$season))*100)[3]`% undertaking it in autumn and only `r round(prop.table(table(couchto5k$season))*100)[4]`% in winter. 

`r solend()`

`r qbegin("City differences", qlabel = FALSE)`

The researchers conducting the study want to first find out a little more about differences between the Edinburgh and Glasgow study sites. Specifically, they would like to investigate whether dropping out of the programme early (prior to week 5), late (week 5 onwards) or not at all (completed all 9 weeks), is different between Edinburgh and Glasgow participants. They would also like to know if the average age of participants is different between the cities.  


::: {.callout-tip collapse="true"}
#### Hints

- The first 5 weeks of the course focused on some of the more fundamental tests of relationships between two variables. Some of these might be useful here!  

:::

`r qend()`

`r solbegin("Conducting the tests", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`
There are two questions here, `dropout ~ city` and `age ~ city`. These are nice and simple questions about the relationships between only two variables.  

The `dropout ~ city` question is asking us to categorise when participants stop the programme into "early", "late", or "not at all". So the question is `categorical ~ categorical`. Sounds like a $\chi^2$ test to me!  

```{r}
couchto5k <- 
  couchto5k %>%
    mutate(
      dropout = ifelse(week_stopped < 5, "early",
                      ifelse(week_stopped <9, "late", "not at all"))
    )
```

let's check that the above `ifelse` statement worked as we wanted:  
```{r}
table(couchto5k$dropout, couchto5k$week_stopped)
```

and let's look at the differences between the cities, and also perform a $\chi^2$ test. 
We're going to simulate the p-value here, because some of our expected cell counts are going to be $<5$ (see e.g. [Week 4 Exercises #favourite-colours](04_ex.html#childrens-favourite-colours){target="_blank"})  

```{r}
#| eval: false
table(couchto5k$dropout, couchto5k$city)
chisq.test(table(couchto5k$dropout, couchto5k$city), simulate.p.value = TRUE)
```
```{r}
#| echo: false
table(couchto5k$dropout, couchto5k$city)
res_dropout <- chisq.test(table(couchto5k$dropout, couchto5k$city), simulate.p.value = TRUE)
res_dropout
```

<br><br>

The `age ~ city` question, on the other hand, is asking whether a continuous variable is different between two groups (Edinburgh and Glasgow). We can do this with a $t$-test!   

Let's first assess the extent to which the ages of two groups of participants (Edinburgh folk and Glasgow folk) have similar variances (an assumption of the standard t-test), as well as the extent to which they are normally distributed: 

```{r echo=c(-1)}
#| fig-height: 4
par(mfrow=c(2,2))

hist(couchto5k$age[couchto5k$city=="Edinburgh"], 
     main = "Edinburgh", xlab = "Age")
hist(couchto5k$age[couchto5k$city=="Glasgow"], 
     main = "Glasgow", xlab = "Age")

qqnorm(couchto5k$age[couchto5k$city=="Edinburgh"], main = "Edinburgh")
qqline(couchto5k$age[couchto5k$city=="Edinburgh"])

qqnorm(couchto5k$age[couchto5k$city=="Glasgow"], main = "Glasgow")
qqline(couchto5k$age[couchto5k$city=="Glasgow"])
```
```{r}
#| echo: false
par(mfrow=c(1,1))
```


These look almost okay to me. Not great, but not completely awful. We should bear in mind that we have >30 participants in each group, which means we can be a little more relaxed about requiring very close to normal data.  

The test of equal variances suggests we have no reason to reject the hypothesis that the two groups have equal variances: 
```{r}
var.test(age ~ city, data = couchto5k)
```

So we can carry on with our t-test of the difference in means^[If we had reason to believe the variances are not equal, we can look at doing Welch's t-test]:  
```{r}
t.test(age ~ city, data = couchto5k, var.equal = TRUE)
```


`r solend()`
`r solbegin("Writing up", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
#| include: false
res_age <- t.test(age ~ city, data = couchto5k, var.equal = TRUE)
```


A $\chi^2$ test of independence indicated that rate of attrition (early-/late-/no- dropout) did not significantly differ between Edinburgh and Glasgow ($\chi^2$(2, n=`r sum(res_dropout$observed)`) = `r round(res_dropout$statistic,3)`, Monte Carlo simulated (B=2000) p = `r round(res_dropout$p.value,3)`). From both cities, approximately half of participants did not drop out of the programme, late drop-outs made up 13% of Glasgow participants and 9% of those from Edinburgh, with the remainder dropping out early (39% of Glasgow, 40% of Edinburgh).  

The mean age of participants was not significantly different between the two cities ($t( `r res_age[['parameter']]` )=`r round(res_age[['statistic']],2)`$, $p=`r round(res_age[['p.value']],2)`$), with a mean age in Edinburgh of `r round(res_age$estimate,1)[1]` and in Glasgow of `r round(res_age$estimate,1)[2]`.


`r solend()`

`r qbegin("Happiness, Health, and a 5k Run", qlabel=FALSE)`
Researchers would like you to examine whether, beyond seasonal and age-related variation, happiness ratings are influenced by how far participants get through the couchto5k programme. Note that they are interested specifically in whether - and how - the effects of couchto5k progression are amplified by feeling healthy, such that getting further along in the programme might lead to greater increases in happiness when people are healthier.    


::: {.callout-tip collapse="true"}
#### Hints

- The use of the word "beyond" here should cue us to be thinking in terms of multiple regression. The question is asking about the relationship between happiness and couchto5k progression _after_ we account for participants' ages and the season in which they took the programme.  
- We also have a clear suggestion of an interaction here, because it asks about an effect of one predictor on the outcome (programme progression on happiness) being "amplified" (i.e. _different_) by another predictor (health)
- This feels a bit like two questions, but the latter really supersedes the first - if we have an interaction, then the question of "what is the effect of progression on happiness?" can only really be answered with "it depends..".      

:::


`r qend()`
`r solbegin("Fitting model(s)", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`

let's standardise the health measure, because we probably don't want to look at things where people have health of 0, and i'm not sure that an increase of 1 is that meaningful..    
```{r}
couchto5k <- couchto5k %>%
  mutate(
    healthZ = (health-mean(health))/sd(health),
  )
```
Here's our model:  
```{r}
hhmod <- lm(happiness ~ age + season + week_stopped * healthZ, couchto5k)
```

let's take a look at assumptions
```{r echo=c(2)}
par(mfrow=c(2,2))
plot(hhmod)
par(mfrow=c(1,1))
```
so this looks a little weird - we've got some sharp 'edges' to our cloud of data in the residual vs fitted plot.  
What I think this is reflecting is that we are being limited by the bounds of the happiness measure (i.e. people are using the full scale of 0 up to 100). Consider how this might influence the residuals. As predicted values get closer to the edges of the scale, the residuals will get smaller. This might not be too much of a problem, but may well be worth discussing. 

Let's conduct an F-test of the interaction:  
```{r}
anova(hhmod)
```

- the final row tells us that the interaction weekstopped*health explains significantly more variance than we would expect by chance


- the coefficients can tell us effect sizes, directions etc.  
```{r}
#| eval: false
summary(hhmod)
```
```{r}
#| echo: false
.pp(summary(hhmod), l=list(10:19))
```

getting further along the couchto5k programme is associated with being more happy, the more healthy you feel. 


- and plots are going to be a *very* useful way to understand and to present.  

```{r}
#| code-fold: true
plotdat <- expand_grid(
  age = mean(couchto5k$age),
  season = "spring",
  week_stopped=1:9,
  healthZ = c(-1, 0, 1)
)

broom::augment(hhmod, newdata = plotdat, interval="confidence") |>
  mutate(
    health = factor(healthZ, levels=c("-1","0","1"),
                    labels=c("Poor health (-1 SD)", 
                             "Average health",
                             "Good health (+1 SD)")
                    )
  ) |> ggplot(aes(x=week_stopped,y=.fitted, col=health,fill=health))+
  geom_line() +
  geom_ribbon(aes(ymin=.lower,ymax=.upper), alpha=.2) +
  scale_color_viridis_d(option="C")+
  scale_fill_viridis_d(option="C")+
  scale_x_continuous(breaks=1:9)+
  facet_wrap(~health) +
  labs(y="Happiness (0-100)",x="- Week Stopped -") +
  guides(col="none",fill="none")
```

- we can also, if we want, get out some standardised coefficients - i.e. some coefficients in terms of standard deviations (for those predictors where SD is applicable). Note that healthZ is _already_ standardised.   


```{r}
#| eval: false
hhmod2 <- lm(scale(happiness) ~ scale(age) + season + scale(week_stopped) * healthZ, data = couchto5k)
summary(hhmod2)
```
```{r}
#| echo: false
hhmod2 <- lm(scale(happiness) ~ scale(age) + season + scale(week_stopped) * healthZ, data = couchto5k)
.pp(summary(hhmod2), l=list(10:19))
```



`r solend()`
`r solbegin("Writing up", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
#| echo: false
res1 = as.data.frame(anova(hhmod))
res1[,4] = round(res1[,4],2)
res1[,5] = format.pval(res1[,5],eps=.001, digits=2)
res2 = broom::tidy(hhmod)
res2$std_estimate = coef(hhmod2) 
res2 = relocate(res2, std_estimate, .after=estimate)
res2$estimate = round(res2$estimate,2)
res2$statistic = round(res2$statistic,2)
res2$std_estimate = round(res2$std_estimate,2)
res2$p.value = format.pval(res2$p.value,eps=.001, digits=2)
res2 = as.data.frame(res2)
```


To investigate the extent to which, over and above seasonal and age related differences, happiness ratings are associated with getting further through (and feeling healthier following) the couch-to-5k programme, happiness ratings on a scale of 0 to 100 were modelled using multiple regression. 

The number of weeks at which participants stopped (1-9), a multi-test measure of health (Z-scored) and their interaction were included as predictors, along with the covariates of age (years) and season (treatment coded with spring as the reference level). The regression model appeared to meet all assumptions, with residuals displaying a constant mean at approximately zero, although the boundaries of the happiness scale induced a smaller residual variance at the tail ends of the fitted values (see Appendix X). This is corroborated by 30% of participants reporting happiness in either the bottom or top 10th of the scale. 

Analysis of variance indicated that after accounting for season and age, there was a significant interaction between participants' self-reported health at the end of the programme and the week at which they stopped ($F(`r res1[5,1]`,`r res1[6,1]`)=`r res1[5,4]`$,  $p `r res1[5,5]`$). The full model explained approximately `r round(summary(hhmod)$adj.r.squared*100)`% (adjusted $R^2$) of the variance in happiness scores.

```{r}
#| echo: false
#| label: tbl-couchanova
#| tbl-cap: "Analysis of variance in happiness scores" 
rownames(res1) <- c("Age","Season","Week Stopped","Health","Week Stopped : Health", "Residual")
res1[,2:3] <- apply(res1[,2:3], 2, round)
colnames(res1) <- c("df","Sum Sq","Mean Sq","F","p")
res1$p[c(3,5)] <- paste0("**",res1$p[c(3,5)],"**")
res1[6,4:5]<-""
pander::pander(res1)
```

For those of average health, there was no statistically reliable change in happiness associated with additional weeks of the couch-to-5k programme ($b = `r res2[6,2]`$, $\beta = `r res2[6,3]`$, $t(`r hhmod[['df.residual']]`) = \, `r res2[6,5]`$, $p = `r res2[6,6]`$).

However this effect was moderated by health such that the weekly change in happiness was more positive for healthier, and more negative for less healthy, people. For each 1SD (`r round(sd(couchto5k$health))` raw points) change in health from the average, happiness ratings changed by an additional `r res2[8,2]` points every week ($b = `r res2[8,2]`$, $\beta = `r res2[8,3]`$, $t(`r hhmod[['df.residual']]`) = \, `r res2[8,5]`$, $p `r res2[8,6]`$). 
@fig-couchint shows the shape of this interaction, and a full regression table can be found in @tbl-couchinttab.  

Happiness following the couch-to-5k programme was found to be related to how far through the programme participants got, and this relationship depended on participant health, with the happiness of healthier participants increasing more for every week longer through the programme they lasted than it did for participants of average health. 

```{r}
#| label: fig-couchint
#| fig-cap: "Interaction between health and duration completed of couch-to-5k on happiness, estimated for the average age and commencing the programme in Spring"
#| echo: false
plotdat <- expand_grid(
  age = mean(couchto5k$age),
  season = "spring",
  week_stopped=1:9,
  healthZ = c(-1, 0, 1)
)

broom::augment(hhmod, newdata = plotdat, interval="confidence") |>
  mutate(
    health = factor(healthZ, levels=c("-1","0","1"),
                    labels=c("Poor health (-1 SD)", 
                             "Average health",
                             "Good health (+1 SD)")
                    )
  ) |> ggplot(aes(x=week_stopped,y=.fitted, col=health,fill=health))+
  geom_line() +
  geom_ribbon(aes(ymin=.lower,ymax=.upper), alpha=.2) +
  scale_color_viridis_d(option="C")+
  scale_fill_viridis_d(option="C")+
  scale_x_continuous(breaks=1:9)+
  facet_wrap(~health) +
  labs(y="Happiness (0-100)",x="- Week Stopped -") +
  guides(col="none",fill="none")
```

```{r}
#| label: tbl-couchinttab
#| tbl-cap: "Happiness ratings (0-100). Table of regression coefficients"
#| echo: false
library(sjPlot)
tab_model(hhmod, dv.labels = "Happiness (0-100)", 
          pred.labels = c("(Intercept)","Age (years)","Season [Summer]",
                          "Season [Autumn]", "Season [Winter]",
                          "Week Stopped (1-9)","Health Metric (Z-scored)",
                          "Week Stopped * Health Metric"))
```


`r solend()`

`r qbegin("Predictors of Drop-out", qlabel=FALSE)`
The second aim of the research is to examine the psychological factors that are associated with people completing the programme. 



::: {.callout-tip collapse="true"}
#### Hints

- Completing vs Dropping-out? Sounds like a binary outcome!  
- Recall (from study description above) that completing the programme has previously been found to vary substantially across the year. _We may well therefore want to account for this in our model!_  
- What variables do we have that measure "psychological factors" that might influence dropping out? (pay attention to _when_ each variable is measured!)  
- How might we visualise the results?   

:::

`r qend()`
`r solbegin("Fitting model(s)", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`

We need to make a binary outcome, out of the `week_stopped` variable. 
```{r}
couchto5k <- couchto5k %>%
  mutate(
    completed = ifelse(week_stopped == 9, 1, 0)
  )
```

here are our variables:  
```{r}
names(couchto5k)
```
per the study description, many of these were measured after participants stopped programme 
```{r}
#| echo: false
tibble(
  variable = names(couchto5k)[-11],
  when = c(NA, "unclear when measured, but assume it is consistent at both points", "measured at start","measured at start", rep("measured at end", 2), "measured at start", "unclear when measured, but assume it is consistent at both points", rep("measured at end", 3))
) %>% pander::pander()
```

it doesn't really make sense for us to think about your happiness _after_ the programme influencing whether or not you complete it (this is not to say that it will not be associated).  

age, season and city are all things that *might* influence completion, or might influence predictors of interest like accountability or self-motivation. We know specifically that season has previously been found to influence completion, so it would be good to at least include that. We also did a test early on that indicated that cities didn't differ in their dropout rates, and also that they didn't differ in the average age of participants. 

It's probably worth scaling the psychometric variables. They are both the sum of 7 questions, each scored 1-5, so it's slightly unclear what a "1 unit increase" really means. It's answering.  
```{r}
couchto5k <-
  couchto5k %>% 
  mutate(
    accountabilityZ = scale(accountability)[,1],
    selfmotZ = scale(selfmot)[,1]
  )

compmod1 <- glm(completed ~ season + age + city, data = couchto5k, family=binomial)

compmod2 <- glm(completed ~ season + age + city + accountabilityZ + selfmotZ, data = couchto5k, family=binomial)

anova(compmod1, compmod2, test="Chisq")
```

beyond participants' age, location and which season programme is undertaken in, psychological factors of accountability and self motivation _do_ appear to improve model fit  

```{r}
#| eval: false
summary(compmod2)
```
```{r}
#| echo: false
.pp(summary(compmod2), l = list(c(3,10:19)))
```

It's always worth visualising the two focal predictors in terms of predicted probability of completion.  

Note that because so few people took part in autumn and winter, this introduces a lot of uncertainty if we try and get at the effect holding `season` at its proportion, so we might be better off just providing the plot for Spring, as that is the most frequent season that people start the programme.  
```{r}
library(effects)
p1 <- effect(c("selfmotZ","season"), compmod2, xlevels=20) |>
  as.data.frame() |>
  filter(season=="spring") |>
  ggplot(aes(x=selfmotZ,y=fit))+
  geom_line()+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=.2) +
  labs(title="Predicted probability of\ncouch-to-5k completion",x="Self Motivation (Z-scored)",y="P(Completed)")

p2 <- effect(c("accountabilityZ","season"), compmod2, xlevels=20) |>
  as.data.frame() |>
  filter(season=="spring") |>
  ggplot(aes(x=accountabilityZ,y=fit))+
  geom_line()+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=.2) +
  labs(title="Predicted probability of\ncouch-to-5k completion",x="Accountability (Z-scored)",y="P(Completed)")

p1 + p2
```


`r solend()`

`r solbegin("Writing up", slabel=FALSE, show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
#| echo: false
res3 = anova(compmod1, compmod2, test="Chisq")
res4 = exp(car::Confint(compmod2))
res4 = apply(res4,2, function(x) round(x,2))
```

Couch-to-5k completion (completed vs dropped out) was modelled using logistic regression, with the location (Glasgow, Edinburgh) and season in which participants undertake the programme as predictors, along with participants age, and their scores on two psychometric measures of accountability and self-motivation that were administered prior to participants starting the programme. A likelihood ratio test indicated that the inclusion of these two measures (accountability and self-motivation) collectively improves model fit over and above age, location and season ($\chi^2(`r res3[2,3]`) = `r round(res3[2,4],2)`, \, p = `r round(res3[2,5],3)`$). All deviance residuals for the full model were less than 3 in magnitude. 

In keeping with previous research, completion of the programme was found to differ between seasons, with participants undertaking the programme in both summer and autumn being associated with increased odds of programme completion ($OR: `r res4[2,1]`$, $95\% CI [`r paste0(res4[2,2:3],collapse=", ")`]$ and $`r res4[3,1]`$ $[`r paste0(res4[3,2:3],collapse=", ")`]$ respectively). Age and city were not found to significantly predict completion.  

While the likelihood of completing the programme was not significantly associated with scores on the accountability measure, a relationship was found between self motivation and programme completion; a 1 standard deviation increase in self-motivation was associated with doubling the odds of finishing the entire 9-weeks ($OR: `r res4[8,1]`\, [`r paste0(res4[8,2:3],collapse=", ")`]$). The model-predicted probabilities of programme completion across values of the two psychometric measures are visualised in @fig-couchglm. Full table of results can be found in @tbl-couchglmcoef  

The present study indicated that the psychometric factors of accountability and self motivation, taken together, were useful in predicting the completion (vs drop out) of the couch-to-5k programme. Specifically, a strong association was found between self-motivation and programme completion, with more motivated participants have a higher probability of finishing the full 9 weeks.  

```{r}
#| label: fig-couchglm
#| fig-cap: "Model estimated probability of completing the couch-to-5k programme across measures of accountability and self-motivation (both Z-scored), estimated for starting the programme in spring, and holding other predictors at their average/proportions"
#| echo: false

p1 + p2 & theme_bw(base_size=12)
```

```{r}
#| label: tbl-couchglmcoef
#| tbl-cap: "Couch-to-5k completion modeled using logistic regression. Table of coefficients."
#| echo: false
cis = cbind(exp(coef(compmod2)), exp(confint(compmod2)))
cis[4,3]<-Inf
cis = tibble(
  Predictors = c("(Intercept)","Season [Summer]","Season [Autumn]",
                          "Season [Winter]", "Age (years)",
                          "City [Glasgow]", "Accountability (Z-scored)",
                          "Self-Motivation (Z-scored)"),
  `Odds Ratios` = unlist(apply(cis, 1, function(x) 
   paste0(round(x[1],1), " [",round(x[2],2),", ",round(x[3],2),"]")))
)
cis[4,2] <- "2.4x10^8 [0, Inf]"
gt::gt(cis)

```


`r solend()`


<!-- # Development of Counterfactual Thinking -->

<!-- :::frame -->
<!-- __Kominsky.csv__   -->

<!-- Do young children struggle to answer the question "what would have happened?" Developmental researchers [Kominsky et al. (2021)](https://cicl.stanford.edu/papers/kominsky2021trajectory.pdf){target="_blank"} asked children between the ages of 5 and 10 to imagine counterfactual situations. Children were randomly assigned to one of the two conditions. They observed a video where Ball A hit Ball E and Ball E started to move. -->

<!-- :::: {.columns} -->
<!-- ::: {.column width="40%"} -->
<!-- __Singly-Determined__   -->

<!-- In the singly-determined condition, the brick wall altered Ball E’s trajectory such that it went into the goal. -->

<!-- ![](images/Brickcon2v2.gif) -->

<!-- ::: -->
<!-- ::: {.column width="10%"} -->
<!-- ::: -->
<!-- ::: {.column width="40%"} -->
<!-- __Over-Determined__   -->

<!-- In the over-determined condition, Ball E also deflects off the wall but would have gone into the goal regardless.  -->

<!-- ![](images/Brickdis2v2.gif) -->

<!-- ::: -->
<!-- :::: -->

<!-- The children were then asked: “What if the brick wall had not been there? Would Ball E have gone into the goal?” (“Yes” or “No”). -->

<!-- You can download a dataset of 120 children from [https://uoepsy.github.io/data/Kominsky.csv](https://uoepsy.github.io/data/Kominsky.csv){target="_blank"}.^[Note, data used here was modified, so it is different from the original dataset.]   -->

<!-- ```{r} -->
<!-- tibble( -->
<!--   variable = c("ID","Sex","Age","Condition","Accuracy"), -->
<!--   description = c("Unique ID number","Children's gender","Children's age","The video children watched: singly-determined vs. over-determined. In the singly-determined condition, the brick was the single cause that caused Ball E to go into the goal. In the over-determined condition, the brick was not the single cause because Ball E would have gone into the goal without it.","Whether children answered the question correctly (1) or no (0). The correct answer should be “no” for the singly-determined condition and should be “yes” for the over-determined condition") -->
<!-- ) %>% gt::gt() -->
<!-- ``` -->

<!-- Researchers were interested in children’s counterfactual thinking ability: How did children perform in the singly-determined vs. over-determined situations, and whether it differed between ages? -->

<!-- They managed to get the same number of children for the 5-6, 7-8, and 9-10 three age groups. Since the sample size was small and the range of ages was small, instead of using age (numeric) as a predictor, they used the age group (factors) as a predictor. -->

<!-- ::: -->

```{r}
#| include: false
kkdat <- read_csv("../../data/Kominsky2021.csv") %>%
  mutate(age = factor(ifelse(age>=5 & age<=6, "5-6",
                      ifelse(age>=7 & age<=8, "7-8",
                      "9-10")))
         )
glm(accuracy ~ sex + condition + age, 
    data = kkdat, family=binomial) %>% summary
```



