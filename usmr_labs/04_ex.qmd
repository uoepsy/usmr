---
title: "Exercises: Chi-Square & Correlation"
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---


```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(tidyverse)
library(patchwork)
library(xaringanExtra)
xaringanExtra::use_panelset()
set.seed(017)
```

# Chi-Square Tests

## Birth-Months

:::frame

> **Research Question:** Are people more likely to be born in certain months than others?  

As you may remember, in the survey we asked students to complete in welcome week, one of the questions concerned the month in which you were born. You can download the data from [https://uoepsy.github.io/data/surveydata_allcourse22.csv](https://uoepsy.github.io/data/surveydata_allcourse22.csv).  

```{r}
survey_data <- 
  read_csv("https://uoepsy.github.io/data/surveydata_allcourse22.csv")
```
:::

`r qbegin(1)`
What is your intuition about the distribution of all students' birth-months?  
Do you think they will be spread uniformly across all months of the year (like a fair 12-sided dice), or do you think people are more likely to be born in certain months more than others?  

Plot the distribution and get an initial idea of how things are looking.  

::: {.callout-tip collapse="true"}
#### Hints  
You can do this quickly with `barplot()` and `table()`, or you could create try using `ggplot()` and looking into `geom_bar()`.  
:::
`r qend()`

`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`
The quick and dirty way to plot:
```{r}
barplot(table(survey_data$birthmonth))
```

A ggplot option:
```{r}
ggplot(data = survey_data, aes(x = birthmonth)) +
    geom_bar() +
    labs(x = "- Birth Month -")
```
`r solend()`

`r qbegin(2)`
We're going to perform a statistical test to assess the extent to which our data conforms to the hypothesis that people are no more likely to be born on one month than another.  

Under this hypothesis, what would be the proportional breakdown of observed births in each of the months?  
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
If people are no more likely to be born in one month than another, then we would expect the same proportion of observed births in each month.  
There are 12 months, so we would expect $\frac{1}{12}$ observations in each month.  

We can write these as: 
$$
\begin{align}
& p_{jan} = 1/12 \\
& p_{feb} = 1/12 \\
& ... \\
& p_{dec} = 1/12 \\
\end{align}
$$
`r solend()`

`r qbegin(3)`

How many observations in our sample would we *expect* to find with a birthday in January? And in February? ... and so on?  

::: {.callout-tip collapse="true"}
#### Hints

How many responses (i.e. not missing values) do we have for this question?  

:::

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
There are `r sum(!is.na(survey_data$birthmonth))` people who have non-NA values (`sum(!is.na(survey_data$birthmonth))`).  

Under the null hypothesis, we would expect $\frac{1}{12} \times$ `r sum(!is.na(survey_data$birthmonth))` = `r round(sum(!is.na(survey_data$birthmonth))/12,2)` observations born in each month. 
`r solend()`

`r qbegin(4)`
The code below creates counts for each month. Before doing that, it removes the rows which have an NA in them for birthmonth: 
```{r}
#| eval: false
survey_data %>%
  filter(!is.na(birthmonth)) %>%
  group_by(birthmonth) %>%
  summarise(
      observed = n()
  )
```
(A shortcut for this would be `survey_data %>% filter(!is.na(birthmonth)) %>% count(birthmonth)`)  

Add to the code above to create columns showing:

- the expected counts $E_i$
- observed-expected ($O_i - E_i$)
- the squared differences $(O_i - E_i)^2$
- the standardised square differences $\frac{(O_i - E_i)^2}{E_i}$  

Then calculate the $\chi^2$ statistic (the sum of the standardised squared differences).  
If your observed counts matched the expected counts *perfectly*, what would the $\chi^2$ statistic be? 

::: {.callout-tip collapse="true"}
#### Hints  
This was all done in the step-by-step example of a $\chi^2$ test in [4A #chi2-goodness-of-fit-test](04a_chisq.html#chi2-goodness-of-fit-test){target="_blank"}
:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
chi_table <- 
    survey_data %>%
    filter(!is.na(birthmonth)) %>%
    group_by(birthmonth) %>%
    summarise(
        observed = n(),
        expected = sum(!is.na(survey_data$birthmonth))/12,
        diff = observed-expected,
        sq_diff = diff^2,
        std_sq_diff = sq_diff / expected
    )
chi_table
```

And we can calculate our $\chi^2$ test statistic by simply summing the values in the last column we created:
```{r}
sum(chi_table$std_sq_diff)
```

If all our observed counts are equal to our expected counts, then the `diff` column above will be all $0$, and $0^2=0$, and $\frac{0}{E_i}$ will be $0$. So $\chi^2$ will be $0$. 
`r solend()`

`r qbegin(5)`
You can see the distribution of $\chi^2$ statistics with different degrees of freedom below.  
```{r}
#| label: fig-chidist
#| echo: false
#| fig.cap: "Chi-Square Distributions"
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Chi-square_pdf.svg/1200px-Chi-square_pdf.svg.png")
```

We can find out the proportion of the distribution which falls to either side of a given value of $\chi^2$ using `pchisq()`. We need to give it our calculated $\chi^2$ statistic, our degrees of freedom (`df`), which is equal to the number of categories minus 1. We also need to specify whether we want the proportion to the left (`lower.tail=TRUE`) or to the right (`lower.tail=FALSE`).  

1. Using `pchisq()`, calculate the probability of observing a $\chi^2$ statistic as least as extreme as the one we have calculated.  
2. Check that these results match with those provided by R's built-in function: `chisq.test(table(survey_data$birthmonth))` (the `table` function will ignore NAs by default, so we don't need to do anything extra for this).    

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
sum(chi_table$std_sq_diff)
pchisq(sum(chi_table$std_sq_diff), df = 11, lower.tail = FALSE)
```

```{r}
chisq.test(table(survey_data$birthmonth))
```
`r solend()`

`r qbegin(6)`
Which months of year had the highest contributions to the chi-square test statistic?  

::: {.callout-tip collapse="true"}
#### Hints  
Think about your standardised squared deviations. 
:::
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
**Standardized squared deviations**  

One possible way to answer this question is to look at the individual contribution of each category to the $\chi^2$ statistic. We computed these values in an earlier question.  
```{r}
chi_table %>%
  select(birthmonth, std_sq_diff)
```

From the barplot we created earlier on, we can see which months make up higher/lower proportions than expected:
```{r}
ggplot(chi_table, aes(x = birthmonth, y = observed/nrow(survey_data))) +
  geom_col(fill = 'lightblue') +
  geom_hline(yintercept = 1/12, color = 'red') +
  theme_classic(base_size = 15)
```

**Pearson residuals**

Equivalently, you could answer by looking at Pearson residuals:
```{r}
chisq.test(table(survey_data$birthmonth))$residuals
```

```{r}
#| echo: false
presids <- chisq.test(table(survey_data$birthmonth))$residuals
presids <- presids[order(abs(presids),decreasing = TRUE)]
```

The greatest *absolute* values are for `r names(presids)[1]` and `r names(presids)[2]`, showing that for these months the deviations from expected to observed were the greatest. 

`r solend()`

## Eye-Colours

:::frame
> **Research Question:** Do the proportions of people with different eye-colours correspond to those suggested by the internet? 

According one part of the internet (that reliable source of information!), 76% of people in the world have brown eyes, 10% have blue, 5% hazel, 5% amber, 2% green, 1% grey, and 1% have some other eye colouring (red/violet/heterochromia).

We'll use the same data from the course survey's here:
```{r}
survey_data <- 
  read_csv("https://uoepsy.github.io/data/surveydata_allcourse22.csv")
```
:::


`r qbegin(7)`
Perform a $\chi^2$ goodness of fit test to assess the extent to which our sample of students conform to this theorised distribution of eye-colours.  

No need to do this manually - once is enough. Just go straight to using the `chisq.test()` function.  

::: {.callout-tip collapse="true"}
#### Hints  
Try using `chisq.test(..., p = c(?,?,?,...) )`.  
We saw this in the example goodness of fit test, [4A #example](04a_chisq.html#example){target="_blank"}  
:::
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
Let's look at the observed counts:
```{r}
table(survey_data$eyecolour)
```
Our theoretical probabilities of different eye colours must match the order in the table which we give `chisq.test()`. They must also always sum to 1.  
```{r}
#| warning: true
#| message: true
chisq.test(table(survey_data$eyecolour), p = c(.05,.1,.76,.02,.01,.05,.01))
```

Note, we get a warning here of <span style="color:blue">"Chi-squared approximation may be incorrect"</span>. This is because some of the expected cell counts are <5.  
```{r}
#| warning: false
#| message: false
chisq.test(table(survey_data$eyecolour), 
           p = c(.05,.1,.76,.02,.01,.05,.01))$expected
```

There are a couple of options here, but the easiest is to use the functionality of `chisq.test()` that allows us to compute the p-value by using a simulation (similar to the idea we saw in [2B#sampling-&-sampling-distributions](02b_sampling.html#sampling-sampling-distributions){target="_blank"}), rather than by comparing it to a theoretical $\chi^2$ distribution.  We can do this by using:  

```{r}
chisq.test(table(survey_data$eyecolour), p = c(.05,.1,.76,.02,.01,.05,.01),
           simulate.p.value = TRUE)
```

`r solend()`

`r qbegin(8)`
What are the *observed* proportions of our sample with each eyecolour?  


::: {.callout-tip collapse="true"}
#### Hints

Look up the `prop.table()` function?  

:::


`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
From the help documentation (`?prop.table()`), we see that we can pass `prop.table()` the argument `x`, which needs to be a table. 
```{r}
prop.table(table(survey_data$eyecolour))*100
```

```{r}
barplot(prop.table(table(survey_data$eyecolour))*100)
```
`r solend()`

<div class="divider div-transparent div-dot"></div>

## Jokes and Tips


:::frame
__Data: TipJokes__  

> **Research Question:** Can telling a joke affect whether or not a waiter in a coffee bar receives a tip from a customer?  

A [study](https://doi.org/10.1111/j.1559-1816.2002.tb00266.x) published in the Journal of Applied Social Psychology^[Gueaguen, N. (2002). The Effects of a Joke on Tipping When It Is Delivered at the Same Time as the Bill. _Journal of Applied Social Psychology, 32_(9), 1955-1963.] investigated this question at a coffee bar of a famous seaside resort on the west Atlantic coast of France. 
The waiter randomly assigned coffee-ordering customers to one of three groups. 
When receiving the bill, one group also received a card telling a joke, another group received a card containing an advertisement for a local restaurant, and a third group received no card at all. 

The data are available at https://uoepsy.github.io/data/TipJoke.csv.  
The dataset contains the variables:

- `Card`: None, Joke, Ad.
- `Tip`: 1 = The customer left a tip, 0 = The customer did not leave tip. 

:::


`r qbegin(9)`
Produce a plot and a table to display the relationship between whether or not the customer left a tip, and what (if any) card they received alongside the bill.  

Don't worry about making it all pretty. Mosaic plots in R are a bit difficult. 

::: {.callout-tip collapse="true"}
#### Hints  
`plot(table(...))` will give you something. You can see one in the example $\chi^2$ test of independence,[4A #example-1](04a_chisq.html#example-1){target="_blank"}.  
:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
tipjoke <- read_csv('https://uoepsy.github.io/data/TipJoke.csv')

table(tipjoke$Card, tipjoke$Tip)

plot(table(tipjoke$Card, tipjoke$Tip))
```
`r solend()`

`r qbegin(10)`
What would you *expect* the cell counts to look like if there were no relationship between what the waiter left and whether or not the customer tipped?  


::: {.callout-tip collapse="true"}
#### Hints

Think about what proportion of customers tipped. 
Then work out how many customers got each type of card. If there were no relationship, then the proportions would be the same in each group. 

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
In total, 60 customers tipped (14+30+16), and 151 did not. So *overall*, 0.28 ($\frac{60}{(60+151)}$) of customers tip.  

74 customers got an Ad card, 72 customers got a Joke, and 65 got None. If this were independent of whether or not they left a tip, we would expect equal proportions of tippers in each group.  
So we would expect 0.28 of each group to leave a tip.  

You can think about observed vs expected by looking at the two-way table along with the marginal row and column totals given:   
```{r}
#| echo: false
table(tipjoke$Card, tipjoke$Tip) %>%
  rbind(colSums(.)) %>% 
  cbind(rowSums(.)) -> conttable
conttable[1:3,1:2]<-"  "
conttable %>% knitr::kable(.) %>%
  kableExtra::kable_styling()
```
For a given cell of the table we can calculate the expected count as $\text{row total} \times \frac{\text{column total}}{\text{samplesize}}$:

**Expected:**
```{r}
#| echo: false
table(tipjoke$Card, tipjoke$Tip) %>%
  rbind(colSums(.)) %>% 
  cbind(rowSums(.)) -> conttable
conttable[1:3,1]<-round(conttable[1:3,3]*(conttable[4,1])/conttable[4,3],2)
conttable[1:3,2]<-round(conttable[1:3,3]*(conttable[4,2])/conttable[4,3],2)
conttable %>% knitr::kable(.) %>%
  kableExtra::kable_styling()
```


If you're wondering how we do this in R.. 
here's our table:  
```{r}
t <- tipjoke %>%
  select(Card, Tip) %>% table()
t
```
Here are the row totals:  
```{r}
rowSums(t)
```
and column totals divided by total:
```{r}
colSums(t) / sum(t)
```

there's a complicated bit of code using `%o%` which could do this for us. You don't need to remember %o%, it's very rarely used): 
```{r}
e <- rowSums(t) %o% colSums(t) / sum(t)
e
```

Or, alternatively, do it one by one:  
```{r}
rowSums(t) * (colSums(t) / sum(t))[1]
rowSums(t) * (colSums(t) / sum(t))[2]
```

`r solend()`

`r qbegin(11)`
Just like we gave the `chisq.test()` function a table of observed frequencies when we conducted a goodness of fit test in earlier exercises, we can give it a two-way table of observed frequencies to conduct a test of independence.  

Try it now.  
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
chisq.test(table(tipjoke$Card, tipjoke$Tip))
```
`r solend()`


<div class="divider div-transparent div-dot"></div>

# Some RMarkdown

```{r}
#| include: false
pass_scores <- read_csv("https://uoepsy.github.io/data/pass_scores.csv")
res2<-t.test(pass_scores$PASS, mu = 33, alternative = "less")
```


Using one of the $t$-tests we saw in the previous week's exercises, we can use an RMarkdown document in which we write our results so that they get compiled to look nice and pretty:  

::: {.panelset}

::: {.panel}
#### Writing this

```{r echo=FALSE, out.width="1000px"}
knitr::include_graphics("images/hypothesis/rmarkdownbacktick.png")
```

:::
::: {.panel}
#### Compiles to this

:::frame
A one-sided one-sample t-test was conducted in order to determine if the average score on the Procrastination Assessment Scale for Students (PASS) for a sample of `r nrow(pass_scores)` students at Edinburgh University was significantly lower ($\alpha = .05$) than the average score obtained during development of the PASS. 

Edinburgh University students scored lower (Mean = `r mean(pass_scores$PASS) %>% round(2)`, SD = `r sd(pass_scores$PASS) %>% round(2)`) than the score reported by the authors of the PASS (Mean = 33). This difference was statistically significant (t(`r nrow(pass_scores)-1`)=`r res2$statistic %>% round(2)`, p < .05, one-tailed).  
:::

:::

:::

This is one of the huge benefits of RMarkdown. Imagine we collected more data - we wouldn't have to edit all the results, we could simply recompile and they would update for us!  
Note how it works:  

  - the code chunk saves the results of the `t.test()` function as a named object `res2`.
  - in text, the backticks <code>&grave;r ... ... ... &grave;</code> are used to execute small bits of R code, and include the output within the text. For instance, the line <code>&grave;r res2\$statistic %>% round(2)&grave;</code> gets the t-statistic from the results, and rounds it to 2 decimal places, which get's printed out as `r res2[["statistic"]] %>% round(2)`. 
  - the bits between the dollar signs, e.g. \$\\alpha\$ will get printed as mathematical symbols such as $\alpha$. 



::: {.callout-important collapse="true"}
#### RMarkdown documents are self-contained.

You need to to put **everything** that is needed to reproduce your analysis **in the correct order**.  

For instance, if you have used the console (bottom left window) to define an object `peppapig <- 30`, you will have an object in your environment (top right window) called "peppapig" which has the value 30.  

If you were to refer to that object in your RMarkdown document, you will be able to run a line of code such as `peppapig/10` because it will find the "peppapig" object in **your** environment. __BUT__ you won't be able to compile the document because it "starts fresh" (i.e., compiles within its own environment). In order for it to compile, you would need to *define* what "peppapig" is **inside** your document, and **before** the document then refers to it. 

The same applies with using functions in from packages. The RMarkdown document needs to know what packages to load before it uses functions from them. Just because *you* yourself have loaded a package in your session, it does not mean the compilation process for your RMarkdown has access to it. 

:::

If you want some extra explanations on these aspects of RMarkdown, then please see Lessons 0-3 of our [Rmd-bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/){target="_blank"}.  

`r qbegin(12)`
Can you create an RMarkdown document which:

1. Reads in the [https://uoepsy.github.io/data/TipJoke.csv](https://uoepsy.github.io/data/TipJoke.csv) data.
2. Conducts and reports a $\chi^2$ test of independence examining whether telling a joke affect whether or not a waiter in a coffee bar receives a tip from a customer.
3. Successfully compiles ("knits") into an **.html** file. 

`r qend()`


# Covariance & Correlation  


`r qbegin(13)`
__Q1:__ Go to [http://guessthecorrelation.com/](http://guessthecorrelation.com/){target="_blank"} and play the "guess the correlation" game for a little while to get an idea of what different strengths and directions of $r$ can look like.
`r qend()`



## Sleepy time  

:::frame
__Data: Sleep levels and daytime functioning__  

A researcher is interested in the relationship between hours slept per night and self-rated effects of sleep on daytime functioning. She recruited 50 healthy adults, and collected data on the Total Sleep Time (TST) over the course of a seven day period via sleep-tracking devices.  
At the end of the seven day period, participants completed a Daytime Functioning (DTF) questionnaire. This involved participants rating their agreement with ten statements (see @tbl-sleepitems). Agreement was measured on a scale from 1-5. An overall score of daytime functioning can be calculated by:  

1. reversing the scores for items 4,5 and 6 (because those items reflect agreement with _positive_ statements, whereas the other ones are agreement with _negative_ statement);
2. summing the scores on each item; and 
3. subtracting the sum score from 50 (the max possible score). This will make higher scores reflect better perceived daytime functioning.  

The data is available at https://uoepsy.github.io/data/sleepdtf.csv. 
  
```{r}
#| label: tbl-sleepitems
#| echo: false
#| tbl-cap: Daytime Functioning Questionnaire
tibble(
  Item = paste0("Item_",1:10),
  Statement = c("I often felt an inability to concentrate","I frequently forgot things","I found thinking clearly required a lot of effort","I often felt happy","I had lots of energy","I worked efficiently","I often felt irritable" ,"I often felt stressed","I often felt sleepy", "I often felt fatigued")
) %>% gt::gt()
```
:::

`r qbegin(14)`
Read in the data, and calculate the overall daytime functioning score, following the criteria outlined above. Make this a new column in your dataset.

::: {.callout-tip collapse="true"}
#### Hints  
To reverse items 4, 5 and 6, we we need to make all the scores of 1 become 5, scores of 2 become 4, and so on... What number satisfies all of these equations: `? - 5 = 1`, `? - 4 = 2`, `? - 3 = 3`?  
  
To quickly sum accross rows, you might find the `rowSums()` function useful (you don't have to use it though)
:::
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r message=FALSE}
sleepdtf <- read_csv("https://uoepsy.github.io/data/sleepdtf.csv")
summary(sleepdtf)
```

To reverse the items, we can simply do 6 minus the score: 
```{r}
sleepdtf <- 
  sleepdtf %>% mutate(
    item_4=6-item_4,
    item_5=6-item_5,
    item_6=6-item_6
  ) 
```

Now we can use `rowSums()`, and subtract the sum scores from from 50 (the max score):  
```{r}
sleepdtf$dtf = 50-rowSums(sleepdtf[, 2:11])
```

An alternative way to do this would be: 

```{r}
#| eval: false
sleepdtf %>% 
  mutate(
    dtf = 50 - (item_1 + item_2 + item_3 + item_4 + item_5 + item_6 + item_7 + item_8 + item_9 + item_10)
  )
```


`r solend()`

`r qbegin(15)`
Calculate the correlation between the total sleep time (`TST`) and the overall daytime functioning score calculated in the previous question.  
Conduct a test to establish the probability of observing a correlation this strong in a sample of this size assuming the true correlation to be 0.  

Write a sentence or two summarising the results. 

::: {.callout-tip collapse="true"}
#### Hints  
You can do this all with one function, see [4B #correlation-test](04b_covcor.html#correlation-tests){target="_blank"}.  
:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
cor.test(sleepdtf$TST, sleepdtf$dtf)
```

:::int
There was a strong positive correlation between total sleep time and self-reported daytime functioning score ($r$ = `r cor(sleepdtf$TST, sleepdtf$dtf) %>% round(2)`, $t(48)$ = `r cor.test(sleepdtf$TST, sleepdtf$dtf)$statistic %>% round(2)`, $p < .001$) in the current sample. As total sleep time increased, levels of self-reported daytime functioning increased. 
:::
`r solend()`

`r qbegin("16 (open-ended)")`
Think about this relationship in terms of _causation_.  
<br>
Claim: _Less sleep causes poorer daytime functioning._  
<br>
Why might it be inappropriate to make the claim above based on these data alone? Think about what sort of study could provide stronger evidence for such a claim.  

::: {.callout-tip collapse="true"}
#### Things to think about:  

+ comparison groups.   
+ random allocation.  
+ measures of daytime functioning.   
+ measures of sleep time.  
+ other (unmeasured) explanatory variables.  

:::
`r qend()`

<div class="divider div-transparent div-dot"></div>

## Attendance and Attainment

:::frame
__Data: Education SIMD Indicators__  

The Scottish Government regularly collates data across a wide range of societal, geographic, and health indicators for every "datazone" (small area) in Scotland.  

The dataset at [https://uoepsy.github.io/data/simd20_educ.csv](https://uoepsy.github.io/data/simd20_educ.csv){target="_blank"} contains some of the education indicators (see @tbl-simd).  

```{r}
#| label: tbl-simd
#| echo: false
#| tbl-cap: "Education indicators from the 2020 SIMD data"  
tibble(
  variable=names(read_csv("../../data/simd20_educ.csv")),
  description=c("Areas of scotland containing populations of between 2.5k-6k household residents", 
                "Average School pupil attendance",
                "Average attainment score of School leavers (based on Scottish Credit and Qualifications Framework (SCQF))",
                "Proportion of 17-21 year olds entering university")
) %>% gt::gt()
```

:::

`r qbegin(17)`
Conduct a test of whether there is a correlation between school attendance and school attainment in Scotland.  

Present and write up the results.  

::: {.callout-tip collapse="true"}
#### Hints  

The readings have _not_ included an example write-up for you to follow. Try to follow the logic of those for t-tests and $\chi^2$-tests. 

  - describe the relevant data
  - explain what test was conducted and why
  - present the relevant statistic, degrees of freedom (if applicable), statement on p-value, etc. 
  - state the conclusion.  
 
Be careful figuring out how many observations your test is conducted on. `cor.test()` includes only the _complete_ observations. 

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
simd <- read_csv("https://uoepsy.github.io/data/simd20_educ.csv")
```

Here are the means of the two variables. We should remember that these calculations will include some observations which have missing data on the other variable.  
```{r}
simd %>% 
  summarise(
    m_attendance = mean(attendance, na.rm = TRUE),
    m_attainment = mean(attainment, na.rm = TRUE)
)
```
Instead, to match with out analysis, we might be inclined to filter our data to complete data:  
```{r}
simd_comp <- simd %>% 
  filter(!is.na(attendance) & !is.na(attainment))

simd_comp %>%
  summarise(
    m_attendance = mean(attendance),
    m_attainment = mean(attainment),
    sd_attendance = sd(attendance),
    sd_attainment = sd(attainment)
)
```

```{r}
cor.test(simd_comp$attendance, simd_comp$attainment)
```



:::int
```{r}
#| echo: false
res = cor.test(simd_comp$attendance, simd_comp$attainment)
```

A correlation test was conducted to assess whether there is a relationship between an area's average school attendance, and its average school attainment level. A total of `r nrow(simd_comp)` geographical areas were included in the analysis, with a mean school attendance of `r round(mean(simd_comp$attendance),2)` (SD = `r round(sd(simd_comp$attendance),2)`) and a mean school attainment score of `r round(mean(simd_comp$attainment),2)` (SD = `r round(sd(simd_comp$attainment),2)`).  
There was a strong positive correlation between a geographical area's level of school attendance and its school attainment ($r$ = `r round(res$estimate,2)`, $t(`r res$parameter`$ = `r round(res$statistic,2)`, $p `r format.pval(res$p.value,eps = .001)`$). We therefore reject the null hypothesis that there is no correlation between an area's school attendance and attainment. @fig-simdplot provides a visualisation of the relationship.  

```{r}
#| label: fig-simdplot
#| fig-cap: "Positive relationship between geographical areas' level of school attendance and school attainment"
#| code-fold: true
ggplot(simd_comp, aes(x=attendance, y=attainment)) + 
  geom_point() + 
  labs(x = "School attendance",
       y = "School attainment")
```

:::

::: {.callout-note collapse="true"}
#### Optional: some extra plotting bits  

Sometimes we may want to highlight certain parts of a plot. We can do that using the __gghighlight__ package, and giving it a set of conditions (like we do for `filter()`) in order for it to decide which points to highlight.  
You can see an example below.  
We have also created the title by referring to the `cor()` function, and 'paste'ing it together to "r = " 

```{r}
library(gghighlight)

ggplot(simd_comp, aes(x=attendance, y=attainment)) + 
  geom_point() + 
  gghighlight( (attainment>6 & attendance<.75) | 
               attendance > .95 | 
               (attendance > .82 & attainment<5),
               label_key = intermediate_zone) + 
  labs(x = "School attendance",
       y = "School attainment",
       title = paste0("r = ",
                       round(
                         cor(simd_comp$attendance,
                                  simd_comp$attainment),
                         2)
                       ))
```

:::


`r solend()`


<div class="divider div-transparent div-dot"></div>



# Optional Extras: Functions & Models

`r qbegin(qlabel = FALSE, "Optional Extra 1")`
The Scottish National Gallery kindly provided us with measurements of side and perimeter (in metres) for a sample of 10 square paintings.

The data are provided below:  
_Note: this is a way of creating a "tibble" (a dataframe in 'tidyverse-style' language) in R, rather than reading one in from an external file._  
```{r eval=FALSE}
sng <- tibble(
  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),
  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)
)
```

Plot the data from the Scottish National Gallery using `ggplot()`, with the side measurements of the paintings on the x-axis, and the perimeter measurements on the y-axis.  
  
We know that there is a mathematical model for the relationship between the side-length and perimeter of squares: $perimeter = 4 \times \ side$.  

Try adding the following line to your plot:
```{r eval=FALSE}
  stat_function(fun = ~.x * 4)
```
`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r}
#| label: fig-squares-scatterplot
#| fig.cap: 'The exact relationship between side and perimeter of squares.'
sng <- tibble(
  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),
  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)
)

ggplot(data = sng, aes(x = side, y = perimeter)) +
  geom_point(colour = 'black', alpha = 0.5, size = 3) +
  labs(x = 'Side (m)', y = 'Perimeter (m)')+
  stat_function(fun = ~.x * 4)
```

The above plot shows perfect agreement between the observed data and the model.
`r solend()`

`r qbegin(qlabel = FALSE, "Optional Extra 2")`
Use our mathematical model to predict the perimeter of a painting with a side of 1.5 metres.  

::: {.callout-tip collapse="true"}
#### Hints  
We don't have a painting with a side of 1.5 metres within the random sample of paintings from the Scottish National Gallery, but we can work out the perimeter of an hypothetical square painting with 1.5m sides, using our model - either using the plot from the previous question, or calculating it algebraically.  
:::

`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
**Visual approach**

```{r echo=FALSE}
ggplot(data = sng, aes(x = side, y = perimeter)) +
  geom_point(colour = 'black', alpha = 0.5, size = 3) +
  labs(x = 'Side (m)', y = 'Perimeter (m)')+
  stat_function(fun = ~.x * 4) +
  geom_segment(aes(x = 1.5, xend = 1.5, y = 0, yend = 4 * 1.5), linetype = 2, 
               colour = 'red', arrow = arrow(length = unit(0.5, "cm"))) +
  geom_segment(aes(x = 1.5, xend = 0 , y = 4 * 1.5, yend = 4 * 1.5), linetype = 2, 
               colour = 'red', arrow = arrow(length = unit(0.5, "cm"))) +
  labs(x = 'Side (m)', y = 'Perimeter (m)')
```

Sometimes we can directly read a predicted value from the graph of the functional relationship.

Consider the plot created in the previous question. First, we need to check where x = 1.5. Then, we draw a vertical dashed line until it meets the blue line. The y value corresponding to x = 1.5 can be read off the y-axis.

However, in this case it is not that easy to read it from the drawing... Let's try the next approach.

<br>
**Algebraic approach**

You can substitute the x value in the formula and calculate the corresponding y value.
$$
\begin{align}
perimeter &= 4 \times \ side \\
&= 4 \times \ (1.5) \\
&= 6
\end{align}
$$

<br>

:::int
The predicted perimeter of squared paintings having a 1.5m side is 6m.
:::

**NOTE**: Don't forget to always include the measurement units when reporting/writing-up results!

`r solend()`

:::frame
__Data: HandHeight__

This dataset, from Jessican M Utts and Robert F Heckard. 2015. _Mind on Statistics_ (Cengage Learning)., records the height and handspan reported by a random sample of 167 students as part of a class survey.  

The variables are:

- `height`, measured in inches
- `handspan`, measured in centimetres

The data are available at [https://uoepsy.github.io/data/handheight.csv](https://uoepsy.github.io/data/handheight.csv){target="_blank"}

:::

`r qbegin(qlabel = FALSE, "Optional Extra 3")`
Consider the relationship between height (in inches) and handspan (in cm).  

Read the handheight data into R, and investigate (visually) how handspan varies as a function of height for the students in the sample.

Do you notice any outliers or points that do not fit with the pattern in the rest of the data? 

Comment on any main differences you notice between this relationship and the relationship between sides and perimeter of squares.
`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
The `handheight` data set contains two variables, height and handspan, which are both numeric and continuous. We display the relationship between two numeric variables with a scatterplot.  

We can also add marginal boxplots for each variable using the package `ggExtra`. Before using the package, make sure you have it installed via `install.packages('ggExtra')`.

```{r}
#| label: fig-handheight-scatterplot
#| fig.cap: 'The statistical relationship between height and handspan.'
handheight <- read_csv(file = 'https://uoepsy.github.io/data/handheight.csv')

library(ggExtra)

plt <- ggplot(handheight, aes(x = height, y = handspan)) +
  geom_point(size = 3, alpha = 0.5) +
  labs(x = 'Height (in.)', y = 'Handspan (cm)')

ggMarginal(plt, type = 'boxplot')
```

Outliers are extreme observations that do not seem to fit with the rest of the data. This could either be:

- *marginally* along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate;
- *jointly*: observations that do not fit with the rest of the point cloud.

The boxplots in fig-handheight-scatterplot do not highlight any outliers in the marginal distributions of height and handspan.
Furthermore, from the scatterplot we do not notice any extreme observations or points that do not fit with the rest of the point cloud.

We notice a moderate, positive (that is, increasing) linear relationship between height and handspan.

Recall @fig-squares-scatterplot, displaying the relationship between side and perimeters of squares.
In the plot we notice two points on top of each other, reflecting the fact that two squares having the same side will always have the same perimeter.
In fact, the data from the Scottish National Gallery include two squared paintings with a side of 1.1m, both having a measured perimeter of 4.4m.

fig-handheight-scatterplot, instead, displays the relationship between height and handspan of a sample of students. The first thing that grabs our attention is the fact that students having the same height do not necessarily have the same handspan. Rather, we clearly see a variety of handspan values for students all having a height of, for example, 70in. To be more precise, the seven students who are 70 in. tall all have differing handspans.
`r solend()`

`r qbegin(qlabel = FALSE, "Optional Extra 4")`
Hopefully, as part of the previous question, you created a scatterplot of handspans against heights. If not, make one now.  

Try adding the following line of code to the scatterplot. It will add a best-fit line describing how handspan varies as a function of height.
For the moment, the argument `se = FALSE` tells R to not display uncertainty bands.
```{r}
#| eval: false
geom_smooth(method = lm, se = FALSE)
```

Think about the differences you notice with between this and the figure you made showing the side-lengths and perimeters of paintings.  
`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r}
#| label: fig-handheight-fitted-model
#| fig-cap: 'The best-fit line.'
ggplot(handheight, aes(x = height, y = handspan)) +
  geom_point(size = 3, alpha = 0.5) +
  geom_smooth(method = lm, se = FALSE) +
  labs(x = 'Height (in.)', y = 'Handspan (cm)')
```

The line representing the relationship between side and perimeter of squares (@fig-squares-scatterplot) is able to predict the actual perimeter value from the measurement of the side of a square. This is possible because the relationship between side and perimeter is an **exact** one. That is, any squares having the same side will have the same perimeter, and there will be no variation in those values.

The line that best fits the relationship between height and handspan (@fig-handheight-fitted-model) is only able to predict the **average** handspan for a given value of height. This is because there will be a distribution of handspans at each value of height. The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.
`r solend()`


:::statbox
Relationships such as that between height and handspan show deviations from an "average pattern". To model this, we need need to create a model that allows for deviations from the linear relationship. This is called a _statistical_ model.  

A statistical model includes **both** a deterministic function and a random error term:
$$
Handspan = \beta_0 + \beta_1 \ Height + \epsilon
$$
or, in short,
$$
y = \underbrace{\beta_0 + \beta_1 \ x}_{f(x)} + \underbrace{\epsilon}_{\text{random error}}
$$

The deterministic function $f(x)$ need not be linear if the scatterplot displays signs of nonlinearity, but in this course we focus primarily on linear relationships.   

In the equation above, the terms $\beta_0$ and $\beta_1$ are numbers specifying where the line going through the data meets the y-axis and its slope (rate of increase/decrease). 
:::

`r qbegin(qlabel = FALSE, "Optional Extra 5")`
```{r eval=FALSE, echo=FALSE}
mdl <- lm(handspan ~ 1 + height, data = handheight)
equatiomatic::extract_eq(mdl, ital_vars = TRUE, use_coefs = TRUE)
```
The line of best-fit is given by:^[Yes, the error term is gone. This is because the line of best-fit gives you the prediction of the average handspan for a given height, and not the individual handspan of a person, which will almost surely be different from the prediction of the line.]
$$
\widehat{Handspan} = -3 + 0.35 \ Height
$$

What is your best guess for the handspan of a student who is 73in tall?

And for students who are 5in?
`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
The predicted average handspan for students who are 73in tall is $-3 + 0.35 * 73 = 22.55$cm.

The predicted average handspan for students who are 5in tall is $-3 + 0.35 * 5 = -1.25$cm. 
But wait, handspan can not be negative... This does not make any sense!
That's right, we went too far off the range of the available data on heights, which were between 57in and 78in. We extrapolated. This is very dangerous...

```{r}
#| label: fig-xkcd2
#| echo: false
#| fig.cap: 'Source: Randall Munroe, xkcd.com'
knitr::include_graphics('https://imgs.xkcd.com/comics/extrapolating.png')
```
`r solend()`



<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>