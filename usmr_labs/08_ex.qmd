---
title: "Week 8 Exercises: Multiple Regression"
link-citations: yes
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(tidyverse)
library(patchwork)
set.seed(017)
```

# Wellbeing and Outdoor Time


:::frame
> **Research Question:** *after* taking into account differences due to people's level of social interactions, to what extent is well-being associated with the time people spend outdoors?  

__Data: wellbeing.csv__  

Researchers interviewed 32 participants, selected at random from the population of residents of Edinburgh & Lothians. They used the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.  
The researchers also asked participants to estimate the average number of hours they spend outdoors each week, the average number of social interactions they have each week (whether on-line or in-person), and whether they believe that they stick to a routine throughout the week (Yes/No).  

The dataset is available at [https://uoepsy.github.io/data/wellbeing.csv](https://uoepsy.github.io/data/wellbeing.csv){target="_blank"} and contains five attributes: 

- `wellbeing`: Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.  
- `outdoor_time`: Self report estimated number of hours per week spent outdoors  
- `social_int`: Self report estimated number of social interactions per week (both online and in-person)
- `routine`: Binary Yes/No response to the question "Do you follow a daily routine throughout the week?"
- `location`: Location of primary residence (City, Suburb, Rural)

:::

`r qbegin(1)`
Read in the data, and explore and describe the variables and relationships that are relevant to the research question.   

:::hints
__Hints:__  

You might want to:  

- plot the _marginal distributions_ (the distributions of each variable in the analysis without reference to the other variables)
- plot the _marginal relationships_ between the outcome variable and each of the explanatory variables.  
- make a quick correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the relationships.
  - e.g. `cor(data[,c(1:4)])` will give us a matrix of correlations between each pair of the first 4 variables in the data  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
#| label: fig-marg
#| fig-cap: "Marginal distribution plots of wellbeing sores, weekly hours spent outdoors, and social interactions"
library(tidyverse)
library(patchwork) #used to arrange plots

mwdata <- read_csv("https://uoepsy.github.io/data/wellbeing.csv")

wellbeing_plot <- 
  ggplot(data = mwdata, aes(x = wellbeing)) +
  geom_density() +
  geom_boxplot(width = 1/250) +
  labs(x = "Score on WEMWBS (range 14-70)", y = "Probability\ndensity")

outdoortime_plot <- 
  ggplot(data = mwdata, aes(x = outdoor_time)) +
  geom_density() +
  geom_boxplot(width = 1/200) +
  labs(x = "Time spent outdoors per week (hours)", y = "Probability\ndensity")

social_plot <- 
  ggplot(data = mwdata, aes(x = social_int)) +
  geom_density() +
  geom_boxplot(width = 1/150) +
  labs(x = "Number of social interactions per week", y = "Probability\ndensity")

wellbeing_plot / outdoortime_plot / social_plot
```

:::int  

+ The marginal distribution of scores on the WEMWBS is unimodal with a mean of approximately `r round(mean(mwdata$wellbeing),1)`. There is variation in scores (SD = `r round(sd(mwdata$wellbeing),1)`).   
+ The marginal distribution of weekly hours spend outdoors is unimodal with a mean of approximately `r round(mean(mwdata$outdoor_time),1)` hours. There is variation in outdoor time (SD = `r round(sd(mwdata$outdoor_time),1)` hours).  
+ The marginal distribution of numbers of social interactions per week is unimodal with a mean of approximately `r round(mean(mwdata$social_int),1)`. There is variation in in numbers of social interactions per week (SD = `r round(sd(mwdata$social_int),1)`).  

:::

```{r}
#| label: fig-mwdata-mlr-rels
#| fig-cap: 'Scatterplots displaying the relationships between scores on the WEMWBS and a) weekly outdoor time (hours), and b) weekly number of social interactions'


wellbeing_outdoor <- 
  ggplot(data = mwdata, aes(x = outdoor_time, y = wellbeing)) +
  geom_point(alpha = 0.5) +
  labs(x = "Time spent outdoors per week (hours)", y = "Wellbeing score (WEMWBS)")

wellbeing_social <- 
  ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +
  geom_point(alpha = 0.5) +
  labs(x = "Number of social interactions per week", y = "Wellbeing score (WEMWBS)")

wellbeing_outdoor | wellbeing_social
```

We can either use:
```{r}
#| eval: false
# correlation matrix of the first 3 columns
cor(mwdata[,1:3])
```
or:
```{r}
# select only the columns we want by name, and pass this to cor()
mwdata %>% 
  select(wellbeing, outdoor_time, social_int) %>%
  cor()
```


:::int
There is a moderate, positive, linear relationship between weekly outdoor time and WEMWBS scores for the participants in the sample.
Participants' wellbeing scores tend to increase, on average, with the number of hours spent outdoors each week.  
There is a moderate, positive, linear relationship between the weekly number of social interactions and WEMWBS scores for the participants in the sample.
Participants' wellbeing scores tend to increase, on average, with the weekly number of social interactions. 
There is also a weak positive correlation between weekly outdoor time and the weekly number of social interactions.  
::: 

`r solend()`

`r qbegin(2)`
> **Research Question:** *after* taking into account differences due to people's level of social interactions, to what extent is well-being associated with the time people spend outdoors?  

Fit a regression model that you can use to answer the research question (make sure to give it a name to store it in your environment).   

:::hints
__Hints:__  

$Wellbeing = b_0 \ + \ b_1 \cdot Social Interactions \ + \ b_2 \cdot Outdoor Time \ + \ \epsilon$

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
wbmodel <- lm(wellbeing ~ 1 + social_int + outdoor_time, data = mwdata)
```
`r solend()`

`r qbegin(3)`
Extract *and interpret* the parameter estimates (the coefficients) from your model.  

:::hints
__Hints:__

- There's a comprehensive section on how we interpret multiple regression coefficients in [8A#multiple-regression-coefficients](08a_mlr.html#multiple-regression-coefficients){target="_blank"}

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
summary(wbmodel)
```

- $\hat \beta_0$ = `r round(coef(wbmodel)[1],2)`, the estimated average wellbeing score associated with zero hours of outdoor time and zero social interactions per week.  
- $\hat \beta_1$ = `r round(coef(wbmodel)[2],2)`, the estimated increase in average wellbeing score associated with an additional social interaction per week (an increase of one), _holding weekly outdoor time constant_ (i.e., when the remaining explanatory variables are held at the same value or are fixed).
- $\hat \beta_2$ = `r round(coef(wbmodel)[3],2)`, the estimated increase in average wellbeing score associated with one hour increase in weekly outdoor time, _holding the number of social interactions constant_. 

`r solend()`

`r qbegin(4)`
Along with the p-values given by `summary()` that test the null hypothesis that each coefficient is equal to zero, we can obtain confidence intervals for our estimates to provide a range of plausible values for each coefficient. This may be useful if we want to focus more on the estimated value, rather than "is it zero or not?".  

Look up the function `confint()` and use it to obtain some 95% Confidence Intervals for the coefficients. 

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
confint(wbmodel, level = 0.95)
```
:::int 

+ The average wellbeing score for all those with zero hours of outdoor time and zero social interactions per week is between `r round(confint(wbmodel, level=.95)[1,1],2)` and `r round(confint(wbmodel, level=.95)[1,2],2)`.  
+ When _holding weekly outdoor time constant_, each increase of one social interaction per week is associated with a difference in wellbeing scores between `r round(confint(wbmodel, level=.95)[2,1],2)` and `r round(confint(wbmodel, level=.95)[2,2],2)`, on average.  
+ When _holding the number of social interactions per week constant_, each one hour increase in weekly outdoor time is associated with a difference in wellbeing scores between `r round(confint(wbmodel, level=.95)[3,1],2)` and `r round(confint(wbmodel, level=.95)[3,2],2)`, on average.  

:::

`r solend()`

`r qbegin(5)`
Does your model provide a better fit to the data than a model with no explanatory variables? (i.e., test against the alternative hypothesis that _at least one_ of the explanatory variables significantly predicts wellbeing scores). 

:::hints
__Hints:__ 

- it's all in the `summary()`!!
- this might not be a useful question to ask, but we're just trying to go through what each bit of the model output shows.  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
summary(wbmodel)
```

:::int
```{r echo=FALSE}
mdl1<-wbmodel
```
Weekly social interactions and outdoor time explained `r paste0(round(summary(mdl1)$adj.r.squared*100,1),"%")` of the variance (adjusted $R^2$ =`r round(summary(mdl1)$adj.r.squared,3)`, $F$(`r paste(summary(mdl1)$fstatistic[2:3],collapse=",")`)=`r round(summary(mdl1)$fstatistic,1)[1]`, p`r map_chr(pf(summary(mdl1)$fstatistic[1],summary(mdl1)$fstatistic[2],summary(mdl1)$fstatistic[3], lower.tail = FALSE), ~ifelse(.<001,"<.001",paste0("=",round(.,2))))`)
:::

`r solend()`

`r qbegin("Optional Question 6", qlabel=FALSE)`
Just to prove it to ourselves, conduct a model comparison between your model and the "null model", and check that the $F$-statistic from the `summary()` of your model matches that from the comparison.

:::hints
__Hints:__

- we talked about the 'null model', and conducting model comparison in [8A#model-comparisons](08a_mlr.html#model-comparisons){target="_blank"}.  
- we can fit a model with no predictors such as `lm(wellbeing ~ 1, data = mwdata)`.  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
nullmodel <- lm(wellbeing ~ 1, data = mwdata)
anova(nullmodel, wbmodel)
```

Matches that seen in the bottom of `summary(wbmodel)`:
```
F-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09
```

`r solend()`


`r qbegin(7)`
Check the assumptions of your model. 

:::hints
__Hints:__  

- See [8B#assumptions](08b_assumptdiag.html){target="_blank"}  
- You don't necessarily have to perform statistical tests of assumptions, but check the plots at the very least!  
- Interpreting these plots is ultimately a judgement call, and comes with experience.  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

We only have $n=32$ observations here, so our plots might look a bit wobbly. I might perform some quick tests to reassure myself we're okay.
```{r}
#| echo: !expr c(2)
par(mfrow=c(2,2))
plot(wbmodel)
par(mfrow=c(1,1))
```

```{r}
shapiro.test(residuals(wbmodel))
library(car)
ncvTest(wbmodel)
```

We seem to be okay!  

`r solend()`

`r qbegin(8)`
Check for influential observations.  

:::hints
__Hints:__ 

- [8B#individual-case-diagnostics](08b_assumptdiag.html#individual-case-diagnostics){target="_blank"} covers a whole load of different metrics you might use. As a starting point, perhaps consider Cook's Distances plots, or use `influence.measures()` to get lots of info.  

:::
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
Here are the Cook's Distance values:  
```{r}
plot(wbmodel, which = 4)
```
We can see that one observation (labelled 27) is a little bit higher than the rest. It's not hugely out of keeping with the others, so I might not be too worried.  

It's not flagged by `influence.measures()`, but another observation is flagged, this time on the covratio metric (influence on the standard errors).  
With only $32$ observations, excluding datapoints comes with a big reduction in statistical power. On balance I might report this influential point in the write up, but keep it in the analysis. This decision is also based on the distribution of covratio values - it doesn't look like one value is really that much higher than the others (it is simply above the internal cutoff that `influence.measures()` uses).  
```{r}
summary(influence.measures(wbmodel))
hist(covratio(wbmodel), breaks=20)
```
`r solend()`


`r qbegin(9)`
Create a visualisation of the relationship between wellbeing and outdoor time, after accounting for social interactions.  

:::hints
__Hints:__

- There's an example of visualising multiple regression coefficients in [8A#multiple-regression-coefficients](08a_mlr.html#multiple-regression-coefficients){target="_blank"}.  
- to visualise just one association, you might need the `terms` argument in `plot_model()`. Don't forget you can look up the documentation by typing `?plot_model` in the console. 

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
library(sjPlot)
plot_model(wbmodel, type = "eff",
           terms = c("outdoor_time"), 
           show.data = TRUE)
```

`r solend()`

`r qbegin(10)`
Create a regression table to present your results

:::hints
__Hints:__  

- There is a useful function called `tab_model()`, also from the __sjPlot__ package. You can see it used in [7A#example](07a_slr.html#example){target="_blank"}.  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
tab_model(wbmodel)
```

`r solend()`

# Student Sleep Quality

:::frame
__USMR 2022 Data__  

The data from the USMR 2022 survey (now closed) can be found at [https://uoepsy.github.io/data/usmr2022.csv](https://uoepsy.github.io/data/usmr2022.csv).  

_note, this is the survey data just from USMR **this** year, not other students on other courses or in previous years_

:::


`r qbegin(11)`
Recall that last week we discussed my little theory that people who believe they have more control over life will rate their sleep quality as being better.  

```{r}
#| label: fig-locsleep
#| fig-cap: "linear model predicting sleep quality ratings by perceived locus of control"
#| echo: false
#| fig-height: 3
usmrdata <- read_csv("https://uoepsy.github.io/data/usmr2022.csv")
ggplot(usmrdata, aes(x = loc, y = sleeprating)) +
  geom_point()+
  geom_smooth(method=lm)+
  labs(x="Locus of Control", y = "Sleep Quality Rating")

```

Monica has pointed out that it's likely that the association we have found (@fig-locsleep) might be due to other things. There are lots of explanations we could come up with. Some of these might involve variables we have measured.^[When designing a study/collected data, it's good practice to do this sort of thinking before hand, to make sure you measure all the things you want to measure] What if the relationship we see between peoples' `loc` and `sleeprating` is better explained by their emotional stability? Monica makes a convincing argument that having higher emotional stability may be correlated with feeling more in control of one's life, and may also influence sleep quality.  
Sometimes it can help to think of models in the form of diagrams:  
```{r}
#| label: fig-surveydag
#| fig-cap: "Monica's suggestion, where emotional stability and locus of control are correlated (indicated by double headed arrow), and both influence sleep quality (indicated by single headed arrows)"
#| echo: false
knitr::include_graphics("images/mlr/surveydag.png")
```

Monica tells me that if I want to look at how 'locus of control' is associated with sleep quality, it would be more useful to think about the association _after_ controlling for emotional stability.  

> How does locus of control (`loc`) influence sleep quality (`sleeprating`) _after_ accounting for emotional stability (`emot_stability`)?  


:::hints
__Hints:__  

- See section [8A#multiple-regression-coefficients](08a_mlr.html#multiple-regression-coefficients){target="_blank"} for how this might be achieved. 
- the way the question is phrased suggests that `sleeprating` is our outcome (the thing being explained/influenced/predicted); `loc` is the _focal predictor_ (the main predictor of interest); and `emot_stability` is a _covariate_. we treat "covariates" and "focal predictors" exactly the same in the model: `lm(outcome ~ covariates and focal predictors)`, it is just terminology that we use to distinguish what we are interested in from what we want to acknowledge as being theoretically relevant.  

- Don't worry about assumptions, we'll take a look at them next. 
 
:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

First we read in the data: 
```{r}
usmrdata <- read_csv("https://uoepsy.github.io/data/usmr2022.csv")
```

Our model is going to be sleep ratings predicted by emotional stability and locus of control:  
```{r}
sleeplocmod2 <- lm(sleeprating ~ emot_stability + loc, usmrdata)
summary(sleeplocmod2)
```



`r solend()`

`r qbegin(12)`

Monica and I want to write up our study of how locus of control is associated with sleep ratings. 

However, we haven't checked any of our model assumptions, and so we shouldn't really trust the p-values we have been looking at so far. 

Take a look at the assumptions and diagnostics of your model. If your assumptions are worryingly weird, there are things that may be useful to consider doing. We would probably recommend bootstrapping (see [8B#back-to-the-bootstrap](08b_assumptdiag.html#back-to-the-bootstrap)).


:::hints
__Hints:__  

- You can ask yourself one of two questions (or both if you like), but we recommend the visualisation approach: 
    - Do the plots look okay? ([8B#plotting-assumptions](08b_assumptdiag.html#plotting-assumptions){target="_blank"})
    - Do the residuals pass statistical tests? ([8B#testing-assumptions](08b_assumptdiag.html#testing-assumptions){target="_blank"})
- It's also worth taking a look at the 'diagnostics' (such as the influence of individual cases, see [8B#individual-case-diagnostics](08b_assumptdiag.html#individual-case-diagnostics){target="_blank"}.  

- In order to bootstrap, you might need to fit the model to a dataset without any NAs in it.  

:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
Let's have a little look at assumption plots:  
```{r echo=c(2)}
par(mfrow=c(2,2))
plot(sleeplocmod2)
par(mfrow=c(1,1))
```
None of these plots look great to me.  

- The "residuals vs fitted" shows a curved line rather than a horizontal line at 0
- The "normal QQ" plot looks okay apart from a couple of points that are dragging it down at the bottom. 
- The "scale-location" plot indicates the variance of residuals changes across the fitted values (the red line isn't horizontal). 
- The "residuals vs leverage" plot shows a few points might be quite influential. However, they are within the bounds of the cook's distance thresholds (the dotted lines).
  - note that some of these points, the 46th and 47th observations, are the same as the ones pulling down the QQplot.. 

Let's take a look at if we have some people who are too influential:  
```{r}
summary(influence.measures(sleeplocmod2))
```

According to cooks distance, all of these are fine (no stars next to the `cook.d` column values). However, observations 46, 47 and 65 all have fairly large values for some of the DFbeta - suggesting they have fairly large influence (relative to the other observations) on our coefficients. 

Let's perform a bootstrap, which means we can relax our assumptions about the distribution of the residuals.  

To do so, we need to get a dataset with only _complete cases_: 
```{r}
moddata <- usmrdata %>% 
  select(sleeprating, emot_stability, loc) %>%
  na.omit()
```

Then refit the model and bootstrap: 
```{r}
sleeplocmod2a <- lm(sleeprating ~ emot_stability + loc, moddata)

library(car)
bootmod <- Boot(sleeplocmod2a, R = 2000)
Confint(bootmod)

```


`r solend()`


`r qbegin(13)`
Monica convinces me that we have theoretical motivation for thinking that sleeprating is influenced by both emotional stability and locus of control.  

Tia is curious if other aspects of personality influence sleep quality ratings. She knows that we measured 5 personality traits: emotional stability, imagination, extraversion, agreeableness, and conscientiousness.  

Tia asks us: 

> Over and above the influence of locus of control and emotional stability, are other personality traits important predictors of how sleep quality is rated?  

:::hints
__Hints:__  

- This question asks about the explanatory power of a __set of__ predictors. The best way to test this might be model comparison (see [8A#model-comparisons](08a_mlr.html#model-comparisons){target="_blank"})
- To compare two models, the models need to be fitted to the _same_ data. However, when we fit a model using `lm()`, rows where there is missing data for _any_ of the variables in the model will be excluded.  
    - if we have a model `mod1 <- lm(y ~ x1)` and we compare it to `mod2 <- lm(y ~ x1 + x2)`, if there is missing data on `x2`, then `mod2` will be fitted to a smaller set of the data.  
    - a good approach is to make a separate object in your environment which is the data you want to model.  
  ```{r}
  #| eval: false
  # select all variables included in either model, and omit the NAs
  moddata <- data %>% select(y, x1, x2) %>% na.omit
  # these two models will now be fitted to the same data
  mod1 <- lm(y ~ x1, moddata)
  mod2 <- lm(y ~ x1 + x2, moddata)
  # meaning we can compare them:
  anova(mod1, mod2)
  ```
    
:::

`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Make a dataset with the complete cases on relevant variables: 
```{r}
moddata <- usmrdata %>% 
  select(sleeprating, emot_stability, loc, extraversion, agreeableness, conscientiousness, imagination) %>% 
  na.omit
```

Fit two models, with and without the relevant set of personality variables:  
```{r}
m2 <- lm(sleeprating ~ emot_stability + loc, moddata)
m3 <- lm(sleeprating ~ emot_stability + loc + extraversion + agreeableness + conscientiousness + imagination, moddata)
```

Conduct a model comparison:
```{r}
anova(m2,m3)
```


`r solend()`

# RMarkdown 

`r qbegin(14)`

Create an RMarkdown document that presents and describes analyses that addresses the research questions below, and then presents and interprets the results.  

> **Research Questions**  
> 
> 1. After accounting for emotional stability, how is perceived control over one's life associated with quality of sleep? 
> 2. In addition to the associations studied above, are other personality traits associated with differences in sleep quality? 


:::hints
__Hints:__

- You've done the modelling already in the last couple of questions, so this just a matter of writing, interpreting, and presenting! 
- Don't forget that we have the "Rmd-bootcamp" materials for reference: [https://uoepsy.github.io/scs/rmd-bootcamp/](https://uoepsy.github.io/scs/rmd-bootcamp/){target="_blank"}

:::

`r qend()`

# Optional Extra: Conscientiousness

`r qbegin("Optional Question 15",qlabel=FALSE)`

:::: {.columns}
::: {.column width="80%"}
This is Eleanor Abernathy. She has been learning about astrology and horoscopes, but is still skeptical. She wants to know if, after accounting for differences between cat/dog people, a person's month-of-birth is associated with how conscientious they are. 
:::
::: {.column width="20%"}
```{r}
#| echo: false
#| out.height: "100px"
#| out.width: "60px"
knitr::include_graphics("images/mlr/Eleanor_Abernathy.png")
```
:::
::::

Using the same USMR 2022 survey data, fit the a model and use it to address the following research question:  

> After accounting for differences between cat/dog people, is month-of-birth associated with conscientiousness?  

:::hints
__Hint:__  

- Note that the question is more a matter of "is"/"does", and not "what is"/"how does". 
- To answer this question, we might be more inclined to analyse the variance in conscientiousness explained by birth-months (rather than looking at specific differences) - see [8A#analysis-of-variance](08a.mlr#analysis-of-variance){target="_blank"}.  

:::
`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

Here's our data: 
```{r}
usmrdata <- read_csv("https://uoepsy.github.io/data/usmr2022.csv")
```

To conduct the analyis of variance, all we do is fit a linear model:
```{r}
bmonthmod <- lm(conscientiousness ~ catdog + birthmonth, data = usmrdata)
```

and then pass that to the `anova()` function, in order to examine the variance explained by the `birthmonth` grouping as a whole:    
```{r}
anova(bmonthmod)
```

Interestingly, note that one of our birthmonth coefficients **is** significant! 
```{r}
summary(bmonthmod)
```
This is because it is testing the _specific_ difference between September and April (the reference level). Taken alone, this is a significant difference. But considered all together, the month-level differences in conscientiousness aren't significant _enough_ to improve over what we'd expect from 12 random groupings. 

```{r}
ggplot(usmrdata, aes(x=birthmonth, y=conscientiousness)) + 
  geom_boxplot()
```

`r solend()`



<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>

