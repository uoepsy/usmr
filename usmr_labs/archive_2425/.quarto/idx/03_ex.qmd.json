{"title":"Exercises: T-tests","markdown":{"yaml":{"title":"Exercises: T-tests","link-citations":true,"params":{"SHOW_SOLS":false,"TOGGLE":true}},"headingText":"Intervals again","containsRefs":false,"markdown":"\n\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\nset.seed(017)\n```\n\n\n`r qbegin(qcounter())`\nAt the end of last week's exercises, we estimated the mean sleep-quality rating, and computed a confidence interval, using the formula below.  \n\n$$\n\\begin{align}\n\\text{95\\% CI: }& \\bar x \\pm 1.96 \\times SE \\\\\n\\end{align}\n$$\n\nCan you use R to show where the 1.96 comes from?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n`qnorm`!  (see the end of [03A #uncertainty-due-to-sampling](03a_inference.html#uncertainty-due-to-sampling){target=\"_blank\"})\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nThe 1.96 comes from 95% of the normal distribution falling within 1.96 standard deviations of the mean:  \n\n```{r}\nqnorm(c(0.025, 0.975))\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nAs we learned in [3B #t-distributions](03b_inference2.html#t---distributions){target=\"_blank\"}, the sampling distribution of a statistic has heavier tails the smaller the size of the sample it is derived from. In practice, we are better using $t$-distributions to construct confidence intervals and perform statistical tests.  \n\nThe code below creates a dataframe that contains the number of books read by 7 people in `r as.numeric(substr(Sys.Date(),1,4))-1`.    \n(Note `tibble` is just a tidyverse version of `data.frame`):  \n```{r}\nbookdata <- \n  tibble(\n    person = c(\"Martin\",\"Umberto\",\"Monica\",\"Emma\",\"Josiah\",\"Dan\",\"Aja\"),\n    books_read = c(12,19,9,11,8,28,13)\n  )\n```\n\nCalculate the mean number of books read in `r as.numeric(substr(Sys.Date(),1,4))-1`, and construct an appropriate 95% confidence interval.   \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nHere is our estimated average number of books read:  \n```{r}\nmean(bookdata$books_read)\n```\n\nAnd our standard error is still $\\frac{s}{\\sqrt{n}}$:  \n```{r}\nsd(bookdata$books_read)/sqrt(nrow(bookdata))\n```\n\nWith $n = 7$ observations, and estimating 1 mean, we are left with $6$ degrees of freedom.  \nFor our 95% confidence interval, the $t^*$ in the formula below is obtained via:^[(Why 97.5? and not 95? We want the _middle_ 95%, and $t$-distributions are symmetric, so we want to split that 5% in half, so that 2.5% is on either side. We could have also used `qt(0.025, df = 6)`, which will just give us the same number but negative: `r qt(0.025, df = 6)`)]  \n```{r}\nqt(0.975, df = 6)\n```\n\nOur confidence interval is therefore:  \n$$\n\\begin{align}\n\\text{CI} &= \\bar{x} \\pm t^* \\times SE \\\\\n\\text{95\\% CI} &= 14.286 \\pm 2.447 \\times 2.652 \\\\\n\\text{95\\% CI} &= [7.80,\\, 20.78] \\\\\n\\end{align}\n$$\n\n`r solend()`\n\n`r qbegin(qcounter())`\nWill a 90% confidence interval be wider or narrow?  \nCalculate it and see.  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nA 90% confidence interval will be narrower:  \n```{r}\nqt(0.95, df = 6)\n```\n\n$$\n\\begin{align}\n\\text{CI} &= \\bar{x} \\pm t^* \\times SE \\\\\n\\text{90\\% CI} &= 14.286 \\pm 1.943 \\times 2.652 \\\\\n\\text{90\\% CI} &= [9.13,\\, 19.44] \\\\\n\\end{align}\n$$\n\nThe intuition behind this is that our level of confidence is inversely related to the width of the interval.   \n\nTake it to the extremes:  \n\n- I have 100% confidence that the interval $[-Infinity, +Infinity]$ contains the true population mean. \n- If I want an narrower interval, then I have to sacrifice confidence. e.g. a 10% CI: $[`r round(t.test(bookdata$books_read,conf.level=0.1)$conf.int[1],2)`, `r round(t.test(bookdata$books_read,conf.level=0.1)$conf.int[2],2)`]$\n\nImagine playing a game of [ringtoss](https://en.wikipedia.org/wiki/Ring_toss){target=\"_blank\"}. A person throwing a 2-meter diameter hoop will have much more confidence that they are going to get it over the pole than a person throwing a 10cm diameter ring.  \n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Procrastination Scores\n\n:::frame\n> __Research Question__\n> Do Edinburgh University students report endorsing procrastination less than the norm?  \n\nThe Procrastination Assessment Scale for Students (PASS) was designed to assess how individuals approach decision situations, specifically the tendency of individuals to postpone decisions (see [Solomon & Rothblum, 1984](http://dx.doi.org/10.1037/0022-0167.31.4.503)). The PASS assesses the prevalence of procrastination in six areas: writing a paper; studying for an exam; keeping up with reading; administrative tasks; attending meetings; and performing general tasks. For a measure of total endorsement of procrastination, responses to 18 questions (each measured on a 1-5 scale) are summed together, providing a single score for each participant (range 0 to 90). The mean score from Solomon & Rothblum, 1984 was 33.  \n\nA student administers the PASS to 20 students from Edinburgh University.  \nThe data are available at [https://uoepsy.github.io/data/pass_scores.csv](https://uoepsy.github.io/data/pass_scores.csv).  \n:::\n\n\n`r qbegin(qcounter())`\n\n1. Read in the data\n2. Calculate some relevant descriptive statistics\n3. Check the assumptions that we will be concerned with for a one-sample test of whether the mean PASS scores is less than 33. \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- What counts as \"relevant statistics\"? Think about the question. It concerns just one variable (the PASS scores), which is numeric. What's a nice way of describing the center and spread of such a variable?  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n\n::::panelset\n:::panel\n#### Data\n\n```{r}\npass_scores <- read_csv(\"https://uoepsy.github.io/data/pass_scores.csv\") \ndim(pass_scores)\nhead(pass_scores)\n```\n\n:::\n:::panel\n#### Descriptives\n\n```{r}\npass_scores |>\n  summarise(\n    mPASS = mean(PASS),\n    sdPASS = sd(PASS),\n    n = n()\n  )\n```\n\n:::\n:::panel\n#### Assumptions\n\nWe want to check that the data are close to normally distributed. This is especially relevant as we have only 20 datapoints here. The plot below makes it look like we may have one or two data points in the tails of the distribution that are further than we might expect. \n```{r}\nggplot(pass_scores, aes(sample = PASS)) + \n  geom_qq() + \n  geom_qq_line()\n```\nBut the Shapiro-Wilk test of $p > .05$ indicates that we are probably okay to continue with our t-test  \n```{r}\nshapiro.test(pass_scores$PASS)\n```\n\n:::\n::::\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nOur test here is going to be have the following hypotheses:  \n\n- __Null:__ mean PASS score in Edinburgh Uni students is $\\geq 33$\n- __Alternative:__ mean PASS score in Edinburgh Uni students is $< 33$ \n\n_Manually_ calculate the relevant test statistic.  \n_Note, we're doing this manually right now as it's a useful learning process. In later questions we will switch to the easy way!_  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- you can see the step-by-step calculation of a one sample t-test in [3B #one-sample-t-test](03b_inference2.html#one-sample-t-test){target=\"_blank\"}. \n- The relevant formula is:  \n$$\n\\begin{align}\n& t =  \\frac{\\bar x - \\mu_0}{\\frac{s}{\\sqrt{n}}} \\\\\n\\qquad \\\\\n& \\text{Where:} \\\\\n& \\bar x : \\text{mean of PASS in our sample} \\\\\n& \\mu_0 : \\text{hypothesised mean score of 33} \\\\\n& s : \\text{standard deviation of PASS in our sample} \\\\\n& n : \\text{number of observations}\n\\end{align}\n$$\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\npass_scores <- read_csv(\"https://uoepsy.github.io/data/pass_scores.csv\") \n\npass_scores |> \n  summarise(\n    xbar = mean(PASS),\n    s = sd(PASS),\n    n = n(),\n    t = (xbar - 33)/(s / sqrt(n))\n  )\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nUsing the test statistic calculated in question 1, compute the p-value.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- this will be needing the `pt()` function.\n- the degrees of freedom is $n-1$ (we used one up by estimating the mean).\n- The test we are performing is against the null hypothesis that the mean is $\\geq 33$. Our t-statistic is in the broad sense calculated as \"mean minus 33\", so negative numbers mean we have a mean lower than 33. These are the instances that we will reject the null hypothesis - if we get a test statistic very low. So we want the lower.tail of the distribution for our p-value.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nWe have 20 participants, so $df=19$\n```{r}\npt(-3.107272, df = 19, lower.tail = TRUE)\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nNow using the `t.test()` function, conduct the same test. Check that the numbers match with your step-by-step calculations in the previous two questions.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \nCheck out the help page for `t.test()` - there is an argument in the function that allows us to easily change between whether our alternative hypothesis is \"less than\", \"greater than\" or \"not equal to\".  \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nt.test(pass_scores$PASS, mu = 33, alternative = \"less\")\n```\nThe $t$ statistic, our $df$, and our $p$-value all match the calculations from the previous questions.  \n\nThe simple `t.test()` approach even gives us a confidence interval! Well.. half of one! This is because we conducted a one-sided test. Remember that null hypothesis significance testing is like asking \"does our confidence interval contain zero?\". With a one-sided test we only reject the null hypothesis if the test statistic is large in _one_ direction, and so our confidence interval is one-sided also.  \n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nCreate a visualisation to illustrate the results.  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\n#| label: fig-passfig\n#| fig-cap: \"Distribution of scores on the Procrastination Assessment Scale for Students (PASS) measure. The majority of the sample scored below the suggested normal score of 33 (red dashed line).\"\n#| fig.height: 3\n#| fig.width: 5\nggplot(data = pass_scores, aes(x=PASS)) + \n  geom_boxplot() + \n  geom_vline(xintercept=33, lty=\"dashed\", col=\"red\")\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nWrite up the results.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \nThere are some quick example write-ups for each test in [3B #basic-tests](03b_inference2.html#basic-tests){target=\"_blank\"}\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r include=FALSE}\nres2<-t.test(pass_scores$PASS, mu = 33, alternative = \"less\")\n```\n\n:::int\nA one-sided one-sample t-test was conducted in order to determine if the average score on the Procrastination Assessment Scale for Students (PASS) for a sample of `r nrow(pass_scores)` students at Edinburgh University was significantly lower ($\\alpha = .05$) than the average score of 33 obtained during development of the PASS. \n\nEdinburgh University students scored lower (Mean = `r mean(pass_scores$PASS) |> round(2)`, SD = `r sd(pass_scores$PASS) |> round(2)`) than the score reported by the authors of the PASS (Mean = 33). This difference was statistically significant ($t(`r nrow(pass_scores)-1`)=`r res2$statistic |> round(2)`$, $p < .05$, one-tailed).  \n:::\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Heights \n\n> __Research Question__\n>  Is the average height of University of Edinburgh Psychology students different from 165cm?  \n\n```{r echo=FALSE, out.width=\"30%\"}\nknitr::include_graphics(\"images/hypothesis/playmo_tms.jpg\")\n```\n\n:::frame\n__Data: Past Surveys__  \nIn the last few years, we have asked students of the statistics courses in the Psychology department to fill out a little survey.  \nAnonymised data are available at [https://uoepsy.github.io/data/surveydata_historical.csv](https://uoepsy.github.io/data/surveydata_historical.csv).  \n\n__Note:__ this does _not_ contain the responses from this year. \n\n```{r}\nsurveydata <- \n  read_csv(\"https://uoepsy.github.io/data/surveydata_historical.csv\")\n```\n:::\n\n\n`r qbegin(qcounter())`\nNo more manual calculations of test statistics and p-values for this week.  \n\nConduct a one sample $t$-test to evaluate whether the average height of UoE psychology students in the last few years was different from 165cm.  \n\nMake sure to consider the assumptions of the test! \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- This is *real data*, and [real data is rarely normal](https://web.archive.org/web/20200927033407/https://dpananos.github.io/posts/2019/08/blog-post-23/)! If you conduct a Shapiro-Wilk test, you may well find $p<.05$ and conclude that your data is not normal.   \nSo what do we do if a test indicates our assumptions are violated?  \nWell, we should bear a couple of things in mind.  \n    1. A decision rule such as $p<.05$ on Shapiro-Wilk test creates very dichotomous thinking for something which is in reality not black and white. Real life distributions are not *either* normal *or* non-normal. Plot the data, and make a judgement!  \n    2. As it happens, the t-test is actually reasonably robust against slight deviations from normality, especially if the sample size is \"large enough\" (rule-of-thumb n = 30) and the data are not heavily skewed. Plot your data and make a judgement!  \n\n```{r}\n#| label: fig-rules\n#| fig-cap: \"The deeper you get into statistics, the more you discover that it is not simply a case of following step-by-step rules.\"  \n#| out-width: \"80%\"\n#| echo: false\nknitr::include_graphics(\"images/hypothesis/guidelines.gif\")\n```\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::::panelset\n:::panel\n#### Data\n\nWe'll read in our data and check the dimensions and variable names\n```{r}\nsurveydata <- read_csv(\"https://uoepsy.github.io/data/surveydata_historical.csv\")\n\ndim(surveydata)\nnames(surveydata)\n```\n\n:::\n:::panel\n#### Descriptives\n\n```{r}\nsurveydata |> \n  summarise(\n    mheight = mean(height, na.rm = T),\n    sdheight = sd(height, na.rm = T),\n    n = sum(!is.na(height))\n  )\n```\n:::\n:::panel\n#### Assumptions\n\nThe `shapiro.test()` suggests that our assumption of normality is not okay!  \n(the p-value is $<.05$, suggesting that we reject the hypothesis that the data are drawn from a normally distributed population)  \n```{r}\nshapiro.test(surveydata$height)\n```\n\nHowever, as always, __visualisations are vital__ here. The histogram below doesn't look all that great, but the t.test is quite robust against slight violations of normality, especially as sample sizes increase beyond 30, and our data here actually looks fairly normal (this is a judgement call here - over time you will start to get a sense of what you might deem worrisome in these plots!).  \n\n```{r}\nggplot(data = surveydata, aes(x = height)) + \n  geom_histogram() +\n  # adding our hypothesised mean\n  geom_vline(xintercept = 165) \n```\nWe can also take a quick look at the QQplot. The points follow the line closely apart from at the tail ends, matching the heavier tails of the distribution that are visible in the histogram above. \n```{r}\nqqnorm(surveydata$height)\nqqline(surveydata$height)\n```\n\nThe data are not very skewed, and together with the fact that we are working with a sample of `r sum(!is.na(surveydata$height))`, i feel fairly satisfied that the $t$-test will lead us to valid inferences.  \n\n:::\n:::panel\n#### t-test\n\n```{r}\nt.test(surveydata$height, mu = 165, alternative = \"two.sided\")\n```\n\n:::\n::::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Names and Tips  \n\n:::frame\n> __Research Question__\n> Can a server earn higher tips simply by introducing themselves by name when greeting customers?\n\nResearchers investigated the effect of a server introducing herself by name on restaurant tipping.\nThe study involved forty, 2-person parties eating a \\$23.21 fixed-price buffet Sunday brunch at Charley Brown's Restaurant in Huntington Beach, California, on April 10 and 17, 1988.  \n\nEach two-person party was randomly assigned by the waitress to either a name or a no-name condition. The total amount paid by each party at the end of their meal was then recorded.  \n  \nThe data are available at [https://uoepsy.github.io/data/gerritysim.csv](https://uoepsy.github.io/data/gerritysim.csv). (This is a simulated example based on [Garrity and Degelman (1990)](https://doi.org/10.1111/j.1559-1816.1990.tb00405.x))  \n:::\n\n`r qbegin(qcounter())`\nConduct an independent samples $t$-test to assess whether higher tips were earned when the server introduced themselves by name, in comparison to when they did not.    \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- There is a direction in the research question stated above, which means we will want to set `alternative = ??`.  \n- We'll want to check the normality (either visually or with a test) of the variable of interest _for each group_.  \n- Some researchers suggest using the Welch t-test by default. This means you can relax the assumption of equal variances in the groups. If you want to _test_ whether two variances are equal, try the `var.test()` function.\n\n:::\n`r qend()`  \n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::::panelset\n:::panel\n#### Data\n```{r}\ntipdata <- read_csv(\"https://uoepsy.github.io/data/gerritysim.csv\")\ndim(tipdata)\nhead(tipdata)\n```\n\nIt might be nice to conduct our analysis on just the _tip_ given, and not the \\$23.21 meal price + tip.  \n```{r}\n#make a \"tip\" column, which is minus the meal amount\ntipdata <- \n  tipdata |> mutate(\n    tip = paid - 23.21\n  )\n```\n\n:::\n:::panel\n#### Descriptives\n  \n```{r}\ntipdata |> \n  group_by(condition) |>\n  summarise(\n    meantip = mean(tip),\n    sdtip = sd(tip)\n  )\n```\n\n:::\n:::panel\n#### Plot\n```{r}\nggplot(data = tipdata, aes(x = tip, y = condition)) +\n  geom_boxplot()\n```\n:::\n:::panel\n#### Assumptions  \n\nAccording to these tests, we have normally distributed data for both groups, with equal variances. \n```{r}\nshapiro.test(tipdata$tip[tipdata$condition==\"name\"])\nshapiro.test(tipdata$tip[tipdata$condition==\"no name\"])\nvar.test(tip ~ condition, data = tipdata)\n```\n\n:::\n:::panel\n#### t-test  \n\nBecause the variances do not appear to be unequal, we can actually use the standard t-test with `var.equal = TRUE` if we want. However, we'll continue with the Welch t-test. \n\nRemember that our alternative hypothesis here is that the average tips in the \"name\" condition is greater than in the \"no name\" condition.  \nR will take the levels in order here (alphabetically), and assume that the alternative is for that group, so we use `alternative = \"greater\"` here to say that the alternative is $\\text{name}-\\text{no name} > 0$.  \n```{r}\nt.test(tip ~ condition, data = tipdata, alternative = \"greater\")\n```\n\n:::\n::::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Optional Extras\n\nHere are a few extra questions for you to practice performing tests and making plots:  \n\n`r qbegin(qlabel = FALSE, \"Optional Extra 1\")`\n\nAre dogs heavier on average than cats?  \nData from Week 1: [https://uoepsy.github.io/data/pets_seattle.csv](https://uoepsy.github.io/data/pets_seattle.csv)  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n  \n- Remember from week 1 - not everything in that data is either a cat or a dog!  \n\n:::\n  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\npets <- read.csv(\"https://uoepsy.github.io/data/pets_seattle.csv\")\ncatsndogs <- pets[pets$species != \"Goat\", ]\n```\n\nIn this case, we want to test whether $dogs > cats$. What we are testing then, whether $dogs - cats > 0$ or $cats - dogs < 0$.  \nBy default, as the `species` variable is a character, it will use alphabetical ordering, and `t.test()` will test $cats - dogs$. So we want our alternative hypothesis to be \"less\":  \n```{r}\n#| eval: false\nt.test(weight_kg ~ species, catsndogs,\n       alternative = \"less\")\n```\n\nAn alternative is to set it as a factor, and specify the levels in the order we want:  \n```{r}\ncatsndogs$species2 <- factor(catsndogs$species, levels = c(\"Dog\",\"Cat\"))\n```\nWhich would then allow us to shove that into the `t.test()` and perform the same test, but using $dogs - cats$ instead. \n\n```{r}\nt.test(weight_kg ~ species2, catsndogs,\n       alternative = \"greater\")\n```\n\n```{r}\ncatsndogs |>\n  ggplot(aes(x=species,y=weight_kg)) + \n  geom_boxplot()\n```\n\n`r solend()`\n\n\n`r qbegin(qlabel = FALSE, \"Optional Extra 2\")`\nIs taking part in a cognitive behavioural therapy (CBT) based programme associated with a greater reduction, on average, in anxiety scores in comparison to a Control group?  \nData are at [https://uoepsy.github.io/data/cbtanx.csv](https://uoepsy.github.io/data/cbtanx.csv). The dataset contains information on each person in an organisation, recording their professional role (management vs employee), whether they are allocated into the CBT programme or not (control vs cbt), and scores on anxiety at both the start and the end of the study period.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- you might have to make a new variable in order to test the research question. \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nBecause we're testing the _reduction_ in anxiety, we need to calculate it. By subtracting anxiety at time 2 from anxiety at time 1, we create a variable for which bigger values represent more reduction in anxiety  \n```{r}\ncbtanx <- read.csv(\"https://uoepsy.github.io/data/cbtanx.csv\")\n\ncbtanx <- cbtanx |> mutate(reduction = anx_t1 - anx_t2)\n```\n\nAnd we can then test whether $cbt - control > 0$:  \n```{r}\nt.test(reduction ~ cbt, data = cbtanx, \n       alternative = \"greater\")\n```\nAnd to make sure we're getting things the right way around, make a plot:\n```{r}\nggplot(cbtanx, aes(x=cbt, y=reduction))+\n  geom_boxplot() + \n  labs(x=\"Experimental Group\",y=\"Reduction in Anxiety across study\")\n```\n\n\n`r solend()`\n\n`r qbegin(qlabel = FALSE, \"Optional Extra 3\")`\n\nAre students on our postgraduate courses shorter/taller than those on our undergraduate courses?  \nWe can again use the data from the past surveys: [https://uoepsy.github.io/data/surveydata_historical.csv](https://uoepsy.github.io/data/surveydata_historical.csv).  \n\n\"USMR\" is our only postgraduate course.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n  \n- You'll need to create a variable that identifies whether a respondent is from a postgrad or and undergrad course.  \n\n:::\n  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nsurveydata <- read_csv(\"https://uoepsy.github.io/data/surveydata_historical.csv\")\nsurveydata <- surveydata |>\n  mutate(\n    isPG = course==\"usmr\"\n  )\ntable(surveydata$isPG)\n```\n\n\n```{r}\nt.test(height ~ isPG, data = surveydata)\n```\n\n```{r}\nggplot(surveydata, aes(x = isPG, y = height)) +\n  geom_boxplot()\n```\n\n`r solend()`\n\n","srcMarkdownNoYaml":"\n\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\nset.seed(017)\n```\n\n# Intervals again  \n\n`r qbegin(qcounter())`\nAt the end of last week's exercises, we estimated the mean sleep-quality rating, and computed a confidence interval, using the formula below.  \n\n$$\n\\begin{align}\n\\text{95\\% CI: }& \\bar x \\pm 1.96 \\times SE \\\\\n\\end{align}\n$$\n\nCan you use R to show where the 1.96 comes from?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n`qnorm`!  (see the end of [03A #uncertainty-due-to-sampling](03a_inference.html#uncertainty-due-to-sampling){target=\"_blank\"})\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nThe 1.96 comes from 95% of the normal distribution falling within 1.96 standard deviations of the mean:  \n\n```{r}\nqnorm(c(0.025, 0.975))\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nAs we learned in [3B #t-distributions](03b_inference2.html#t---distributions){target=\"_blank\"}, the sampling distribution of a statistic has heavier tails the smaller the size of the sample it is derived from. In practice, we are better using $t$-distributions to construct confidence intervals and perform statistical tests.  \n\nThe code below creates a dataframe that contains the number of books read by 7 people in `r as.numeric(substr(Sys.Date(),1,4))-1`.    \n(Note `tibble` is just a tidyverse version of `data.frame`):  \n```{r}\nbookdata <- \n  tibble(\n    person = c(\"Martin\",\"Umberto\",\"Monica\",\"Emma\",\"Josiah\",\"Dan\",\"Aja\"),\n    books_read = c(12,19,9,11,8,28,13)\n  )\n```\n\nCalculate the mean number of books read in `r as.numeric(substr(Sys.Date(),1,4))-1`, and construct an appropriate 95% confidence interval.   \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nHere is our estimated average number of books read:  \n```{r}\nmean(bookdata$books_read)\n```\n\nAnd our standard error is still $\\frac{s}{\\sqrt{n}}$:  \n```{r}\nsd(bookdata$books_read)/sqrt(nrow(bookdata))\n```\n\nWith $n = 7$ observations, and estimating 1 mean, we are left with $6$ degrees of freedom.  \nFor our 95% confidence interval, the $t^*$ in the formula below is obtained via:^[(Why 97.5? and not 95? We want the _middle_ 95%, and $t$-distributions are symmetric, so we want to split that 5% in half, so that 2.5% is on either side. We could have also used `qt(0.025, df = 6)`, which will just give us the same number but negative: `r qt(0.025, df = 6)`)]  \n```{r}\nqt(0.975, df = 6)\n```\n\nOur confidence interval is therefore:  \n$$\n\\begin{align}\n\\text{CI} &= \\bar{x} \\pm t^* \\times SE \\\\\n\\text{95\\% CI} &= 14.286 \\pm 2.447 \\times 2.652 \\\\\n\\text{95\\% CI} &= [7.80,\\, 20.78] \\\\\n\\end{align}\n$$\n\n`r solend()`\n\n`r qbegin(qcounter())`\nWill a 90% confidence interval be wider or narrow?  \nCalculate it and see.  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nA 90% confidence interval will be narrower:  \n```{r}\nqt(0.95, df = 6)\n```\n\n$$\n\\begin{align}\n\\text{CI} &= \\bar{x} \\pm t^* \\times SE \\\\\n\\text{90\\% CI} &= 14.286 \\pm 1.943 \\times 2.652 \\\\\n\\text{90\\% CI} &= [9.13,\\, 19.44] \\\\\n\\end{align}\n$$\n\nThe intuition behind this is that our level of confidence is inversely related to the width of the interval.   \n\nTake it to the extremes:  \n\n- I have 100% confidence that the interval $[-Infinity, +Infinity]$ contains the true population mean. \n- If I want an narrower interval, then I have to sacrifice confidence. e.g. a 10% CI: $[`r round(t.test(bookdata$books_read,conf.level=0.1)$conf.int[1],2)`, `r round(t.test(bookdata$books_read,conf.level=0.1)$conf.int[2],2)`]$\n\nImagine playing a game of [ringtoss](https://en.wikipedia.org/wiki/Ring_toss){target=\"_blank\"}. A person throwing a 2-meter diameter hoop will have much more confidence that they are going to get it over the pole than a person throwing a 10cm diameter ring.  \n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Procrastination Scores\n\n:::frame\n> __Research Question__\n> Do Edinburgh University students report endorsing procrastination less than the norm?  \n\nThe Procrastination Assessment Scale for Students (PASS) was designed to assess how individuals approach decision situations, specifically the tendency of individuals to postpone decisions (see [Solomon & Rothblum, 1984](http://dx.doi.org/10.1037/0022-0167.31.4.503)). The PASS assesses the prevalence of procrastination in six areas: writing a paper; studying for an exam; keeping up with reading; administrative tasks; attending meetings; and performing general tasks. For a measure of total endorsement of procrastination, responses to 18 questions (each measured on a 1-5 scale) are summed together, providing a single score for each participant (range 0 to 90). The mean score from Solomon & Rothblum, 1984 was 33.  \n\nA student administers the PASS to 20 students from Edinburgh University.  \nThe data are available at [https://uoepsy.github.io/data/pass_scores.csv](https://uoepsy.github.io/data/pass_scores.csv).  \n:::\n\n\n`r qbegin(qcounter())`\n\n1. Read in the data\n2. Calculate some relevant descriptive statistics\n3. Check the assumptions that we will be concerned with for a one-sample test of whether the mean PASS scores is less than 33. \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- What counts as \"relevant statistics\"? Think about the question. It concerns just one variable (the PASS scores), which is numeric. What's a nice way of describing the center and spread of such a variable?  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n\n::::panelset\n:::panel\n#### Data\n\n```{r}\npass_scores <- read_csv(\"https://uoepsy.github.io/data/pass_scores.csv\") \ndim(pass_scores)\nhead(pass_scores)\n```\n\n:::\n:::panel\n#### Descriptives\n\n```{r}\npass_scores |>\n  summarise(\n    mPASS = mean(PASS),\n    sdPASS = sd(PASS),\n    n = n()\n  )\n```\n\n:::\n:::panel\n#### Assumptions\n\nWe want to check that the data are close to normally distributed. This is especially relevant as we have only 20 datapoints here. The plot below makes it look like we may have one or two data points in the tails of the distribution that are further than we might expect. \n```{r}\nggplot(pass_scores, aes(sample = PASS)) + \n  geom_qq() + \n  geom_qq_line()\n```\nBut the Shapiro-Wilk test of $p > .05$ indicates that we are probably okay to continue with our t-test  \n```{r}\nshapiro.test(pass_scores$PASS)\n```\n\n:::\n::::\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nOur test here is going to be have the following hypotheses:  \n\n- __Null:__ mean PASS score in Edinburgh Uni students is $\\geq 33$\n- __Alternative:__ mean PASS score in Edinburgh Uni students is $< 33$ \n\n_Manually_ calculate the relevant test statistic.  \n_Note, we're doing this manually right now as it's a useful learning process. In later questions we will switch to the easy way!_  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- you can see the step-by-step calculation of a one sample t-test in [3B #one-sample-t-test](03b_inference2.html#one-sample-t-test){target=\"_blank\"}. \n- The relevant formula is:  \n$$\n\\begin{align}\n& t =  \\frac{\\bar x - \\mu_0}{\\frac{s}{\\sqrt{n}}} \\\\\n\\qquad \\\\\n& \\text{Where:} \\\\\n& \\bar x : \\text{mean of PASS in our sample} \\\\\n& \\mu_0 : \\text{hypothesised mean score of 33} \\\\\n& s : \\text{standard deviation of PASS in our sample} \\\\\n& n : \\text{number of observations}\n\\end{align}\n$$\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\npass_scores <- read_csv(\"https://uoepsy.github.io/data/pass_scores.csv\") \n\npass_scores |> \n  summarise(\n    xbar = mean(PASS),\n    s = sd(PASS),\n    n = n(),\n    t = (xbar - 33)/(s / sqrt(n))\n  )\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nUsing the test statistic calculated in question 1, compute the p-value.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- this will be needing the `pt()` function.\n- the degrees of freedom is $n-1$ (we used one up by estimating the mean).\n- The test we are performing is against the null hypothesis that the mean is $\\geq 33$. Our t-statistic is in the broad sense calculated as \"mean minus 33\", so negative numbers mean we have a mean lower than 33. These are the instances that we will reject the null hypothesis - if we get a test statistic very low. So we want the lower.tail of the distribution for our p-value.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nWe have 20 participants, so $df=19$\n```{r}\npt(-3.107272, df = 19, lower.tail = TRUE)\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nNow using the `t.test()` function, conduct the same test. Check that the numbers match with your step-by-step calculations in the previous two questions.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \nCheck out the help page for `t.test()` - there is an argument in the function that allows us to easily change between whether our alternative hypothesis is \"less than\", \"greater than\" or \"not equal to\".  \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nt.test(pass_scores$PASS, mu = 33, alternative = \"less\")\n```\nThe $t$ statistic, our $df$, and our $p$-value all match the calculations from the previous questions.  \n\nThe simple `t.test()` approach even gives us a confidence interval! Well.. half of one! This is because we conducted a one-sided test. Remember that null hypothesis significance testing is like asking \"does our confidence interval contain zero?\". With a one-sided test we only reject the null hypothesis if the test statistic is large in _one_ direction, and so our confidence interval is one-sided also.  \n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nCreate a visualisation to illustrate the results.  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\n#| label: fig-passfig\n#| fig-cap: \"Distribution of scores on the Procrastination Assessment Scale for Students (PASS) measure. The majority of the sample scored below the suggested normal score of 33 (red dashed line).\"\n#| fig.height: 3\n#| fig.width: 5\nggplot(data = pass_scores, aes(x=PASS)) + \n  geom_boxplot() + \n  geom_vline(xintercept=33, lty=\"dashed\", col=\"red\")\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nWrite up the results.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \nThere are some quick example write-ups for each test in [3B #basic-tests](03b_inference2.html#basic-tests){target=\"_blank\"}\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r include=FALSE}\nres2<-t.test(pass_scores$PASS, mu = 33, alternative = \"less\")\n```\n\n:::int\nA one-sided one-sample t-test was conducted in order to determine if the average score on the Procrastination Assessment Scale for Students (PASS) for a sample of `r nrow(pass_scores)` students at Edinburgh University was significantly lower ($\\alpha = .05$) than the average score of 33 obtained during development of the PASS. \n\nEdinburgh University students scored lower (Mean = `r mean(pass_scores$PASS) |> round(2)`, SD = `r sd(pass_scores$PASS) |> round(2)`) than the score reported by the authors of the PASS (Mean = 33). This difference was statistically significant ($t(`r nrow(pass_scores)-1`)=`r res2$statistic |> round(2)`$, $p < .05$, one-tailed).  \n:::\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Heights \n\n> __Research Question__\n>  Is the average height of University of Edinburgh Psychology students different from 165cm?  \n\n```{r echo=FALSE, out.width=\"30%\"}\nknitr::include_graphics(\"images/hypothesis/playmo_tms.jpg\")\n```\n\n:::frame\n__Data: Past Surveys__  \nIn the last few years, we have asked students of the statistics courses in the Psychology department to fill out a little survey.  \nAnonymised data are available at [https://uoepsy.github.io/data/surveydata_historical.csv](https://uoepsy.github.io/data/surveydata_historical.csv).  \n\n__Note:__ this does _not_ contain the responses from this year. \n\n```{r}\nsurveydata <- \n  read_csv(\"https://uoepsy.github.io/data/surveydata_historical.csv\")\n```\n:::\n\n\n`r qbegin(qcounter())`\nNo more manual calculations of test statistics and p-values for this week.  \n\nConduct a one sample $t$-test to evaluate whether the average height of UoE psychology students in the last few years was different from 165cm.  \n\nMake sure to consider the assumptions of the test! \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- This is *real data*, and [real data is rarely normal](https://web.archive.org/web/20200927033407/https://dpananos.github.io/posts/2019/08/blog-post-23/)! If you conduct a Shapiro-Wilk test, you may well find $p<.05$ and conclude that your data is not normal.   \nSo what do we do if a test indicates our assumptions are violated?  \nWell, we should bear a couple of things in mind.  \n    1. A decision rule such as $p<.05$ on Shapiro-Wilk test creates very dichotomous thinking for something which is in reality not black and white. Real life distributions are not *either* normal *or* non-normal. Plot the data, and make a judgement!  \n    2. As it happens, the t-test is actually reasonably robust against slight deviations from normality, especially if the sample size is \"large enough\" (rule-of-thumb n = 30) and the data are not heavily skewed. Plot your data and make a judgement!  \n\n```{r}\n#| label: fig-rules\n#| fig-cap: \"The deeper you get into statistics, the more you discover that it is not simply a case of following step-by-step rules.\"  \n#| out-width: \"80%\"\n#| echo: false\nknitr::include_graphics(\"images/hypothesis/guidelines.gif\")\n```\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::::panelset\n:::panel\n#### Data\n\nWe'll read in our data and check the dimensions and variable names\n```{r}\nsurveydata <- read_csv(\"https://uoepsy.github.io/data/surveydata_historical.csv\")\n\ndim(surveydata)\nnames(surveydata)\n```\n\n:::\n:::panel\n#### Descriptives\n\n```{r}\nsurveydata |> \n  summarise(\n    mheight = mean(height, na.rm = T),\n    sdheight = sd(height, na.rm = T),\n    n = sum(!is.na(height))\n  )\n```\n:::\n:::panel\n#### Assumptions\n\nThe `shapiro.test()` suggests that our assumption of normality is not okay!  \n(the p-value is $<.05$, suggesting that we reject the hypothesis that the data are drawn from a normally distributed population)  \n```{r}\nshapiro.test(surveydata$height)\n```\n\nHowever, as always, __visualisations are vital__ here. The histogram below doesn't look all that great, but the t.test is quite robust against slight violations of normality, especially as sample sizes increase beyond 30, and our data here actually looks fairly normal (this is a judgement call here - over time you will start to get a sense of what you might deem worrisome in these plots!).  \n\n```{r}\nggplot(data = surveydata, aes(x = height)) + \n  geom_histogram() +\n  # adding our hypothesised mean\n  geom_vline(xintercept = 165) \n```\nWe can also take a quick look at the QQplot. The points follow the line closely apart from at the tail ends, matching the heavier tails of the distribution that are visible in the histogram above. \n```{r}\nqqnorm(surveydata$height)\nqqline(surveydata$height)\n```\n\nThe data are not very skewed, and together with the fact that we are working with a sample of `r sum(!is.na(surveydata$height))`, i feel fairly satisfied that the $t$-test will lead us to valid inferences.  \n\n:::\n:::panel\n#### t-test\n\n```{r}\nt.test(surveydata$height, mu = 165, alternative = \"two.sided\")\n```\n\n:::\n::::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Names and Tips  \n\n:::frame\n> __Research Question__\n> Can a server earn higher tips simply by introducing themselves by name when greeting customers?\n\nResearchers investigated the effect of a server introducing herself by name on restaurant tipping.\nThe study involved forty, 2-person parties eating a \\$23.21 fixed-price buffet Sunday brunch at Charley Brown's Restaurant in Huntington Beach, California, on April 10 and 17, 1988.  \n\nEach two-person party was randomly assigned by the waitress to either a name or a no-name condition. The total amount paid by each party at the end of their meal was then recorded.  \n  \nThe data are available at [https://uoepsy.github.io/data/gerritysim.csv](https://uoepsy.github.io/data/gerritysim.csv). (This is a simulated example based on [Garrity and Degelman (1990)](https://doi.org/10.1111/j.1559-1816.1990.tb00405.x))  \n:::\n\n`r qbegin(qcounter())`\nConduct an independent samples $t$-test to assess whether higher tips were earned when the server introduced themselves by name, in comparison to when they did not.    \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- There is a direction in the research question stated above, which means we will want to set `alternative = ??`.  \n- We'll want to check the normality (either visually or with a test) of the variable of interest _for each group_.  \n- Some researchers suggest using the Welch t-test by default. This means you can relax the assumption of equal variances in the groups. If you want to _test_ whether two variances are equal, try the `var.test()` function.\n\n:::\n`r qend()`  \n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::::panelset\n:::panel\n#### Data\n```{r}\ntipdata <- read_csv(\"https://uoepsy.github.io/data/gerritysim.csv\")\ndim(tipdata)\nhead(tipdata)\n```\n\nIt might be nice to conduct our analysis on just the _tip_ given, and not the \\$23.21 meal price + tip.  \n```{r}\n#make a \"tip\" column, which is minus the meal amount\ntipdata <- \n  tipdata |> mutate(\n    tip = paid - 23.21\n  )\n```\n\n:::\n:::panel\n#### Descriptives\n  \n```{r}\ntipdata |> \n  group_by(condition) |>\n  summarise(\n    meantip = mean(tip),\n    sdtip = sd(tip)\n  )\n```\n\n:::\n:::panel\n#### Plot\n```{r}\nggplot(data = tipdata, aes(x = tip, y = condition)) +\n  geom_boxplot()\n```\n:::\n:::panel\n#### Assumptions  \n\nAccording to these tests, we have normally distributed data for both groups, with equal variances. \n```{r}\nshapiro.test(tipdata$tip[tipdata$condition==\"name\"])\nshapiro.test(tipdata$tip[tipdata$condition==\"no name\"])\nvar.test(tip ~ condition, data = tipdata)\n```\n\n:::\n:::panel\n#### t-test  \n\nBecause the variances do not appear to be unequal, we can actually use the standard t-test with `var.equal = TRUE` if we want. However, we'll continue with the Welch t-test. \n\nRemember that our alternative hypothesis here is that the average tips in the \"name\" condition is greater than in the \"no name\" condition.  \nR will take the levels in order here (alphabetically), and assume that the alternative is for that group, so we use `alternative = \"greater\"` here to say that the alternative is $\\text{name}-\\text{no name} > 0$.  \n```{r}\nt.test(tip ~ condition, data = tipdata, alternative = \"greater\")\n```\n\n:::\n::::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Optional Extras\n\nHere are a few extra questions for you to practice performing tests and making plots:  \n\n`r qbegin(qlabel = FALSE, \"Optional Extra 1\")`\n\nAre dogs heavier on average than cats?  \nData from Week 1: [https://uoepsy.github.io/data/pets_seattle.csv](https://uoepsy.github.io/data/pets_seattle.csv)  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n  \n- Remember from week 1 - not everything in that data is either a cat or a dog!  \n\n:::\n  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\npets <- read.csv(\"https://uoepsy.github.io/data/pets_seattle.csv\")\ncatsndogs <- pets[pets$species != \"Goat\", ]\n```\n\nIn this case, we want to test whether $dogs > cats$. What we are testing then, whether $dogs - cats > 0$ or $cats - dogs < 0$.  \nBy default, as the `species` variable is a character, it will use alphabetical ordering, and `t.test()` will test $cats - dogs$. So we want our alternative hypothesis to be \"less\":  \n```{r}\n#| eval: false\nt.test(weight_kg ~ species, catsndogs,\n       alternative = \"less\")\n```\n\nAn alternative is to set it as a factor, and specify the levels in the order we want:  \n```{r}\ncatsndogs$species2 <- factor(catsndogs$species, levels = c(\"Dog\",\"Cat\"))\n```\nWhich would then allow us to shove that into the `t.test()` and perform the same test, but using $dogs - cats$ instead. \n\n```{r}\nt.test(weight_kg ~ species2, catsndogs,\n       alternative = \"greater\")\n```\n\n```{r}\ncatsndogs |>\n  ggplot(aes(x=species,y=weight_kg)) + \n  geom_boxplot()\n```\n\n`r solend()`\n\n\n`r qbegin(qlabel = FALSE, \"Optional Extra 2\")`\nIs taking part in a cognitive behavioural therapy (CBT) based programme associated with a greater reduction, on average, in anxiety scores in comparison to a Control group?  \nData are at [https://uoepsy.github.io/data/cbtanx.csv](https://uoepsy.github.io/data/cbtanx.csv). The dataset contains information on each person in an organisation, recording their professional role (management vs employee), whether they are allocated into the CBT programme or not (control vs cbt), and scores on anxiety at both the start and the end of the study period.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n\n- you might have to make a new variable in order to test the research question. \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nBecause we're testing the _reduction_ in anxiety, we need to calculate it. By subtracting anxiety at time 2 from anxiety at time 1, we create a variable for which bigger values represent more reduction in anxiety  \n```{r}\ncbtanx <- read.csv(\"https://uoepsy.github.io/data/cbtanx.csv\")\n\ncbtanx <- cbtanx |> mutate(reduction = anx_t1 - anx_t2)\n```\n\nAnd we can then test whether $cbt - control > 0$:  \n```{r}\nt.test(reduction ~ cbt, data = cbtanx, \n       alternative = \"greater\")\n```\nAnd to make sure we're getting things the right way around, make a plot:\n```{r}\nggplot(cbtanx, aes(x=cbt, y=reduction))+\n  geom_boxplot() + \n  labs(x=\"Experimental Group\",y=\"Reduction in Anxiety across study\")\n```\n\n\n`r solend()`\n\n`r qbegin(qlabel = FALSE, \"Optional Extra 3\")`\n\nAre students on our postgraduate courses shorter/taller than those on our undergraduate courses?  \nWe can again use the data from the past surveys: [https://uoepsy.github.io/data/surveydata_historical.csv](https://uoepsy.github.io/data/surveydata_historical.csv).  \n\n\"USMR\" is our only postgraduate course.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints  \n  \n- You'll need to create a variable that identifies whether a respondent is from a postgrad or and undergrad course.  \n\n:::\n  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nsurveydata <- read_csv(\"https://uoepsy.github.io/data/surveydata_historical.csv\")\nsurveydata <- surveydata |>\n  mutate(\n    isPG = course==\"usmr\"\n  )\ntable(surveydata$isPG)\n```\n\n\n```{r}\nt.test(height ~ isPG, data = surveydata)\n```\n\n```{r}\nggplot(surveydata, aes(x = isPG, y = height)) +\n  geom_boxplot()\n```\n\n`r solend()`\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"output-file":"03_ex.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","toc_float":true,"code-annotations":"hover","link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Exercises: T-tests","params":{"SHOW_SOLS":false,"TOGGLE":true}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}