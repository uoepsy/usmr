{"title":"WalkThrough: Advanced Data Wrangling","markdown":{"yaml":{"title":"WalkThrough: Advanced Data Wrangling","reference-location":"margin","citation-location":"margin","params":{"SHOW_SOLS":true,"TOGGLE":true}},"headingText":"Different Data Formats","containsRefs":false,"markdown":"\n\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\nset.seed(017)\n```\n\nIn many projects (both in academic research & in other sectors), more time will be spent cleaning and organising data than will actually be spent conducting statistical analyses (a well designed study with a well-thought through data collection process can go a long way to remedy this!).\n\nFor this reason, we're going to take a little detour away from statistics to get some more practice wrangling and cleaning data in R. Don't worry about the trying to remember all of the new R functions introduced in this topic - there are a lot. Use them as a means of learning about some of the different ways of doing things in R.    \n  \n\n:::frame\n__Study Background & Data__  \n\nThe data we're going to look at now is from an experiment on language comprehension, looking at whether people perceive blinking as a sign of lying. \n\n> **Research Question:** Is the rate of blinking during speech interpreted as a sign of dishonesty (in the context of a lie-detection game)?  \n\nParticipants were informed that they were going to take part in a lie-detection game. They were presented with audiovisual recordings of a speaker stating behind which of two objects (displayed on screen) there was hidden treasure. Utterances took the form of \"The treasure is behind the [target name]\".   \nOver 20 trials, participants were tasked with using the mouse to click on the object *they believed* the treasure to be behind. They were told that the speaker in the video was attempting to mislead them, meaning that sometimes they told the truth, and sometimes they lied. \nCrucially, in the videos presented of the speaker producing the utterances, we manipulated the number of times the speaker blinked (from 1 to 10 times). \nParticipants eyes were tracked for the duration of the experiment, with the time spent looking at either object taken as an implicit indication of perceiving a truthful utterance (in which the participant looks at and clicks on the 'target object' (the one identified by the speaker as hiding the treasure)) or a dishonest one (in which the participant would look at and click on the alternative 'distractor' object).\n\n<center>**blink_setup.csv**</center>    \nThe data from the experimental design are available at [https://uoepsy.github.io/data/blink_setup.csv](https://uoepsy.github.io/data/blink_setup.csv). In this data, each participant is a row, and the information about what video is presented in each trial are presented in separate columns for each trial. The first bit of the data looks like this: \n```{r echo=FALSE}\nlibrary(tidyverse)\nlibrary(readxl)\n\ndownload.file('https://uoepsy.github.io/data/blink_eyegaze.xlsx', 'data/blink_eyegaze.xlsx', mode=\"wb\")\neyedata <- read_excel(path = 'data/blink_eyegaze.xlsx')\n\nsetupdata <- read_csv(\"https://uoepsy.github.io/data/blink_setup.csv\", col_names = FALSE)\nhead(setupdata)[,1:4] |>\n  cbind(`...` = rep(\"...\",6)) |>\n  rbind(\"...\") |> rbind(\"...\") |> \n  knitr::kable(col.names = NULL)\n```\n\n<center>**blink_eyegaze.xlsx**</center>    \nThe data from the eye-tracker, which has been processed to show the proportion of time spent looking at the distractor object in each trial, can be found at [https://uoepsy.github.io/data/blink_eyegaze.xlsx](https://uoepsy.github.io/data/blink_eyegaze.xlsx). In contrast to the blink_setup.csv data, in this data each trial is a row, so we have 20 rows per participant.  \n```{r echo=FALSE}\ncbind(variable_names = names(eyedata),\n      description = c(\"Participant number\",\"Trial number\",\"Time spent looking at distractor object (measured in milliseconds from onset of noun phrase)\",\"Time taken to click on an object (measured in milliseconds from the onset of the noun phrase\")) |>\n    knitr::kable()\n```\nThe top of the data looks like this:\n```{r echo=FALSE}\nhead(eyedata) |>\n  rbind(\"...\") |> rbind(\"...\") |> \n  knitr::kable()\n```\n:::\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n\nData can come in lots of different formats, meaning that we need lots of different ways to read data into R. Below is some information on some of the more common functions for reading and writing different types of data. \n\n\n**Text based files**\n\n|  filetype|  description|  reading| writing|\n|:--|:--|--:|--:|\n|  .csv|  comma separated values|  tidyverse - `read_csv()`<br>`read.csv()`<br>`read.table(..., sep = \",\")`| tidyverse - `write_csv()`<br>`write.csv()`<br>`write.table(..., sep=\",\")`|\n|  .tsv|  tab separated values|  tidyverse - `read_tsv()`<br>`read.table(..., sep = \"\\t\")`| tidyverse - `write_tsv()`<br>`write.table(..., sep = \"\\t\")`|\n|  .txt|  anything-separated values!|  `read.table(..., sep = ...)`| `write.table(..., sep = ...)`|\n\n\n**R files**  \n  \n|  filetype|  description|  reading| writing|\n|:--|:--|--:|--:|\n|  .RDS|  1 file = a single R object|  `readRDS()`| `saveRDS()` |\n|  .RData| 1 file = a collection of R objects|  `load()`| `save()`<br>`save.image()` - to save all objects in the environment) |\n  \n**Excel files**  \nThe package **readxl** provides a variety of functions for reading in different types of Microsoft Excel spreadsheet, such as `read_excel()`, `read_xls()`, `read_xlsx()`.  \n\n**Other software**  \nThe package **haven** provides functions for files which have been saved from other statistical software, for instance with `read_spss()`/`read_sav()` and `read_sas()` for files from SPSS and SAS.  \n\n**Google sheets**  \nThe **googlesheets4** package can read in data directly from a spreadsheet stored on google drive. You simply find the *id* of the sheet (it's the big long string of numbers & letters in the url of your google sheet), and pass it to `read_sheet()`.  \nIt will prompt you to authenticate your account via your browser, but it's really easy!  \n\n`r qbegin(qcounter())`\nRead in the two data-sets. Take care to look at the file extension (e.g., **.csv**, **.tsv**, **.xlsx**) as indicators of what function to try.  \nMake sure you assign them identifiable names.  \nOnce you've loaded the data-set, take a look at them using functions like `summary()`, `str()`, `dim()`/`nrow()`, or viewing them by clicking on them in the environment. \n  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- Some functions like `read_excel()` don't allow you to download directly from a url, like we have been doing with __.csv__ files.  \n  - Solution 1:\n    - Download the data to your computer\n    - upload to the rstudio server if you are using it\n    - Direct the function to read it from the place you stored it. \n  - Solution 2: \n    - Make R download the data directly to somewhere in your working directory (see `download.file()`). \n- Do both the data-sets have column names? By default R will assume the first row is the name of the column. Look in the help documentation to see how to stop this from happening.  \n\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(tidyverse)\nlibrary(readxl)\n\ndownload.file('https://uoepsy.github.io/data/blink_eyegaze.xlsx', 'blink_eyegaze.xlsx', mode=\"wb\")\neyedata <- read_excel(path = 'blink_eyegaze.xlsx')\n\nsetupdata <- read_csv(\"https://uoepsy.github.io/data/blink_setup.csv\", col_names = FALSE)\n```\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Renaming Columns  \n\nYou can access the column names from a data-set using `names()` or `colnames()`. \n```{r eval=FALSE}\nnames(data)\ncolnames(data)\n```\nAnd we can easily rename these using indexing:\n```{r eval=FALSE}\n#name the third column \"peppapig\"\nnames(data)[3]<-\"peppapig\"\n```\nOr in tidyverse, using `rename()`:\n```{r eval=FALSE}\ndata |>\n  rename(newname = currentname)\n```\n\n`r qbegin(qcounter())`\n**Problem**  \n\nThe *blink_setup.csv* file doesn't have any column names!  \nWe know that there are 20 trials for each participant, and we can see that the 2nd column has information about which subject it is.  \nColumns 3:22 are trials 1 to 20.  \n\n```{r eval=FALSE}\nhead(setupdata)\n```\n```{r echo=FALSE}\nhead(setupdata)[,1:3] |>\n  cbind(`...` = rep(\"...\",6)) |>\n  rbind(\"...\") |> rbind(\"...\")\n```\n\n**Task**\n\n1. Remove the first column\n2. Rename columns 2 to 22 with sensible names. \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n```{r eval=FALSE}\nnames(setupdata) # what are the names\nnames(setupdata)[2] # what is the 2nd name\nnames(setupdata) <- c(\"...\", \"...\", \"...\",..) # set the names\n```\n```{r}\nc(\"kermit\", paste(\"peppapig\", 1:3, sep=\"_\"))\n```\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nremove the first column\n```{r}\nsetupdata <- setupdata[,-1]\n```\nSet the names\n```{r}\nnames(setupdata) <- c(\"sub\",paste(\"trial\", 1:20, sep = \"_\"))\n```\n\nCheck:\n```{r eval=FALSE}\nhead(setupdata)\n```\n```{r echo=FALSE}\nhead(setupdata)[,1:2] |>\n  cbind(`...` = rep(\"...\",6)) |>\n  rbind(\"...\") |> rbind(\"...\")\n```\n\n`r solend()`\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Reshaping data \n\n**Pivot!**  \n\nOne of the more confusing things to get to grips with is the idea of reshaping a dataframe.  \nFor different reasons, you might sometimes want to have data in wide, or in long format. \n\n```{r echo=FALSE, fig.cap=\"Source: https://fromthebottomoftheheap.net/2019/10/25/pivoting-tidily/\"}\nknitr::include_graphics(\"https://www.fromthebottomoftheheap.net/assets/img/posts/tidyr-longer-wider.gif\")\n```\n\nWhen the data is wide, we can make it long using `pivot_longer()`. When we make data longer, we're essentially making lots of columns into 2 longer columns. Above, in the animation, the wide variable **x**, **y** and **z** go into a new longer column called **name** that specifies which (x/y/z) it came from, and the values get put into the **val** column.  \n\nThe animation takes a shortcut in the code it displays above, but you could also use `pivot_longer(c(x,y,z), names_to = \"name\", values_to = \"val\")`. To reverse this, and put it back to being wide, we tell R which columns to take the names and values *from*: `pivot_wider(names_from = name, values_from = val)`.  \n\n`r qbegin(qcounter())`\n**Problem**  \nThe *blink_setup.csv* file has the data in a different shape to the *blink_eyegaze.xlsx* file.  \n  \n- *blink_setup.csv* : one row per participant  \n- *blink_eyegaze.xlsx* : one row per trial  \n  \n**Task** \n\nReshape the data to make it so that there is one row per trial.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n\n- in the tidyverse functions, you can specify all columns between column **x** and column **z** by using the colon, `x:z`.  \n\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n(Note that this will depend on what you called your columns in the previous question - we just called them \"trial_1\", ... , \"trial_20\"). \n\n```{r}\nsetuplong <- \n  setupdata |>\n  pivot_longer(trial_1:trial_20, names_to = \"trial_number\", values_to = \"video\")\n\nsetuplong\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Dealing with character strings\n\nThere are loads of functions we can use to do various things with character strings in R.  \nHere are a few examples:\n\n\n::: {.callout-note collapse=\"true\"}\n#### gsub() - substitute a string of characters for another string\n\n\n```{r}\ngsub(\"don't like\",\"love\", \"i really really really don't like statistics!\")\n```\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### separate() - separate a column into multiple columns by splitting at a set of characters\n\n```{r}\nmupsimp <- read_csv(\"https://uoepsy.github.io/data/muppet_simp.csv\")\nmupsimp\n\nmupsimp |> \n  separate(show_name, into = c(\"show\",\"name\"), sep = \"_\")\n```\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### substr() - extract or replace substrings in a character vector\n\n```{r}\n# get the first 3 letters\nsubstr(mupsimp$show_name, 1, 3)\n```\n\nCan be combined with functions like `nchar()` (to find the number of characters in each string). Additionally, can be used in tidyverse easily:\n```{r}\nmupsimp |>\n  mutate(\n    first3 = substr(show_name, 1, 3),\n    last3 = substr(show_name, nchar(show_name)-2, nchar(show_name))\n  )\n```\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### paste() - quickly combine two character vectors\n\n```{r}\npaste(\"hello\",\"everyone\",sep=\" \")\n```\nYou can also use it to *collapse* a vector into a single string:\n```{r}\npaste(mupsimp$show_name, collapse=\" \")\n```\nand `paste0()` is a quick shortcut for using `sep=\"\"`:\n```{r}\npaste0(\"hello\",\"everyone\")\n```\n\n:::\n\n`r qbegin(qcounter())`\n**Problem**   \nIf you look at what data was captured by the software to indicate which video was used in each trial, there is a lot of unnecessary data there. The number of the filename indicates how many blinks are in the video. This is the only bit of information we want.   \n```{r}\nhead(setuplong$video)\n```\n**Task** \n\n- In your (now reshaped to long) **blink_setup.csv** data, make a new, or edit an existing column, which is a *numeric* variable containing the number of blinks presented in the video in each trial  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n  \n\n- there are lots of different ways you could do this.  \n- you can substitute out multiple different strings by separating them with the `|` symbol:\n```{r}\n  gsub(\"dog|cat\", \"horse\", \"I have a dog and a cat and the dogs name is Graham\")\n```\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nsetuplong <- setuplong |>\n  mutate(\n    nr_blinks = as.numeric(gsub(\"/files/vids/|blinks_|blinsk_|.mp4\",\"\",video))\n  )\n\nsetuplong\n```\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Joining/merging\n\nNow comes a fun bit.  \nRecall that the research question is interested in the relationship between the number of times the speaker was seen to blink, and the time the participants spent looking at the distractor object (indicating perceived dishonesty).  \nYou may have noticed that these variables are currently in different data-sets! The **blink_setup.csv** contains information about the numbers of blinks in the videos, and the **blink_eyegaze.xlsx** contains the data on the fixations. \n  \nSolution: we need to join them together!  \n\nNote that because both data-sets contain information on participant number and trial number, which uniquely identifies each observation, we can join them together matching on these variables!  \n\nThere are lots of different ways to join data-sets, depending on whether we want to keep rows from one data-set or the other, or keep only those in both data-sets etc. \n\n```{r echo=FALSE, fig.cap=\"Check out the help documentation for them all using `?full_join`.\"}\nknitr::include_graphics(\"images/messy/joins.png\")\n```\n\n`r qbegin(qcounter())`\n**Problem**  \nVariables are in different data-sets.  \n\n**Task**  \n\n1. Join the two data-sets (the reshaped-to-long **blink_setup.csv** data, and the **blink_eyegaze.xlsx** data) together, and store the joined data in a new object (you can use your own name, but the solutions will use the name `blinks_full`).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n\nWe want to match the observations based on two columns which are present in each data-set, indicating which participant, and which trial.  \n  \n+ Remember that R doesn't have your intelligence - it doesn't *know* that in one data-set the variable is called e.g., `trial_no` and in the other it is called `trial_number`.  \n+ Another thing which R doesn't know is that \"subject_1\" in setup data is the same participant as \"1\" in the eye gaze data. It needs to match the same symbols, and what is more, it needs the variables to be *the same type* (character, numeric, factor etc).   \n  - you might want to make use of the skills you learned for manipulating character strings.  \n  \n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nIn this solution, let's build up a sequence step by step. Work through the steps, adding lines of code each time. Between each step, run the code to quickly see what the output looks like at each step.   \n\n1. First, let's see how we can remove the \"subject_\" from \"subject_1\" etc.. \n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = gsub(\"subject_\",\"\",sub)\n  )\n```\n2. But we also want it to be numeric, to match the `sub` variable in the eyegaze data, so let's edit it to:\n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub))\n  )\n```\n3. We'll also need to do the same for the `trial_number` variable, so let's add that line too:\n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  )\n```\n4. And then, we'll note that we need to have the same name for variables indicating trial number in both data-sets, so lets rename it:\n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) |>\n  rename(trial_no = trial_number)\n```\n5. And now... add the join! \n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) |>\n  rename(trial_no = trial_number) |>\n  full_join(x = _, y = eyedata)\n```\n  **NOTE** the solution has `x = _, y = eyedata` to make it clear that we are 'piping in' (using `|>`) the thing coming out of the previous lines of code, and putting it where the `_` is. `.... |> full_join(eyedata)` would do the same.   \n  \nWe use `full_join` here because we want to keep all the data, but `left_join` would do the same. `right_join` would be slightly different, because there are 3 observations in the setup data (when reshaped to long, n = 460) which aren't in the eye gaze data (n = 457). You can see which ones they are by using `anti_join`.  \n  \n  \n6. Finally - we need to give the whole output a name to store it in our environment! \n\n```{r}\nblinks_full <- \n  setuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) |>\n  rename(trial_no = trial_number) |>\n  full_join(x = _, y = eyedata)\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Impossible Values \n\nIt's important to check that there are no values in the data which are impossible, given what you know about how the data was measured. This is where exploratory plots and descriptive statistics come in handy.\n\n```{r}\nhist(as.numeric(blinks_full$distractor_fix))\n```\n\nIn some trials, participants spent less that 0ms fixating on the distractor object!?!?!?\n\nWe have a couple of options as to how to deal with them.  \n\n1. Delete the entire row\n2. Change the specific entry/s in that variable to be `NA` (Not Applicable) - this has the benefit of keeping the rows should we consider those row to have a valid observation in other variables (for instance the `rt` - reaction time?)    \n\nSome of the tools we learned in the [Reading 1B](01b_data.html) will come in handy here. \n\n`r qbegin(qcounter())`\n**Problem**  \nSome impossible values in the `distractor_fix` variable.  \n\n**Task**  \n- Assign the entries of the `distractor_fix` variable which are < 0 to be `NA`.  \n- Are there any other impossible values (or combinations of values) in the data?\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n\n- While you're there, why not convert any variables to the right type (numeric, factor, etc).  \n- We might not have come across this before, but there is a really useful function called `ifelse()`.  \n    Play around with the below code to learn:\n```{r eval=FALSE}\ntibble(x = 1:10) |>\n  mutate(\n    new_variable = ifelse(x>5,1,0),\n    another_new_variable = ifelse(x>5,\"peppapig\",\"kermit\"),\n    morevariables = ifelse(another_new_variable == \"kermit\",\"kermit the frog\", another_new_variable)\n  )\n```\n  \n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nBelow we've taken similar steps for both the `distractor_fix` and `rt` variables. Neither can be <0 or >5000.  \nHowever, we know that the `distractor_fix` variable has no entries >5000 (because of the histogram above).  \n```{r}\nblinks_full <- \n  blinks_full |>\n  mutate(\n    distractor_fix = as.numeric(distractor_fix),\n    distractor_fix = ifelse(distractor_fix<0, NA, distractor_fix),\n    rt = ifelse(as.numeric(rt)>5000 | as.numeric(rt)<0, NA, as.numeric(rt))\n  )\n```\nNote how two steps (making it numeric, and replacing values with `NA`s) are combined for the `rt` variable. Note also how we have specified that we replace with `NA`s entries which meet either on condition (>5000) **or** (using `|`) another (<0). \n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Missing Data in R\n\nMissing data can be a big problem for statistics. For those of you thinking of taking Multivariate Statistics & Methodology in R next semester, you can look forward to discussions around this sort of issue.  \n\nHere, however, we are simply going to discuss the practicalities of how to make R code work when some of your values are `NA`s. \n\nConsider:  \n```{r}\nvec <- c(1,2,3,4,NA)\nmean(vec)\n```\nThink about why this is:\n$$\n\\text{mean(vec)} = \\frac{1+2+3+4+\\text{NA}}{5} = \\frac{\\text{??}}{5} = \\text{??}\n$$\nThere are numerous different ways that functions in R cope with missing values, but if you're ever in doubt, try `na.rm = TRUE`. This will basically tell R to \"remove the NAs before doing the calculation\".  \n```{r}\nmean(vec, na.rm=T)\n```\n\nOther functions include `na.omit()`, which remove any row with has an `NA` anywhere in it:\n```{r eval=FALSE}\ncomplete_data <- na.omit(data)\n```\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Outliers  \n\n*Outliers* are the extreme - but plausible - values in variables. \nThere is no one way to identify what is extreme enough to consider and outlier, nor is there one way to handle them.   \nSome outliers could be considered important observations which we would not want to exclude. However, being an outlier *can* (but not always) result in an observation exerting too great an influence on our analysis.  \n\n:::statbox\nSome common approaches to identifying outliers:  \n\n+ observations which are $> 3$ (sometimes $> 2.5$) standard deviations away from the mean.\n+ observations greater than $1.5 \\times IQR$ below the first quartile $Q_1$ or above the third quartile $Q_3$.  \n\nSome common approaches to handling outliers:\n\n+ Exclude now - for instance, set as NA\n+ \"Winsorize\" -  set to a specified percentile. For example, all observations below the 5th percentile set to the 5th percentile, and all observations above the 95th percentile set to the 95th percentile\n+ Exclude from analysis later, based on measures of influence (we'll learn about this in future topics)  \n\n:::\n\n\n`r qbegin(qcounter())`\nMake a bloxplot of the `distractor_fix` variable. Does it look like there might be any outliers? \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nThe last line of this is there just because I personally don't like the default look of `geom_boxplot` where it is really wide, so this line changes the limits of the x-axis (and also removes the ticks). \n```{r}\nggplot(data = blinks_full, aes(y = distractor_fix)) +\n  geom_boxplot()+\n  scale_x_continuous(limits = c(-2,2), breaks = NULL)\n```\n\nIt looks like there are possibly some outliers at the upper end of the distribution. One of them looks really quite anomalous! \n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Custom Functions\n\n`r qbegin(qcounter())`\n**Writing your own function**    \n  \nWe already saw some custom functions in the first week, where we made some called `dice()` and `wdice()`.   \nCan you write a function which, given a vector, returns TRUE if it is an outlier and FALSE if it is not, based on the criterion of being $>3$ sd away from the mean.  \n\n```{r eval=FALSE}\noutliers <- function(obs){\n ...\n ...\n ...\n}\n```\n\n`r qend()`\n\n`r solbegin(label=\"Solution Part 1 - Working out the internal code\",slabel=FALSE,show=params$TOGGLE, toggle=params$TOGGLE)`\n\nLet's do the calculation on a little vector, keeping it all outside of a function first:  \n```{r}\n# a random vector (length = 20)\nvec <- rnorm(n = 20, mean = 0, sd = 1)\n# pick two random entries and make them outliers (one in each direction)\nvec[3] <- 150\nvec[16] <- -150\nvec\n\n# deviations from each point to mean\nvec - mean(vec)\n# and three times the standard deviation\n3 * sd(vec)\n\n# but this won't work because some are below, rather than above the mean. \n(vec - mean(vec)) > (3 * sd(vec))\n# instead we want the ABSOLUTE value \nabs(vec - mean(vec)) > (3 * sd(vec))\n```\n\n`r solend()`  \n\n`r solbegin(label=\"Solution Part 2 - Writing it as a function\",slabel=FALSE,show=params$TOGGLE, toggle=params$TOGGLE)`\n\nOkay, now that we've worked out the code, we want to make this a function. The template function in the question had an input called `obs`:\n```{r eval=FALSE}\noutliers <- function(obs){\n\n}\n```\nSo we would want to add our code to the function, but change it to use `obs` (which is whatever we give the function)\n```{r}\noutliers <- function(obs){\n  abs(obs - mean(obs)) > (3 * sd(obs))\n}\n```\n\n\n`r solend()`  \n\n`r solbegin(label=\"Solution Part 3 - Testing the function\",slabel=FALSE,show=params$TOGGLE, toggle=params$TOGGLE)`\n\nwe can test it on the `vec` object we created earlier. \n```{r}\noutliers(obs = vec)\n```\n\nWe can use it to access and edit those entries:\n```{r}\nvec[outliers(vec)]\nvec[outliers(vec)] <- NA\n```\n\n`r solend()`  \n\n`r solbegin(label=\"Extra - Adding more arguments\",slabel=FALSE,show=params$TOGGLE, toggle=params$TOGGLE)`\n\nWe could edit the function so that we can also vary how many standard deviations away we are wanting to identify!\n```{r}\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs)) > (x * sd(obs))\n}\n```\nthe `x = 3` means that the function will default to looking 3 standard deviations away, but if we wanted to use `outliers(obs = vec, x = 2)` we could identify those which are 2 away!   \n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\nLook through the solutions to the question above, and make sure that you are comfortable with how writing a function works.  \n\nCan you edit the `outliers()` function you wrote to make it work with vectors which include `NA`s?  \n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n```{r}\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs, na.rm=TRUE)) > (x * sd(obs, na.rm=TRUE))\n}\n```\n`r solend()`\n\n`r qbegin(qcounter())`\n\n**Problem**  \nPossible outliers in the `distractor_fix` variable. \n\n**Task**  \n\n1. Replace any values of the `distractor_fix` variable which are $>3$ standard deviations from the mean with `NA`.  \n2. Make a new boxplot of the variable\n\n::: {.callout-note collapse=\"true\"}\n#### If you skipped questions `r qcounter_i-2` and `r qcounter_i-1`  \n\nIf you skipped the last couple of questions, then copy and run this code into your document.  \n\nIt will give you a function which takes a vector and returns TRUEs and FALSEs based on whether each entry is greater than 3 standard deviations from the mean. \n```{r}\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs, na.rm=TRUE)) > (x * sd(obs, na.rm=TRUE))\n}\n```\n:::\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nblinks_full$distractor_fix[outliers(blinks_full$distractor_fix)]<- NA\n\nggplot(data = blinks_full, aes(y = distractor_fix)) +\n  geom_boxplot()+\n  scale_x_continuous(limits = c(-2,2), breaks = NULL)\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Summary plots  \n\nSo where are we now? \nWe have a dataset that has one row per trial per subject, and it contains information on the number of blinks, and on the time spent looking at the distractor:\n\n```{r}\nhead(blinks_full)\n```\nThinking _way back_ to the top of this page, we recall that our research question is concerned with whether perceived lying (as implied by more looking at the distractor) increases with the number of blinks seen.  \n\nSo we might start by plotting those two variables:\n```{r}\nggplot(blinks_full, aes(x=nr_blinks, y = distractor_fix))+\n  geom_point()\n```\n\nIt's hard to see a pattern clearly here, so we're going to introduce a handy part of **ggplot**.  The `stat_summary()` function allows us to plot _summarised data_ (i.e. the mean of the y-variable), rather than the data itself. If we choose to plot it as a \"pointrange\", it gives us the mean and standard error for $y$ across each level of $x$:    \n```{r}\n#| fig-height: 2.5\nggplot(blinks_full, aes(x = nr_blinks, y = distractor_fix)) +\n  stat_summary(geom = \"pointrange\")\n```\n\nThis is the same as doing some grouping and summarising first, and then giving those summarised values to the plot: \n```{r}\n#| fig-height: 2.5\nblinks_full |>\n  group_by(nr_blinks) |>\n  summarise(mean = mean(distractor_fix, na.rm=TRUE),\n            se = sd(distractor_fix, na.rm=TRUE)/sqrt(n()),\n            lwr = mean-se,\n            upr = mean+se\n            ) |>\n  ggplot(aes(x = nr_blinks, y = mean, ymin = lwr, ymax = upr)) +\n  geom_pointrange()\n```\n\n# Build a model!\n\nWe're now finally getting to the analysis. As we said earlier, this can sometimes be very straightforward in comparison to the amount of effort involved in cleaning data.\n\nRecall that we're interested in whether the perception of whether or not a speaker is lying about the location of some hidden treasure (as measured by the pattern of eye fixations towards the object *not* referred to by the speaker) is influenced by the number of times the speaker is seen to blink while producing the utterance.  \n\n`r qbegin(qcounter())`\nFit the linear model specified below to the data using the `lm()` function and store the output in the environment as an object named `blinks_mdl`.\n\n$$\n\\begin{align}\n& \\text{Fixation time to distractor} = b_0 + b_1 \\ \\text{Number of blinks} + \\epsilon \\\\\n\\quad \\\\\n& \\text{where} \\quad \\\\\n& \\epsilon \\sim N(0, \\sigma) \\text{ independently}\n\\end{align}\n$$\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nblinks_mdl <- lm(distractor_fix ~ 1 + nr_blinks, data=blinks_full)\n\nsummary(blinks_mdl)\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nThe $\\epsilon \\sim N(0, \\sigma) \\text{ independently}$ bit of our model is an assumption we have to make. It concerns the errors (the deviations from observations to our line). Our model assumes that these are normally distributed and centered on 0.\nWe can plot the distribution of residuals to check how well our assumption holds:\n```{r}\n#| fig-height: 2.5\nhist(residuals(blinks_mdl))\n```\n\nHowever, we also make the assumption that the errors are __independent__ - i.e. they are not related to one another.\n\nFor us, this is _not_ the case, and so we should not be using this simple linear regression here.\n\nIn what way are we violating the assumption of independence?\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe dataset to which we are fitting our model does not contain _independent_ observations. We have multiple observations from each participant. i.e. Subject 1 makes up 20 rows, and subject 2 makes up 20 rows.  \n\n\n__Independence of observations__ is actually an assumption that is relied upon by all the tests that we cover in this course. So we can't actually perform an analysis on this data as it is!! We will learn about how to deal with this sort of study design next semester, in the _Multivariate Statistics & Methodoligy using R (MSMR)_ course.  \n\n\nOne option open to us now is to simply \"aggregate up\", so that we remove the dependence from our rows in our dataset. However, this means reducing the number of rows. This is sub-optimal (and we'll see why next semester!), but we can calculate the average `distractor_fix` for each level of `nr_blinks`, and then use _those_ in our model.  \n\nWe can do this the same way as we saw with our summary plots - with `group_by()` and `summarise()`!  \n\n```{r}\nblinks_agg <- blinks_full |>\n  group_by(nr_blinks) |>\n  summarise(\n    meanDF = mean(distractor_fix, na.rm=TRUE)\n  )\nhead(blinks_agg)\n```\n\nOne obvious disadvantage here is that we are going from _loads_ of datapoints to only 10! Furthermore, because of some of the missing data, each of these 10 datapoints is estimated from a slightly different number of trials, and from a slightly different set of participants. Our final model is really just a very simple line fitted to 10 datapoints, but this is pretty far away from modelling how these values actually came to arise in the real world! \n\n```{r}\nggplot(blinks_agg, aes(x = nr_blinks, y = meanDF)) +\n  geom_point() +\n  geom_smooth(method=lm)\n```\n\nBut we can still get some useful linear approximation of the pattern - avg look at the distractor increase by 64ms for every additional blink in the video!  \n\n```{r}\nmod <- lm(meanDF ~ nr_blinks, data = blinks_agg)\n\nsummary(mod)\n```\n\n`r solend()`\n\n\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>\n","srcMarkdownNoYaml":"\n\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\nset.seed(017)\n```\n\nIn many projects (both in academic research & in other sectors), more time will be spent cleaning and organising data than will actually be spent conducting statistical analyses (a well designed study with a well-thought through data collection process can go a long way to remedy this!).\n\nFor this reason, we're going to take a little detour away from statistics to get some more practice wrangling and cleaning data in R. Don't worry about the trying to remember all of the new R functions introduced in this topic - there are a lot. Use them as a means of learning about some of the different ways of doing things in R.    \n  \n\n:::frame\n__Study Background & Data__  \n\nThe data we're going to look at now is from an experiment on language comprehension, looking at whether people perceive blinking as a sign of lying. \n\n> **Research Question:** Is the rate of blinking during speech interpreted as a sign of dishonesty (in the context of a lie-detection game)?  \n\nParticipants were informed that they were going to take part in a lie-detection game. They were presented with audiovisual recordings of a speaker stating behind which of two objects (displayed on screen) there was hidden treasure. Utterances took the form of \"The treasure is behind the [target name]\".   \nOver 20 trials, participants were tasked with using the mouse to click on the object *they believed* the treasure to be behind. They were told that the speaker in the video was attempting to mislead them, meaning that sometimes they told the truth, and sometimes they lied. \nCrucially, in the videos presented of the speaker producing the utterances, we manipulated the number of times the speaker blinked (from 1 to 10 times). \nParticipants eyes were tracked for the duration of the experiment, with the time spent looking at either object taken as an implicit indication of perceiving a truthful utterance (in which the participant looks at and clicks on the 'target object' (the one identified by the speaker as hiding the treasure)) or a dishonest one (in which the participant would look at and click on the alternative 'distractor' object).\n\n<center>**blink_setup.csv**</center>    \nThe data from the experimental design are available at [https://uoepsy.github.io/data/blink_setup.csv](https://uoepsy.github.io/data/blink_setup.csv). In this data, each participant is a row, and the information about what video is presented in each trial are presented in separate columns for each trial. The first bit of the data looks like this: \n```{r echo=FALSE}\nlibrary(tidyverse)\nlibrary(readxl)\n\ndownload.file('https://uoepsy.github.io/data/blink_eyegaze.xlsx', 'data/blink_eyegaze.xlsx', mode=\"wb\")\neyedata <- read_excel(path = 'data/blink_eyegaze.xlsx')\n\nsetupdata <- read_csv(\"https://uoepsy.github.io/data/blink_setup.csv\", col_names = FALSE)\nhead(setupdata)[,1:4] |>\n  cbind(`...` = rep(\"...\",6)) |>\n  rbind(\"...\") |> rbind(\"...\") |> \n  knitr::kable(col.names = NULL)\n```\n\n<center>**blink_eyegaze.xlsx**</center>    \nThe data from the eye-tracker, which has been processed to show the proportion of time spent looking at the distractor object in each trial, can be found at [https://uoepsy.github.io/data/blink_eyegaze.xlsx](https://uoepsy.github.io/data/blink_eyegaze.xlsx). In contrast to the blink_setup.csv data, in this data each trial is a row, so we have 20 rows per participant.  \n```{r echo=FALSE}\ncbind(variable_names = names(eyedata),\n      description = c(\"Participant number\",\"Trial number\",\"Time spent looking at distractor object (measured in milliseconds from onset of noun phrase)\",\"Time taken to click on an object (measured in milliseconds from the onset of the noun phrase\")) |>\n    knitr::kable()\n```\nThe top of the data looks like this:\n```{r echo=FALSE}\nhead(eyedata) |>\n  rbind(\"...\") |> rbind(\"...\") |> \n  knitr::kable()\n```\n:::\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Different Data Formats\n\nData can come in lots of different formats, meaning that we need lots of different ways to read data into R. Below is some information on some of the more common functions for reading and writing different types of data. \n\n\n**Text based files**\n\n|  filetype|  description|  reading| writing|\n|:--|:--|--:|--:|\n|  .csv|  comma separated values|  tidyverse - `read_csv()`<br>`read.csv()`<br>`read.table(..., sep = \",\")`| tidyverse - `write_csv()`<br>`write.csv()`<br>`write.table(..., sep=\",\")`|\n|  .tsv|  tab separated values|  tidyverse - `read_tsv()`<br>`read.table(..., sep = \"\\t\")`| tidyverse - `write_tsv()`<br>`write.table(..., sep = \"\\t\")`|\n|  .txt|  anything-separated values!|  `read.table(..., sep = ...)`| `write.table(..., sep = ...)`|\n\n\n**R files**  \n  \n|  filetype|  description|  reading| writing|\n|:--|:--|--:|--:|\n|  .RDS|  1 file = a single R object|  `readRDS()`| `saveRDS()` |\n|  .RData| 1 file = a collection of R objects|  `load()`| `save()`<br>`save.image()` - to save all objects in the environment) |\n  \n**Excel files**  \nThe package **readxl** provides a variety of functions for reading in different types of Microsoft Excel spreadsheet, such as `read_excel()`, `read_xls()`, `read_xlsx()`.  \n\n**Other software**  \nThe package **haven** provides functions for files which have been saved from other statistical software, for instance with `read_spss()`/`read_sav()` and `read_sas()` for files from SPSS and SAS.  \n\n**Google sheets**  \nThe **googlesheets4** package can read in data directly from a spreadsheet stored on google drive. You simply find the *id* of the sheet (it's the big long string of numbers & letters in the url of your google sheet), and pass it to `read_sheet()`.  \nIt will prompt you to authenticate your account via your browser, but it's really easy!  \n\n`r qbegin(qcounter())`\nRead in the two data-sets. Take care to look at the file extension (e.g., **.csv**, **.tsv**, **.xlsx**) as indicators of what function to try.  \nMake sure you assign them identifiable names.  \nOnce you've loaded the data-set, take a look at them using functions like `summary()`, `str()`, `dim()`/`nrow()`, or viewing them by clicking on them in the environment. \n  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- Some functions like `read_excel()` don't allow you to download directly from a url, like we have been doing with __.csv__ files.  \n  - Solution 1:\n    - Download the data to your computer\n    - upload to the rstudio server if you are using it\n    - Direct the function to read it from the place you stored it. \n  - Solution 2: \n    - Make R download the data directly to somewhere in your working directory (see `download.file()`). \n- Do both the data-sets have column names? By default R will assume the first row is the name of the column. Look in the help documentation to see how to stop this from happening.  \n\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(tidyverse)\nlibrary(readxl)\n\ndownload.file('https://uoepsy.github.io/data/blink_eyegaze.xlsx', 'blink_eyegaze.xlsx', mode=\"wb\")\neyedata <- read_excel(path = 'blink_eyegaze.xlsx')\n\nsetupdata <- read_csv(\"https://uoepsy.github.io/data/blink_setup.csv\", col_names = FALSE)\n```\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Renaming Columns  \n\nYou can access the column names from a data-set using `names()` or `colnames()`. \n```{r eval=FALSE}\nnames(data)\ncolnames(data)\n```\nAnd we can easily rename these using indexing:\n```{r eval=FALSE}\n#name the third column \"peppapig\"\nnames(data)[3]<-\"peppapig\"\n```\nOr in tidyverse, using `rename()`:\n```{r eval=FALSE}\ndata |>\n  rename(newname = currentname)\n```\n\n`r qbegin(qcounter())`\n**Problem**  \n\nThe *blink_setup.csv* file doesn't have any column names!  \nWe know that there are 20 trials for each participant, and we can see that the 2nd column has information about which subject it is.  \nColumns 3:22 are trials 1 to 20.  \n\n```{r eval=FALSE}\nhead(setupdata)\n```\n```{r echo=FALSE}\nhead(setupdata)[,1:3] |>\n  cbind(`...` = rep(\"...\",6)) |>\n  rbind(\"...\") |> rbind(\"...\")\n```\n\n**Task**\n\n1. Remove the first column\n2. Rename columns 2 to 22 with sensible names. \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n```{r eval=FALSE}\nnames(setupdata) # what are the names\nnames(setupdata)[2] # what is the 2nd name\nnames(setupdata) <- c(\"...\", \"...\", \"...\",..) # set the names\n```\n```{r}\nc(\"kermit\", paste(\"peppapig\", 1:3, sep=\"_\"))\n```\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nremove the first column\n```{r}\nsetupdata <- setupdata[,-1]\n```\nSet the names\n```{r}\nnames(setupdata) <- c(\"sub\",paste(\"trial\", 1:20, sep = \"_\"))\n```\n\nCheck:\n```{r eval=FALSE}\nhead(setupdata)\n```\n```{r echo=FALSE}\nhead(setupdata)[,1:2] |>\n  cbind(`...` = rep(\"...\",6)) |>\n  rbind(\"...\") |> rbind(\"...\")\n```\n\n`r solend()`\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Reshaping data \n\n**Pivot!**  \n\nOne of the more confusing things to get to grips with is the idea of reshaping a dataframe.  \nFor different reasons, you might sometimes want to have data in wide, or in long format. \n\n```{r echo=FALSE, fig.cap=\"Source: https://fromthebottomoftheheap.net/2019/10/25/pivoting-tidily/\"}\nknitr::include_graphics(\"https://www.fromthebottomoftheheap.net/assets/img/posts/tidyr-longer-wider.gif\")\n```\n\nWhen the data is wide, we can make it long using `pivot_longer()`. When we make data longer, we're essentially making lots of columns into 2 longer columns. Above, in the animation, the wide variable **x**, **y** and **z** go into a new longer column called **name** that specifies which (x/y/z) it came from, and the values get put into the **val** column.  \n\nThe animation takes a shortcut in the code it displays above, but you could also use `pivot_longer(c(x,y,z), names_to = \"name\", values_to = \"val\")`. To reverse this, and put it back to being wide, we tell R which columns to take the names and values *from*: `pivot_wider(names_from = name, values_from = val)`.  \n\n`r qbegin(qcounter())`\n**Problem**  \nThe *blink_setup.csv* file has the data in a different shape to the *blink_eyegaze.xlsx* file.  \n  \n- *blink_setup.csv* : one row per participant  \n- *blink_eyegaze.xlsx* : one row per trial  \n  \n**Task** \n\nReshape the data to make it so that there is one row per trial.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n\n- in the tidyverse functions, you can specify all columns between column **x** and column **z** by using the colon, `x:z`.  \n\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n(Note that this will depend on what you called your columns in the previous question - we just called them \"trial_1\", ... , \"trial_20\"). \n\n```{r}\nsetuplong <- \n  setupdata |>\n  pivot_longer(trial_1:trial_20, names_to = \"trial_number\", values_to = \"video\")\n\nsetuplong\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Dealing with character strings\n\nThere are loads of functions we can use to do various things with character strings in R.  \nHere are a few examples:\n\n\n::: {.callout-note collapse=\"true\"}\n#### gsub() - substitute a string of characters for another string\n\n\n```{r}\ngsub(\"don't like\",\"love\", \"i really really really don't like statistics!\")\n```\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### separate() - separate a column into multiple columns by splitting at a set of characters\n\n```{r}\nmupsimp <- read_csv(\"https://uoepsy.github.io/data/muppet_simp.csv\")\nmupsimp\n\nmupsimp |> \n  separate(show_name, into = c(\"show\",\"name\"), sep = \"_\")\n```\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### substr() - extract or replace substrings in a character vector\n\n```{r}\n# get the first 3 letters\nsubstr(mupsimp$show_name, 1, 3)\n```\n\nCan be combined with functions like `nchar()` (to find the number of characters in each string). Additionally, can be used in tidyverse easily:\n```{r}\nmupsimp |>\n  mutate(\n    first3 = substr(show_name, 1, 3),\n    last3 = substr(show_name, nchar(show_name)-2, nchar(show_name))\n  )\n```\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### paste() - quickly combine two character vectors\n\n```{r}\npaste(\"hello\",\"everyone\",sep=\" \")\n```\nYou can also use it to *collapse* a vector into a single string:\n```{r}\npaste(mupsimp$show_name, collapse=\" \")\n```\nand `paste0()` is a quick shortcut for using `sep=\"\"`:\n```{r}\npaste0(\"hello\",\"everyone\")\n```\n\n:::\n\n`r qbegin(qcounter())`\n**Problem**   \nIf you look at what data was captured by the software to indicate which video was used in each trial, there is a lot of unnecessary data there. The number of the filename indicates how many blinks are in the video. This is the only bit of information we want.   \n```{r}\nhead(setuplong$video)\n```\n**Task** \n\n- In your (now reshaped to long) **blink_setup.csv** data, make a new, or edit an existing column, which is a *numeric* variable containing the number of blinks presented in the video in each trial  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n  \n\n- there are lots of different ways you could do this.  \n- you can substitute out multiple different strings by separating them with the `|` symbol:\n```{r}\n  gsub(\"dog|cat\", \"horse\", \"I have a dog and a cat and the dogs name is Graham\")\n```\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nsetuplong <- setuplong |>\n  mutate(\n    nr_blinks = as.numeric(gsub(\"/files/vids/|blinks_|blinsk_|.mp4\",\"\",video))\n  )\n\nsetuplong\n```\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Joining/merging\n\nNow comes a fun bit.  \nRecall that the research question is interested in the relationship between the number of times the speaker was seen to blink, and the time the participants spent looking at the distractor object (indicating perceived dishonesty).  \nYou may have noticed that these variables are currently in different data-sets! The **blink_setup.csv** contains information about the numbers of blinks in the videos, and the **blink_eyegaze.xlsx** contains the data on the fixations. \n  \nSolution: we need to join them together!  \n\nNote that because both data-sets contain information on participant number and trial number, which uniquely identifies each observation, we can join them together matching on these variables!  \n\nThere are lots of different ways to join data-sets, depending on whether we want to keep rows from one data-set or the other, or keep only those in both data-sets etc. \n\n```{r echo=FALSE, fig.cap=\"Check out the help documentation for them all using `?full_join`.\"}\nknitr::include_graphics(\"images/messy/joins.png\")\n```\n\n`r qbegin(qcounter())`\n**Problem**  \nVariables are in different data-sets.  \n\n**Task**  \n\n1. Join the two data-sets (the reshaped-to-long **blink_setup.csv** data, and the **blink_eyegaze.xlsx** data) together, and store the joined data in a new object (you can use your own name, but the solutions will use the name `blinks_full`).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n\nWe want to match the observations based on two columns which are present in each data-set, indicating which participant, and which trial.  \n  \n+ Remember that R doesn't have your intelligence - it doesn't *know* that in one data-set the variable is called e.g., `trial_no` and in the other it is called `trial_number`.  \n+ Another thing which R doesn't know is that \"subject_1\" in setup data is the same participant as \"1\" in the eye gaze data. It needs to match the same symbols, and what is more, it needs the variables to be *the same type* (character, numeric, factor etc).   \n  - you might want to make use of the skills you learned for manipulating character strings.  \n  \n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nIn this solution, let's build up a sequence step by step. Work through the steps, adding lines of code each time. Between each step, run the code to quickly see what the output looks like at each step.   \n\n1. First, let's see how we can remove the \"subject_\" from \"subject_1\" etc.. \n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = gsub(\"subject_\",\"\",sub)\n  )\n```\n2. But we also want it to be numeric, to match the `sub` variable in the eyegaze data, so let's edit it to:\n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub))\n  )\n```\n3. We'll also need to do the same for the `trial_number` variable, so let's add that line too:\n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  )\n```\n4. And then, we'll note that we need to have the same name for variables indicating trial number in both data-sets, so lets rename it:\n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) |>\n  rename(trial_no = trial_number)\n```\n5. And now... add the join! \n```{r eval=FALSE}\nsetuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) |>\n  rename(trial_no = trial_number) |>\n  full_join(x = _, y = eyedata)\n```\n  **NOTE** the solution has `x = _, y = eyedata` to make it clear that we are 'piping in' (using `|>`) the thing coming out of the previous lines of code, and putting it where the `_` is. `.... |> full_join(eyedata)` would do the same.   \n  \nWe use `full_join` here because we want to keep all the data, but `left_join` would do the same. `right_join` would be slightly different, because there are 3 observations in the setup data (when reshaped to long, n = 460) which aren't in the eye gaze data (n = 457). You can see which ones they are by using `anti_join`.  \n  \n  \n6. Finally - we need to give the whole output a name to store it in our environment! \n\n```{r}\nblinks_full <- \n  setuplong |>\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) |>\n  rename(trial_no = trial_number) |>\n  full_join(x = _, y = eyedata)\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Impossible Values \n\nIt's important to check that there are no values in the data which are impossible, given what you know about how the data was measured. This is where exploratory plots and descriptive statistics come in handy.\n\n```{r}\nhist(as.numeric(blinks_full$distractor_fix))\n```\n\nIn some trials, participants spent less that 0ms fixating on the distractor object!?!?!?\n\nWe have a couple of options as to how to deal with them.  \n\n1. Delete the entire row\n2. Change the specific entry/s in that variable to be `NA` (Not Applicable) - this has the benefit of keeping the rows should we consider those row to have a valid observation in other variables (for instance the `rt` - reaction time?)    \n\nSome of the tools we learned in the [Reading 1B](01b_data.html) will come in handy here. \n\n`r qbegin(qcounter())`\n**Problem**  \nSome impossible values in the `distractor_fix` variable.  \n\n**Task**  \n- Assign the entries of the `distractor_fix` variable which are < 0 to be `NA`.  \n- Are there any other impossible values (or combinations of values) in the data?\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n\n- While you're there, why not convert any variables to the right type (numeric, factor, etc).  \n- We might not have come across this before, but there is a really useful function called `ifelse()`.  \n    Play around with the below code to learn:\n```{r eval=FALSE}\ntibble(x = 1:10) |>\n  mutate(\n    new_variable = ifelse(x>5,1,0),\n    another_new_variable = ifelse(x>5,\"peppapig\",\"kermit\"),\n    morevariables = ifelse(another_new_variable == \"kermit\",\"kermit the frog\", another_new_variable)\n  )\n```\n  \n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nBelow we've taken similar steps for both the `distractor_fix` and `rt` variables. Neither can be <0 or >5000.  \nHowever, we know that the `distractor_fix` variable has no entries >5000 (because of the histogram above).  \n```{r}\nblinks_full <- \n  blinks_full |>\n  mutate(\n    distractor_fix = as.numeric(distractor_fix),\n    distractor_fix = ifelse(distractor_fix<0, NA, distractor_fix),\n    rt = ifelse(as.numeric(rt)>5000 | as.numeric(rt)<0, NA, as.numeric(rt))\n  )\n```\nNote how two steps (making it numeric, and replacing values with `NA`s) are combined for the `rt` variable. Note also how we have specified that we replace with `NA`s entries which meet either on condition (>5000) **or** (using `|`) another (<0). \n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Missing Data in R\n\nMissing data can be a big problem for statistics. For those of you thinking of taking Multivariate Statistics & Methodology in R next semester, you can look forward to discussions around this sort of issue.  \n\nHere, however, we are simply going to discuss the practicalities of how to make R code work when some of your values are `NA`s. \n\nConsider:  \n```{r}\nvec <- c(1,2,3,4,NA)\nmean(vec)\n```\nThink about why this is:\n$$\n\\text{mean(vec)} = \\frac{1+2+3+4+\\text{NA}}{5} = \\frac{\\text{??}}{5} = \\text{??}\n$$\nThere are numerous different ways that functions in R cope with missing values, but if you're ever in doubt, try `na.rm = TRUE`. This will basically tell R to \"remove the NAs before doing the calculation\".  \n```{r}\nmean(vec, na.rm=T)\n```\n\nOther functions include `na.omit()`, which remove any row with has an `NA` anywhere in it:\n```{r eval=FALSE}\ncomplete_data <- na.omit(data)\n```\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Outliers  \n\n*Outliers* are the extreme - but plausible - values in variables. \nThere is no one way to identify what is extreme enough to consider and outlier, nor is there one way to handle them.   \nSome outliers could be considered important observations which we would not want to exclude. However, being an outlier *can* (but not always) result in an observation exerting too great an influence on our analysis.  \n\n:::statbox\nSome common approaches to identifying outliers:  \n\n+ observations which are $> 3$ (sometimes $> 2.5$) standard deviations away from the mean.\n+ observations greater than $1.5 \\times IQR$ below the first quartile $Q_1$ or above the third quartile $Q_3$.  \n\nSome common approaches to handling outliers:\n\n+ Exclude now - for instance, set as NA\n+ \"Winsorize\" -  set to a specified percentile. For example, all observations below the 5th percentile set to the 5th percentile, and all observations above the 95th percentile set to the 95th percentile\n+ Exclude from analysis later, based on measures of influence (we'll learn about this in future topics)  \n\n:::\n\n\n`r qbegin(qcounter())`\nMake a bloxplot of the `distractor_fix` variable. Does it look like there might be any outliers? \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nThe last line of this is there just because I personally don't like the default look of `geom_boxplot` where it is really wide, so this line changes the limits of the x-axis (and also removes the ticks). \n```{r}\nggplot(data = blinks_full, aes(y = distractor_fix)) +\n  geom_boxplot()+\n  scale_x_continuous(limits = c(-2,2), breaks = NULL)\n```\n\nIt looks like there are possibly some outliers at the upper end of the distribution. One of them looks really quite anomalous! \n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Custom Functions\n\n`r qbegin(qcounter())`\n**Writing your own function**    \n  \nWe already saw some custom functions in the first week, where we made some called `dice()` and `wdice()`.   \nCan you write a function which, given a vector, returns TRUE if it is an outlier and FALSE if it is not, based on the criterion of being $>3$ sd away from the mean.  \n\n```{r eval=FALSE}\noutliers <- function(obs){\n ...\n ...\n ...\n}\n```\n\n`r qend()`\n\n`r solbegin(label=\"Solution Part 1 - Working out the internal code\",slabel=FALSE,show=params$TOGGLE, toggle=params$TOGGLE)`\n\nLet's do the calculation on a little vector, keeping it all outside of a function first:  \n```{r}\n# a random vector (length = 20)\nvec <- rnorm(n = 20, mean = 0, sd = 1)\n# pick two random entries and make them outliers (one in each direction)\nvec[3] <- 150\nvec[16] <- -150\nvec\n\n# deviations from each point to mean\nvec - mean(vec)\n# and three times the standard deviation\n3 * sd(vec)\n\n# but this won't work because some are below, rather than above the mean. \n(vec - mean(vec)) > (3 * sd(vec))\n# instead we want the ABSOLUTE value \nabs(vec - mean(vec)) > (3 * sd(vec))\n```\n\n`r solend()`  \n\n`r solbegin(label=\"Solution Part 2 - Writing it as a function\",slabel=FALSE,show=params$TOGGLE, toggle=params$TOGGLE)`\n\nOkay, now that we've worked out the code, we want to make this a function. The template function in the question had an input called `obs`:\n```{r eval=FALSE}\noutliers <- function(obs){\n\n}\n```\nSo we would want to add our code to the function, but change it to use `obs` (which is whatever we give the function)\n```{r}\noutliers <- function(obs){\n  abs(obs - mean(obs)) > (3 * sd(obs))\n}\n```\n\n\n`r solend()`  \n\n`r solbegin(label=\"Solution Part 3 - Testing the function\",slabel=FALSE,show=params$TOGGLE, toggle=params$TOGGLE)`\n\nwe can test it on the `vec` object we created earlier. \n```{r}\noutliers(obs = vec)\n```\n\nWe can use it to access and edit those entries:\n```{r}\nvec[outliers(vec)]\nvec[outliers(vec)] <- NA\n```\n\n`r solend()`  \n\n`r solbegin(label=\"Extra - Adding more arguments\",slabel=FALSE,show=params$TOGGLE, toggle=params$TOGGLE)`\n\nWe could edit the function so that we can also vary how many standard deviations away we are wanting to identify!\n```{r}\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs)) > (x * sd(obs))\n}\n```\nthe `x = 3` means that the function will default to looking 3 standard deviations away, but if we wanted to use `outliers(obs = vec, x = 2)` we could identify those which are 2 away!   \n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\nLook through the solutions to the question above, and make sure that you are comfortable with how writing a function works.  \n\nCan you edit the `outliers()` function you wrote to make it work with vectors which include `NA`s?  \n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n```{r}\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs, na.rm=TRUE)) > (x * sd(obs, na.rm=TRUE))\n}\n```\n`r solend()`\n\n`r qbegin(qcounter())`\n\n**Problem**  \nPossible outliers in the `distractor_fix` variable. \n\n**Task**  \n\n1. Replace any values of the `distractor_fix` variable which are $>3$ standard deviations from the mean with `NA`.  \n2. Make a new boxplot of the variable\n\n::: {.callout-note collapse=\"true\"}\n#### If you skipped questions `r qcounter_i-2` and `r qcounter_i-1`  \n\nIf you skipped the last couple of questions, then copy and run this code into your document.  \n\nIt will give you a function which takes a vector and returns TRUEs and FALSEs based on whether each entry is greater than 3 standard deviations from the mean. \n```{r}\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs, na.rm=TRUE)) > (x * sd(obs, na.rm=TRUE))\n}\n```\n:::\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nblinks_full$distractor_fix[outliers(blinks_full$distractor_fix)]<- NA\n\nggplot(data = blinks_full, aes(y = distractor_fix)) +\n  geom_boxplot()+\n  scale_x_continuous(limits = c(-2,2), breaks = NULL)\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Summary plots  \n\nSo where are we now? \nWe have a dataset that has one row per trial per subject, and it contains information on the number of blinks, and on the time spent looking at the distractor:\n\n```{r}\nhead(blinks_full)\n```\nThinking _way back_ to the top of this page, we recall that our research question is concerned with whether perceived lying (as implied by more looking at the distractor) increases with the number of blinks seen.  \n\nSo we might start by plotting those two variables:\n```{r}\nggplot(blinks_full, aes(x=nr_blinks, y = distractor_fix))+\n  geom_point()\n```\n\nIt's hard to see a pattern clearly here, so we're going to introduce a handy part of **ggplot**.  The `stat_summary()` function allows us to plot _summarised data_ (i.e. the mean of the y-variable), rather than the data itself. If we choose to plot it as a \"pointrange\", it gives us the mean and standard error for $y$ across each level of $x$:    \n```{r}\n#| fig-height: 2.5\nggplot(blinks_full, aes(x = nr_blinks, y = distractor_fix)) +\n  stat_summary(geom = \"pointrange\")\n```\n\nThis is the same as doing some grouping and summarising first, and then giving those summarised values to the plot: \n```{r}\n#| fig-height: 2.5\nblinks_full |>\n  group_by(nr_blinks) |>\n  summarise(mean = mean(distractor_fix, na.rm=TRUE),\n            se = sd(distractor_fix, na.rm=TRUE)/sqrt(n()),\n            lwr = mean-se,\n            upr = mean+se\n            ) |>\n  ggplot(aes(x = nr_blinks, y = mean, ymin = lwr, ymax = upr)) +\n  geom_pointrange()\n```\n\n# Build a model!\n\nWe're now finally getting to the analysis. As we said earlier, this can sometimes be very straightforward in comparison to the amount of effort involved in cleaning data.\n\nRecall that we're interested in whether the perception of whether or not a speaker is lying about the location of some hidden treasure (as measured by the pattern of eye fixations towards the object *not* referred to by the speaker) is influenced by the number of times the speaker is seen to blink while producing the utterance.  \n\n`r qbegin(qcounter())`\nFit the linear model specified below to the data using the `lm()` function and store the output in the environment as an object named `blinks_mdl`.\n\n$$\n\\begin{align}\n& \\text{Fixation time to distractor} = b_0 + b_1 \\ \\text{Number of blinks} + \\epsilon \\\\\n\\quad \\\\\n& \\text{where} \\quad \\\\\n& \\epsilon \\sim N(0, \\sigma) \\text{ independently}\n\\end{align}\n$$\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nblinks_mdl <- lm(distractor_fix ~ 1 + nr_blinks, data=blinks_full)\n\nsummary(blinks_mdl)\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nThe $\\epsilon \\sim N(0, \\sigma) \\text{ independently}$ bit of our model is an assumption we have to make. It concerns the errors (the deviations from observations to our line). Our model assumes that these are normally distributed and centered on 0.\nWe can plot the distribution of residuals to check how well our assumption holds:\n```{r}\n#| fig-height: 2.5\nhist(residuals(blinks_mdl))\n```\n\nHowever, we also make the assumption that the errors are __independent__ - i.e. they are not related to one another.\n\nFor us, this is _not_ the case, and so we should not be using this simple linear regression here.\n\nIn what way are we violating the assumption of independence?\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe dataset to which we are fitting our model does not contain _independent_ observations. We have multiple observations from each participant. i.e. Subject 1 makes up 20 rows, and subject 2 makes up 20 rows.  \n\n\n__Independence of observations__ is actually an assumption that is relied upon by all the tests that we cover in this course. So we can't actually perform an analysis on this data as it is!! We will learn about how to deal with this sort of study design next semester, in the _Multivariate Statistics & Methodoligy using R (MSMR)_ course.  \n\n\nOne option open to us now is to simply \"aggregate up\", so that we remove the dependence from our rows in our dataset. However, this means reducing the number of rows. This is sub-optimal (and we'll see why next semester!), but we can calculate the average `distractor_fix` for each level of `nr_blinks`, and then use _those_ in our model.  \n\nWe can do this the same way as we saw with our summary plots - with `group_by()` and `summarise()`!  \n\n```{r}\nblinks_agg <- blinks_full |>\n  group_by(nr_blinks) |>\n  summarise(\n    meanDF = mean(distractor_fix, na.rm=TRUE)\n  )\nhead(blinks_agg)\n```\n\nOne obvious disadvantage here is that we are going from _loads_ of datapoints to only 10! Furthermore, because of some of the missing data, each of these 10 datapoints is estimated from a slightly different number of trials, and from a slightly different set of participants. Our final model is really just a very simple line fitted to 10 datapoints, but this is pretty far away from modelling how these values actually came to arise in the real world! \n\n```{r}\nggplot(blinks_agg, aes(x = nr_blinks, y = meanDF)) +\n  geom_point() +\n  geom_smooth(method=lm)\n```\n\nBut we can still get some useful linear approximation of the pattern - avg look at the distractor increase by 64ms for every additional blink in the video!  \n\n```{r}\nmod <- lm(meanDF ~ nr_blinks, data = blinks_agg)\n\nsummary(mod)\n```\n\n`r solend()`\n\n\n\n<div class=\"tocify-extend-page\" data-unique=\"tocify-extend-page\" style=\"height: 0;\"></div>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"reference-location":"margin","output-file":"06_wt.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","toc_float":true,"code-annotations":"hover","link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"WalkThrough: Advanced Data Wrangling","citation-location":"margin","params":{"SHOW_SOLS":true,"TOGGLE":true}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}