{"title":"Exercises: GLM","markdown":{"yaml":{"title":"Exercises: GLM","params":{"SHOW_SOLS":false,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"Invisible Gorillas","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n```\n\n\n`r qbegin(qcounter())`\nBefore doing anything else, watch this video, and try to count _exactly_ how many times the players wearing white pass the basketball.    \n\n<iframe width=\"336\" height=\"189\" src=\"https://www.youtube.com/embed/vJG698U2Mvo?si=ovazszvjhjobNMUg&amp;start=5\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n\n`r qend()`\n\n\n\n\n:::frame\n__Data: invisibleg.csv__  \n\n```{r}\n#| include: false\n#ss=runif(1,1e4,1e6)\nss=393502.4\nset.seed(ss)\nN=477\ninvis <- tibble(\n  O = rnorm(N),\n  C = rnorm(N),\n  E = O*.1+rnorm(N),\n  A = C*.2 + rnorm(N),\n  N = O*-.1 + C*-.2 + rnorm(N),\n  gorilla = rbinom(N, 1, prob = plogis(-.5+scale(.21*O + -.1*C + rnorm(N,0,.5))))\n)\ninvis[,1:5] = apply(invis[,1:5],2,scale)\ninvis$N[sample(1:N,4)] <- (-99)\ninvis = bind_rows(\n  invis, \n  tibble(\n    O = rnorm(6),C = rnorm(6),E = rnorm(6),A = rnorm(6),N = rnorm(6),\n    gorilla = -99\n  )\n) |> slice_sample(prop=1) |>\n  mutate(\n    ppt_id = paste0(\"ppt_\",1:n()),\n    ppt_name = randomNames::randomNames(n(),which.names=\"first\")\n  ) |> relocate(ppt_id,ppt_name)\n\ninvis$ppt_name[sample(1:N,64)] <- NA\n\n#write_csv(invis, \"../../data/invisibleg.csv\")\n\n# invis2 <- invis |>\n#   filter(N!=-99, gorilla!=-99)\n# glm(gorilla~.,data=invis2,family=binomial) |> sjPlot::plot_model(type=\"pred\",terms=\"O\")\n# glm(gorilla~.,data=invis2,family=binomial) |> sjPlot::tab_model()\n\n```\n\nThe data here come from a study of `r nrow(invis)` participants who completed a Big 5 Personality Inventory (providing standardised scores on 5 personality traits of Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism), and then completed the selective attention task as seen above, from [Simons & Chabris 1999](https://doi.org/10.1068/p281059){target=\"_blank\"}.  \n\nWe're interested in whether and how individual differences in personality are associated with susceptibility to _inattentional blindness_ (i.e. not noticing the gorilla).  \n\nThe data are available at [https://uoepsy.github.io/data/invisibleg.csv](https://uoepsy.github.io/data/invisibleg.csv){target=\"_blank\"}. \n\n```{r}\n#| label: tbl-invisdict\n#| tbl-cap: \"Data dictionary for invisibleg.csv\"\n#| echo: false\ntibble(\n  variable = names(invis),\n  description = c(\n    \"Participant ID number\",\n    \"Participant Name (if recorded)\",\n    \"Openness (Z-scored)\",\n    \"Conscientiousness (Z-scored)\",\n    \"Extraversion (Z-scored)\",\n    \"Agreeableness (Z-scored)\",\n    \"Neuroticism (Z-scored)\",\n    \"Whether or not participants noticed the gorilla (0 = did not notice, 1 = did notice)\"   \n  )\n) |> gt::gt()\n```\n\n\n\n:::\n\n`r qbegin(qcounter())`\nRead in the data, have a look around, plot, describe, and generally explore.  \nDo any cleaning that you think might be necessary.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThere's nothing new to any of the data cleaning that needs done here. We can do everything that needs doing by using something like `ifelse()`.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\ninvis <- read_csv(\"https://uoepsy.github.io/data/invisibleg.csv\")\n\nsummary(invis)\n```\n\n\nRight away we can see there's something odd with the Neuroticism variable (`N`). It shouldn't have values of -99.  \n\nAs it happens, a well-known statistical software package ([ahem](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/SPSS_logo.svg/1200px-SPSS_logo.svg.png){target=\"_blank\"}) often ends with missing values being stored as \"-99\", or \"-999\".  \n\nWe can also see that we have some \"-99\" in the `gorilla` variable.  \n\nSo let's replace all those with NA's\n\n```{r}\ninvis <- invis |>\n  mutate(\n    N = ifelse(N == -99, NA, N),\n    gorilla = ifelse(gorilla == -99, NA, gorilla)\n  )\n\nsummary(invis)\n```\n\nThere's not a great deal to describe here, because our variables are already Z-scored (i.e. they all have means of 0 and standard deviations of 1).  \n\nIt's still important to look at our data though: \n```{r}\npsych::pairs.panels(invis)\n```\n\nAnd we can tabulate the number of participants that do/don't notice the gorilla:  \n```{r}\ntable(invis$gorilla)\n```\nOnly `r round(prop.table(table(invis$gorilla))[2]*100)`% of people noticed the gorilla!  \n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nHere is an \"intercept-only\" model of the binary outcome 'did they notice the gorilla or not':  \n\n```{r}\n#| eval: false\nglm(gorilla ~ 1, data = invis, family=binomial) |>\n  summary()\n```\n```\n...\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -0.45640    0.09397  -4.857 1.19e-06 ***\n```\n\n1. Convert the intercept estimate from **log-odds** into **odds**  \n2. Convert those **odds** into **probability**  \n3. What does that probability represent?  \n    - *hint:* in `lm(y~1)` the intercept is the same as `mean(y)`\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\n#| include: false\nm0<-glm(gorilla ~ 1, data = invis, family=binomial)\ncc<-coef(m0) |> round(3)\nec<-exp(cc) |> round(3)\n```\n\n\nThe intercept estimate of `r cc` is in log-odds.  \n  \nTo convert from log-odds to odds, we exponentiate ($odds = e^{log-odds}$)  \n\nThe odds of noticing the gorilla are $e^{`r cc`} = `r ec`$.   \n  \nTo convert this back to probability, we calculate $\\frac{odds}{1+odds}$.  \n\n$\\frac{`r ec`}{`r ec+1`} = `r round(plogis(cc),3)`$.  \n\nSo there is a `r round(plogis(cc),3)` probability of a participant noticing the gorilla.  \n\nDoes this number seem familiar?  \nBecause there's no predictors in the model, our intercept is just the proportion of 1s in our outcome variable!  \n```{r}\nprop.table(table(invis$gorilla))\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nDoes personality (i.e. all our measured personality traits collectively) predict inattentional blindness?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWe're wanting to test the influence of a _set_ of predictors here. Sounds like a job for model comparison! (see [10A #comparing-models](10a_glm.html#comparing-models){target=\"_blank\"}).    \n\nBUT WAIT... we might have some missing data...  \n_(this depends on whether, during your data cleaning, you a) replaced values of -99 with `NA`, or b) removed those entire rows from the data)._  \n\nModels like `lm()` and `glm()` will exclude any observation (the entire row) if it has a missing value for _any_ variable in the model (outcome _or_ predictor). As we have missing data on the `N` variable, then when we put that in as a predictor, those rows are omitted from the model.  \n\nSo we'll need to ensure that _both_ models that we are comparing are fitted to exactly the same set of observations.\n\n:::\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\nIf we just try a comparison, we get an error:\n```{r}\n#| eval: false\nm0 <- glm(gorilla ~ 1, data = invis, family=binomial)\nm1 <- glm(gorilla ~ O+C+E+A+N, data = invis, family=binomial)\nanova(m0,m1, test=\"Chisq\")\n```\n<p style=\"color:red;font-size:.8em\">Error in anova.glmlist(c(list(object), dotargs), dispersion = dispersion,  :<br> \n  models were not all fitted to the same size of dataset</p>\n  \nSo what we need to do is fit both models to the data that has values for all of the variables in our full model.  \n\nIf you haven't discovered it already, `na.omit(dataset)` is a quick way to remove all rows that have incomplete data.  \n\nBut we need to be careful - if we just use `na.omit()` on the _entire_ dataset, then we could be removing a whole load of data that is actually perfectly useful to us:\n```{r}\n#| results: 'hold'\n# number of rows in entire dataset:\ninvis |> nrow()\n# number of rows with complete data:\nna.omit(invis) |> nrow()\n# number of rows with complete data in the variables we're using in model:\nna.omit(invis[,3:8]) |> nrow()\n```\n\nWe can see that if we just used `na.omit(invis)` here, we would be removing `r nrow(invis)-nrow(na.omit(invis))` people. As it happens, this is excluding a whole bunch of participants for whom their names are missing. But we're not using their names, so we can actually use these in our model!\n\n\n```{r}\nmoddat <- na.omit(invis[,3:8])\n\nm0 <- glm(gorilla ~ 1, data = moddat,\n          family=binomial)\nm1 <- glm(gorilla ~ O+C+E+A+N, data = moddat, \n          family=binomial)\n\nanova(m0,m1, test=\"Chisq\")\n```\n\n```{r}\n#| include: false\nres=as.data.frame(anova(m0,m1, test=\"Chisq\"))\nres$Deviance=round(res$Deviance,2)\nres$`Pr(>Chi)`=format.pval(res$`Pr(>Chi)`,eps=.001,digits=3)\n```\n\n:::int\nThe inclusion of the Big 5 Personality Traits (Openness, Conscientiousness, Extraversion, Agreeablenss and Neuroticism) were found to result in a significant improvement in model fit over the null model ($\\chi^2(`r res[2,3]`)=`r res[2,4]`, p`r res[2,5]`$), suggesting that personality is useful in predicting inattentional blindness. \n:::\n  \n`r solend()`\n\n\n`r qbegin(qcounter())`\nHow are different aspects of personality associated with inattentional blindness?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThe interpretation of logistic regression coefficients is explained in [10A #coefficient-interpretation](10a_glm.html#coefficient-interpretation){target=\"_blank\"}.  \n\nYou might want to explain the key finding(s) in terms of odds ratios.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe coefficients we get from our model are in log-odds. So values $<0$ represent decreasing probability, and values $>0$ represent increasing probability.  \n\nBut that's about as much as we can interpret in this scale.  \nWhen we exponentiate them, we get our odds-ratios. These are \"how much the odds are multiplied by\", so values $<1$ represent decreased odds (i.e. decreasing probability) and values $>1$ represent increased odds.  \n\nOnly Openness (`O`) is significantly associated with the probability of noticing the gorilla.  \n```{r}\n#| echo: false\nec=round(exp(coef(m1)),2)\nbroom::tidy(m1) |> \n  transmute(\n    coefficient = term, \n    b = case_when(\n      p.value<.05 ~ paste0(round(estimate,2),\"***\"),\n      TRUE ~ paste0(round(estimate,2))\n    ),\n    `exp(b)`= case_when(\n      p.value<.05 ~ paste0(round(exp(estimate),2),\"***\"),\n      TRUE ~ paste0(round(exp(estimate),2))\n    ),\n    interpretation = c(\n      paste0(\"for someone at the mean on all personality traits, the odds of noticing the gorilla are \",ec[1],\" to 1\"),\n      paste0(\"holding other personality traits constant, being 1 SD higher on openness is associated with \",ec[2],\" times the odds of noticing the gorilla\"),\n      \"\",\"\",\"\",\"\"\n    )\n  ) |> gt::gt()\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nCompute confidence intervals for your odds ratios.  \n\n::: {.callout-tip collapse=\"true\"}\n#### confidence interval refresher\n\nWe haven't been using confidence intervals very much, but we very easily could have been. Functions like `t.test()`, `cor.test()` etc present confidence intervals in their output, and functions like `confint()` can be used on linear regression models to get confidence intervals for our coefficients.  \n\nConfidence intervals (CIs) are often used to make a statement about a null hypothesis _just like_ a p-value (see [3A #inference](03a_inference.html#null-hypothesis-significance-testing-nhst){target=\"_blank\"}. If a 95% CI does not contain zero then we can, with that same level of confidence, reject the null hypothesis that the population value is zero. So a 95% confidence interval maps to $p<.05$, and a 99% CI maps to $p<.01$, and so on.  \n\nHowever, many people these days prefer confidence intervals to $p$-values as they take the focus (slightly) away from the null hypothesis and toward a range of effect sizes that are compatible with the data.  \n\nThe function `confint()` will give you confidence intervals. The function `car::Confint()`^[the colon here means \"look in the **car** package and use the `Confint()` function. It saves having to load the package with `library(car)`] will do exactly the same but put them alongside the estimates (which saves you scrolling up and down between different outputs).  \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nexp(car::Confint(m1))\n```\n```{r}\n#| echo: false\nres = exp(car::Confint(m1))\nres = apply(res,2,round,2)\n```\n\n:::int\n`r paste0(\"holding other personality traits constant, being 1 SD higher on openness is associated with \",ec[2],\" (95% CI: \",res[2,2],\", \",res[2,3],\") times the odds of noticing the gorilla\")`\n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\nProduce a plot of the predicted probabilities of noticing the gorilla as a function of openness.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThere's an example of this at [10A #visualising](10a_glm.html#visualising){target=\"_blank\"}. Using the __effects__ package will be handy.  \n\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nthe `xlevels` argument here says to give us the fitted values for 20 different values across the predictor  \n```{r}\nlibrary(effects)\n\neffect(term = \"O\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=O,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nTry creating an equivalent plot for the other personality traits - before you do, what do you expect them to look like?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nFrom our coefficients, we should expect the lines to go *up* as E and A increase, and *down* as C and N increase.  \nHowever, for all of these, we should expect a lot of uncertainty (i.e. for all of these, 0 is inside our confidence intervals (i.e. they're non-significant))  \n```{r}\ncar::Confint(m1)\n```\n\ne.g., for extraversion:  \n```{r}\n#| code-fold: true\nlibrary(patchwork)\nplte <- effect(term = \"E\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=E,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\npltc <- effect(term = \"C\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=C,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\npltn <- effect(term = \"N\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=N,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\nplta <- effect(term = \"A\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=A,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\n(plte + plta) / (pltn + pltc)\n```\n\n`r solend()`\n\n\n# Invisible Marshmallows\n\n:::frame\n__Data: mallow2.csv__ \n\n```{r}\n#| include: false\nss=454086.9\nset.seed(ss)\ntibble(\n  name = randomNames::randomNames(300,which.names=\"first\"),\n  agemonths = rdunif(300, 39, 115),\n  timeofday = rbinom(300,1,plogis(scale(agemonths*-.1))),\n  visibility = rep(c(\"hidden\",\"visible\"),e=150),\n  lp2 = -3.4*(visibility==\"hidden\") - 4*(scale(agemonths)) + timeofday*.8 + 3.2*(visibility==\"hidden\")*(scale(agemonths)),\n  taken = rbinom(300,1,plogis(scale(lp2)))\n) |> \n  mutate(\n    timeofday = ifelse(timeofday==1,\"pm\",\"am\"),\n    taken = ifelse(taken==1,\"taken\",\"waited\"),\n  ) |> select(-lp2) -> mallow2\n\n\nbind_rows(\n  mallow2, \n  tribble(\n    ~name,~agemonths,~timeofday,~visibility,~taken,\n    \"Josiah\",12*33,\"pm\",\"visible\",\"waited\",\n    \"Martin\",12*53,\"am\",\"hidden\",\"taken\",\n    \"Dougal\",12*3,\"noon\",\"visible\",\"taken\",\n    \"Oscar\",12*10,\"5 pm\",\"hidden\",\"waited\"\n  )\n) |> slice_sample(prop=1) -> mallow2\n# write_csv(mallow2, \"../../data/mallow2.csv\")\n```\n\nWe already played with some marshmallow-related data in [reading 10A](10a_glm.html#fitting-glm-in-r){target=\"_blank\"}. Here we are extending this study to investigate whether the visibility of the immediate reward moderates age effects on the ability to delay gratification (the ability to forgo an immediate reward for a greater reward at a later point).  \n\n`r nrow(mallow2)` children took part, ranging in ages from 3 to 10 years old. Each child was shown a marshmallow, and it was explained that they were about to be left alone for 10 minutes. They were told that they were welcome to eat the marshmallow while they were waiting, but if the marshmallow was still there after 10 minutes, they would be rewarded with __two__ marshmallows.  \n\nFor half of the children who took part, the marshmallow was visible for the entire 10 minutes (or until they ate it!). For the other half, the marshmallow was placed under a plastic cup.  \n\nThe experiment took part at various times throughout the working day, and researchers were worried about children being more hungry at certain times of day, so they kept track of whether each child completed the task in the morning or the afternoon, so that they could control for this in their analyses.  \n\nThe data are available at [https://uoepsy.github.io/data/mallow2.csv](https://uoepsy.github.io/data/mallow2.csv){target=\"_blank\"}. \n\n```{r}\n#| label: tbl-mallow2dict\n#| tbl-cap: \"Data dictionary for mallow2.csv\"\n#| echo: false\ntibble(\n  variable = names(mallow2),\n  description = c(\n    \"Participant Name\",\n    \"Age in months\",\n    \"Time of day that the experiment took place ('am' = morning, 'pm' = afternoon)\",\n    \"Experimental condition - whether the marshmallow was 'visible' or 'hidden' for the 10 minutes\",\n    \"Whether or not the participant took the marshmallow within the 10 minutes\"\n  )\n) |> gt::gt()\n```\n\n:::\n\n`r qbegin(qcounter())`\nRead in the data, check, clean, plot, describe, explore.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- It's good practice to set categorical variables as factors (see [](){target=\"_blank\"}).  \n- It might be easier to transform age into years rather than months (up to you!)\n\n:::\n\n\n`r qend()`\n`r solbegin(label=\"Solution Part 1 - Check\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\nmallow2 <- read_csv(\"https://uoepsy.github.io/data/mallow2.csv\")\n```\n\nWe've only got one numeric variable here (age), so I'm going to plot that, and then tabulate the rest: \n\nSomething looks odd here.. a couple of very old children!  \n```{r}\nhist(mallow2$agemonths)\n```\nAccording to the design, our age range should be 3 to 10 years old. So here are all the participants over 10 years old (i.e. over 120 months old):  \n```{r}\nmallow2[mallow2$agemonths>120, ]\n```\nAha... who knows how they got in there! We'll deal with them in a minute.. \n\nThe `visibility` variable looks as we would expect - half in each condition:\n```{r}\ntable(mallow2$visibility)\n```\n\nThis looks off.. we have one mis-coded as \"5 pm\", which I'm guessing should just be \"pm\". And we have one at \"noon\". There's no way of knowing whether that was morning or afternoon, so I would be inclined to remove it.  \n```{r}\ntable(mallow2$timeofday)\n```\n\nAnd we can see that our outcome variable has got 2 unique values, which is what we expect.  \n```{r}\ntable(mallow2$taken)\n```\n\n`r solend()`\n`r solbegin(label=\"Solution Part 2 - Clean\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nSo we need to:\n\n1. replace \"5 pm\" with \"pm\" in `timeofday`\n2. remove \"noon\" with `NA` in `timeofday` \n3. remove Martin and Josiah.. they are not the population we're interested in... \n4. make any appropriate variables factors (good practice!)\n5. while we're there - I think I'll also make an `age` variable that is in years rather than months\n\n```{r}\nmallow2 <- \n  mallow2 |>\n    mutate(\n      age = agemonths/12,\n      timeofday = factor(timeofday, \n                         levels=c(\"am\",\"pm\",\"5 pm\"), # possible levels\n                         labels = c(\"am\",\"pm\",\"pm\")), # make the levels these\n      visibility = factor(visibility, \n                          levels=c(\"visible\",\"hidden\")),\n      taken = factor(taken, \n                     levels=c(\"waited\",\"taken\"))\n    ) |>\n  filter(agemonths <= 120, !is.na(timeofday))\n```\n\n**KEEP TRACK**  \nWe've removed 3 observations entirely from the data. \nTwo of these (Martin & Josiah) were clearly not representative of the population of interest. The other was one that had an unclear `timeofday` value. If we replaced it with `NA`, any analysis using that variable would not include that observation. And since we know we're going to use `timeofday` in our analysis (and since it's just 1 participant), it may be cleaner to just to start with a complete data.  \n\nWhen writing up, we would want to:\n\n1. Detail any removal of observations and the reasons for doing so.  \n2. Describe the final dataset (if the final dataset contains `NA`s, then it's also worth providing descriptions of the patterns of missingness).  \n\n`r solend()`\n`r solbegin(label=\"Solution Part 3 - Describe & Explore\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\nmallow2 |>\n  group_by(visibility) |>\n  summarise(\n    n = n(),\n    mean_age = mean(age),\n    sd_age = sd(age),\n    percent_pm = sum(timeofday==\"pm\")/n()*100,\n    percent_taken = sum(taken==\"taken\")/n()*100\n  ) |>\n  gt::gt() # this just a nice way to prettify tables \n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nFit a model that you can use to address the research aims of the study.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nTake a look back at the description of the study.  \n\n- What are we wanting to find out? How can we operationalise this into a model?   \n  - *hint:* 'moderation' is another word for 'interaction'.  \n- Is there anything that we think it is important to account for? \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nmm1 <- glm(taken ~ timeofday + age * visibility, data = mallow2, family = binomial)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nWhat do you conclude?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Remember...  \n\nWhen you have an interaction `Y ~ X1 + X2 + X3 + X2:X3` in your model, the coefficients that involved in the interaction (`X2` and `X3`) represent the associations _when_ the other variable in the interaction is zero.  \nThe interaction coefficient itself represents the *adjustment* to these associations when we move up 1 in the other variable.  \n\n:::\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n```{r}\n#| echo: false\ncc = coef(mm1) |> round(2)\nec = coef(mm1) |> exp() |> round(2)\n```\n\nHere are the coefficients from the model we have fitted. We've exponentiated them so that they are in odds ratios.  \n```{r}\nexp(car::Confint(mm1))\n```\n\nFrom our coefficients, it looks like when the marshmallow is visible, the odds of taking the marshmallow are more than halved (`r ec[3]`) for every year older a child is.  \n\nCompared to when the marshmallow is visible, the odds ratio associated with every additional year of age is `r ec[5]` times bigger in the hidden-marshmallow condition.  \n\nThis is a bit of a weird one to think about, but it means that instead of having an OR of `r ec[3]` (as we do for the visible condition), for the hidden condition we have an OR that is $`r ec[3]` \\times `r ec[5]` = `r round(ec[3]*ec[5],2)`$.  \n\nThis is almost always going to be more easily presented as a plot of predicted probabilities:\n\n```{r}\n#| echo: false\neffect(term = \"age*visibility\", mod = mm1, xlevels=20) |>\n  as.data.frame() |>\n  ggplot(aes(x=age, y=fit, col=visibility, fill=visibility)) +\n  geom_line() +\n  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=.3)\n```\n\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nWrite up the methods and results, providing a plot and regression table.  \n\nA template RMarkown file can be found at [https://uoepsy.github.io/usmr/2324/misc/marshmallows.Rmd](https://uoepsy.github.io/usmr/2324/misc/marshmallows.Rmd){target=\"_blank\"} if you want it. It contains a list of questions try and make sure you answer in your write-up.  \n\n`r qend()`\n\n\n# Optional Extras\n\n`r qbegin(qcounter())`\nBelow is the background and design to a study investigating how different types of more active learning strategies improve understanding, in comparison to just studying materials.  \n\nFit an appropriate model to address the research aims, interpret it, make a plot, etc.  \n\n::: {.callout-note collapse=\"true\"}\n#### immersivelearning.csv  \n\nAn experiment was run to investigate strategies for learning. Three groups of 30 participants were presented with materials on a novel language to learn.  \n\nAll groups were given two hours of preparation time, after which their learning was assessed. The first group (`studystudy`) spent both hours studying the materials. The second group (`studytest`) spent the first hour studying the materials, and the second hour testing themselves on the materials. The third group (`studyimmersion`) spent the first hour studying the materials, and the second hour trying to converse with a native speaker of the language (they were not permitted to attempt to converse in any other language during this time).  \n\nAfter the two hours were up, participants were the assessed via a series of 30 communication tasks. The number of tasks each participant got correct was recorded.  \n\nInformation on two potential covariates was also included - previous language learning experience (novice/experienced), and cognitive aptitude (a 20 item questionnaire leading to a standardised test score).  \n\nThe data are available at [https://uoepsy.github.io/data/immersivelearning.csv](https://uoepsy.github.io/data/immersivelearning.csv){target=\"_blank\"}. \n\n```{r}\n#| echo: false\n#| label: tbl-immersedict\n#| tbl-cap: \"Data dictionary: immersivelearning.csv\"\nset.seed(698646.6)\ndf = tibble(\n  group = rep(c(\"studystudy\",\"studytest\",\"studyimmersion\"),\n              e = 30),\n  plle = sample(c(\"novice\",\"experienced\"),90,T,prob=c(.8,.2)),\n  cog_apt = round(rnorm(90),1),\n  lp = -.5 + \n    (group==\"studytest\")*.2 +\n    (group==\"studyimmersion\")*.5 + rnorm(90,0,.7),\n  n_correct = rbinom(90,30,prob=plogis(scale(lp)))\n) |> select(-lp) |>\n  mutate(PID = paste0(\"ppt_\",1:n())) |>\n  relocate(PID)\n\n# write_csv(df, \"../../data/immersivelearning.csv\")\n# m = glm(cbind(n_correct,30-n_correct) ~ plle+cog_apt+group,\n#     df |> mutate(\n#       group=fct_relevel(factor(group),\"studystudy\")\n#     ), family=binomial)\n# summary(m)\n# sjPlot::plot_model(m,type=\"eff\",terms=c(\"group\"))\n\ntibble(\n  variable = names(df),\n  description = c(\n    \"Participant ID number\",\n    \"Experimental group (studystudy = 2 hours of study, studytest = 1 hour study, 1 hour testing, studyimmersion = 1 hour study, 1 hour conversing)\",\n    \"Previous language learning experience (novice or experienced)\",\n    \"Cognitive Aptitude (Standardised Z Score)\",\n    \"Number of the 30 communication tasks that each participant correctly completed\"\n  )\n) |> gt::gt()\n```\n\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- This might not be binary (0 or 1), but it's binomial (\"how many success in 30 trials\").  \n- See the optional box under logistic regression in [10A #fitting-glm-in-r](10a_glm.html#fitting-glm-in-r){target=\"_blank\"} for how to fit a binomial model to data like this.   \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nBelow is the code *we* would use to investigate this. Some of these decisions you might make differently, and that is okay - the important thing is to clearly explain and justify the decision we make.  \n\n```{r}\nimmers <- read_csv(\"https://uoepsy.github.io/data/immersivelearning.csv\")\n\nimmers <- immers |> mutate(\n  fct_relevel(factor(group), \"studystudy\")\n)\n\nmst1 = glm(cbind(n_correct,30-n_correct) ~ plle+cog_apt+group,\n    data = immers, family=binomial)\n\nsummary(mst1)\n\neffect(term = \"group\", mod = mst1) |>\n  as.data.frame() |>\n  ggplot(aes(x=group, y=fit,ymin=lower,ymax=upper))+\n  geom_pointrange()\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nPeople and behaviours are a lot more difficult to predict than something like, say, the colour of different wines. \n\nBuild a model that predicts the colour of wine based on all available information. How accurately can it predict wine colours?  \n\n*(Generally speaking, this question doesn't reflect how we do research in psychology. Ideally, we would have a theoretical question that motivates the inclusion (and testing of) specific predictors.)*\n\n::: {.callout-note collapse=\"true\"}\n#### usmr_wines.csv\n\nYou can download a dataset of 6497 different wines (1599 red, 4898 white) from [https://uoepsy.github.io/data/usmr_wines.csv](https://uoepsy.github.io/data/usmr_wines.csv).  \n\nIt contains information on various physiochemical properties such as pH, a measure of level of sulphates, residual sugar, citric acid, volatile acidity and alcohol content, and also quality ratings from a sommelier (wine expert).  All the wines are vinho verde from Portugal, and the data was collected between 2004 and 2007.  \n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- `glm(outcome ~ ., data = mydata)` is a shorthand way of putting _all_ variables in the data in as predictors.  \n- See [the lecture slides](https://uoepsy.github.io/usmr/2324/lectures/lecture09.html#/accuracy){target=\"_blank\"} for an example of how we can get a number for \"how accurately can my model predict\".  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nBelow is the code *we* would use to investigate this. Some of these decisions you might make differently, and that is okay - the important thing is to clearly explain and justify the decision we make.  \n\n```{r}\nwines <- read_csv(\"https://uoepsy.github.io/data/usmr_wines.csv\")\n\nwines <- \n  wines |> \n  mutate(\n    col = factor(col, levels=c(\"white\",\"red\"))\n  )\n\nwinemod <- glm(col ~ ., data = wines, family = binomial)\n\n# in logit units\nguess <- predict(winemod)\n# logit 0 is p of .5:\nguess <- ifelse(guess > 0, \"red\", \"white\")\n# how many predicted colours match the observed colours??\nhits <- sum(guess == wines$col)\n# what percentage?  \nhits/length(wines$col)\n```\n\n\n\n`r solend()`\n\n\n\n\n\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n```\n\n\n`r qbegin(qcounter())`\nBefore doing anything else, watch this video, and try to count _exactly_ how many times the players wearing white pass the basketball.    \n\n<iframe width=\"336\" height=\"189\" src=\"https://www.youtube.com/embed/vJG698U2Mvo?si=ovazszvjhjobNMUg&amp;start=5\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n\n`r qend()`\n\n\n\n# Invisible Gorillas\n\n:::frame\n__Data: invisibleg.csv__  \n\n```{r}\n#| include: false\n#ss=runif(1,1e4,1e6)\nss=393502.4\nset.seed(ss)\nN=477\ninvis <- tibble(\n  O = rnorm(N),\n  C = rnorm(N),\n  E = O*.1+rnorm(N),\n  A = C*.2 + rnorm(N),\n  N = O*-.1 + C*-.2 + rnorm(N),\n  gorilla = rbinom(N, 1, prob = plogis(-.5+scale(.21*O + -.1*C + rnorm(N,0,.5))))\n)\ninvis[,1:5] = apply(invis[,1:5],2,scale)\ninvis$N[sample(1:N,4)] <- (-99)\ninvis = bind_rows(\n  invis, \n  tibble(\n    O = rnorm(6),C = rnorm(6),E = rnorm(6),A = rnorm(6),N = rnorm(6),\n    gorilla = -99\n  )\n) |> slice_sample(prop=1) |>\n  mutate(\n    ppt_id = paste0(\"ppt_\",1:n()),\n    ppt_name = randomNames::randomNames(n(),which.names=\"first\")\n  ) |> relocate(ppt_id,ppt_name)\n\ninvis$ppt_name[sample(1:N,64)] <- NA\n\n#write_csv(invis, \"../../data/invisibleg.csv\")\n\n# invis2 <- invis |>\n#   filter(N!=-99, gorilla!=-99)\n# glm(gorilla~.,data=invis2,family=binomial) |> sjPlot::plot_model(type=\"pred\",terms=\"O\")\n# glm(gorilla~.,data=invis2,family=binomial) |> sjPlot::tab_model()\n\n```\n\nThe data here come from a study of `r nrow(invis)` participants who completed a Big 5 Personality Inventory (providing standardised scores on 5 personality traits of Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism), and then completed the selective attention task as seen above, from [Simons & Chabris 1999](https://doi.org/10.1068/p281059){target=\"_blank\"}.  \n\nWe're interested in whether and how individual differences in personality are associated with susceptibility to _inattentional blindness_ (i.e. not noticing the gorilla).  \n\nThe data are available at [https://uoepsy.github.io/data/invisibleg.csv](https://uoepsy.github.io/data/invisibleg.csv){target=\"_blank\"}. \n\n```{r}\n#| label: tbl-invisdict\n#| tbl-cap: \"Data dictionary for invisibleg.csv\"\n#| echo: false\ntibble(\n  variable = names(invis),\n  description = c(\n    \"Participant ID number\",\n    \"Participant Name (if recorded)\",\n    \"Openness (Z-scored)\",\n    \"Conscientiousness (Z-scored)\",\n    \"Extraversion (Z-scored)\",\n    \"Agreeableness (Z-scored)\",\n    \"Neuroticism (Z-scored)\",\n    \"Whether or not participants noticed the gorilla (0 = did not notice, 1 = did notice)\"   \n  )\n) |> gt::gt()\n```\n\n\n\n:::\n\n`r qbegin(qcounter())`\nRead in the data, have a look around, plot, describe, and generally explore.  \nDo any cleaning that you think might be necessary.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThere's nothing new to any of the data cleaning that needs done here. We can do everything that needs doing by using something like `ifelse()`.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\ninvis <- read_csv(\"https://uoepsy.github.io/data/invisibleg.csv\")\n\nsummary(invis)\n```\n\n\nRight away we can see there's something odd with the Neuroticism variable (`N`). It shouldn't have values of -99.  \n\nAs it happens, a well-known statistical software package ([ahem](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/SPSS_logo.svg/1200px-SPSS_logo.svg.png){target=\"_blank\"}) often ends with missing values being stored as \"-99\", or \"-999\".  \n\nWe can also see that we have some \"-99\" in the `gorilla` variable.  \n\nSo let's replace all those with NA's\n\n```{r}\ninvis <- invis |>\n  mutate(\n    N = ifelse(N == -99, NA, N),\n    gorilla = ifelse(gorilla == -99, NA, gorilla)\n  )\n\nsummary(invis)\n```\n\nThere's not a great deal to describe here, because our variables are already Z-scored (i.e. they all have means of 0 and standard deviations of 1).  \n\nIt's still important to look at our data though: \n```{r}\npsych::pairs.panels(invis)\n```\n\nAnd we can tabulate the number of participants that do/don't notice the gorilla:  \n```{r}\ntable(invis$gorilla)\n```\nOnly `r round(prop.table(table(invis$gorilla))[2]*100)`% of people noticed the gorilla!  \n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nHere is an \"intercept-only\" model of the binary outcome 'did they notice the gorilla or not':  \n\n```{r}\n#| eval: false\nglm(gorilla ~ 1, data = invis, family=binomial) |>\n  summary()\n```\n```\n...\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -0.45640    0.09397  -4.857 1.19e-06 ***\n```\n\n1. Convert the intercept estimate from **log-odds** into **odds**  \n2. Convert those **odds** into **probability**  \n3. What does that probability represent?  \n    - *hint:* in `lm(y~1)` the intercept is the same as `mean(y)`\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\n#| include: false\nm0<-glm(gorilla ~ 1, data = invis, family=binomial)\ncc<-coef(m0) |> round(3)\nec<-exp(cc) |> round(3)\n```\n\n\nThe intercept estimate of `r cc` is in log-odds.  \n  \nTo convert from log-odds to odds, we exponentiate ($odds = e^{log-odds}$)  \n\nThe odds of noticing the gorilla are $e^{`r cc`} = `r ec`$.   \n  \nTo convert this back to probability, we calculate $\\frac{odds}{1+odds}$.  \n\n$\\frac{`r ec`}{`r ec+1`} = `r round(plogis(cc),3)`$.  \n\nSo there is a `r round(plogis(cc),3)` probability of a participant noticing the gorilla.  \n\nDoes this number seem familiar?  \nBecause there's no predictors in the model, our intercept is just the proportion of 1s in our outcome variable!  \n```{r}\nprop.table(table(invis$gorilla))\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nDoes personality (i.e. all our measured personality traits collectively) predict inattentional blindness?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWe're wanting to test the influence of a _set_ of predictors here. Sounds like a job for model comparison! (see [10A #comparing-models](10a_glm.html#comparing-models){target=\"_blank\"}).    \n\nBUT WAIT... we might have some missing data...  \n_(this depends on whether, during your data cleaning, you a) replaced values of -99 with `NA`, or b) removed those entire rows from the data)._  \n\nModels like `lm()` and `glm()` will exclude any observation (the entire row) if it has a missing value for _any_ variable in the model (outcome _or_ predictor). As we have missing data on the `N` variable, then when we put that in as a predictor, those rows are omitted from the model.  \n\nSo we'll need to ensure that _both_ models that we are comparing are fitted to exactly the same set of observations.\n\n:::\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\nIf we just try a comparison, we get an error:\n```{r}\n#| eval: false\nm0 <- glm(gorilla ~ 1, data = invis, family=binomial)\nm1 <- glm(gorilla ~ O+C+E+A+N, data = invis, family=binomial)\nanova(m0,m1, test=\"Chisq\")\n```\n<p style=\"color:red;font-size:.8em\">Error in anova.glmlist(c(list(object), dotargs), dispersion = dispersion,  :<br> \n  models were not all fitted to the same size of dataset</p>\n  \nSo what we need to do is fit both models to the data that has values for all of the variables in our full model.  \n\nIf you haven't discovered it already, `na.omit(dataset)` is a quick way to remove all rows that have incomplete data.  \n\nBut we need to be careful - if we just use `na.omit()` on the _entire_ dataset, then we could be removing a whole load of data that is actually perfectly useful to us:\n```{r}\n#| results: 'hold'\n# number of rows in entire dataset:\ninvis |> nrow()\n# number of rows with complete data:\nna.omit(invis) |> nrow()\n# number of rows with complete data in the variables we're using in model:\nna.omit(invis[,3:8]) |> nrow()\n```\n\nWe can see that if we just used `na.omit(invis)` here, we would be removing `r nrow(invis)-nrow(na.omit(invis))` people. As it happens, this is excluding a whole bunch of participants for whom their names are missing. But we're not using their names, so we can actually use these in our model!\n\n\n```{r}\nmoddat <- na.omit(invis[,3:8])\n\nm0 <- glm(gorilla ~ 1, data = moddat,\n          family=binomial)\nm1 <- glm(gorilla ~ O+C+E+A+N, data = moddat, \n          family=binomial)\n\nanova(m0,m1, test=\"Chisq\")\n```\n\n```{r}\n#| include: false\nres=as.data.frame(anova(m0,m1, test=\"Chisq\"))\nres$Deviance=round(res$Deviance,2)\nres$`Pr(>Chi)`=format.pval(res$`Pr(>Chi)`,eps=.001,digits=3)\n```\n\n:::int\nThe inclusion of the Big 5 Personality Traits (Openness, Conscientiousness, Extraversion, Agreeablenss and Neuroticism) were found to result in a significant improvement in model fit over the null model ($\\chi^2(`r res[2,3]`)=`r res[2,4]`, p`r res[2,5]`$), suggesting that personality is useful in predicting inattentional blindness. \n:::\n  \n`r solend()`\n\n\n`r qbegin(qcounter())`\nHow are different aspects of personality associated with inattentional blindness?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThe interpretation of logistic regression coefficients is explained in [10A #coefficient-interpretation](10a_glm.html#coefficient-interpretation){target=\"_blank\"}.  \n\nYou might want to explain the key finding(s) in terms of odds ratios.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe coefficients we get from our model are in log-odds. So values $<0$ represent decreasing probability, and values $>0$ represent increasing probability.  \n\nBut that's about as much as we can interpret in this scale.  \nWhen we exponentiate them, we get our odds-ratios. These are \"how much the odds are multiplied by\", so values $<1$ represent decreased odds (i.e. decreasing probability) and values $>1$ represent increased odds.  \n\nOnly Openness (`O`) is significantly associated with the probability of noticing the gorilla.  \n```{r}\n#| echo: false\nec=round(exp(coef(m1)),2)\nbroom::tidy(m1) |> \n  transmute(\n    coefficient = term, \n    b = case_when(\n      p.value<.05 ~ paste0(round(estimate,2),\"***\"),\n      TRUE ~ paste0(round(estimate,2))\n    ),\n    `exp(b)`= case_when(\n      p.value<.05 ~ paste0(round(exp(estimate),2),\"***\"),\n      TRUE ~ paste0(round(exp(estimate),2))\n    ),\n    interpretation = c(\n      paste0(\"for someone at the mean on all personality traits, the odds of noticing the gorilla are \",ec[1],\" to 1\"),\n      paste0(\"holding other personality traits constant, being 1 SD higher on openness is associated with \",ec[2],\" times the odds of noticing the gorilla\"),\n      \"\",\"\",\"\",\"\"\n    )\n  ) |> gt::gt()\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nCompute confidence intervals for your odds ratios.  \n\n::: {.callout-tip collapse=\"true\"}\n#### confidence interval refresher\n\nWe haven't been using confidence intervals very much, but we very easily could have been. Functions like `t.test()`, `cor.test()` etc present confidence intervals in their output, and functions like `confint()` can be used on linear regression models to get confidence intervals for our coefficients.  \n\nConfidence intervals (CIs) are often used to make a statement about a null hypothesis _just like_ a p-value (see [3A #inference](03a_inference.html#null-hypothesis-significance-testing-nhst){target=\"_blank\"}. If a 95% CI does not contain zero then we can, with that same level of confidence, reject the null hypothesis that the population value is zero. So a 95% confidence interval maps to $p<.05$, and a 99% CI maps to $p<.01$, and so on.  \n\nHowever, many people these days prefer confidence intervals to $p$-values as they take the focus (slightly) away from the null hypothesis and toward a range of effect sizes that are compatible with the data.  \n\nThe function `confint()` will give you confidence intervals. The function `car::Confint()`^[the colon here means \"look in the **car** package and use the `Confint()` function. It saves having to load the package with `library(car)`] will do exactly the same but put them alongside the estimates (which saves you scrolling up and down between different outputs).  \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nexp(car::Confint(m1))\n```\n```{r}\n#| echo: false\nres = exp(car::Confint(m1))\nres = apply(res,2,round,2)\n```\n\n:::int\n`r paste0(\"holding other personality traits constant, being 1 SD higher on openness is associated with \",ec[2],\" (95% CI: \",res[2,2],\", \",res[2,3],\") times the odds of noticing the gorilla\")`\n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\nProduce a plot of the predicted probabilities of noticing the gorilla as a function of openness.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThere's an example of this at [10A #visualising](10a_glm.html#visualising){target=\"_blank\"}. Using the __effects__ package will be handy.  \n\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nthe `xlevels` argument here says to give us the fitted values for 20 different values across the predictor  \n```{r}\nlibrary(effects)\n\neffect(term = \"O\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=O,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nTry creating an equivalent plot for the other personality traits - before you do, what do you expect them to look like?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nFrom our coefficients, we should expect the lines to go *up* as E and A increase, and *down* as C and N increase.  \nHowever, for all of these, we should expect a lot of uncertainty (i.e. for all of these, 0 is inside our confidence intervals (i.e. they're non-significant))  \n```{r}\ncar::Confint(m1)\n```\n\ne.g., for extraversion:  \n```{r}\n#| code-fold: true\nlibrary(patchwork)\nplte <- effect(term = \"E\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=E,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\npltc <- effect(term = \"C\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=C,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\npltn <- effect(term = \"N\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=N,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\nplta <- effect(term = \"A\", mod = m1, xlevels = 20) |>\n  as.data.frame() |>\n  ggplot(aes(x=A,y=fit,ymin=lower,ymax=upper))+\n  geom_line()+\n  geom_ribbon(alpha=.3)\n\n(plte + plta) / (pltn + pltc)\n```\n\n`r solend()`\n\n\n# Invisible Marshmallows\n\n:::frame\n__Data: mallow2.csv__ \n\n```{r}\n#| include: false\nss=454086.9\nset.seed(ss)\ntibble(\n  name = randomNames::randomNames(300,which.names=\"first\"),\n  agemonths = rdunif(300, 39, 115),\n  timeofday = rbinom(300,1,plogis(scale(agemonths*-.1))),\n  visibility = rep(c(\"hidden\",\"visible\"),e=150),\n  lp2 = -3.4*(visibility==\"hidden\") - 4*(scale(agemonths)) + timeofday*.8 + 3.2*(visibility==\"hidden\")*(scale(agemonths)),\n  taken = rbinom(300,1,plogis(scale(lp2)))\n) |> \n  mutate(\n    timeofday = ifelse(timeofday==1,\"pm\",\"am\"),\n    taken = ifelse(taken==1,\"taken\",\"waited\"),\n  ) |> select(-lp2) -> mallow2\n\n\nbind_rows(\n  mallow2, \n  tribble(\n    ~name,~agemonths,~timeofday,~visibility,~taken,\n    \"Josiah\",12*33,\"pm\",\"visible\",\"waited\",\n    \"Martin\",12*53,\"am\",\"hidden\",\"taken\",\n    \"Dougal\",12*3,\"noon\",\"visible\",\"taken\",\n    \"Oscar\",12*10,\"5 pm\",\"hidden\",\"waited\"\n  )\n) |> slice_sample(prop=1) -> mallow2\n# write_csv(mallow2, \"../../data/mallow2.csv\")\n```\n\nWe already played with some marshmallow-related data in [reading 10A](10a_glm.html#fitting-glm-in-r){target=\"_blank\"}. Here we are extending this study to investigate whether the visibility of the immediate reward moderates age effects on the ability to delay gratification (the ability to forgo an immediate reward for a greater reward at a later point).  \n\n`r nrow(mallow2)` children took part, ranging in ages from 3 to 10 years old. Each child was shown a marshmallow, and it was explained that they were about to be left alone for 10 minutes. They were told that they were welcome to eat the marshmallow while they were waiting, but if the marshmallow was still there after 10 minutes, they would be rewarded with __two__ marshmallows.  \n\nFor half of the children who took part, the marshmallow was visible for the entire 10 minutes (or until they ate it!). For the other half, the marshmallow was placed under a plastic cup.  \n\nThe experiment took part at various times throughout the working day, and researchers were worried about children being more hungry at certain times of day, so they kept track of whether each child completed the task in the morning or the afternoon, so that they could control for this in their analyses.  \n\nThe data are available at [https://uoepsy.github.io/data/mallow2.csv](https://uoepsy.github.io/data/mallow2.csv){target=\"_blank\"}. \n\n```{r}\n#| label: tbl-mallow2dict\n#| tbl-cap: \"Data dictionary for mallow2.csv\"\n#| echo: false\ntibble(\n  variable = names(mallow2),\n  description = c(\n    \"Participant Name\",\n    \"Age in months\",\n    \"Time of day that the experiment took place ('am' = morning, 'pm' = afternoon)\",\n    \"Experimental condition - whether the marshmallow was 'visible' or 'hidden' for the 10 minutes\",\n    \"Whether or not the participant took the marshmallow within the 10 minutes\"\n  )\n) |> gt::gt()\n```\n\n:::\n\n`r qbegin(qcounter())`\nRead in the data, check, clean, plot, describe, explore.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- It's good practice to set categorical variables as factors (see [](){target=\"_blank\"}).  \n- It might be easier to transform age into years rather than months (up to you!)\n\n:::\n\n\n`r qend()`\n`r solbegin(label=\"Solution Part 1 - Check\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\nmallow2 <- read_csv(\"https://uoepsy.github.io/data/mallow2.csv\")\n```\n\nWe've only got one numeric variable here (age), so I'm going to plot that, and then tabulate the rest: \n\nSomething looks odd here.. a couple of very old children!  \n```{r}\nhist(mallow2$agemonths)\n```\nAccording to the design, our age range should be 3 to 10 years old. So here are all the participants over 10 years old (i.e. over 120 months old):  \n```{r}\nmallow2[mallow2$agemonths>120, ]\n```\nAha... who knows how they got in there! We'll deal with them in a minute.. \n\nThe `visibility` variable looks as we would expect - half in each condition:\n```{r}\ntable(mallow2$visibility)\n```\n\nThis looks off.. we have one mis-coded as \"5 pm\", which I'm guessing should just be \"pm\". And we have one at \"noon\". There's no way of knowing whether that was morning or afternoon, so I would be inclined to remove it.  \n```{r}\ntable(mallow2$timeofday)\n```\n\nAnd we can see that our outcome variable has got 2 unique values, which is what we expect.  \n```{r}\ntable(mallow2$taken)\n```\n\n`r solend()`\n`r solbegin(label=\"Solution Part 2 - Clean\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nSo we need to:\n\n1. replace \"5 pm\" with \"pm\" in `timeofday`\n2. remove \"noon\" with `NA` in `timeofday` \n3. remove Martin and Josiah.. they are not the population we're interested in... \n4. make any appropriate variables factors (good practice!)\n5. while we're there - I think I'll also make an `age` variable that is in years rather than months\n\n```{r}\nmallow2 <- \n  mallow2 |>\n    mutate(\n      age = agemonths/12,\n      timeofday = factor(timeofday, \n                         levels=c(\"am\",\"pm\",\"5 pm\"), # possible levels\n                         labels = c(\"am\",\"pm\",\"pm\")), # make the levels these\n      visibility = factor(visibility, \n                          levels=c(\"visible\",\"hidden\")),\n      taken = factor(taken, \n                     levels=c(\"waited\",\"taken\"))\n    ) |>\n  filter(agemonths <= 120, !is.na(timeofday))\n```\n\n**KEEP TRACK**  \nWe've removed 3 observations entirely from the data. \nTwo of these (Martin & Josiah) were clearly not representative of the population of interest. The other was one that had an unclear `timeofday` value. If we replaced it with `NA`, any analysis using that variable would not include that observation. And since we know we're going to use `timeofday` in our analysis (and since it's just 1 participant), it may be cleaner to just to start with a complete data.  \n\nWhen writing up, we would want to:\n\n1. Detail any removal of observations and the reasons for doing so.  \n2. Describe the final dataset (if the final dataset contains `NA`s, then it's also worth providing descriptions of the patterns of missingness).  \n\n`r solend()`\n`r solbegin(label=\"Solution Part 3 - Describe & Explore\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\nmallow2 |>\n  group_by(visibility) |>\n  summarise(\n    n = n(),\n    mean_age = mean(age),\n    sd_age = sd(age),\n    percent_pm = sum(timeofday==\"pm\")/n()*100,\n    percent_taken = sum(taken==\"taken\")/n()*100\n  ) |>\n  gt::gt() # this just a nice way to prettify tables \n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nFit a model that you can use to address the research aims of the study.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nTake a look back at the description of the study.  \n\n- What are we wanting to find out? How can we operationalise this into a model?   \n  - *hint:* 'moderation' is another word for 'interaction'.  \n- Is there anything that we think it is important to account for? \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nmm1 <- glm(taken ~ timeofday + age * visibility, data = mallow2, family = binomial)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nWhat do you conclude?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Remember...  \n\nWhen you have an interaction `Y ~ X1 + X2 + X3 + X2:X3` in your model, the coefficients that involved in the interaction (`X2` and `X3`) represent the associations _when_ the other variable in the interaction is zero.  \nThe interaction coefficient itself represents the *adjustment* to these associations when we move up 1 in the other variable.  \n\n:::\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n```{r}\n#| echo: false\ncc = coef(mm1) |> round(2)\nec = coef(mm1) |> exp() |> round(2)\n```\n\nHere are the coefficients from the model we have fitted. We've exponentiated them so that they are in odds ratios.  \n```{r}\nexp(car::Confint(mm1))\n```\n\nFrom our coefficients, it looks like when the marshmallow is visible, the odds of taking the marshmallow are more than halved (`r ec[3]`) for every year older a child is.  \n\nCompared to when the marshmallow is visible, the odds ratio associated with every additional year of age is `r ec[5]` times bigger in the hidden-marshmallow condition.  \n\nThis is a bit of a weird one to think about, but it means that instead of having an OR of `r ec[3]` (as we do for the visible condition), for the hidden condition we have an OR that is $`r ec[3]` \\times `r ec[5]` = `r round(ec[3]*ec[5],2)`$.  \n\nThis is almost always going to be more easily presented as a plot of predicted probabilities:\n\n```{r}\n#| echo: false\neffect(term = \"age*visibility\", mod = mm1, xlevels=20) |>\n  as.data.frame() |>\n  ggplot(aes(x=age, y=fit, col=visibility, fill=visibility)) +\n  geom_line() +\n  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=.3)\n```\n\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nWrite up the methods and results, providing a plot and regression table.  \n\nA template RMarkown file can be found at [https://uoepsy.github.io/usmr/2324/misc/marshmallows.Rmd](https://uoepsy.github.io/usmr/2324/misc/marshmallows.Rmd){target=\"_blank\"} if you want it. It contains a list of questions try and make sure you answer in your write-up.  \n\n`r qend()`\n\n\n# Optional Extras\n\n`r qbegin(qcounter())`\nBelow is the background and design to a study investigating how different types of more active learning strategies improve understanding, in comparison to just studying materials.  \n\nFit an appropriate model to address the research aims, interpret it, make a plot, etc.  \n\n::: {.callout-note collapse=\"true\"}\n#### immersivelearning.csv  \n\nAn experiment was run to investigate strategies for learning. Three groups of 30 participants were presented with materials on a novel language to learn.  \n\nAll groups were given two hours of preparation time, after which their learning was assessed. The first group (`studystudy`) spent both hours studying the materials. The second group (`studytest`) spent the first hour studying the materials, and the second hour testing themselves on the materials. The third group (`studyimmersion`) spent the first hour studying the materials, and the second hour trying to converse with a native speaker of the language (they were not permitted to attempt to converse in any other language during this time).  \n\nAfter the two hours were up, participants were the assessed via a series of 30 communication tasks. The number of tasks each participant got correct was recorded.  \n\nInformation on two potential covariates was also included - previous language learning experience (novice/experienced), and cognitive aptitude (a 20 item questionnaire leading to a standardised test score).  \n\nThe data are available at [https://uoepsy.github.io/data/immersivelearning.csv](https://uoepsy.github.io/data/immersivelearning.csv){target=\"_blank\"}. \n\n```{r}\n#| echo: false\n#| label: tbl-immersedict\n#| tbl-cap: \"Data dictionary: immersivelearning.csv\"\nset.seed(698646.6)\ndf = tibble(\n  group = rep(c(\"studystudy\",\"studytest\",\"studyimmersion\"),\n              e = 30),\n  plle = sample(c(\"novice\",\"experienced\"),90,T,prob=c(.8,.2)),\n  cog_apt = round(rnorm(90),1),\n  lp = -.5 + \n    (group==\"studytest\")*.2 +\n    (group==\"studyimmersion\")*.5 + rnorm(90,0,.7),\n  n_correct = rbinom(90,30,prob=plogis(scale(lp)))\n) |> select(-lp) |>\n  mutate(PID = paste0(\"ppt_\",1:n())) |>\n  relocate(PID)\n\n# write_csv(df, \"../../data/immersivelearning.csv\")\n# m = glm(cbind(n_correct,30-n_correct) ~ plle+cog_apt+group,\n#     df |> mutate(\n#       group=fct_relevel(factor(group),\"studystudy\")\n#     ), family=binomial)\n# summary(m)\n# sjPlot::plot_model(m,type=\"eff\",terms=c(\"group\"))\n\ntibble(\n  variable = names(df),\n  description = c(\n    \"Participant ID number\",\n    \"Experimental group (studystudy = 2 hours of study, studytest = 1 hour study, 1 hour testing, studyimmersion = 1 hour study, 1 hour conversing)\",\n    \"Previous language learning experience (novice or experienced)\",\n    \"Cognitive Aptitude (Standardised Z Score)\",\n    \"Number of the 30 communication tasks that each participant correctly completed\"\n  )\n) |> gt::gt()\n```\n\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- This might not be binary (0 or 1), but it's binomial (\"how many success in 30 trials\").  \n- See the optional box under logistic regression in [10A #fitting-glm-in-r](10a_glm.html#fitting-glm-in-r){target=\"_blank\"} for how to fit a binomial model to data like this.   \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nBelow is the code *we* would use to investigate this. Some of these decisions you might make differently, and that is okay - the important thing is to clearly explain and justify the decision we make.  \n\n```{r}\nimmers <- read_csv(\"https://uoepsy.github.io/data/immersivelearning.csv\")\n\nimmers <- immers |> mutate(\n  fct_relevel(factor(group), \"studystudy\")\n)\n\nmst1 = glm(cbind(n_correct,30-n_correct) ~ plle+cog_apt+group,\n    data = immers, family=binomial)\n\nsummary(mst1)\n\neffect(term = \"group\", mod = mst1) |>\n  as.data.frame() |>\n  ggplot(aes(x=group, y=fit,ymin=lower,ymax=upper))+\n  geom_pointrange()\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nPeople and behaviours are a lot more difficult to predict than something like, say, the colour of different wines. \n\nBuild a model that predicts the colour of wine based on all available information. How accurately can it predict wine colours?  \n\n*(Generally speaking, this question doesn't reflect how we do research in psychology. Ideally, we would have a theoretical question that motivates the inclusion (and testing of) specific predictors.)*\n\n::: {.callout-note collapse=\"true\"}\n#### usmr_wines.csv\n\nYou can download a dataset of 6497 different wines (1599 red, 4898 white) from [https://uoepsy.github.io/data/usmr_wines.csv](https://uoepsy.github.io/data/usmr_wines.csv).  \n\nIt contains information on various physiochemical properties such as pH, a measure of level of sulphates, residual sugar, citric acid, volatile acidity and alcohol content, and also quality ratings from a sommelier (wine expert).  All the wines are vinho verde from Portugal, and the data was collected between 2004 and 2007.  \n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- `glm(outcome ~ ., data = mydata)` is a shorthand way of putting _all_ variables in the data in as predictors.  \n- See [the lecture slides](https://uoepsy.github.io/usmr/2324/lectures/lecture09.html#/accuracy){target=\"_blank\"} for an example of how we can get a number for \"how accurately can my model predict\".  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nBelow is the code *we* would use to investigate this. Some of these decisions you might make differently, and that is okay - the important thing is to clearly explain and justify the decision we make.  \n\n```{r}\nwines <- read_csv(\"https://uoepsy.github.io/data/usmr_wines.csv\")\n\nwines <- \n  wines |> \n  mutate(\n    col = factor(col, levels=c(\"white\",\"red\"))\n  )\n\nwinemod <- glm(col ~ ., data = wines, family = binomial)\n\n# in logit units\nguess <- predict(winemod)\n# logit 0 is p of .5:\nguess <- ifelse(guess > 0, \"red\", \"white\")\n# how many predicted colours match the observed colours??\nhits <- sum(guess == wines$col)\n# what percentage?  \nhits/length(wines$col)\n```\n\n\n\n`r solend()`\n\n\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"output-file":"10_ex.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","toc_float":true,"code-annotations":"hover","link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Exercises: GLM","params":{"SHOW_SOLS":false,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}