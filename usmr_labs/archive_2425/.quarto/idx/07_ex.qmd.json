{"title":"Exercises: Multiple Regression","markdown":{"yaml":{"title":"Exercises: Multiple Regression","params":{"SHOW_SOLS":false,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"More monkeys","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n```\n\n\n```{r}\n#| include: false\nset.seed(919805)\ndf = \n  expand_grid(\n    obj_type = 0:1,\n    obj_colour = 0:2,\n    obj_size = 0:2,\n    n = 1:7\n  ) |> select(-n) |>\n  mutate(\n    age = round(runif(n(),1,21) + 4*obj_type),\n    species = sample(c(\"macaque\",\"capuchin\"), n(), T)\n  )\nxm = model.matrix(lm(rnorm(nrow(df)) ~ age + obj_type + obj_size + species,df))\n\ndf$exploration_time = xm %*% c(14,-.27, 2.5, -.5, -3) + rnorm(nrow(df),0,3.5)\n\ndf$exploration_time = round(df$exploration_time[,1],1)\n# df |> mutate(adult=ifelse(age>8,1,0)) |> pairs()\n\ndf <- df |> select(age,species,obj_type,obj_colour, obj_size,exploration_time) |>\n  mutate(\n    obj_type = factor(obj_type, labels=c(\"soft\",\"mechanical\")),\n    obj_colour = factor(obj_colour, labels=c(\"red\",\"green\",\"blue\")),\n    obj_size = map_dbl(obj_size, ~30+round(rnorm(1,.*20,11.5)))\n    #obj_size = factor(obj_size, labels=c(\"small\",\"medium\",\"large\")),\n  )\n\ndf$exploration_time <- pmax(0,df$exploration_time)\ndf <- slice_sample(df,prop=.95)\n\n\nsomenames = read.table(\"https://artofmemory.com/files/forum/947/initials.txt\",header=F,sep=\",\")\nset.seed(44)\ndf$name = sample(somenames$V2, nrow(df))\ndf <- df |> relocate(name)\n\ndf <- monkeytoys <- df |> select(-species)\n#write_csv(monkeytoys,\"../../data/monkeytoys.csv\")\n\n```\n\n\n\n:::frame\n__Data: monkeytoys.csv__  \n\nAfter their recent study investigating how age is associated with inquisitiveness in monkeys (see [Week 5 Exercises](05_ex.html#monkey-exploration){target=\"_blank\"}) our researchers have become interested in whether primates show preferences for certain types of object - are they more interested in toys with moving parts, or with soft plush toys?  \n\nThey conduct another study (Bolton, Archer, Peng, Winther & Gandolfi, 2024^[Another fake study!]) in which they gave `r nrow(monkeytoys)` monkeys each a different toy, and recorded the amount of time each monkey spent exploring their toy. Toys were categorised as either being 'mechanical' or 'soft'. Mechanical toys had several parts that could be manipulated, while soft toys did not. They also recorded the age of each monkey, and a few further attributes of each toy (its size and colour).  \n\nThe aim of this study is to investigate the following question:  \n\n> Do monkeys have a preference between soft toys vs toys with moving parts?\n\nThe data is available at [https://uoepsy.github.io/data/monkeytoys.csv](https://uoepsy.github.io/data/monkeytoys.csv){target=\"_blank\"} and contains the variables described in @tbl-monkeytoys\n```{r}\n#| label: tbl-monkeytoys\n#| echo: false\n#| tbl-cap: \"Data dictionary for monkeytoys.csv\"\ntibble(\n  variable = names(monkeytoys),\n  description = c(\"Monkey Name\",\"Age of monkey in years\", \"Type of novel object given (mechanical / soft)\",\"Main colour of object (red / green / blue)\",\"Size of object in cm (length of largest dimension of the object)\",\"Time (in minutes) spent exploring the object\")\n) |>\n  gt::gt()\n```\n\n\n:::\n\n`r qbegin(qcounter())`\nFit a simple linear model examining whether `exploration_time` depends on the type of object given to monkeys (`obj_type`).  \n\nMake a plot too if you want!  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThere's nothing new here. It's just `lm(outcome ~ predictor)`.  \n\nFor the plot, try a boxplot maybe? or even a violin plot if you're feeling adventurous!  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nmonkeytoys <-  read_csv(\"https://uoepsy.github.io/data/monkeytoys.csv\")\n\n\nmodel1 <- lm(exploration_time ~ obj_type, data = monkeytoys)\nsummary(model1)\n```\n\nFrom this, we would conclude that monkeys do not significantly differ in how much time they spend exploring one type of toy over another (mechanical or soft).  \n\nLet's go wild and put a boxplot _on top of_ a violin plot!  \n```{r}\nggplot(monkeytoys, \n       aes(x=obj_type, y=exploration_time, \n           col=obj_type)) +\n  geom_violin() + \n  geom_boxplot(alpha=.3, width=.4)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nIs the distribution of ages of the monkeys with soft toys similar to those with mechanical toys?  \n\nIs there a way you could test this? \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWe're wanting to know if age (continuous) is different between two groups (monkeys seeing soft toys and monkeys seeing moving toys). Anyone for $t$?  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\n#| echo: false\nres <- t.test(age ~ obj_type, data = monkeytoys)\n```\n\n\n```{r}\nt.test(age ~ obj_type, data = monkeytoys)\n```\n\n:::int\nThe average age of monkeys with the soft toys is `r with(monkeytoys,round(mean(age[obj_type==\"soft\"]),1))` years (SD = `r with(monkeytoys,round(sd(age[obj_type==\"soft\"]),1))`), and the average of those with the mechanical toys is `r with(monkeytoys,round(mean(age[obj_type==\"mechanical\"]),1))` (SD = `r with(monkeytoys,round(sd(age[obj_type==\"mechanical\"]),1))`). This difference is significant as indicated by a Welch two-sample $t$-test ($t(`r round(res[['parameter']],1)`)=`r round(res[['statistic']],2)`, \\, p`r format.pval(res[['p.value']],eps=.001,digits=2)`$).  \n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\n**Discuss:** What does this mean for our model of `exploration_time`? Remember - the researchers already discovered last week that younger monkeys tend to be more inquisitive about new objects than older monkeys are.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- If older monkeys spend less time exploring novel objects\n- And our group of monkeys with mechanical toys are older than the group with soft toys. \n- Then... \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe have reason to believe that older monkeys spend less time exploring novel objects. We discovered this last week.  \n\nBecause our group of monkeys with mechanical toys are of a different age than the group with soft toys, surely we can't discern whether any difference in `exploration_time` between the two types of toy is because of these age differences or because of the type of toy?  \n\n<a id='Kq5SmFeASyhw1TtTYj75YA' class='gie-single' href='http://www.gettyimages.com/detail/586024350' target='_blank' style='color:#a7a7a7;text-decoration:none;font-weight:normal !important;border:none;display:inline-block;'>Embed from Getty Images</a><script>window.gie=window.gie||function(c){(gie.q=gie.q||[]).push(c)};gie(function(){gie.widgets.load({id:'Kq5SmFeASyhw1TtTYj75YA',sig:'1fKQopDLlPOpG9cuEzA7G5fZuR_u8eWzlQV2GELvt2U=',w:'511px',h:'338px',items:'586024350',caption: true ,tld:'com',is360: false })});</script><script src='//embed-cdn.gettyimages.com/widgets.js' charset='utf-8' async></script>\n\n`r solend()`\n\n\n\n`r qbegin(qcounter())`\nFit a model the association between exploration time and type of object while controlling for age.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- When we add multiple predictors in to `lm()`, it can sometimes matter what order we put them in (e.g. if we want to use `anova(model)` to do a quick series of incremental model comparisons as in [7A #shortcuts-for-model-comparisons](07a_mlr.html#shortcuts-for-model-comparisons){target=\"_blank\"}). Good practice is to put the thing you're interested in (the 'focal predictor') at the end, e.g.: `lm(outcome ~ covariates + predictor-of-interest)`    \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nmodel2 <- lm(exploration_time ~ age + obj_type, data = monkeytoys)\n\nsummary(model2)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nThe thing we're interested in here is association between `exploration_time` and `obj_type`.  \nHow does it differ between the models we've created so far, and why?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- To quickly compare several models side by side, the `tab_model()` function from the **sjPlot** package can be quite useful, e.g. `tab_model(model1, model2, ...)`.  \n- alternatively, just use `summary()` on each model.  \n\n:::\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\nlibrary(sjPlot)\ntab_model(model1, model2)\n```\n\n  \nThe coefficient for `obj_type` is much bigger when we include `age` in the model, and it is significant!  \n\nIn the model without `age`, we're just comparing the two groups. We can see this in the left hand panel of the plot below - it's the difference between the two group means.  \nWhen we include `age` in the model, the coefficient for `obj_type` represents the difference in the heights of the two lines in the right hand panel below. \n\n```{r}\n#| code-fold: true\n#| out-width: \"100%\"\nlibrary(patchwork)\np1 <- ggplot(monkeytoys, aes(x=obj_type, y=exploration_time,\n             col=obj_type))+\n  geom_jitter(width=.05)+\n  stat_summary(geom=\"pointrange\", fun.data = mean_cl_normal, \n               position = position_nudge(x=.14)) +\n  labs(subtitle=\"exp_time~obj_type\")+\n  scale_y_continuous(breaks=seq(0,22,2))+\n  guides(col=\"none\")\n\np2 <- broom::augment(model2, interval=\"confidence\") |>\n  ggplot(aes(x=age, col=obj_type))+\n  geom_point(aes(y=exploration_time))+\n  geom_line(aes(y=.fitted))+\n  geom_ribbon(aes(ymin=.lower,ymax=.upper,\n                  fill=obj_type),col=NA,alpha=.2)+\n  scale_y_continuous(breaks=seq(0,22,2))+\n  labs(subtitle=\"exp_time~age+obj_type\")\n\np1 + p2 \n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nPlot the *model estimated* difference in exploration time for each object type.  \n\nTo do this, you'll need to create a little data frame for plotting, then give that to the `augment()` function from the **broom** package. This will then give us the model fitted value and the confidence interval, which we can plot!    \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- An example of this whole process is in [7A#model-visualisations](07a_mlr.html#model-visualisations){target=\"_blank\"}.  \n  - The example has a continuous predictor, so we plotted a line and a ribbon. An alternative for a categorical predictor might be a `geom_pointrange()`.  \n\n:::\n\n\n`r qend()`\n\nWe've split this solution in to parts so that you can have a go at some bits without seeing it all at once.  \n\n`r solbegin(label=\"Solution Part 1 - make a dataframe\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nHere's our dataframe to add model estimated values to:  \n```{r}\nplotdat <- data.frame(\n  obj_type = c(\"soft\",\"mechanical\"),\n  age = mean(monkeytoys$age)\n)\n```\n\n`r solend()`\n\n`r solbegin(label=\"Solution Part 2 - use broom::augment\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nThis gives us our estimates and intervals:  \n```{r}\nlibrary(broom)\naugment(model2, newdata = plotdat, interval=\"confidence\")\n```\n\n\n`r solend()`\n\n`r solbegin(label=\"Solution Part 3 - into ggplot!\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\naugment(model2, newdata = plotdat, interval=\"confidence\") |>\n  ggplot(aes(x=obj_type,y=.fitted))+\n  geom_pointrange(aes(ymin=.lower,ymax=.upper))\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nAre other aspects of the toys (their size and colour) also associated with more/less exploration time?  \n\nWe can phrase this as \"do size and colour explain additional variance in exploration time?\". How might we test such a question? \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- We basically just want to add these new predictors into our model.  \n- Don't worry about interpreting the coefficients right now (we'll talk more about categorical predictors next week), but we can still test whether the inclusion of size and colour improve our model! (see [7A#model-comparisons](07a_mlr.html#model-comparisons){target=\"_blank\"}).  \n\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nThis is our current model: \n```{r}\nmodel2 <- lm(exploration_time ~ age + obj_type, data = monkeytoys)\n```\nAnd we can add the two colour and size variables:  \n```{r}\nmodel3 <- lm(exploration_time ~ age + obj_type + obj_colour +\n               obj_size, data = monkeytoys)\n```\n\nLet's compare them:  \n```{r}\nanova(model2, model3)\n```\n\n```{r}\n#| echo: false\nres <- anova(model2, model3)\n```\n\n:::int\nAfter accounting for differences due to age and type of object (mechanical vs soft), other features of objects - size (cm) and colour (red/green/blue) - were found to significantly explain variation in the time monkeys spent exploring those objects ($F(`r res[2,3]`,`r res[2,1]`)=`r round(res[2,5],2)`, \\, p=`r format.pval(res[2,6],eps=.001,digits=2)`$). \n:::\n\n`r solend()`\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Social Media Use\n\n```{r}\n#| include: false\n\nlibrary(tidyverse)\nset.seed(764)\nN = runif(1,60,150)\ndf <- tibble(\n  x1 = rnorm(N),\n  x2 = rnorm(N),\n  x3 = .7*x1 + -.5*x2 + rnorm(N),\n  y = .1*x3 + 1.1*x1 + .7*x2 + rnorm(N)\n  # x2 = rnorm(N),\n  # x3 = -.8*x2 + rnorm(N),\n  # y = -.01*x3 - 1*x2 + rnorm(N)\n)\ndf |> transmute(\n  happy = round(scale(y)[,1]*7.02+25),\n  smm = (round((scale(x3)[,1]*24.2+76.4)/5)*5),\n  f2f = (round((scale(x1)[,1]*45 + 90)/15)*15)/60,\n  age = round(scale(x2)[,1]*6.7 + 27)\n) |> \n  mutate(\n    happy = pmax(0,pmin(45,happy)),\n    smm = pmax(0,smm),\n    f2f = pmax(0,f2f),\n    age = pmax(12,age),\n    name = randomNames::randomNames(nrow(df),which.names = \"first\")\n  ) |> relocate(name, age) -> df\n\n# psych::multi.hist(df[,-1], global=F)\n# ggplot(df, aes(x=smm,y=happy))+\n#   geom_point()\n# \n# sjPlot::tab_model(\n#   lm(happy ~ smm,df),\n#   lm(happy ~ smm+f2f,df),\n#   lm(happy ~ smm+age,df),\n#   lm(happy ~ smm+f2f+age,df)\n# )\n\nch = sample(1:nrow(df),4)\ndf$smm[ch] <- paste0(df$smm[ch],\" minutes\")\ndf$happy[sample(1:nrow(df),1)] <- 47\n\ndf1 <- df |> select(name, smm, happy)\ndf2 <- df\nsmmdat <- df\n#write_csv(df, file=\"../../data/socmedmin.csv\")\n```\n\n:::frame\n__Data: socmedmin.csv__  \n\n> Is more social media use associated with more happiness?  \n\n`r nrow(df)` participants completed a short online form that included a questionnaire (9 questions) to get a measure of their happiness. Information was also recorded on their age, the number of minutes per day spent using social media, and the number of hours per day spent having face-to-face interactions.\n\nThe data is available at [https://uoepsy.github.io/data/socmedmin.csv](https://uoepsy.github.io/data/socmedmin.csv){target=\"_blank\"}\n\n```{r}\n#| echo: false\n#| tbl-cap: \"Data Dictionary: socmedmin.csv\"\n#| label: tbl-smmdict\nsmmdat <- read_csv(\"../../data/socmedmin.csv\")\ntibble(\n  variable = names(smmdat),\n  description = c(\"Participant Name\",\n                  \"Participant Age (years)\",\n                  \"Happiness Score (sum of 9 likert questions each scored 1-5)\",\n                  \"Social Media Use (minutes per day)\",\n                  \"Face-to-face interactions (hours per day)\"\n                  )\n) |> gt::gt()\n```\n\n:::\n\n\n`r qbegin(qcounter())`\nRead in the data and have a look around. \n\nData often doesn't come to us in a neat format. Something here is a bit messy, so you'll need to figure out how to tidy it up.\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIs every variable of the right type (numeric, character, factor etc)? If not, we'll probably want to convert any that aren't the type we want.  \n\nBe careful not to lose data when we convert things. Note that R cannot do this:  \n```{r}\nas.numeric(\"20 minutes\")\n```\n\nSo maybe some combination of `as.numeric()` and `gsub()` might work? (see [6A #dealing-with-character-strings](06_wt.html#dealing-with-character-strings){target=\"_blank\"}) \n\n:::\n\n`r qend()`\n`r solbegin(label=\"Solution Part 1 - identify the problem\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\n#| eval: false\nsmmdat <- read_csv(\"https://uoepsy.github.io/data/socmedmin.csv\")\n```\n\nNote that the `smm` variable seems to be a character..  \n```{r}\nhead(smmdat)\n```\nwe could just convert it all to numeric by using `as.numeric()`: \n```{r}\nas.numeric(smmdat$smm)\n```\n\nNote that this has introduced some `NA` values though! We've lost some data:\n\n```{r}\nsum(is.na(smmdat$smm)) # NAs in original data\nsum(is.na(as.numeric(smmdat$smm))) # NAs in numeric-converted data\n```\n\nIf we look carefully, these entries that we are losing are all slightly different from the rest. They all have \" minutes\" in them, rather than just the minutes.. \n```{r}\nsmmdat$smm[is.na(as.numeric(smmdat$smm))]\n```\n\nAnd when we ask R to make \"20 minutes\" into a number, it isn't clever enough to recognise that it is a number, so it just turns it into `NA`:\n```{r}\nas.numeric(\"20 minutes\")\n```\n\n`r solend()`\n`r solbegin(label=\"Solution Part 2 - figure out a fix\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nSo we need to _first_ remove the \" minutes\" bit, and _then_ change to numeric.  \nWe can use `gsub()` to substitute \" minutes\" with \"\" (i.e. nothingness):\n```{r}\ngsub(\" minutes\", \"\", \"20 minutes\")\n```\nAnd we can then turn _that_ into numbers.. \n```{r}\nas.numeric(gsub(\" minutes\", \"\", \"20 minutes\"))\n```\n\n`r solend()`\n`r solbegin(label=\"Solution Part 3 - implement!\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nNow that we've figured out how to convert it, I'm just going to overwrite the `smm` variable, rather than creating a new one.  \n\n::::panelset\n:::panel\n#### base R\n```{r}\nsmmdat$smm <- as.numeric(gsub(\" minutes\", \"\", smmdat$smm))\n```\n:::\n:::panel\n#### tidyverse\n```{r}\nsmmdat <- smmdat |> \n  mutate(\n    smm = as.numeric(gsub(\" minutes\", \"\", smm))\n  )\n```\n:::\n::::\n\nOkay, now the `smm` variable is numeric, and we haven't lost any datapoints!\n```{r}\nsummary(smmdat)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nSomething we haven't really come across until now is the importance of checking the _range_ (i.e. min and max) of our variables. \nThis is a good way to check for errors in the data (i.e. values that we shouldn't be able to obtain using our measurement tool).  \n\nCheck the range of the `happy` variable - does it look okay, based on the description of how it is recorded? \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- `min()`, `max()`, or even just `range()`!!  \n- If there are any observations you think have impossible values, then you could set them as NA for now (see [6A #impossible-values ](06_wt.html#impossible-values){target=\"_blank\"}).  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nrange(smmdat$happy)\n```\nThe minimum is `r min(smmdat$happy)`, and the maximum is `r max(smmdat$happy)`.  \n\nBut our scores are based on the sum of 9 questions that can each score from 1 to 5. So surely that means the minimum someone could score would be 9, and the maximum they could score would be 45?  \n\n```{r}\nsmmdat <- smmdat |>\n  mutate(\n    happy = ifelse(happy < 9 | happy > 45, NA, happy)\n  )\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nFinally, we've got to a point where we can look at some descriptive statistics - e.g. mean and standard deviations for continuous variables, frequencies (counts) if there are any categorical variables.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou can do this the manual way, calculating it for each variable, but there are also lots of handy functions to make use of.  \n\n- `describe()` from the __psych__ package\n- `CreateTableOne()` from the __tableone__ package  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::::panelset\n:::panel\n#### Tidyverse\n\nIn tidyverse, we could do this like:  \n```{r}\nsmmdat |> \n  summarise(\n    mean_age = mean(age),\n    sd_age = sd(age),\n    mean_happy = mean(happy, na.rm=TRUE),\n    sd_happy = sd(happy, na.rm=TRUE),\n    mean_smm = mean(smm),\n    sd_smm = sd(smm)\n  )\n```\n\n:::\n:::panel\n#### psych::describe\n\nWe can use the `describe` function from the __psych__ package: \n```{r}\nlibrary(psych)\ndescribe(smmdat)\n```\n\n\n:::\n:::panel\n#### tableone\n\nThe tableone package will also be clever and give counts and percentages for categorical data like the `name` variable. However, names aren't something we really want to summarise, so it's easier just to give the function everything except the `name` variable.  \n```{r}\nlibrary(tableone)\nCreateTableOne(data = smmdat |> select(-name) )\n```\n\n:::\n::::\n\n`r solend()`\n\n<!-- `r qbegin(qcounter())` -->\n<!-- Again, we're going to start with a one-predictor model.   -->\n\n<!-- Fit a simple linear regression model to address our research question (\"Is more social media use associated with more happiness?\").   -->\n\n<!-- Make a plot too.   -->\n\n<!-- What do you conclude?   -->\n\n\n<!-- ::: {.callout-tip collapse=\"true\"} -->\n<!-- #### Hints -->\n\n<!-- We're using `lm()` again.  -->\n\n<!-- To make a plot, because we just have a very simple one predictor model, we could just plot the data itself and then add `geom_smooth(method=lm)` to it to display the model.   -->\n\n\n<!-- ::: -->\n\n<!-- `r qend()` -->\n<!-- `r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)` -->\n\n<!-- From the model below, we would conclude that more social media use is associated with more happiness. The coefficient from our model is positive (more social media = more happiness), and significantly different from zero.   -->\n\n<!-- ```{r} -->\n<!-- mod1 <- lm(happy ~ smm, smmdat) -->\n<!-- summary(mod1) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- ggplot(smmdat, aes(x=smm,y=happy))+ -->\n<!--   geom_point()+ -->\n<!--   geom_smooth(method=lm)+ -->\n<!--   labs(x=\"Social Media Usage (minutes per day)\", -->\n<!--        y=\"Happiness Score\") -->\n<!-- ``` -->\n\n<!-- `r solend()` -->\n\n`r qbegin(qcounter())`\n\nFor our research question (\"Is more social media use associated with more happiness?\"), we could consider fitting the following model:  \n```\nlm(happy ~ smm, data = smmdat)\n```\n\n**But** is it not a bit more complicated than that? Surely there are lots of other things that are relevant? For instance, it's quite reasonable to assume that social media use is related to someone's age? It's also quite likely that happiness changes with age too. But that means that our coefficient of `happy ~ smm` could actually just be changes in happiness due to something else (like age)? Similarly, people who use social media might just be more sociable people (i.e. they might see more people in real life, and that might be what makes them happy).  \n\nEspecially in observational research (i.e. we aren't intervening and asking some people to use social media and others to not use it), figuring out the relevant association that we want can be incredibly tricky.  \n\nAs it happens, we _do_ have data on these participants' ages, and on the amount of time they spend having face-to-face interactions with people!  \n\nLook at how all these variables correlate with one another, and make some quick plots.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- You can give a data frame of numeric variables to `cor()` and it gives you all the correlations between pairs of variables in a \"correlation matrix\"  \n- if you want some quick pair-wise plots (not pretty, but useful!), try the `pairs.panels()` function from the __psych__ package.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nHere is a correlation matrix. It shows the correlations between each pair of variables.  \nNote that the bit below the diagonal is the same as the bit above. The diagonal is always going to be all 1's, because a variable is always perfectly correlated with itself.  \n```{r}\nsmmdat |> \n  select(-name) |>\n  filter(!is.na(happy)) |>\n  cor()\n```\n\nThe `pairs.panels()` function is a useful way to quickly explore the bivariate (two-variables) patterns in a dataset:  \n```{r}\nlibrary(psych)\nsmmdat |> \n  select(-name) |>\n  pairs.panels()\n```\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nIs social media usage associated with happiness, after accounting for age and the number of face-to-face interactions?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- This question can be answered in a couple of ways. You might be able to do some sort of model comparison, or you could look at the test of a coefficient.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe could do this by fitting the model with `age` and `f2f` predicting `happy`, and then compare that to the model _also_ with `smm`:  \n```{r}\nmod1 <- lm(happy ~ age + f2f, smmdat)\nmod2 <- lm(happy ~ age + f2f + smm, smmdat)\nanova(mod1, mod2)\n```\n\nThis is testing the addition of **one** parameter (thing being estimated) to our model - the coefficient for `smm`.  \nWe can see that it is just one more parameter because the table abovw shows that the additional degrees of freedom taken up by `mod2` is 1 (the \"Df\" column, and the change in the \"Res.Df\" column).  \n\nSo we could actually just look at the test of that individual parameter, and whether it is different from zero. \nIt's the same:  \n```{r}\nsummary(mod2)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nPlot the model estimated association between social media usage and happiness.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThis follows just the same logic as we did for the monkeys!  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nplotdat <- data.frame(\n  age = mean(smmdat$age), # mean age\n  f2f = mean(smmdat$f2f), # mean f2f interactions\n  smm = 0:150 # social media use from 0 to 150 mins\n)\n\naugment(mod2, newdata = plotdat, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3)+\n  labs(x = \"social media usage\\n(minutes per day)\",\n       y = \"Happiness Score\",\n       title = \"Happiness and social media usage\",\n       subtitle = \"controlling for age and IRL interactions\")\n```\n\n`r solend()`\n\n\n`r qbegin(\"Optional Extra\", qlabel=FALSE)`\n\nIn all the plots we have been making from our models, the other predictors in our model (e.g. `age` and `f2f` in this case) have been held at their mean.  \n\nWhat happens if you create a plot estimating the association between happiness and social media usage, but having `age` at 15, or 30, or 45?  \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\n#| echo: false\n#| out-height: \"350px\"\nplotdat <- \n  expand_grid(\n    age = c(15,30,45),\n    f2f = mean(smmdat$f2f),\n    smm = 0:150 \n  )\n\naugment(mod2, newdata = plotdat, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3) +\n  facet_wrap(~age)\n```\n\nThe **slope** doesn't change at all, but note that it moves up and down. This makes sense, because our model coefficients indicated that happiness goes up with age.  \nNote also that the uncertainty changes, and this is what we want - we have less data on people at age 45, or 15, so we are less confident in our estimates.  \n\nI'm going to use this space to show you a little trick that may come in handy. The function `expand_grid()` will take all combinations of the values you give it for each variable, and expand outwards:  \ne.g.  \n```{r}\nexpand_grid(\n  v1 = c(\"a\",\"b\"),\n  v2 = 1:4\n)\n```\n\nSo instead of creating lots of individual `plotdat` dataframes for each value of `age` 15, 30, and 45, we can create just one that contains all three. Then we can just deal with that in the ggplot.  \n\n::::panelset\n:::panel\n#### One-by-one  \n```{r}\nplotdat1 <- data.frame(\n  age = 15,\n  f2f = mean(smmdat$f2f), \n  smm = 0:150 \n)\nplotdat2 <- data.frame(\n  age = 30,\n  f2f = mean(smmdat$f2f), \n  smm = 0:150 \n)\nplotdat3 <- data.frame(\n  age = 45,\n  f2f = mean(smmdat$f2f), \n  smm = 0:150 \n)\n\np1 <- augment(mod2, newdata = plotdat1, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3)+\n  ylim(5,45)\n\np2 <- augment(mod2, newdata = plotdat2, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3)+\n  ylim(5,45)\n\np3 <- augment(mod2, newdata = plotdat3, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3)+\n  ylim(5,45)\n\n# the patchwork package allows us to add plots together:\np1 + p2 + p3\n```\n\n:::\n:::panel\n#### All-in-one\n`\n```{r}\nplotdat <- \n  expand_grid(\n    age = c(15,30,45),\n    f2f = mean(smmdat$f2f),\n    smm = 0:150 \n  )\n\naugment(mod2, newdata = plotdat, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3) +\n  facet_wrap(~age)\n```\n\n:::\n::::\n\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nHow many observations has our model been fitted to?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIt's not just the 77 people why have in the dataset.. \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nBecause we had those very happy and very unhappy people (`happy` variable was outside our range) that we replaced with `NA`, we have fewer bits of data to fit our model to.  \n\nThat's because `lm()` will default to something called \"listwise deletion\", which will remove any observation where any variable in the model (outcome or predictor) is missing. \n\nWe can see how many observations went into our model because we know how many residuals we have: \n```{r}\nlength(residuals(mod2))\n```\n\nAnd we can also see it from the degrees of freedom at the bottom of the `summary()` output. We know that we have $n-k-1$ degrees of freedom (see [7A #the-f-statistic-a-joint-test](07a_mlr.html#the-f-statistic-a-joint-test){target=\"_blank\"}), and that is shown as 71 here. $k$ is the number of predictors, which we know is 3. So $n$ is 75!  \n```{r}\n#| eval: false\nsummary(mod2)\n```\n```\n...\nF-statistic: 98.23 on 3 and 71 DF,  p-value: < 2.2e-16\n```\n\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nCheck the assumptions of your model.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n[7B Assumptions & Diagnostics](07b_assumptdiag.html){target=\"_blank\"} shows how we can do this. We can rely on tests if we like, or we can do it visually through plots. Getting a good sense of \"what looks weird\" in these assumption plots is something that comes with time.  \n\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nHere are our plots..  \nThey don't look too bad _to me_ (you might feel differently!)\n```{r echo=c(2)}\npar(mfrow=c(2,2))\nplot(mod2)\npar(mfrow=c(1,1))\n```\n\n`r solend()`\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# More RMarkdown/Quarto\n\n`r qbegin(qcounter())`\n\n\n1. Open a .Rmd or .qmd document, and delete all the template stuff.  \n    - Keep the code chunk at the top called \"setup\"  \n2. In the \"setup\" chunk, change it to `echo = FALSE`. This will make sure all code gets hidden from the final rendered document.  \n3. Make a new code chunk called \"analysis\", and for this chunk, set `include = FALSE`. This will make sure that the code in that chunk gets run, but does not actually produce any output.  \n4. Shove all our working analysis (below) in that 'analysis' code chunk.  \n5. Write a paragraph describing the analysis.  \n    - what type of model/analysis is being conducted?\n    - what is the outcome? the predictors? how are they smeasured?\n6. Write a paragraph highlighting the key results. Try to use inline R code. [This example](https://uoepsy.github.io/usmr/2324/misc/socmedmin.Rmd){target=\"_blank\"} may help.  \n7. In a new code chunk, create and show a plot. Make sure this code chunk is set to `include = TRUE`, because we _do_ want the output to show (leaving it blank will also work, because this is the default).  \n8. Click Knit! \n\n\n::: {.callout-note collapse=\"true\"}\n#### Study: Lie detectors\n\n```{r}\n#| include: false\nss=88173#round(runif(1,1e3,1e5))\nset.seed(ss)\nldf = tibble(\n  age = round(runif(142,22,64)),\n  anx = round(rnorm(142,0,1),2),\n  strategy = rbinom(142, 3, plogis(scale(anx)*2)),\n  hr = 45 + .3*age +3*anx+ (strategy==2)*-3.4 + (strategy==3)*-5.6 + rnorm(142,0,3)\n) \n#psych::pairs.panels(ldf)\n#summary(lm(hr~age+anx+factor(strategy),ldf))\n#plot(lm(hr~age+anx+factor(strategy),ldf),which=4)\nldf$hr <- round(ldf$hr,1)\nldf$strategy[60] <- 5\nldf$hr[ldf$hr>75]<- 37.0\n#write_csv(ldf,file=\"../../data/usmr_polygraph.csv\")\n```\n\nLaw enforcement in some countries regularly rely on 'polygraph' tests as a form of 'lie detection'. These tests involve measuring heart rate, blood pressure, respiratory rate and sweat. However, there is very little evidence to suggest that these methods are remotely accurate in being able to determine whether or not someone is lying.  \n\nResearchers are interested in if peoples' heart rates during polygraph tests can be influenced by various pre-test strategies, including deep breathing, or closing their eyes. They recruited `r nrow(ldf)` participants (ages `r min(ldf$age)` to `r max(ldf$age)`). Participants were told they were playing a game in which their task was to deceive the polygraph test, and they would receive financial rewards if they managed successfully. At the outset of the study, they completed a questionnaire which asked about their anxiety in relation to taking part. Participants then chose one of 4 strategies to prepare themselves for the test, each lasting 1 minute. These were \"do nothing\", \"deep breathing\", \"close your eyes\" or \"cough\"^[apparently coughing is a method of immediately lowering heart rate!]. The average heart rate of each participant was recorded during their test. \n\n\n```{r}\n#| echo: false\n#| tbl-cap: \"usmr_polygraph.csv data dictionary\"\ntibble(\n  variable = names(ldf),\n  description = c(\n    \"Age of participant (years)\",\n    \"Anxiety measure (Z-scored)\",\n    \"Pre-test Strategy (0 = do nothing, 1 = close eyes, 2 = cough, 3 = deep breathing)\",\n    \"Average Heart Rate (bpm) during test\"\n  )\n) |> gt::gt()\n```\n\n__Analysis__  \n\n```{r}\n#| eval: false\n#| code-fold: true\n# load libraries\nlibrary(tidyverse)\nlibrary(psych)\n# read in the data\nliedf <- read_csv(\"https://uoepsy.github.io/data/usmr_polygraph.csv\")\n\n# there seems to be a 5 there.. \ntable(liedf$strategy)\n# the other variables look okay though\ndescribe(liedf)\npairs.panels(liedf)\n\n\nliedf <- liedf |> \n  filter(strategy!=5) |>\n  mutate(\n    # strategy is a factor. but currently numbers\n    # i'm going to give them better labels too.. \n    # to do this is need to tell factor() what \"levels\" to look for\n    # and then give it some \"labels\" to apply to those.\n    strategy = factor(strategy, \n                      levels = c(\"0\",\"1\",\"2\",\"3\"),\n                      labels = c(\"do nothing\", \"close eyes\",\n                                 \"cough\", \"deep breathing\")\n                      )\n  )\n\nliemod <- lm(hr ~ age + anx + strategy, data = liedf)\n\n# Does HR differ between strategies?\nanova(liemod)\n# the above is a shortcut for getting this comparison out:\nanova(\n  lm(hr ~ age + anx, data = liedf),\n  lm(hr ~ age + anx + strategy, data = liedf)\n)\n\n# i want a plot to show the HRs of different strategies.. \n# ??\n```\n\n\n:::\n\n\n\n\n\n\n`r qend()`\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n```\n\n# More monkeys \n\n```{r}\n#| include: false\nset.seed(919805)\ndf = \n  expand_grid(\n    obj_type = 0:1,\n    obj_colour = 0:2,\n    obj_size = 0:2,\n    n = 1:7\n  ) |> select(-n) |>\n  mutate(\n    age = round(runif(n(),1,21) + 4*obj_type),\n    species = sample(c(\"macaque\",\"capuchin\"), n(), T)\n  )\nxm = model.matrix(lm(rnorm(nrow(df)) ~ age + obj_type + obj_size + species,df))\n\ndf$exploration_time = xm %*% c(14,-.27, 2.5, -.5, -3) + rnorm(nrow(df),0,3.5)\n\ndf$exploration_time = round(df$exploration_time[,1],1)\n# df |> mutate(adult=ifelse(age>8,1,0)) |> pairs()\n\ndf <- df |> select(age,species,obj_type,obj_colour, obj_size,exploration_time) |>\n  mutate(\n    obj_type = factor(obj_type, labels=c(\"soft\",\"mechanical\")),\n    obj_colour = factor(obj_colour, labels=c(\"red\",\"green\",\"blue\")),\n    obj_size = map_dbl(obj_size, ~30+round(rnorm(1,.*20,11.5)))\n    #obj_size = factor(obj_size, labels=c(\"small\",\"medium\",\"large\")),\n  )\n\ndf$exploration_time <- pmax(0,df$exploration_time)\ndf <- slice_sample(df,prop=.95)\n\n\nsomenames = read.table(\"https://artofmemory.com/files/forum/947/initials.txt\",header=F,sep=\",\")\nset.seed(44)\ndf$name = sample(somenames$V2, nrow(df))\ndf <- df |> relocate(name)\n\ndf <- monkeytoys <- df |> select(-species)\n#write_csv(monkeytoys,\"../../data/monkeytoys.csv\")\n\n```\n\n\n\n:::frame\n__Data: monkeytoys.csv__  \n\nAfter their recent study investigating how age is associated with inquisitiveness in monkeys (see [Week 5 Exercises](05_ex.html#monkey-exploration){target=\"_blank\"}) our researchers have become interested in whether primates show preferences for certain types of object - are they more interested in toys with moving parts, or with soft plush toys?  \n\nThey conduct another study (Bolton, Archer, Peng, Winther & Gandolfi, 2024^[Another fake study!]) in which they gave `r nrow(monkeytoys)` monkeys each a different toy, and recorded the amount of time each monkey spent exploring their toy. Toys were categorised as either being 'mechanical' or 'soft'. Mechanical toys had several parts that could be manipulated, while soft toys did not. They also recorded the age of each monkey, and a few further attributes of each toy (its size and colour).  \n\nThe aim of this study is to investigate the following question:  \n\n> Do monkeys have a preference between soft toys vs toys with moving parts?\n\nThe data is available at [https://uoepsy.github.io/data/monkeytoys.csv](https://uoepsy.github.io/data/monkeytoys.csv){target=\"_blank\"} and contains the variables described in @tbl-monkeytoys\n```{r}\n#| label: tbl-monkeytoys\n#| echo: false\n#| tbl-cap: \"Data dictionary for monkeytoys.csv\"\ntibble(\n  variable = names(monkeytoys),\n  description = c(\"Monkey Name\",\"Age of monkey in years\", \"Type of novel object given (mechanical / soft)\",\"Main colour of object (red / green / blue)\",\"Size of object in cm (length of largest dimension of the object)\",\"Time (in minutes) spent exploring the object\")\n) |>\n  gt::gt()\n```\n\n\n:::\n\n`r qbegin(qcounter())`\nFit a simple linear model examining whether `exploration_time` depends on the type of object given to monkeys (`obj_type`).  \n\nMake a plot too if you want!  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThere's nothing new here. It's just `lm(outcome ~ predictor)`.  \n\nFor the plot, try a boxplot maybe? or even a violin plot if you're feeling adventurous!  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nmonkeytoys <-  read_csv(\"https://uoepsy.github.io/data/monkeytoys.csv\")\n\n\nmodel1 <- lm(exploration_time ~ obj_type, data = monkeytoys)\nsummary(model1)\n```\n\nFrom this, we would conclude that monkeys do not significantly differ in how much time they spend exploring one type of toy over another (mechanical or soft).  \n\nLet's go wild and put a boxplot _on top of_ a violin plot!  \n```{r}\nggplot(monkeytoys, \n       aes(x=obj_type, y=exploration_time, \n           col=obj_type)) +\n  geom_violin() + \n  geom_boxplot(alpha=.3, width=.4)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nIs the distribution of ages of the monkeys with soft toys similar to those with mechanical toys?  \n\nIs there a way you could test this? \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWe're wanting to know if age (continuous) is different between two groups (monkeys seeing soft toys and monkeys seeing moving toys). Anyone for $t$?  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\n#| echo: false\nres <- t.test(age ~ obj_type, data = monkeytoys)\n```\n\n\n```{r}\nt.test(age ~ obj_type, data = monkeytoys)\n```\n\n:::int\nThe average age of monkeys with the soft toys is `r with(monkeytoys,round(mean(age[obj_type==\"soft\"]),1))` years (SD = `r with(monkeytoys,round(sd(age[obj_type==\"soft\"]),1))`), and the average of those with the mechanical toys is `r with(monkeytoys,round(mean(age[obj_type==\"mechanical\"]),1))` (SD = `r with(monkeytoys,round(sd(age[obj_type==\"mechanical\"]),1))`). This difference is significant as indicated by a Welch two-sample $t$-test ($t(`r round(res[['parameter']],1)`)=`r round(res[['statistic']],2)`, \\, p`r format.pval(res[['p.value']],eps=.001,digits=2)`$).  \n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\n**Discuss:** What does this mean for our model of `exploration_time`? Remember - the researchers already discovered last week that younger monkeys tend to be more inquisitive about new objects than older monkeys are.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- If older monkeys spend less time exploring novel objects\n- And our group of monkeys with mechanical toys are older than the group with soft toys. \n- Then... \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe have reason to believe that older monkeys spend less time exploring novel objects. We discovered this last week.  \n\nBecause our group of monkeys with mechanical toys are of a different age than the group with soft toys, surely we can't discern whether any difference in `exploration_time` between the two types of toy is because of these age differences or because of the type of toy?  \n\n<a id='Kq5SmFeASyhw1TtTYj75YA' class='gie-single' href='http://www.gettyimages.com/detail/586024350' target='_blank' style='color:#a7a7a7;text-decoration:none;font-weight:normal !important;border:none;display:inline-block;'>Embed from Getty Images</a><script>window.gie=window.gie||function(c){(gie.q=gie.q||[]).push(c)};gie(function(){gie.widgets.load({id:'Kq5SmFeASyhw1TtTYj75YA',sig:'1fKQopDLlPOpG9cuEzA7G5fZuR_u8eWzlQV2GELvt2U=',w:'511px',h:'338px',items:'586024350',caption: true ,tld:'com',is360: false })});</script><script src='//embed-cdn.gettyimages.com/widgets.js' charset='utf-8' async></script>\n\n`r solend()`\n\n\n\n`r qbegin(qcounter())`\nFit a model the association between exploration time and type of object while controlling for age.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- When we add multiple predictors in to `lm()`, it can sometimes matter what order we put them in (e.g. if we want to use `anova(model)` to do a quick series of incremental model comparisons as in [7A #shortcuts-for-model-comparisons](07a_mlr.html#shortcuts-for-model-comparisons){target=\"_blank\"}). Good practice is to put the thing you're interested in (the 'focal predictor') at the end, e.g.: `lm(outcome ~ covariates + predictor-of-interest)`    \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nmodel2 <- lm(exploration_time ~ age + obj_type, data = monkeytoys)\n\nsummary(model2)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nThe thing we're interested in here is association between `exploration_time` and `obj_type`.  \nHow does it differ between the models we've created so far, and why?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- To quickly compare several models side by side, the `tab_model()` function from the **sjPlot** package can be quite useful, e.g. `tab_model(model1, model2, ...)`.  \n- alternatively, just use `summary()` on each model.  \n\n:::\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\nlibrary(sjPlot)\ntab_model(model1, model2)\n```\n\n  \nThe coefficient for `obj_type` is much bigger when we include `age` in the model, and it is significant!  \n\nIn the model without `age`, we're just comparing the two groups. We can see this in the left hand panel of the plot below - it's the difference between the two group means.  \nWhen we include `age` in the model, the coefficient for `obj_type` represents the difference in the heights of the two lines in the right hand panel below. \n\n```{r}\n#| code-fold: true\n#| out-width: \"100%\"\nlibrary(patchwork)\np1 <- ggplot(monkeytoys, aes(x=obj_type, y=exploration_time,\n             col=obj_type))+\n  geom_jitter(width=.05)+\n  stat_summary(geom=\"pointrange\", fun.data = mean_cl_normal, \n               position = position_nudge(x=.14)) +\n  labs(subtitle=\"exp_time~obj_type\")+\n  scale_y_continuous(breaks=seq(0,22,2))+\n  guides(col=\"none\")\n\np2 <- broom::augment(model2, interval=\"confidence\") |>\n  ggplot(aes(x=age, col=obj_type))+\n  geom_point(aes(y=exploration_time))+\n  geom_line(aes(y=.fitted))+\n  geom_ribbon(aes(ymin=.lower,ymax=.upper,\n                  fill=obj_type),col=NA,alpha=.2)+\n  scale_y_continuous(breaks=seq(0,22,2))+\n  labs(subtitle=\"exp_time~age+obj_type\")\n\np1 + p2 \n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nPlot the *model estimated* difference in exploration time for each object type.  \n\nTo do this, you'll need to create a little data frame for plotting, then give that to the `augment()` function from the **broom** package. This will then give us the model fitted value and the confidence interval, which we can plot!    \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- An example of this whole process is in [7A#model-visualisations](07a_mlr.html#model-visualisations){target=\"_blank\"}.  \n  - The example has a continuous predictor, so we plotted a line and a ribbon. An alternative for a categorical predictor might be a `geom_pointrange()`.  \n\n:::\n\n\n`r qend()`\n\nWe've split this solution in to parts so that you can have a go at some bits without seeing it all at once.  \n\n`r solbegin(label=\"Solution Part 1 - make a dataframe\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nHere's our dataframe to add model estimated values to:  \n```{r}\nplotdat <- data.frame(\n  obj_type = c(\"soft\",\"mechanical\"),\n  age = mean(monkeytoys$age)\n)\n```\n\n`r solend()`\n\n`r solbegin(label=\"Solution Part 2 - use broom::augment\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nThis gives us our estimates and intervals:  \n```{r}\nlibrary(broom)\naugment(model2, newdata = plotdat, interval=\"confidence\")\n```\n\n\n`r solend()`\n\n`r solbegin(label=\"Solution Part 3 - into ggplot!\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\naugment(model2, newdata = plotdat, interval=\"confidence\") |>\n  ggplot(aes(x=obj_type,y=.fitted))+\n  geom_pointrange(aes(ymin=.lower,ymax=.upper))\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nAre other aspects of the toys (their size and colour) also associated with more/less exploration time?  \n\nWe can phrase this as \"do size and colour explain additional variance in exploration time?\". How might we test such a question? \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- We basically just want to add these new predictors into our model.  \n- Don't worry about interpreting the coefficients right now (we'll talk more about categorical predictors next week), but we can still test whether the inclusion of size and colour improve our model! (see [7A#model-comparisons](07a_mlr.html#model-comparisons){target=\"_blank\"}).  \n\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nThis is our current model: \n```{r}\nmodel2 <- lm(exploration_time ~ age + obj_type, data = monkeytoys)\n```\nAnd we can add the two colour and size variables:  \n```{r}\nmodel3 <- lm(exploration_time ~ age + obj_type + obj_colour +\n               obj_size, data = monkeytoys)\n```\n\nLet's compare them:  \n```{r}\nanova(model2, model3)\n```\n\n```{r}\n#| echo: false\nres <- anova(model2, model3)\n```\n\n:::int\nAfter accounting for differences due to age and type of object (mechanical vs soft), other features of objects - size (cm) and colour (red/green/blue) - were found to significantly explain variation in the time monkeys spent exploring those objects ($F(`r res[2,3]`,`r res[2,1]`)=`r round(res[2,5],2)`, \\, p=`r format.pval(res[2,6],eps=.001,digits=2)`$). \n:::\n\n`r solend()`\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Social Media Use\n\n```{r}\n#| include: false\n\nlibrary(tidyverse)\nset.seed(764)\nN = runif(1,60,150)\ndf <- tibble(\n  x1 = rnorm(N),\n  x2 = rnorm(N),\n  x3 = .7*x1 + -.5*x2 + rnorm(N),\n  y = .1*x3 + 1.1*x1 + .7*x2 + rnorm(N)\n  # x2 = rnorm(N),\n  # x3 = -.8*x2 + rnorm(N),\n  # y = -.01*x3 - 1*x2 + rnorm(N)\n)\ndf |> transmute(\n  happy = round(scale(y)[,1]*7.02+25),\n  smm = (round((scale(x3)[,1]*24.2+76.4)/5)*5),\n  f2f = (round((scale(x1)[,1]*45 + 90)/15)*15)/60,\n  age = round(scale(x2)[,1]*6.7 + 27)\n) |> \n  mutate(\n    happy = pmax(0,pmin(45,happy)),\n    smm = pmax(0,smm),\n    f2f = pmax(0,f2f),\n    age = pmax(12,age),\n    name = randomNames::randomNames(nrow(df),which.names = \"first\")\n  ) |> relocate(name, age) -> df\n\n# psych::multi.hist(df[,-1], global=F)\n# ggplot(df, aes(x=smm,y=happy))+\n#   geom_point()\n# \n# sjPlot::tab_model(\n#   lm(happy ~ smm,df),\n#   lm(happy ~ smm+f2f,df),\n#   lm(happy ~ smm+age,df),\n#   lm(happy ~ smm+f2f+age,df)\n# )\n\nch = sample(1:nrow(df),4)\ndf$smm[ch] <- paste0(df$smm[ch],\" minutes\")\ndf$happy[sample(1:nrow(df),1)] <- 47\n\ndf1 <- df |> select(name, smm, happy)\ndf2 <- df\nsmmdat <- df\n#write_csv(df, file=\"../../data/socmedmin.csv\")\n```\n\n:::frame\n__Data: socmedmin.csv__  \n\n> Is more social media use associated with more happiness?  \n\n`r nrow(df)` participants completed a short online form that included a questionnaire (9 questions) to get a measure of their happiness. Information was also recorded on their age, the number of minutes per day spent using social media, and the number of hours per day spent having face-to-face interactions.\n\nThe data is available at [https://uoepsy.github.io/data/socmedmin.csv](https://uoepsy.github.io/data/socmedmin.csv){target=\"_blank\"}\n\n```{r}\n#| echo: false\n#| tbl-cap: \"Data Dictionary: socmedmin.csv\"\n#| label: tbl-smmdict\nsmmdat <- read_csv(\"../../data/socmedmin.csv\")\ntibble(\n  variable = names(smmdat),\n  description = c(\"Participant Name\",\n                  \"Participant Age (years)\",\n                  \"Happiness Score (sum of 9 likert questions each scored 1-5)\",\n                  \"Social Media Use (minutes per day)\",\n                  \"Face-to-face interactions (hours per day)\"\n                  )\n) |> gt::gt()\n```\n\n:::\n\n\n`r qbegin(qcounter())`\nRead in the data and have a look around. \n\nData often doesn't come to us in a neat format. Something here is a bit messy, so you'll need to figure out how to tidy it up.\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIs every variable of the right type (numeric, character, factor etc)? If not, we'll probably want to convert any that aren't the type we want.  \n\nBe careful not to lose data when we convert things. Note that R cannot do this:  \n```{r}\nas.numeric(\"20 minutes\")\n```\n\nSo maybe some combination of `as.numeric()` and `gsub()` might work? (see [6A #dealing-with-character-strings](06_wt.html#dealing-with-character-strings){target=\"_blank\"}) \n\n:::\n\n`r qend()`\n`r solbegin(label=\"Solution Part 1 - identify the problem\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\n#| eval: false\nsmmdat <- read_csv(\"https://uoepsy.github.io/data/socmedmin.csv\")\n```\n\nNote that the `smm` variable seems to be a character..  \n```{r}\nhead(smmdat)\n```\nwe could just convert it all to numeric by using `as.numeric()`: \n```{r}\nas.numeric(smmdat$smm)\n```\n\nNote that this has introduced some `NA` values though! We've lost some data:\n\n```{r}\nsum(is.na(smmdat$smm)) # NAs in original data\nsum(is.na(as.numeric(smmdat$smm))) # NAs in numeric-converted data\n```\n\nIf we look carefully, these entries that we are losing are all slightly different from the rest. They all have \" minutes\" in them, rather than just the minutes.. \n```{r}\nsmmdat$smm[is.na(as.numeric(smmdat$smm))]\n```\n\nAnd when we ask R to make \"20 minutes\" into a number, it isn't clever enough to recognise that it is a number, so it just turns it into `NA`:\n```{r}\nas.numeric(\"20 minutes\")\n```\n\n`r solend()`\n`r solbegin(label=\"Solution Part 2 - figure out a fix\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nSo we need to _first_ remove the \" minutes\" bit, and _then_ change to numeric.  \nWe can use `gsub()` to substitute \" minutes\" with \"\" (i.e. nothingness):\n```{r}\ngsub(\" minutes\", \"\", \"20 minutes\")\n```\nAnd we can then turn _that_ into numbers.. \n```{r}\nas.numeric(gsub(\" minutes\", \"\", \"20 minutes\"))\n```\n\n`r solend()`\n`r solbegin(label=\"Solution Part 3 - implement!\", slabel=FALSE,show=TRUE, toggle=params$TOGGLE)`\n\nNow that we've figured out how to convert it, I'm just going to overwrite the `smm` variable, rather than creating a new one.  \n\n::::panelset\n:::panel\n#### base R\n```{r}\nsmmdat$smm <- as.numeric(gsub(\" minutes\", \"\", smmdat$smm))\n```\n:::\n:::panel\n#### tidyverse\n```{r}\nsmmdat <- smmdat |> \n  mutate(\n    smm = as.numeric(gsub(\" minutes\", \"\", smm))\n  )\n```\n:::\n::::\n\nOkay, now the `smm` variable is numeric, and we haven't lost any datapoints!\n```{r}\nsummary(smmdat)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nSomething we haven't really come across until now is the importance of checking the _range_ (i.e. min and max) of our variables. \nThis is a good way to check for errors in the data (i.e. values that we shouldn't be able to obtain using our measurement tool).  \n\nCheck the range of the `happy` variable - does it look okay, based on the description of how it is recorded? \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- `min()`, `max()`, or even just `range()`!!  \n- If there are any observations you think have impossible values, then you could set them as NA for now (see [6A #impossible-values ](06_wt.html#impossible-values){target=\"_blank\"}).  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nrange(smmdat$happy)\n```\nThe minimum is `r min(smmdat$happy)`, and the maximum is `r max(smmdat$happy)`.  \n\nBut our scores are based on the sum of 9 questions that can each score from 1 to 5. So surely that means the minimum someone could score would be 9, and the maximum they could score would be 45?  \n\n```{r}\nsmmdat <- smmdat |>\n  mutate(\n    happy = ifelse(happy < 9 | happy > 45, NA, happy)\n  )\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nFinally, we've got to a point where we can look at some descriptive statistics - e.g. mean and standard deviations for continuous variables, frequencies (counts) if there are any categorical variables.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou can do this the manual way, calculating it for each variable, but there are also lots of handy functions to make use of.  \n\n- `describe()` from the __psych__ package\n- `CreateTableOne()` from the __tableone__ package  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::::panelset\n:::panel\n#### Tidyverse\n\nIn tidyverse, we could do this like:  \n```{r}\nsmmdat |> \n  summarise(\n    mean_age = mean(age),\n    sd_age = sd(age),\n    mean_happy = mean(happy, na.rm=TRUE),\n    sd_happy = sd(happy, na.rm=TRUE),\n    mean_smm = mean(smm),\n    sd_smm = sd(smm)\n  )\n```\n\n:::\n:::panel\n#### psych::describe\n\nWe can use the `describe` function from the __psych__ package: \n```{r}\nlibrary(psych)\ndescribe(smmdat)\n```\n\n\n:::\n:::panel\n#### tableone\n\nThe tableone package will also be clever and give counts and percentages for categorical data like the `name` variable. However, names aren't something we really want to summarise, so it's easier just to give the function everything except the `name` variable.  \n```{r}\nlibrary(tableone)\nCreateTableOne(data = smmdat |> select(-name) )\n```\n\n:::\n::::\n\n`r solend()`\n\n<!-- `r qbegin(qcounter())` -->\n<!-- Again, we're going to start with a one-predictor model.   -->\n\n<!-- Fit a simple linear regression model to address our research question (\"Is more social media use associated with more happiness?\").   -->\n\n<!-- Make a plot too.   -->\n\n<!-- What do you conclude?   -->\n\n\n<!-- ::: {.callout-tip collapse=\"true\"} -->\n<!-- #### Hints -->\n\n<!-- We're using `lm()` again.  -->\n\n<!-- To make a plot, because we just have a very simple one predictor model, we could just plot the data itself and then add `geom_smooth(method=lm)` to it to display the model.   -->\n\n\n<!-- ::: -->\n\n<!-- `r qend()` -->\n<!-- `r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)` -->\n\n<!-- From the model below, we would conclude that more social media use is associated with more happiness. The coefficient from our model is positive (more social media = more happiness), and significantly different from zero.   -->\n\n<!-- ```{r} -->\n<!-- mod1 <- lm(happy ~ smm, smmdat) -->\n<!-- summary(mod1) -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- ggplot(smmdat, aes(x=smm,y=happy))+ -->\n<!--   geom_point()+ -->\n<!--   geom_smooth(method=lm)+ -->\n<!--   labs(x=\"Social Media Usage (minutes per day)\", -->\n<!--        y=\"Happiness Score\") -->\n<!-- ``` -->\n\n<!-- `r solend()` -->\n\n`r qbegin(qcounter())`\n\nFor our research question (\"Is more social media use associated with more happiness?\"), we could consider fitting the following model:  \n```\nlm(happy ~ smm, data = smmdat)\n```\n\n**But** is it not a bit more complicated than that? Surely there are lots of other things that are relevant? For instance, it's quite reasonable to assume that social media use is related to someone's age? It's also quite likely that happiness changes with age too. But that means that our coefficient of `happy ~ smm` could actually just be changes in happiness due to something else (like age)? Similarly, people who use social media might just be more sociable people (i.e. they might see more people in real life, and that might be what makes them happy).  \n\nEspecially in observational research (i.e. we aren't intervening and asking some people to use social media and others to not use it), figuring out the relevant association that we want can be incredibly tricky.  \n\nAs it happens, we _do_ have data on these participants' ages, and on the amount of time they spend having face-to-face interactions with people!  \n\nLook at how all these variables correlate with one another, and make some quick plots.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- You can give a data frame of numeric variables to `cor()` and it gives you all the correlations between pairs of variables in a \"correlation matrix\"  \n- if you want some quick pair-wise plots (not pretty, but useful!), try the `pairs.panels()` function from the __psych__ package.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nHere is a correlation matrix. It shows the correlations between each pair of variables.  \nNote that the bit below the diagonal is the same as the bit above. The diagonal is always going to be all 1's, because a variable is always perfectly correlated with itself.  \n```{r}\nsmmdat |> \n  select(-name) |>\n  filter(!is.na(happy)) |>\n  cor()\n```\n\nThe `pairs.panels()` function is a useful way to quickly explore the bivariate (two-variables) patterns in a dataset:  \n```{r}\nlibrary(psych)\nsmmdat |> \n  select(-name) |>\n  pairs.panels()\n```\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nIs social media usage associated with happiness, after accounting for age and the number of face-to-face interactions?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- This question can be answered in a couple of ways. You might be able to do some sort of model comparison, or you could look at the test of a coefficient.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe could do this by fitting the model with `age` and `f2f` predicting `happy`, and then compare that to the model _also_ with `smm`:  \n```{r}\nmod1 <- lm(happy ~ age + f2f, smmdat)\nmod2 <- lm(happy ~ age + f2f + smm, smmdat)\nanova(mod1, mod2)\n```\n\nThis is testing the addition of **one** parameter (thing being estimated) to our model - the coefficient for `smm`.  \nWe can see that it is just one more parameter because the table abovw shows that the additional degrees of freedom taken up by `mod2` is 1 (the \"Df\" column, and the change in the \"Res.Df\" column).  \n\nSo we could actually just look at the test of that individual parameter, and whether it is different from zero. \nIt's the same:  \n```{r}\nsummary(mod2)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nPlot the model estimated association between social media usage and happiness.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThis follows just the same logic as we did for the monkeys!  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nplotdat <- data.frame(\n  age = mean(smmdat$age), # mean age\n  f2f = mean(smmdat$f2f), # mean f2f interactions\n  smm = 0:150 # social media use from 0 to 150 mins\n)\n\naugment(mod2, newdata = plotdat, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3)+\n  labs(x = \"social media usage\\n(minutes per day)\",\n       y = \"Happiness Score\",\n       title = \"Happiness and social media usage\",\n       subtitle = \"controlling for age and IRL interactions\")\n```\n\n`r solend()`\n\n\n`r qbegin(\"Optional Extra\", qlabel=FALSE)`\n\nIn all the plots we have been making from our models, the other predictors in our model (e.g. `age` and `f2f` in this case) have been held at their mean.  \n\nWhat happens if you create a plot estimating the association between happiness and social media usage, but having `age` at 15, or 30, or 45?  \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\n#| echo: false\n#| out-height: \"350px\"\nplotdat <- \n  expand_grid(\n    age = c(15,30,45),\n    f2f = mean(smmdat$f2f),\n    smm = 0:150 \n  )\n\naugment(mod2, newdata = plotdat, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3) +\n  facet_wrap(~age)\n```\n\nThe **slope** doesn't change at all, but note that it moves up and down. This makes sense, because our model coefficients indicated that happiness goes up with age.  \nNote also that the uncertainty changes, and this is what we want - we have less data on people at age 45, or 15, so we are less confident in our estimates.  \n\nI'm going to use this space to show you a little trick that may come in handy. The function `expand_grid()` will take all combinations of the values you give it for each variable, and expand outwards:  \ne.g.  \n```{r}\nexpand_grid(\n  v1 = c(\"a\",\"b\"),\n  v2 = 1:4\n)\n```\n\nSo instead of creating lots of individual `plotdat` dataframes for each value of `age` 15, 30, and 45, we can create just one that contains all three. Then we can just deal with that in the ggplot.  \n\n::::panelset\n:::panel\n#### One-by-one  \n```{r}\nplotdat1 <- data.frame(\n  age = 15,\n  f2f = mean(smmdat$f2f), \n  smm = 0:150 \n)\nplotdat2 <- data.frame(\n  age = 30,\n  f2f = mean(smmdat$f2f), \n  smm = 0:150 \n)\nplotdat3 <- data.frame(\n  age = 45,\n  f2f = mean(smmdat$f2f), \n  smm = 0:150 \n)\n\np1 <- augment(mod2, newdata = plotdat1, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3)+\n  ylim(5,45)\n\np2 <- augment(mod2, newdata = plotdat2, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3)+\n  ylim(5,45)\n\np3 <- augment(mod2, newdata = plotdat3, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3)+\n  ylim(5,45)\n\n# the patchwork package allows us to add plots together:\np1 + p2 + p3\n```\n\n:::\n:::panel\n#### All-in-one\n`\n```{r}\nplotdat <- \n  expand_grid(\n    age = c(15,30,45),\n    f2f = mean(smmdat$f2f),\n    smm = 0:150 \n  )\n\naugment(mod2, newdata = plotdat, interval = \"confidence\") |>\n  ggplot(aes(x = smm, y = .fitted)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha=.3) +\n  facet_wrap(~age)\n```\n\n:::\n::::\n\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nHow many observations has our model been fitted to?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIt's not just the 77 people why have in the dataset.. \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nBecause we had those very happy and very unhappy people (`happy` variable was outside our range) that we replaced with `NA`, we have fewer bits of data to fit our model to.  \n\nThat's because `lm()` will default to something called \"listwise deletion\", which will remove any observation where any variable in the model (outcome or predictor) is missing. \n\nWe can see how many observations went into our model because we know how many residuals we have: \n```{r}\nlength(residuals(mod2))\n```\n\nAnd we can also see it from the degrees of freedom at the bottom of the `summary()` output. We know that we have $n-k-1$ degrees of freedom (see [7A #the-f-statistic-a-joint-test](07a_mlr.html#the-f-statistic-a-joint-test){target=\"_blank\"}), and that is shown as 71 here. $k$ is the number of predictors, which we know is 3. So $n$ is 75!  \n```{r}\n#| eval: false\nsummary(mod2)\n```\n```\n...\nF-statistic: 98.23 on 3 and 71 DF,  p-value: < 2.2e-16\n```\n\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nCheck the assumptions of your model.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n[7B Assumptions & Diagnostics](07b_assumptdiag.html){target=\"_blank\"} shows how we can do this. We can rely on tests if we like, or we can do it visually through plots. Getting a good sense of \"what looks weird\" in these assumption plots is something that comes with time.  \n\n:::\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nHere are our plots..  \nThey don't look too bad _to me_ (you might feel differently!)\n```{r echo=c(2)}\npar(mfrow=c(2,2))\nplot(mod2)\npar(mfrow=c(1,1))\n```\n\n`r solend()`\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# More RMarkdown/Quarto\n\n`r qbegin(qcounter())`\n\n\n1. Open a .Rmd or .qmd document, and delete all the template stuff.  \n    - Keep the code chunk at the top called \"setup\"  \n2. In the \"setup\" chunk, change it to `echo = FALSE`. This will make sure all code gets hidden from the final rendered document.  \n3. Make a new code chunk called \"analysis\", and for this chunk, set `include = FALSE`. This will make sure that the code in that chunk gets run, but does not actually produce any output.  \n4. Shove all our working analysis (below) in that 'analysis' code chunk.  \n5. Write a paragraph describing the analysis.  \n    - what type of model/analysis is being conducted?\n    - what is the outcome? the predictors? how are they smeasured?\n6. Write a paragraph highlighting the key results. Try to use inline R code. [This example](https://uoepsy.github.io/usmr/2324/misc/socmedmin.Rmd){target=\"_blank\"} may help.  \n7. In a new code chunk, create and show a plot. Make sure this code chunk is set to `include = TRUE`, because we _do_ want the output to show (leaving it blank will also work, because this is the default).  \n8. Click Knit! \n\n\n::: {.callout-note collapse=\"true\"}\n#### Study: Lie detectors\n\n```{r}\n#| include: false\nss=88173#round(runif(1,1e3,1e5))\nset.seed(ss)\nldf = tibble(\n  age = round(runif(142,22,64)),\n  anx = round(rnorm(142,0,1),2),\n  strategy = rbinom(142, 3, plogis(scale(anx)*2)),\n  hr = 45 + .3*age +3*anx+ (strategy==2)*-3.4 + (strategy==3)*-5.6 + rnorm(142,0,3)\n) \n#psych::pairs.panels(ldf)\n#summary(lm(hr~age+anx+factor(strategy),ldf))\n#plot(lm(hr~age+anx+factor(strategy),ldf),which=4)\nldf$hr <- round(ldf$hr,1)\nldf$strategy[60] <- 5\nldf$hr[ldf$hr>75]<- 37.0\n#write_csv(ldf,file=\"../../data/usmr_polygraph.csv\")\n```\n\nLaw enforcement in some countries regularly rely on 'polygraph' tests as a form of 'lie detection'. These tests involve measuring heart rate, blood pressure, respiratory rate and sweat. However, there is very little evidence to suggest that these methods are remotely accurate in being able to determine whether or not someone is lying.  \n\nResearchers are interested in if peoples' heart rates during polygraph tests can be influenced by various pre-test strategies, including deep breathing, or closing their eyes. They recruited `r nrow(ldf)` participants (ages `r min(ldf$age)` to `r max(ldf$age)`). Participants were told they were playing a game in which their task was to deceive the polygraph test, and they would receive financial rewards if they managed successfully. At the outset of the study, they completed a questionnaire which asked about their anxiety in relation to taking part. Participants then chose one of 4 strategies to prepare themselves for the test, each lasting 1 minute. These were \"do nothing\", \"deep breathing\", \"close your eyes\" or \"cough\"^[apparently coughing is a method of immediately lowering heart rate!]. The average heart rate of each participant was recorded during their test. \n\n\n```{r}\n#| echo: false\n#| tbl-cap: \"usmr_polygraph.csv data dictionary\"\ntibble(\n  variable = names(ldf),\n  description = c(\n    \"Age of participant (years)\",\n    \"Anxiety measure (Z-scored)\",\n    \"Pre-test Strategy (0 = do nothing, 1 = close eyes, 2 = cough, 3 = deep breathing)\",\n    \"Average Heart Rate (bpm) during test\"\n  )\n) |> gt::gt()\n```\n\n__Analysis__  \n\n```{r}\n#| eval: false\n#| code-fold: true\n# load libraries\nlibrary(tidyverse)\nlibrary(psych)\n# read in the data\nliedf <- read_csv(\"https://uoepsy.github.io/data/usmr_polygraph.csv\")\n\n# there seems to be a 5 there.. \ntable(liedf$strategy)\n# the other variables look okay though\ndescribe(liedf)\npairs.panels(liedf)\n\n\nliedf <- liedf |> \n  filter(strategy!=5) |>\n  mutate(\n    # strategy is a factor. but currently numbers\n    # i'm going to give them better labels too.. \n    # to do this is need to tell factor() what \"levels\" to look for\n    # and then give it some \"labels\" to apply to those.\n    strategy = factor(strategy, \n                      levels = c(\"0\",\"1\",\"2\",\"3\"),\n                      labels = c(\"do nothing\", \"close eyes\",\n                                 \"cough\", \"deep breathing\")\n                      )\n  )\n\nliemod <- lm(hr ~ age + anx + strategy, data = liedf)\n\n# Does HR differ between strategies?\nanova(liemod)\n# the above is a shortcut for getting this comparison out:\nanova(\n  lm(hr ~ age + anx, data = liedf),\n  lm(hr ~ age + anx + strategy, data = liedf)\n)\n\n# i want a plot to show the HRs of different strategies.. \n# ??\n```\n\n\n:::\n\n\n\n\n\n\n`r qend()`\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"output-file":"07_ex.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","toc_float":true,"code-annotations":"hover","link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Exercises: Multiple Regression","params":{"SHOW_SOLS":false,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}