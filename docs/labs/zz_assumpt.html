<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Recipe Book: LM Assumptions</title>

<script src="site_libs/header-attrs-2.8/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-chevron-circle-right')) {
    f.classList.add('fa-chevron-circle-down')
    f.classList.remove('fa-chevron-circle-right')
} else {
    f.classList.add('fa-chevron-circle-right')
    f.classList.remove('fa-chevron-circle-down')
}
}
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="https://uoepsy.github.io/usmr/">
    <span class="fas fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    USMR Starts Here!
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="00_introPG.html">Getting started with R &amp; RStudio</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data &amp; Distributions
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_categorical.html">1: Categorical Data</a>
    </li>
    <li>
      <a href="02_numerical.html">2: Numeric Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tests, Models &amp; Data Wrangling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">3: Hypothesis testing</li>
    <li class="dropdown-header">4: More tests</li>
    <li class="dropdown-header">5: Cov, Cor, Functions &amp; Models</li>
    <li class="dropdown-header">--- 6: Break Week ---</li>
    <li class="dropdown-header">7: Messy data</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Regression models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">8: Linear Regression</li>
    <li class="dropdown-header">9: More Linear Regression</li>
    <li class="dropdown-header">10: GLM!</li>
    <li class="dropdown-header">11: Writing up</li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extras
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">LM Assumptions: Recipe book</li>
    <li class="dropdown-header">Incremental Validity: A Caution</li>
    <li class="dropdown-header">Model Selection</li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Recipe Book: LM Assumptions</h1>

</div>


<div id="choose-fit-assess-use" class="section level1">
<h1>Choose &gt; Fit &gt; Assess &gt; Use</h1>
<div class="lo">
<p><strong>IMPORTANT!</strong></p>
<p>It may help to think of the sequence of steps involved in statistical modeling as:<br />
<span class="math display">\[
\text{Choose} \rightarrow \text{Fit} \rightarrow \text{Assess} \rightarrow \text{Use}
\]</span>
<br></p>
<ol style="list-style-type: decimal">
<li>We explore/visualise our data and <strong>Choose</strong> our model specification.<br />
</li>
<li>Then we <strong>Fit</strong> the model in R.<br />
</li>
<li>Next, we <strong>Assess</strong> the fit, to ensure that it meets all the underlying assumptions?<br />
</li>
<li><em>Finally</em>, we <strong>Use</strong> our model to draw statistical inferences about the world, or to make predictions.</li>
</ol>
<strong>A general rule</strong><br />

<center>
Do not <strong>use</strong> (draw inferences or predictions from) a model <em>before</em> you have <strong>assessed</strong> that the model satisfies the underlying assumptions
</center>
</div>
</div>
<div id="the-line-mnemonic" class="section level1">
<h1>The LINE Mnemonic</h1>
<p>The assumptions of the linear model can be committed to memory using the <strong>LINE</strong> mnemonic:</p>
<div class="statbox">
<ul>
<li><strong>L</strong>inearity: The relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is linear.</li>
<li><strong>I</strong>ndependence of errors: The error terms should be independent from one another.</li>
<li><strong>N</strong>ormality: The errors <span class="math inline">\(\epsilon\)</span> are normally distributed</li>
<li><strong>E</strong>qual variances (“Homoscedasticity”): The scale of the variability of the errors <span class="math inline">\(\epsilon\)</span> is constant at all values of <span class="math inline">\(x\)</span>.</li>
</ul>
</div>
<p>When we fit a model, we evaluate many of these assumptions by looking at the <em>residuals</em><br />
(the deviations from the observed values <span class="math inline">\(y_i\)</span> and the model estimated value <span class="math inline">\(\hat y_i\)</span>).</p>
<p>The residuals, <span class="math inline">\(\hat \epsilon\)</span> are our estimates of the actual unknown true error term <span class="math inline">\(\epsilon\)</span>. These assumptions hold both for a regression model with a single predictor and for one with multiple predictors.</p>
</div>
<div id="setup" class="section level1">
<h1>Setup</h1>
<div class="optional-begin">

</div>
<div class="optional-body">
<pre class="r"><code>library(tidyverse)
# Read in data
mwdata = read_csv(file = &quot;https://uoepsy.github.io/data/wellbeing.csv&quot;)</code></pre>
<p>Recall the form of our model which we fitted and stored as <code>wbmodel</code>:</p>
<p><span class="math display">\[ 
\text{Wellbeing} = \beta_0 + \beta_1 \cdot \text{Outdoor Time} + \beta_2 \cdot \text{Social Interactions} + \epsilon
\]</span></p>
<p>Which we fitted in R using:</p>
<pre class="r"><code>wbmodel &lt;- lm(wellbeing ~ outdoor_time + social_int, data = mwdata)</code></pre>
<p><strong>Note:</strong> We have have forgone writing the <code>1</code> in <code>lm(y ~ 1 + x...</code>. The 1 just tells R that we want to estimate the Intercept, and it will do this by default even if we leave it out.</p>
</div>
<p class="optional-end">
</p>
</div>
<div id="linearity" class="section level1">
<h1>Linearity</h1>
<div class="statbox">
<p>In simple linear regression with only one explanatory variable, we can assess linearity through a simple scatterplot of the outcome variable against the explanatory. In multiple regression, however, it becomes more necessary to rely on diagnostic plots of the model residuals. This is because we need to know whether the relations are linear between the outcome and each predictor <em>after accounting for the other predictors in the model.</em></p>
<p>In order to assess this, we use <strong>partial-residual plots</strong> (also known as ‘component-residual plots’). This is a plot with each explanatory variable <span class="math inline">\(x_j\)</span> on the x-axis, and <strong>partial residuals</strong> on the y-axis.</p>
<p>Partial residuals for a predictor <span class="math inline">\(x_j\)</span> are calculated as:
<span class="math display">\[
\hat \epsilon + \hat \beta_j x_j
\]</span></p>
</div>
<div class="rtip">
<p><strong>In R</strong> we can easily create these plots for all predictors in the model by using the <code>crPlots()</code> function from the <strong>car</strong> package.</p>
</div>
<div class="question-begin">
Question Q1
</div>
<div class="question-body">
<p>Create partial-residual plots for the <code>wbmodel</code> model.<br />
Remember to load the <strong>car</strong> package first. If it does not load correctly, it might mean that you have need to install it.</p>
<p>Write a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">

</div>
<div class="solution-body">
<pre class="r"><code>library(car)
crPlots(wbmodel)</code></pre>
<p><img src="zz_assumpt_files/figure-html/unnamed-chunk-3-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="int">
<p>The smoother (the pink line) follows quite closely to a linear relationship (the dashed blue line), suggesting that the linearity assumption is met.</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="equal-variances-homoscedasticity" class="section level1">
<h1>Equal variances (Homoscedasticity)</h1>
<div class="statbox">
<p>The equal variances assumption is that the error variance <span class="math inline">\(\sigma^2\)</span> is constant across values of the predictors <span class="math inline">\(x_1\)</span>, … <span class="math inline">\(x_k\)</span>, and across values of the fitted values <span class="math inline">\(\hat y\)</span>. This sometimes gets termed “Constant” vs “Non-constant” variance. Figures <a href="#fig:ncv1">1</a> &amp; <a href="#fig:ncv2">2</a> shows what these look like visually.</p>
<div class="figure" style="text-align: center"><span id="fig:ncv1"></span>
<img src="zz_assumpt_files/figure-html/ncv1-1.png" alt="Non-constant variance for numeric and categorical x" width="80%" />
<p class="caption">
Figure 1: Non-constant variance for numeric and categorical x
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:ncv2"></span>
<img src="zz_assumpt_files/figure-html/ncv2-1.png" alt="Constant variance for numeric and categorical x" width="80%" />
<p class="caption">
Figure 2: Constant variance for numeric and categorical x
</p>
</div>
</div>
<div class="rtip">
<p><strong>In R</strong> we can create plots of the <em>Pearson residuals</em> against the predicted values <span class="math inline">\(\hat y\)</span> and against the predictors <span class="math inline">\(x_1\)</span>, … <span class="math inline">\(x_k\)</span> by using the <code>residualPlots()</code> function from the <strong>car</strong> package. This function also provides the results of a lack-of-fit test for each of these relationships (note when it is the fitted values <span class="math inline">\(\hat y\)</span> it gets called “Tukey’s test”).</p>
<p><code>ncvTest(model)</code> (also from the <strong>car</strong> package) performs a test against the alternative hypothesis that the error variance changes with the level of the fitted value (also known as the “Breusch-Pagan test”). <span class="math inline">\(p &gt;.05\)</span> indicates that we do <em>not</em> have evidence that the assumption has been violated.</p>
</div>
<div class="question-begin">
Question Q2
</div>
<div class="question-body">
<p>Use <code>residualPlots()</code> to plot residuals against each predictor, and use <code>ncvTest()</code> to perform a test against the alternative hypothesis that the error variance changes with the level of the fitted value.</p>
<p>Write a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to plots and/or formal tests where available.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">

</div>
<div class="solution-body">
<pre class="r"><code>residualPlots(wbmodel)</code></pre>
<p><img src="zz_assumpt_files/figure-html/unnamed-chunk-4-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre><code>##              Test stat Pr(&gt;|Test stat|)
## outdoor_time   -0.3478           0.7306
## social_int     -0.1068           0.9157
## Tukey test     -0.4189           0.6753</code></pre>
<pre class="r"><code>#test against the alternative hypothesis that error variance changes with level of fitted value
ncvTest(wbmodel)</code></pre>
<pre><code>## Non-constant Variance Score Test 
## Variance formula: ~ fitted.values 
## Chisquare = 0.001925809, Df = 1, p = 0.965</code></pre>
<div class="int">
<p>Partial residual plots show no clear non-linear trends between residuals and predictors.
Visual inspection of suggested little sign of non-constant variance, with the Breusch-Pagan test failing to reject the null that error varance does not change across the fitted values (<span class="math inline">\(\chi^2(1)=0.002\)</span>, <span class="math inline">\(p = .965\)</span>).</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question Q3
</div>
<div class="question-body">
<p>Create the “residuals vs. fitted plot” - a scatterplot with the residuals <span class="math inline">\(\hat \epsilon\)</span> on the y-axis and the fitted values <span class="math inline">\(\hat y\)</span> on the x-axis.<br />
<br>
You can either do this:</p>
<ol style="list-style-type: lower-alpha">
<li>manually, using the functions <code>residuals()</code> and <code>fitted()</code>, or</li>
<li>quickly by giving the <code>plot()</code> function your model. This will actually give you lots of plots, so we can specify which plot we want to return - e.g., <code>plot(wbmodel, which = 1)</code></li>
</ol>
<p>You can use this plot to visually assess:</p>
<ul>
<li><strong>L</strong>inearity: Does the average of the residuals <span class="math inline">\(\hat \epsilon\)</span> remain close to 0 across the plot?<br />
</li>
<li><strong>E</strong>qual Variance: does the spread of the residuals <span class="math inline">\(\hat \epsilon\)</span> remain constant across the predicted values <span class="math inline">\(\hat y\)</span>?</li>
</ul>
</div>
<p class="question-end">
</p>
<div class="solution-begin">

</div>
<div class="solution-body">
<p>The long way:</p>
<pre class="r"><code># Notice that we create a tibble and pass it directly to ggplot()
# using the %&gt;%.
# This means we don&#39;t have to store it as an object in the environment,
# it is just being used to create the plot
tibble(
  residuals = residuals(wbmodel),
  fitted = fitted(wbmodel)
) %&gt;% 
  ggplot(aes(x = fitted, y = residuals)) + 
  geom_point() + 
  geom_smooth(color=&quot;red&quot;,se=FALSE)</code></pre>
<p><img src="zz_assumpt_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The quick way:</p>
<pre class="r"><code>plot(wbmodel, which=1)</code></pre>
<p><img src="zz_assumpt_files/figure-html/unnamed-chunk-6-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="int">
<p>The horizontal red line shows that the average of the residual remains close to zero across the fitted values.<br />
The spread of the residuals remains reasonably constant across the fitted values.</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="independence" class="section level1">
<h1>Independence</h1>
<div class="statbox">
<p>The “independence of errors” assumption is the condition that the errors do not have some underlying relationship which is causing them to influence one another.
<br>
There are many sources of possible dependence, and often these are issues of study design. For example, we may have groups of observations in our data which we would expect to be related (e.g., multiple trials from the same participant). Our modelling strategy would need to take this into account.
<br>
One form of dependence is <strong>autocorrelation</strong> - this is when observations influence those adjacent to them. It is common in data for which <em>time</em> is a variable of interest (e.g, the humidity today is dependent upon the rainfall yesterday).</p>
</div>
<div class="rtip">
<p><strong>In R</strong> we can test against the alternative hypothesis that there is autocorrelation in our errors using the <code>durbinWatsonTest()</code> (an abbreviated function <code>dwt()</code> is also available) in the <strong>car</strong> package.</p>
</div>
<div class="question-begin">
Question Q4
</div>
<div class="question-body">
<p>Perform a test against the alternative hypothesis that there is autocorrelation in the error terms.</p>
<p>Write a sentence summarising whether or not you consider the assumption of independence to have been met (you may have to assume certain aspects of the study design).</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">

</div>
<div class="solution-body">
<pre class="r"><code>dwt(wbmodel)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1       -0.318249      2.600574    0.16
##  Alternative hypothesis: rho != 0</code></pre>
<div class="int">
<p>A Durbin-Watson test of autocorrelation failed to reject the null hypothesis that there was no serial dependence in the error (<span class="math inline">\(DW = 2.6\)</span>, <span class="math inline">\(p = .138\)</span>). We will also assume that observations to be randomly sampled during study recruitment.</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="normality-of-errors" class="section level1">
<h1>Normality of errors</h1>
<div class="statbox">
<p>The normality assumption is the condition that the errors <span class="math inline">\(\epsilon\)</span> are normally distributed.</p>
<p>We can visually assess this condition through histograms, density plots, and quantile-quantile plots (QQplots) of our residuals <span class="math inline">\(\hat \epsilon\)</span>.<br />
We can also perform a Shapiro-Wilk test against the alternative hypothesis that the residuals were not sampled from a normally distributed population.</p>
</div>
<div class="rtip">
<ul>
<li>The <code>shapiro.test()</code> function in R performs a Shapiro-Wilk test.</li>
<li><code>plot(model_name, which = 2)</code> gives us a QQplot of the residuals (or you can do it manually by extracting the residuals using <code>resid(model_name)</code>).</li>
</ul>
</div>
<div class="question-begin">
Question Q5
</div>
<div class="question-body">
<p>Assess the normality assumption by producing a qqplot of the residuals (either manually or using <code>plot(model, which = ???)</code>), and conducting a Shapiro-Wilk test.</p>
<p>Write a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to plots and/or formal tests where available.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">

</div>
<div class="solution-body">
<p>We can get the QQplot from one of the <code>plot(model)</code> plots:</p>
<pre class="r"><code>plot(wbmodel, which = 2)</code></pre>
<p><img src="zz_assumpt_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" />
Or we can make our own:</p>
<pre class="r"><code>tibble(
  resids = residuals(wbmodel)
) %&gt;% ggplot(aes(sample=resids))+
  geom_qq()+
  geom_qq_line()</code></pre>
<p><img src="zz_assumpt_files/figure-html/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>shapiro.test(residuals(wbmodel))</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(wbmodel)
## W = 0.94831, p-value = 0.129</code></pre>
<div class="int">
<p>The QQplot indicates that the residuals follow close to a normal distribution, although with evidence of heavier tails. A Shapiro-Wilk test failed to reject the null hypothesis that the residuals were drawn from a normally distributed population (<span class="math inline">\(W = 0.95\)</span>, <span class="math inline">\(p = .129\)</span>)</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="multicollinearity" class="section level1">
<h1>Multicollinearity</h1>
<div class="statbox">
For the linear model with multiple explanatory variables, we need to also think about <strong>multicollinearity</strong> - this is when two (or more) of the predictors in our regression model are moderately or highly correlated.<br />
Recall our interpretation of multiple regression coefficients as<br />

<center>
“the effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> when <em>holding the values of <span class="math inline">\(x_2\)</span>, <span class="math inline">\(x_3\)</span>, … <span class="math inline">\(x_k\)</span> constant</em>”
</center>
<p>This interpretation falls down if predictors are highly correlated because if, e.g., predictors <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are highly correlated, then changing the value of <span class="math inline">\(x_1\)</span> necessarily entails a change the value of <span class="math inline">\(x_2\)</span> meaning that it no longer makes sense to talk about <em>holding <span class="math inline">\(x_2\)</span> constant.</em><br />
<br>
We can assess multicollinearity using the <strong>variance inflation factor (VIF)</strong>, which for a given predictor <span class="math inline">\(x_j\)</span> is calculated as:<br />
<span class="math display">\[
VIF_j = \frac{1}{1-R_j^2} \\
\]</span>
Where <span class="math inline">\(R_j^2\)</span> is the coefficient of determination (the R-squared) resulting from a regression of <span class="math inline">\(x_j\)</span> on to all the other predictors in the model (<span class="math inline">\(x_j = x_1 + ... x_k + \epsilon\)</span>).<br />
The more highly correlated <span class="math inline">\(x_j\)</span> is with other predictors, the bigger <span class="math inline">\(R_j^2\)</span> becomes, and thus the bigger <span class="math inline">\(VIF_j\)</span> becomes.<br />
<br>
The square root of VIF indicates how much the SE of the coefficient has been inflated due to multicollinearity. For example, if the VIF of a predictor variable were 4.6 (<span class="math inline">\(\sqrt{4.6} = 2.1\)</span>), then the standard error of the coefficient of that predictor is 2.1 times larger than if the predictor had zero correlation with the other predictor variables. Suggested cut-offs for VIF are varied. Some suggest 10, others 5. Define what you will consider an acceptable value <em>prior</em> to calculating it.</p>
</div>
<div class="rtip">
<p><strong>In R</strong>, the <code>vif()</code> function from the <strong>car</strong> package will provide VIF values for each predictor in your model.</p>
</div>
<div class="question-begin">
Question Q6
</div>
<div class="question-body">
<p>Calculate the variance inflation factor (VIF) for the predictors in the model.</p>
<p>Write a sentence summarising whether or not you consider multicollinearity to be a problem here.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">

</div>
<div class="solution-body">
<pre class="r"><code>vif(wbmodel)</code></pre>
<pre><code>## outdoor_time   social_int 
##      1.13023      1.13023</code></pre>
<div class="int">
<p>VIF values &lt;5 indicate that multicollinearity is not adversely affecting model estimates.</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
</div>

<div>
  <hr/>
  <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br/>
  This workbook was written by Josiah King, Umberto Noe, and Martin
  Corley, and is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
