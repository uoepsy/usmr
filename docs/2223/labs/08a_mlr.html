<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>USMR - 8A: Multiple Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-hand-o-right')) {
    f.classList.add('fa-hand-o-down')
    f.classList.remove('fa-hand-o-right')
} else {
    f.classList.add('fa-hand-o-right')
    f.classList.remove('fa-hand-o-down')
}
}
</script>

<script src="https://kit.fontawesome.com/120b08a6f5.js" crossorigin="anonymous"></script>
<link href="site_libs/panelset-0.2.6/panelset.css" rel="stylesheet">
<script src="site_libs/panelset-0.2.6/panelset.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">USMR</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-1" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 1</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-1">    
        <li>
    <a class="dropdown-item" href="./01a_R.html">
 <span class="dropdown-text">1A: First look at R/RStudio</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./01b_data.html">
 <span class="dropdown-text">1B: More R: Basic Data Skills</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./01_ex.html">
 <span class="dropdown-text">Exercises: Intro R</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-2" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 2</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-2">    
        <li>
    <a class="dropdown-item" href="./02a_measurement.html">
 <span class="dropdown-text">2A: Measurements &amp; Distributions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./02b_sampling.html">
 <span class="dropdown-text">2B: Sampling &amp; Curves</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./02_ex.html">
 <span class="dropdown-text">Exercises: More R; Estimates &amp; Intervals</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-3" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 3</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-3">    
        <li>
    <a class="dropdown-item" href="./03a_inference.html">
 <span class="dropdown-text">3A: Foundations of Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./03b_inference2.html">
 <span class="dropdown-text">3B: Practical Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./03_ex.html">
 <span class="dropdown-text">Exercises: T-tests</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-4" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 4</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-4">    
        <li>
    <a class="dropdown-item" href="./04a_chisq.html">
 <span class="dropdown-text">4A: Chi-Square Tests</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./04b_revisitnhst.html">
 <span class="dropdown-text">4B: Revisiting NHST</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./04_ex.html">
 <span class="dropdown-text">Exercises: Chi-Square Tests</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-5" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 5</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-5">    
        <li class="dropdown-header">5A: Covariance &amp; Correlation</li>
        <li class="dropdown-header">Exercises: Cov, Cor, Models</li>
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-6" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 6</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-6">    
        <li class="dropdown-header">Walkthrough: Advanced Data Wrangling</li>
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-7" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 7</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-7">    
        <li class="dropdown-header">7A: Simple Linear Regression</li>
        <li class="dropdown-header">Exercises: Simple Linear Regression</li>
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-8" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 8</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-8">    
        <li class="dropdown-header">8A: Multiple Linear Regression</li>
        <li class="dropdown-header">8B: Assumptions, Diagnostics, and Troubleshooting</li>
        <li class="dropdown-header">Exercises: Multiple Linear Regression</li>
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-9" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 9</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-9">    
        <li class="dropdown-header">9A: Interactions</li>
        <li class="dropdown-header">9B: Categorical Predictors</li>
        <li class="dropdown-header">Exercises: Interactions</li>
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-10" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 10</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-10">    
        <li class="dropdown-header">10A: GLM!</li>
        <li class="dropdown-header">Exercises: Logistic Regression</li>
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-week-11" role="button" data-bs-toggle="dropdown" aria-expanded="false">Week 11</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-week-11">    
        <li class="dropdown-header">11A: Common Tests as Linear Models</li>
        <li class="dropdown-header">11B: Writing Up</li>
    </ul>
  </li>
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-multiple-regression-model" id="toc-the-multiple-regression-model" class="nav-link active" data-scroll-target="#the-multiple-regression-model">The Multiple Regression Model</a></li>
  <li><a href="#multiple-regression-coefficients" id="toc-multiple-regression-coefficients" class="nav-link" data-scroll-target="#multiple-regression-coefficients">Multiple Regression Coefficients</a></li>
  <li><a href="#multiple-categories-multiple-regression" id="toc-multiple-categories-multiple-regression" class="nav-link" data-scroll-target="#multiple-categories-multiple-regression">Multiple Categories = Multiple Regression</a></li>
  <li><a href="#model-evaluation" id="toc-model-evaluation" class="nav-link" data-scroll-target="#model-evaluation">Model Evaluation</a>
  <ul class="collapse">
  <li><a href="#adjusted-r2" id="toc-adjusted-r2" class="nav-link" data-scroll-target="#adjusted-r2">Adjusted <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#joint-test" id="toc-joint-test" class="nav-link" data-scroll-target="#joint-test">Joint test</a></li>
  </ul></li>
  <li><a href="#model-comparisons" id="toc-model-comparisons" class="nav-link" data-scroll-target="#model-comparisons">Model Comparisons</a></li>
  <li><a href="#analysis-of-variance" id="toc-analysis-of-variance" class="nav-link" data-scroll-target="#analysis-of-variance">Analysis of Variance</a></li>
  <li><a href="#correlation-vs-causation-again" id="toc-correlation-vs-causation-again" class="nav-link" data-scroll-target="#correlation-vs-causation-again">Correlation vs Causation, Again!</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">8A: Multiple Linear Regression</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>The simple linear regression model with a single predictor <code>lm(y ~ x1)</code> is a useful introduction to the idea of model-based thinking, but it’s not clear how much benefit this gives us as it is actually equivalent to the basic statistical tests we have already seen.</p>
<div class="statbox">
<p><strong>Simple Statistical Tests as Regression Models</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 16%">
<col style="width: 19%">
<col style="width: 15%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">outcome (y)</th>
<th style="text-align: left;">predictor (x)</th>
<th style="text-align: left;">regression</th>
<th style="text-align: left;">equivalent to</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">continuous</td>
<td style="text-align: left;">continuous</td>
<td style="text-align: left;">lm(y ~ x)</td>
<td style="text-align: left;">cor.test(x, y) and cor.test(y, x)</td>
</tr>
<tr class="even">
<td style="text-align: left;">continuous</td>
<td style="text-align: left;">binary</td>
<td style="text-align: left;">lm(y ~ x)</td>
<td style="text-align: left;">t.test(y ~ x)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="optional-begin">
<span id="opt-start-1" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-1', 'opt-start-1')"> <span class="olab">Optional: correlation = regression</span></span>
</div>
<div id="opt-body-1" class="optional-body" style="display: none;">
<p>Remember, the covariance is a measure of the shared variance in two variables (i.e., how one variable varies with the other). However, it is hard to interpret because it is dependent on the units of the variables. Correlation is a <em>standardised</em> way of expressing this.</p>
<p>One way to think about this is to remember that we can <strong>standardise</strong> our variables (subtract each value from the mean and divide by the standard deviation (See, e.g.&nbsp;<a href="02b_sampling.html#the-standard-normal-distribution" target="_blank">2B #the-standard-normal-distribution</a>)), which transforms our set of numbers so that they have a mean of zero and a standard deviation of one. If we standardise both variable <span class="math inline">\(x\)</span> and variable <span class="math inline">\(y\)</span>, the covariance of <span class="math inline">\(x_{standardised}\)</span> and <span class="math inline">\(y_{standardised}\)</span> is the same as the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> (see <a href="05a_covcor.html#correlation" target="_blank">5A #correlation</a>).</p>
<p>If you’ve been reading these “optional dropdowns”, you may remember that the regression coefficient from <code>lm(y ~ x)</code> is <em>also</em> the covariance between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, simply rescaled to be the amount of change in <span class="math inline">\(y\)</span> when <span class="math inline">\(x\)</span> changes by 1 (see the optional dropdown in <a href="07a_slr.html#the-model" target="_blank">7A #the-model</a>).</p>
<p>So actually, all these metrics are pretty much the same thing, only scaled in different ways. And whether we perform a test of the relationship (e.g.&nbsp;test the correlation using <code>cor.test()</code>, or test of the regression slope from <code>lm(y~x)</code>), we’re actually testing the same thing.</p>
<p>Note that the <span class="math inline">\(t\)</span>-statistics and <span class="math inline">\(p\)</span>-values are identical:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor.test</span>(df<span class="sc">$</span>x_cont, df<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Pearson's product-moment correlation

data:  df$x_cont and df$y
t = 3.5282, df = 98, p-value = 0.0006388
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.1491293 0.4992136
sample estimates:
      cor 
0.3357138 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x_cont, <span class="at">data =</span> df))<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              Estimate Std. Error   t value     Pr(&gt;|t|)
(Intercept) -0.6838938  0.5621419 -1.216586 0.2266837999
x_cont       1.9322184  0.5476566  3.528157 0.0006387745</code></pre>
</div>
</div>
<p>In fact, the <strong>“correlation coefficient”</strong> <span class="math inline">\(r\)</span> is equivalent to the <strong>standardised</strong> regression slope of <span class="math inline">\(y_{standardised} \sim b_0 + b_1 (x_{standardised})\)</span>.</p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-2" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-2', 'opt-start-2')"> <span class="olab">Optional: t.test = regression</span></span>
</div>
<div id="opt-body-2" class="optional-body" style="display: none;">
<p>We saw last week about when we have a linear regression model with one binary predictor, we interpret the regression coefficient as the difference in mean <span class="math inline">\(y\)</span> between the two levels of our predictor (see <a href="07a_slr.html#binary-predictors" target="_blank">7A #binary-predictors</a>).</p>
<p>We’ve actually seen this idea before. <a href="03a_inference2.html#two-sample-t-test" target="_blank">3A #two-sample-t-test</a> saw how we can use a <span class="math inline">\(t\)</span>-test to test whether the mean of some variable is different between two groups.</p>
<p>These are actually just different expressions of the same thing. The <span class="math inline">\(t\)</span>-statistics and <span class="math inline">\(p\)</span>-values are identical:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(df<span class="sc">$</span>y <span class="sc">~</span> df<span class="sc">$</span>x_cat, <span class="at">var.equal =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Two Sample t-test

data:  df$y by df$x_cat
t = -3.2848, df = 98, p-value = 0.001416
alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0
95 percent confidence interval:
 -6.102816 -1.506025
sample estimates:
mean in group 0 mean in group 1 
     -3.1488840       0.6555365 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x_cat, <span class="at">data =</span> df))<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             Estimate Std. Error   t value     Pr(&gt;|t|)
(Intercept) -3.148884  0.9045774 -3.481055 0.0007473914
x_cat1       3.804421  1.1581927  3.284791 0.0014162481</code></pre>
</div>
</div>
<p><strong>Note:</strong> The <code>t.test()</code> function allows us to perform a Welch t-test, which means we can relax the assumption of equal variance in the two groups. Simple linear regression does not allow us to do this, so if our research question is straightforward enough to be simply “is the mean of <span class="math inline">\(y\)</span> different between these two groups”, then a Welch t-test <em>may</em> be preferable.</p>
</div>
<p class="optional-end">
</p>
</div>
<p>The real power of regression models comes into effect when we start to concern ourselves with more than just “one outcome explained by one predictor”.</p>
<p>This week, enter… <span class="math inline">\(x_2\)</span>!</p>
<p>We will initially look at the case of “one outcome, two predictors”, but the beauty of this is that the logic scales up to however many predictor variables we want to include in our model.</p>
<pre><code>lm(y ~ x1 + x2 + ... + xp)</code></pre>
<section id="the-multiple-regression-model" class="level1">
<h1>The Multiple Regression Model</h1>
<p>When we fitted the simple regression model with <strong>one</strong> predictor:</p>
<p><span class="math display">\[
y = b_0 + b_1(x) + \epsilon
\]</span></p>
<p>we were fitting a <em>line</em> to a scatterplot of points that we plotted in <em>2 dimensions</em> (an x-axis and a y-axis).</p>
<p>When we fit a multiple regression model with <strong>two</strong> predictors:</p>
<p><span class="math display">\[
y = b_0 + b_1(x_1) + b_2(x_2) + \epsilon
\]</span></p>
<p>we are fitting a <strong>surface</strong> (or “plane”) to a 3-dimensional cloud of datapoints (<a href="#fig-regsurf">Figure&nbsp;1</a>). There are three dimensions: x1, x2, and y.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-regsurf" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/fig-regsurf-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 1: Regression surface for y~x1+x2, from two different angles</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Don’t worry about trying to figure out how to visualise it if we had more predictors! We can only conceive of 3 spatial dimensions.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> However, the logic stays the same when we increase this to having <span class="math inline">\(p\)</span> predictors, but we have a model that is a <span class="math inline">\(p\)</span>-dimensional surface, and each coefficient is the angle of that surface with respect to each predictor.</p>
<p>When we have two predictors, our model is now determined by three numbers:</p>
<ul>
<li>the <strong>intercept</strong>, denoted <span class="math inline">\(b_0\)</span>.<br>
This is the point at which the plane hits the y-axis (i.e.&nbsp;where <span class="math inline">\(x_1=0\)</span> <strong>and</strong> <span class="math inline">\(x_2=0\)</span>)</li>
<li>the <strong>slope of x1</strong>, in this case denoted <span class="math inline">\(b_1\)</span>.<br>
This is the angle of the regression plane with respect to the axis of <span class="math inline">\(x_1\)</span>. It is the amount which the plane increases for every 1 increase in <span class="math inline">\(x_1\)</span>.<br>
</li>
<li>the <strong>slope of x2</strong>, in this case denoted <span class="math inline">\(b_2\)</span>.<br>
This is the angle of the regression plane with respect to the axis of <span class="math inline">\(x_2\)</span>. It is the amount which the plane increases for every 1 increase in <span class="math inline">\(x_2\)</span>.</li>
</ul>
<div class="rtip">
<p><strong>Fitting Multiple Regression Models in R</strong></p>
<p>As we did for simple linear regression, we can fit our multiple regression model using the <code>lm()</code> function. We can add as many explanatory variables as we like, separating them with a <code>+</code>.</p>
<pre><code>model_name &lt;- lm(y ~ 1 + x1 + x2 + ... + xk, data = dataframe)</code></pre>
<p>And we can use all the same functions that we have already seen such as <code>summary()</code>, <code>predict()</code>, <code>fitted()</code>, <code>coef()</code> etc.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://uoepsy.github.io/data/usmr_mlr.csv"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>eg_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> mydata)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(eg_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x1 + x2, data = mydata)

Residuals:
     Min       1Q   Median       3Q      Max 
-16.5201  -4.2912  -0.0268   3.3044  16.2154 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept) -2.39138    3.67735  -0.650  0.51867   
x1           0.17570    0.06435   2.730  0.00888 **
x2          -0.64756    0.19959  -3.244  0.00217 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 7.069 on 47 degrees of freedom
Multiple R-squared:  0.2643,    Adjusted R-squared:  0.233 
F-statistic: 8.443 on 2 and 47 DF,  p-value: 0.0007369</code></pre>
</div>
</div>
</div>
<p>So <strong>why</strong> is this a useful thing to do? There are two primary aims that might lead you to fit models with more predictors:</p>
<ol type="1">
<li><strong>Estimation:</strong> Our coefficients now estimate the association between each predictor and the outcome variable, <em>after accounting for variance explained by other predictors.</em><br>
</li>
<li><strong>Prediction:</strong> We can build a model that better predicts the outcome.</li>
</ol>
<p>Typically, psychological research is more interested in <em>estimation</em> of specific associations. Other areas (think industry/data science/machine learning et al.) may be more interested in building a model for a functional purpose - e.g.&nbsp;to predict what product on a website a user is going to click on. We’ll take a look later on about some of the overall model metrics (like <span class="math inline">\(R^2\)</span> etc.), but we’re going to first focus on the coefficients from multiple regression models.</p>
<div class="divider div-transparent div-dot">

</div>
</section>
<section id="multiple-regression-coefficients" class="level1">
<h1>Multiple Regression Coefficients</h1>
<p>The benefit of multiple regression models is that they allow us to exercise <em>statistical control</em>.</p>
<p>We often conduct research where we are interested mainly in one relationship, but we know that there are other things also at play - there are other variables that will probably strongly influence results if they aren’t held constant. <em>Statistical control</em> allows us to examine the relationship of interest <em>while holding constant</em> these other variables.</p>
<p>When we have multiple predictor variables in our model, the coefficients we get out represent the association between the outcome <span class="math inline">\(y\)</span> and <strong>the bit of each predictor variable that is unique from the other predictors</strong>.</p>
<div class="statbox">
<p><strong>Terminology</strong></p>
<p>As with all areas of statistics, people seem to use lots of different terms here. It can be confusing!</p>
<ul>
<li><strong>outcome/response/dependent variable</strong>: variable on the left hand side of the model equation</li>
<li><strong>predictor:</strong> any variable on the right hand side of the model equation</li>
<li><strong>focal predictor/independent variable:</strong> the predictor of interest</li>
<li><strong>covariates/confounders/control variables:</strong> other variables that we are less interested in but believe to relevant to how the data comes about, and that may influence both the outcome and the focal predictor.</li>
</ul>
</div>
<p>A common way to build this intuition is to consider a Venn diagram with a circle showing the variance in each variable. <a href="#fig-vennslr">Figure&nbsp;2</a> shows a simple linear regression with one predictor (i.e.&nbsp;<code>lm(y ~ x1)</code>). The circle for <span class="math inline">\(y\)</span> shows the total variance in <span class="math inline">\(y\)</span> (the same for the <span class="math inline">\(x_1\)</span> circle). The overlap between circles (labelled “A”) shows the variance in <span class="math inline">\(y\)</span> that is explained by <span class="math inline">\(x_1\)</span> (i.e.&nbsp;the covariance).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vennslr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/mlr/venn_slr.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 2: Venn Diagram for Simple Regression y ~ x1</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>When we add in a new predictor, <span class="math inline">\(x_2\)</span>, where do we add it? If <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are <em>completely</em> uncorrelated with one another, then it would look something like <a href="#fig-vennmlr1">Figure&nbsp;3</a>, where there is no overlap between the <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> circles. The total variance explained in <span class="math inline">\(y\)</span> by both predictors is <span class="math inline">\(A + B\)</span>, and in this case, nothing changes in our estimate of the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x_1\)</span>. It’s just the same as before (the area labelled “A” is the same in both <a href="#fig-vennslr">Figure&nbsp;2</a> and <a href="#fig-vennmlr1">Figure&nbsp;3</a>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vennmlr1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/mlr/venn_mlr1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 3: Venn Diagram for Multiple Regression y ~ x1 + x2 where x1 and x2 are completely uncorrelated</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>However, in practice the predictors in our regression model are likely to overlap a bit (it’s hard to find additional predictor variables that are not correlated with other predictors). In this case, our Venn diagram is going to look like <a href="#fig-vennmlr2">Figure&nbsp;4</a>. The correlation between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> is shown by the overlap of those two circles (the area <span class="math inline">\(C + D\)</span> in the diagram). The total variance explained in <span class="math inline">\(y\)</span> is now separated into the areas <span class="math inline">\(A + B + C\)</span> (and <span class="math inline">\(E\)</span> is the <em>unexplained</em> variance - the residuals).</p>
<p>Areas <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are no longer the same as in the previous diagrams - there’s a little bit (area <span class="math inline">\(C\)</span>) that we don’t want to double count in its explanatory power as it can’t be attributable to specifically one variable or the other.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vennmlr2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/mlr/venn_mlr2.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 4: Venn Diagram for Multiple Regression y ~ x1 + x2 where x1 and x2 are somewhat correlated</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li><span class="math inline">\(A\)</span> is the variance in <span class="math inline">\(y\)</span> <em>uniquely</em> explained by <span class="math inline">\(x_1\)</span><br>
</li>
<li><span class="math inline">\(B\)</span> is the variance in <span class="math inline">\(y\)</span> <em>uniquely</em> explained by <span class="math inline">\(x_2\)</span></li>
<li><span class="math inline">\(C\)</span> is the variance in <span class="math inline">\(y\)</span> that is explained by both <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> but not attributable to either one uniquely.</li>
</ul>
<p>The coefficients (one for each predictor) from our multiple regression model <code>lm(y ~ x1 + x2)</code> reflect the areas <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, scaled to be the “change in <span class="math inline">\(y\)</span> associated with a one unit change in [predictor], holding [other predictors] constant”.</p>
<div class="sticky">
<p><strong>Interpreting multiple regression coefficients</strong></p>
<p>The parameters of a multiple regression model are:</p>
<ul>
<li><span class="math inline">\(b_0\)</span> (The intercept);</li>
<li><span class="math inline">\(b_1\)</span> (The slope across values of <span class="math inline">\(x_1\)</span>);</li>
<li>…<br>
</li>
<li>…</li>
<li><span class="math inline">\(b_k\)</span> (The slope across values of <span class="math inline">\(x_k\)</span>);</li>
<li><span class="math inline">\(\sigma\)</span> (The standard deviation of the errors).</li>
</ul>
<p><br> You’ll hear a lot of different ways that people explain multiple regression coefficients. For the model <span class="math inline">\(y = b_0 + b_1(x_1) + b_2 (x_2) + \epsilon\)</span>, we might hear <span class="math inline">\(b_1\)</span> (the coefficient for <span class="math inline">\(x_1\)</span>), described as:</p>
<p>the increase in <span class="math inline">\(y\)</span> for a one unit increase in <span class="math inline">\(x_1\)</span> when…</p>
<ul>
<li>holding <span class="math inline">\(x_2\)</span> constant.</li>
<li>controlling for differences in <span class="math inline">\(x_2\)</span>.</li>
<li>partialling out the effects of <span class="math inline">\(x_2\)</span>.</li>
<li>holding <span class="math inline">\(x_2\)</span> equal.</li>
<li>accounting for effects of <span class="math inline">\(x_2\)</span>.</li>
</ul>
<p>What exactly do all these mean? If we return to our regression surface, our coefficients are the angles of this surface. We can see that as <span class="math inline">\(x_1\)</span> increases, the surface goes up. This increase is the same no matter where on <span class="math inline">\(x_2\)</span> we are (i.e.&nbsp;the angle doesn’t change as we move up <span class="math inline">\(x_2\)</span>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://uoepsy.github.io/data/usmr_mlr.csv"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>eg_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> mydata)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(eg_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept) -2.39138    3.67735  -0.650  0.51867   
x1           0.17570    0.06435   2.730  0.00888 **
x2          -0.64756    0.19959  -3.244  0.00217 **</code></pre>
<p>Imagine a person who scores 3 on <span class="math inline">\(x_1\)</span>. what is the estimated change in <span class="math inline">\(y\)</span> if they scored 4 instead? The coefficient for <span class="math inline">\(x_1\)</span> tells us how much their score on <span class="math inline">\(y\)</span> would increase by 0.176 <em>provided they don’t also change on <span class="math inline">\(x_2\)</span>.</em> So we are moving along the regression surface in the <span class="math inline">\(x_1\)</span> direction. This makes sense, because if they <em>also</em> changed on <span class="math inline">\(x_2\)</span>, then we would expect their score on <span class="math inline">\(y\)</span> to change because of this too (i.e.&nbsp;we would be moving diagonally on the surface).</p>
</div>
<div class="sticky">
<p><strong>Visualising Associations</strong></p>
<p>The associations we get out from our coefficients are conditional upon holding constant other predictors. How are we supposed to visualise this?</p>
<p>Three-dimensional plots like the ones above are lovely, but a) they’re difficult to make and b) they only work when there is <em>one</em> other predictor variable being controlled for.</p>
<p>The typical way to plot these associations is to make a 2-dimensional figure that shows the <em>model estimated</em> increase in <span class="math inline">\(y\)</span> across values of <span class="math inline">\(x\)</span>. Notice the use of “model estimated” - we are visualising the model, <em>not</em> the data.</p>
<p>Luckily, the <strong>sjPlot</strong> package can make it very easy for us to create plots of model estimated effects. We need to give it the model, the type of thing we want plotted (in this case “eff” for “effect”), and the relevant predictor term (in this case “x1”):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://uoepsy.github.io/data/usmr_mlr.csv"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>eg_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> mydata)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(fit, <span class="at">type =</span> <span class="st">"eff"</span>, <span class="at">terms =</span> <span class="st">"x1"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>It might help to think of this as if we are just tilting the our view of the regression surface so that we see it from only one edge:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<div class="optional-begin">
<span id="opt-start-3" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-3', 'opt-start-3')"> <span class="olab">Optional: manually making the plot</span></span>
</div>
<div id="opt-body-3" class="optional-body" style="display: none;">
<p>We can extract the predicted values, and confidence bounds, using <code>predict()</code>. First we create a dataset of the values of the predictors that we wish to predict across. We’ll predict <span class="math inline">\(y\)</span> for all values of <span class="math inline">\(x1\)</span> from 18 to 70 (the range of x1 in our data), and holding <span class="math inline">\(x2\)</span> as 12.6 (the mean of x2 in our data):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plotdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="dv">18</span><span class="sc">:</span><span class="dv">70</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fl">12.6</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we add the predictions and the standard error</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plotdata <span class="ot">&lt;-</span> plotdata <span class="sc">%&gt;%</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">predy =</span> <span class="fu">predict</span>(eg_model, <span class="at">newdata=</span>plotdata),</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">se =</span> <span class="fu">predict</span>(eg_model, plotdata, <span class="at">se.fit =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>se</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And use the standard error to create the confidence intervals. Doing <span class="math inline">\(1.96 \times SE\)</span> would get us close, but to do it properly we should use the <span class="math inline">\(t\)</span>-distribution:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>plotdata <span class="ot">&lt;-</span> plotdata <span class="sc">%&gt;%</span> </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> predy <span class="sc">-</span> (<span class="fu">qt</span>(.<span class="dv">975</span>, <span class="at">df=</span><span class="dv">47</span>) <span class="sc">*</span> se),</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper =</span> predy <span class="sc">+</span> (<span class="fu">qt</span>(.<span class="dv">975</span>, <span class="at">df=</span><span class="dv">47</span>) <span class="sc">*</span> se)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And finally we can plot!</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plotdata, <span class="fu">aes</span>(<span class="at">x =</span> x1, <span class="at">y =</span> predy, </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper)) <span class="sc">+</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">alpha =</span> .<span class="dv">3</span>) <span class="co"># alpha sets the transparency</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<p class="optional-end">
</p>
</div>
<div class="statbox">
<p><strong>Example: Caffeine Heart Rates</strong></p>
<p>We have a sample of 100 people, and we measure their resting heart rate and their caffeine consumption. We’re interested in estimating how caffeine consumption is associated with differences in resting heart rate. However, we also know that heart rate increases with age <em>and</em> we think that older people tend to drink less caffeine. So we want to isolate the differences in heart rate due to caffeine from those due to age.</p>
<p>The toy dataset for our heart rate and caffeine example is at <a href="https://uoepsy.github.io/data/usmr_hrcaff.csv">https://uoepsy.github.io/data/usmr_hrcaff.csv</a>.<br>
We can see plots of the different relationships in <a href="#fig-caffplot">Figure&nbsp;5</a>. It looks from these like heart rate <em>decreases</em> with caffeine, and <em>increases</em> with age. But note also that caffeine decreases with age.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>hrcaff <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://uoepsy.github.io/data/usmr_hrcaff.csv"</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hrcaff, <span class="fu">aes</span>(<span class="at">x=</span>caffeine,<span class="at">y=</span>rhr))<span class="sc">+</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hrcaff, <span class="fu">aes</span>(<span class="at">x=</span>age,<span class="at">y=</span>rhr))<span class="sc">+</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hrcaff, <span class="fu">aes</span>(<span class="at">x=</span>age,<span class="at">y=</span>caffeine))<span class="sc">+</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-caffplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/fig-caffplot-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 5: bi-variate relationships between each of resting heart rate, caffeine consumption, and age</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>If we fit a simple regression <span class="math inline">\(heartrate \sim b_0 + b_1(caffeine)\)</span>, we get a nice line, with a significant negative slope, suggesting to us that drinking more caffeine is associated with lower heart rate! Good news for me, I’m on my 6th coffee today!</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hrcaff, <span class="fu">aes</span>(<span class="at">x=</span>caffeine,<span class="at">y=</span>rhr))<span class="sc">+</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span>lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<pre><code>lm(rhr ~ caffeine, data = hrcaff)
...
Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 101.1746     5.3424  18.938  &lt; 2e-16 ***
caffeine     -0.2600     0.0527  -4.933 3.31e-06 ***</code></pre>
<p>But… what if the reason that people in our sample who drink more caffeine have lower heart rates <em>not</em> because they drink more caffeine, but because they are older (and older people have lower heart rates).</p>
<p>The coefficient for the association between caffeine and heart rate when we <em>also</em> include age in as a predictor (<code>lm(rhr ~ age + caffeine)</code>), is no longer significant.</p>
<pre><code>lm(rhr ~ age + caffeine, data = hrcaff)
...
Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  41.8310    16.0000   2.614 0.010363 *  
age           0.3914     0.1003   3.904 0.000175 ***
caffeine      0.0933     0.1030   0.906 0.367398  </code></pre>
<p>Why? Because after we take into account how old people are, knowing their caffeine consumption doesn’t actually provide any information about their heart rate.</p>
<p>If it helps, we might think of this model as the diagram in <a href="#fig-vennhrcaff">Figure&nbsp;6</a>. When we don’t have age in our model, then the estimated effect of caffeine on heart rate is the areas <span class="math inline">\(B + C\)</span>. When we <em>do</em> have age in the model, the variance in heart rate explained <strong>uniquely</strong> by caffeine is just the tiny area <span class="math inline">\(B\)</span> (not a useful amount).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vennhrcaff" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/mlr/venn_hrcaff.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 6: lm(rhr ~ age + caffeine)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="frame">
<p>This example is a very extreme one where the relationship completely disappears. in real data associations tend to be more subtle/less clear cut. Including <span class="math inline">\(x_2\)</span> may increase or decrease the association between <span class="math inline">\(y\)</span> and <span class="math inline">\(x_1\)</span>, depending on the extent to which <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are correlated.</p>
</div>
</div>
<div class="optional-begin">
<span id="opt-start-4" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-4', 'opt-start-4')"> <span class="olab">Optional: Control on the front-end</span></span>
</div>
<div id="opt-body-4" class="optional-body" style="display: none;">
<p>If we haven’t collected the data yet, one option is to <strong>control by design</strong>. This would involve trying to collect our data such that the predictor of interest is <em>independent</em> from other possibly confounding variables.</p>
<p>We could do this by <strong>randomisation</strong>, where we randomly allocate people to different levels of our focal predictor, meaning that other variables will not be related to the focal predictor. This is what a “randomized control trial” does, randomly allocating people to take a drug or a placebo means that the two groups should be similar in aspects such as age.</p>
<p>Alternatively, we could do achieve it by <strong>“case-matching”</strong>. This involves finding people at different levels of the focal predictor who match on possible confounders. For example, for every 60 year old taking the drug, we also measure a 60 year old taking the placebo.</p>
</div>
<p class="optional-end">
</p>
<div class="divider div-transparent div-dot">

</div>
</section>
<section id="multiple-categories-multiple-regression" class="level1">
<h1>Multiple Categories = Multiple Regression</h1>
<p>We saw last week how to interpret simple regression models when there is a binary predictor (see <a href="07a_slr.html#binary-predictors">7A#binary-predictors</a>). The addition of binary predictors in multiple regression models is pretty much the same - the coefficient will give us the estimated change in <span class="math inline">\(y\)</span> when moving from one level to the other<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, <em>holding other predictors constant.</em></p>
<p>If you want a visual intuition to this, it is like a shift between two lines, or between two surfaces (depending on how many other predictors there are). It’s actually just another dimension to the model, but a dimension that is on a <strong>discrete</strong> scale - observations fall on 0 or 1, not on the continuum in between.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>What about when we have a predictor with more than two categories? We might have lots of different conditions in our experiment, or we might have observations from lots of different distinct groups of people.</p>
<p>Consider an example where we are investigating the brain mass of different species of animals. We might have a datset which looks like this:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>braindata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://uoepsy.github.io/data/usmr_braindata.csv"</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(braindata)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">species</th>
<th style="text-align: left;">mass_body</th>
<th style="text-align: left;">mass_brain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Human</td>
<td style="text-align: left;">66</td>
<td style="text-align: left;">0.577</td>
</tr>
<tr class="even">
<td style="text-align: left;">Rhesus monkey</td>
<td style="text-align: left;">18</td>
<td style="text-align: left;">0.398</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Potar monkey</td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">0.349</td>
</tr>
<tr class="even">
<td style="text-align: left;">Rhesus monkey</td>
<td style="text-align: left;">18</td>
<td style="text-align: left;">0.48</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Potar monkey</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">0.083</td>
</tr>
<tr class="even">
<td style="text-align: left;">Rhesus monkey</td>
<td style="text-align: left;">18</td>
<td style="text-align: left;">0.534</td>
</tr>
<tr class="odd">
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>When we consider a model in which brain mass is predicted by species, the <code>species</code> variable contains more than just two categories. In our example it has 3: “Potar monkey”, “Rhesus Monkey” and “Human”.</p>
<p>When we fit the model <code>lm(mass_brain ~ species)</code>, the default way in which the <code>species</code> predictor is included in the model is by setting one category as the “reference level”, and comparing each level to that reference level. So if the reference level is “Human”, the coefficients we get out include the intercept (which is the estimated brain mass of humans); the estimated difference in brain mass when we move from humans to potar monkeys; and from humans to rhesus monkeys:</p>
<pre><code>lm(formula = mass_brain ~ species, data = mm)

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)           0.60271    0.02748  21.936  &lt; 2e-16 ***
speciesPotar monkey  -0.35735    0.04142  -8.627 7.38e-10 ***
speciesRhesus monkey -0.15261    0.04257  -3.585   0.0011 ** </code></pre>
<p>Under the hood, what really gets inputted into our model is a set of variables that are all 0s and 1s (much like it did for a binary predictor). In the table below, the left column shows the original <code>species</code> variable, and the remaining columns are the variables that R actually inputs to the model when we give it <code>species</code> as a predictor. We can see that one category (“Human”) is where all these are zeros.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">speciesPotar monkey</th>
<th style="text-align: left;">speciesRhesus monkey</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Human</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">Potar monkey</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Rhesus monkey</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>For a categorical variable with <span class="math inline">\(k\)</span> levels, this is the same as adding <span class="math inline">\(k-1\)</span> predictors into our model. Each of <span class="math inline">\(k-1\)</span> predictors is actually just another dimension to the model:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="08a_mlr_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<div class="rtip">
<p>R will default to using alphabetical ordering, hence the reference level being set as “Human”. We could override this by making it a factor with an ordering to it’s levels (see the use of <code>factor()</code> and <code>levels()</code> in <a href="02a_measurement.html#categorical" target="_blank">2A#categorical</a>). Functions like <code>fct_relevel()</code> might be handy too.</p>
</div>
<div class="divider div-transparent div-dot">

</div>
</section>
<section id="model-evaluation" class="level1">
<h1>Model Evaluation</h1>
<p>Alongside the estimation of specific parameters of interest (i.e.&nbsp;the coefficients from our model), we may well want to ask how good our model is as a whole. There are lots of ways to do this, but in this course we’re going to just focus on the ones which R will automatically show us at the bottom of the <code>summary(model)</code> output. These are the same <span class="math inline">\(R^2\)</span> and the <span class="math inline">\(F\)</span>-test that we saw in the simple regression model (<a href="07a_slr.html#model-evaluation" target="_blank">7A#model-evaluation</a>), only it’s a little different when we have multiple predictors.</p>
<section id="adjusted-r2" class="level2">
<h2 class="anchored" data-anchor-id="adjusted-r2">Adjusted <span class="math inline">\(R^2\)</span></h2>
<p>We know from our work on simple linear regression that the R-squared can be obtained as:</p>
<p><span class="math display">\[
R^2 = \frac{SS_{Model}}{SS_{Total}} = 1 - \frac{SS_{Residual}}{SS_{Total}}
\]</span></p>
<p>If we briefly return to the venn diagrams we used above, the <span class="math inline">\(R^2\)</span> is capturing all variance in <span class="math inline">\(y\)</span> that is explained by the predictors (including the overlapping bits between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>). It is the total variance in <span class="math inline">\(y\)</span> explained by all predictors combined. This is area <span class="math inline">\(A + B + C\)</span> in <a href="#fig-vennmlr3">Figure&nbsp;7</a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vennmlr3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/mlr/venn_mlr2.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 7: Venn Diagram for Multiple Regression y ~ x1 + x2 where x1 and x2. The R squared is areas A + B + C</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>However, when we add more and more predictors into a multiple regression model, <span class="math inline">\(SS_{Residual}\)</span> cannot increase. In fact, it will <em>always</em> decrease, regardless of how useful our new predictors are. This means that <span class="math inline">\(R^2\)</span> will <em>always increase</em> (because <span class="math inline">\(SS_{Total}\)</span> is constant, so <span class="math inline">\(1-\frac{SS_{Residual}}{SS_{Total}}\)</span> will increase as <span class="math inline">\(SS_{Residual}\)</span> decreases). If we added randomly generated 1000 new predictors (completely random, so they have nothing to do with the outcome), then by chance alone they will explain <em>some</em> variance in the outcome <span class="math inline">\(y\)</span>.</p>
<p>An alternative, the Adjusted-<span class="math inline">\(R^2\)</span>, does not necessarily increase with the addition of more explanatory variables, by including a penalty according to the number of explanatory variables in the model. It is not by itself meaningful, but can be useful in determining what predictors to include in a model.</p>
<p><span class="math display">\[
\begin{align}
&amp; Adjusted{-}R^2=1-\frac{(1-R^2)(n-1)}{n-k-1} \\
&amp; \quad \\
&amp; \text{Where:} \\
&amp; n = \text{sample size} \\
&amp; k = \text{number of explanatory variables} \\
\end{align}
\]</span></p>
<p><strong>In R,</strong> you can view the mutiple and adjusted <span class="math inline">\(R^2\)</span> at the bottom of the output of <code>summary(&lt;modelname&gt;)</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://uoepsy.github.io/data/usmr_mlr.csv"</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>eg_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> mydata)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(eg_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/mlr/output_mlr_rsq.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="joint-test" class="level2">
<h2 class="anchored" data-anchor-id="joint-test">Joint test</h2>
<p>As in simple linear regression, the F-statistic is used to test the null hypothesis that <strong>all</strong> regression slopes are zero (it is just that now that we have multiple predictors, so “all” is more than 1).</p>
<p><span class="math display">\[
\begin{aligned}
H_0: &amp; \text{the model is ineffective, } \\
&amp; b_1, ..., b_k = 0 \\
H_1: &amp;\text{the model is effective, } \\
&amp; \text{any of }b_1, ..., b_k \neq 0
\end{aligned}
\]</span></p>
<p>The <span class="math inline">\(F\)</span>-statistic is sometimes called the F-ratio because it is the ratio of the how much of the variation is explained by the model (per parameter) versus how much of the variation is unexplained (per remaining degrees of freedom).</p>
<p>We extend the formula for the <span class="math inline">\(F\)</span>-statistic for simple regression to encompass situations where there are more predictors:</p>
<p><span class="math display">\[
\begin{align}
&amp; F_{df_{model},df_{residual}} = \frac{MS_{Model}}{MS_{Residual}} = \frac{SS_{Model}/df_{Model}}{SS_{Residual}/df_{Residual}} \\
&amp; \quad \\
&amp; \text{Where:} \\
&amp; df_{model} = k \\
&amp; df_{error} = n-k-1 \\
&amp; n = \text{sample size} \\
&amp; k  = \text{number of explanatory variables} \\
\end{align}
\]</span></p>
<p><strong>In R,</strong> at the bottom of the output of <code>summary(&lt;modelname&gt;)</code>, you can view the F ratio, along with an hypothesis test against the alternative hypothesis that the at least one of the coefficients <span class="math inline">\(\neq 0\)</span> (under the null hypothesis that all coefficients = 0, the ratio of explained:unexplained variance should be approximately 1):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://uoepsy.github.io/data/usmr_mlr.csv"</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>eg_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> mydata)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(eg_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/mlr/output_mlr_f.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<div class="divider div-transparent div-dot">

</div>
</section>
</section>
<section id="model-comparisons" class="level1">
<h1>Model Comparisons</h1>
<p>The <span class="math inline">\(F\)</span>-statistic we see at the bottom of <code>summary(model)</code> is actually a comparison between two models: our model (with some explanatory variables in predicting <span class="math inline">\(y\)</span>) and <strong>the null model.</strong> In regression, the null model can be thought of as the model in which all explanatory variables have zero regression coefficients. It is also referred to as the <strong>intercept-only model</strong>, because if all predictor variable coefficients are zero, then the only we are only estimating <span class="math inline">\(y\)</span> via an intercept (which will be the mean: <span class="math inline">\(\bar y\)</span>).</p>
<p>We aren’t limited to comparing our model to the null model. We can compare all the intermediate models which vary in the complexity, from the null model to our full model.</p>
<div class="statbox">
<p><strong>Incremental F-test</strong></p>
<p>If (<em>and only if</em>) two models are <strong>nested</strong> (one model contains all the predictors of the other and is fitted to the same data), we can compare them using an <strong>incremental F-test.</strong></p>
<p>This is a formal test of whether the <strong>additional predictors</strong> provide a better fitting model.<br>
Formally this is the test of:</p>
<ul>
<li><span class="math inline">\(H_0:\)</span> coefficients for the added/ommitted variables are all zero.</li>
<li><span class="math inline">\(H_1:\)</span> at least one of the added/ommitted variables has a coefficient that is not zero.</li>
</ul>
<div class="rtip">
<p><strong>In R,</strong> we can conduct an incremental F-test by constructing two models, and passing them to the <code>anova()</code> function:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>( ... </span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>( ... </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(model1, model2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="optional-begin">
<span id="opt-start-5" class="fa fa-hand-o-right optional-icon clickable" onclick="toggle_visibility('opt-body-5', 'opt-start-5')"> <span class="olab">Optional: F-ratio written for model comparison</span></span>
</div>
<div id="opt-body-5" class="optional-body" style="display: none;">
<p>The F-ratio for comparing the residual sums of squares between two models can be written as:</p>
<p><span class="math display">\[
\begin{align}
&amp; F_{(df_R-df_F),df_F} = \frac{(SSR_R-SSR_F)/(df_R-df_F)}{SSR_F / df_F} \\
&amp; \quad \\
&amp; \text{Where:} \\
&amp; SSR_R = \text{residual sums of squares for the restricted model} \\
&amp; SSR_F = \text{residual sums of squares for the full model} \\
&amp; df_R = \text{residual degrees of freedom from the restricted model} \\
&amp; df_F = \text{residual degrees of freedom from the full model} \\
\end{align}
\]</span></p>
</div>
<p class="optional-end">
</p>
<p>For example, we might compare a model with just one predictor, <span class="math inline">\(x_1\)</span>, to a model with 3 predictors: <span class="math inline">\(x_1,\ x_2,\ x_3\)</span>, thereby assessing the extent to which the variables <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_3\)</span> jointly improve model fit:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"https://uoepsy.github.io/data/usmr_mlr.csv"</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>eg_model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> mydata)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>eg_model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> mydata)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(eg_model1, eg_model2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ x1
Model 2: y ~ x1 + x2 + x3
  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  
1     48 2874.8                              
2     45 2294.3  3    580.55 3.7956 0.01648 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div class="divider div-transparent div-dot">

</div>
</section>
<section id="analysis-of-variance" class="level1">
<h1>Analysis of Variance</h1>
<p>Another thing we can do is take a single model and partition out variance explained by the <em><strong>incremental addition</strong> of each predictor.</em> We can do that by building a model with <code>lm()</code> and then giving the <code>anova()</code> function that model.</p>
<p>It’s very important to note that the <strong>order matters</strong> here, because it will assess the improvement in model fit due to each predictor in turn:</p>
<ol type="1">
<li><span class="math inline">\(x_1\)</span> vs no predictors</li>
<li>then the addition of <span class="math inline">\(x_2\)</span> to the model with <span class="math inline">\(x_1\)</span></li>
<li>then the addition of <span class="math inline">\(x_3\)</span> to the model with <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>)</li>
</ol>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>eg_model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> mydata)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(eg_model2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: y
          Df  Sum Sq Mean Sq F value   Pr(&gt;F)   
x1         1  317.77  317.77  6.2327 0.016271 * 
x2         1  526.06  526.06 10.3181 0.002435 **
x3         2   54.50   27.25  0.5344 0.589671   
Residuals 45 2294.29   50.98                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>If it helps, we might think of this again in terms of a Venn diagram. Each line of the Analysis of Variance Table above corresponds to the area of one of the coloured areas in <a href="#fig-vennss1">Figure&nbsp;8</a> (relative to the size of the white area labelled “E”).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vennss1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/mlr/venn_ss_type1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 8: Venn Diagram showing incremental sums of squares</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>And this is really just a big set of model comparisons:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>eg_model0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> mydata)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>eg_model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> mydata)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>eg_model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> mydata)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>eg_model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> mydata)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(eg_model0, eg_model1, eg_model2, eg_model3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that this is a very different thing from what we have been doing previously, which was examining the effect of all predictors <strong>after</strong> considering all others (see <a href="#fig-vennss3">Figure&nbsp;9</a>). The area <span class="math inline">\(C\)</span> is the same in both <a href="#fig-vennss1">Figure&nbsp;8</a> and <a href="#fig-vennss3">Figure&nbsp;9</a>, demonstrating that this approach is like considering each predictor as if it were the “last one in” in the incremental approach.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vennss3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/mlr/venn_ss_type3.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 9: Venn Diagram showing partial (‘last one in’) sums of squares</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Our interpretation of our regression coefficients matches the “last one in” approach shown in <a href="#fig-vennss1">Figure&nbsp;8</a>, but the hypothesis tests of coefficients are technically tests against the null hypothesis that that the coefficient is zero. The <code>drop1()</code> function allows us to conduct an analysis of variance using the “last one in” approach:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>eg_model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, mydata)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">drop1</span>(eg_model2, <span class="at">test =</span> <span class="st">"F"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Single term deletions

Model:
y ~ x1 + x2 + x3
       Df Sum of Sq    RSS    AIC F value   Pr(&gt;F)   
&lt;none&gt;              2294.3 201.31                    
x1      1     416.2 2710.5 207.64  8.1634 0.006450 **
x2      1     445.1 2739.4 208.17  8.7301 0.004965 **
x3      2      54.5 2348.8 198.48  0.5344 0.589671   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>It might seem pointless to do this, given we can just look at our regression coefficients. In fact, the p-values for <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are just the same as the p-values for our coefficients:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(eg_model2)<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -8.66876    4.77570  -1.815 0.076164 .  
x1           0.12176    0.07469   1.630 0.110026    
x2          -0.60298    0.23596  -2.555 0.014054 *  
x3level2     7.59135    2.80859   2.703 0.009663 ** 
x3level3    11.62405    3.22863   3.600 0.000789 ***</code></pre>
<p>But note that <span class="math inline">\(x_3\)</span> is a categorical variable that has three levels: “level1”, “level2”, “level3”, which means we get out <em>two</em> coefficients that test <em>two</em> specific differences (level2 vs level1; level3 vs level1). The analysis of variance approach (above) allows us to perform one single test of whether the entire grouping (of observations into the three levels) explains variance in the outcome variable.</p>
<p>The very big picture could be taken as:</p>
<ul>
<li>Analysis of Variance: “are there group differences in <span class="math inline">\(y\)</span>?”</li>
<li>Coefficients: “what are the differences in <span class="math inline">\(y\)</span> when comparing specific groups?”</li>
</ul>
</section>
<section id="correlation-vs-causation-again" class="level1">
<h1>Correlation vs Causation, Again!</h1>
<p>It’s very important to remember that all of this extra “control” we are able to exert on our model estimates doesn’t just allow us to start talking about causal effects. The coefficients we get from a multiple regression model are <em>still</em> just associations (i.e.&nbsp;correlations), it is simply that they are now <em>conditional</em> upon holding constant some other variable.</p>
<p>To make the point, we could fit a model such as:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(birthweight <span class="sc">~</span> IQ_age11 <span class="sc">+</span> bilingual, <span class="at">data =</span> ...)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And get some coefficients:</p>
<pre><code>Coefficients:
            Estimate    ...   ...
(Intercept)  600.000    ...   ...
IQ_age11     10.0000    ...   ...
bilingualYes 5.00000    ...   ...</code></pre>
<p>Now imagine that you have a newborn baby who weighs 700 grams. Are we to say that “If I raise this child to be bilingual, her birthweight will increase by 5 grams (assuming her IQ at age 11 remains the same)”?<br>
This is obviously nonsense - the baby weighs 700 grams and that’s not something that will change.</p>
<p>To talk about causal effects we need a lot of careful thought about our theoretical model of the world (i.e.&nbsp;what causes what) combined with a model that isolates the relevant effect of interest by controlling for the appropriate possible confounds (either through statistical control or control by design).</p>


</section>


<div id="quarto-appendix" class="default"><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1" role="doc-endnote"><p>One could imagine this surface changing over time, which would bring in a 4th dimension, but beyond that, it’s not worth trying!<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>and the intercept will be the estimated <span class="math inline">\(y\)</span> when all predictors are zero, where “zero” is the reference category of the binary predictor<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>