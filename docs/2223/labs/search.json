[
  {
    "objectID": "04_sampling.html",
    "href": "04_sampling.html",
    "title": "Curves & Sampling",
    "section": "",
    "text": "Normal distributions\nwhy normal?\nsampling is random\ndeviations around a mean\nrnorm() pnorm()\n\nThere are certain properties of normal distributions which we can exploit, in order to determine how plausible an observed value is relative to a distribution. When a distribution is normal (symmetric and bell-shaped):\n\n68% of values will lie within 1 standard deviation of the mean.\n95% of values will lie within 1.96 standard deviations of the mean.\n99.7% of values will lie within 3 standard deviations of the mean.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSampling Distributions\nOften, what we’re really interested does not concern a specific individual but the wider population in general. For example, TODO\nIn practice, when we do research we tend to collect data from a sample, because it is not feasible to collect data from the entire population. By using a random sample to represent a population of interest, we introduce uncertainty (due to sampling variability) in how accurate our sample statistic is as an estimate of the population parameter.\nFor example, TODO -MATCH ABOVE TODO \nLet’s look at this with a little example.\nLet’s pretend that the average height of the entire global adult population is exactly 178cm, and that the standard deviation of heights is 10cm. However, let’s also pretend that we do not know that the average height is 178cm, and that we are interested in trying to estimate the average height. Unfortunately, all we have is the measurements of 20 people who we randomly sampled. We want to use the mean height of our sample as an estimate of the mean height of the population.\nIn R, we can simulate the act of randomly sampling 20 people’s heights from the population with \\(\\mu = 178\\) and \\(\\sigma = 10\\) using rnorm():\n\nour_sample <- rnorm(n = 20, mean = 178, sd = 10)\nmean(our_sample)\n\n[1] 176.7317\n\n\nNote that the mean of our sample (176.73) is not quite the same as the mean of the population (178 exactly). As we know, samples vary. If we do the same thing again, R will take a different sample of 20, and so the mean of this new sample will also be different:\n\nmean(rnorm(n = 20, mean = 178, sd = 10))\n\n[1] 181.0967\n\n\nEach time we get a new sample, we get a different mean:\n\nmean(rnorm(n = 20, mean = 178, sd = 10))\nmean(rnorm(n = 20, mean = 178, sd = 10))\nmean(rnorm(n = 20, mean = 178, sd = 10))\n\n\n\n[1] 179.3159\n\n\n[1] 178.1062\n\n\n[1] 175.7159\n\n\nWhat we’re wanting to do here is think about all possible samples of 20 people we could take, and all the possible resulting mean heights. Let’s suppose we took 1000 samples of 20 people, and for each one we calculated the mean height. Where would all these different means fall? Some would be above our population parameter (i.e. we just might happened to have sampled some slightly taller people) and some would be below.\nWe can use R to enact this repeated sampling: the replicate() function allows us to repeatedly execute a bit of code, which means we can take lots of samples and calculate their means. These means we can then visualise using hist():\n\nmanysamplemeans <- replicate(1000, mean(rnorm(n = 20, mean = 178, sd = 10)))\nhist(manysamplemeans)\n\n\n\n\n\n\n\n\nNote what happens to the distribution when we take 1000 means of samples of size \\(n=200\\), rather than \\(n=20\\). Many more of the of the values are in a much narrower bracket (pay careful attention to the x-axis) than when we took lots of samples of \\(n=20\\).\n\nmanysamplemeans200 <- replicate(1000, mean(rnorm(n = 200, mean = 178, sd = 10)))\nhist(manysamplemeans200)\n\n\n\n\n\n\n\n\nWhy is this important?\nWhat we’re doing here is showing the process of taking many samples of the same size from a population and calculating a statistic on each sample. The distribution of these sample statistics shows how the statistic will vary from sample to sample due to chance. Provided that our sampling is truly random, the sample statistics will be centered around the population parameter.\nIn the above example, for samples of \\(n=20\\) drawn from a population with mean \\(\\mu=178\\) and standard deviation \\(\\sigma=10\\), the sample means are centered around 178, and we’re quite likely to get sample means between 174 and 182, but less likely to see sample means \\(<174\\) and \\(>182\\). Importantly, we can quantify this. The distribution of means from samples of size \\(n=20\\) has a standard deviation of:\n\nsd(manysamplemeans)\n\n[1] 2.30394\n\n\nThis metric, the standard deviation of the sampling distribution of a statistic, is known as the standard error.\n\nSampling Distribution and Standard Error\n\nThe theoretical distribution of how sample statistics will vary on repeated sampling is known as the sampling distribution.\n\nThe standard deviation of the sampling distribution is known as the standard error.\n\nNote that the bigger our sample size, the smaller our standard error - i.e., the more precise our sample means are going to be as estimates of the population mean:\n\n\n\n\n\n\n\n\n\n\n\n\n\nStandard Error in practice\nIn practice, we cannot actually take lots and lots of samples in order to construct a sampling distribution, and nor do we know the population parameters which are required to generate samples like we did above (we do not know the population mean \\(\\mu\\) or standard deviation \\(\\sigma\\))\nInstead, we start with just one observed sample, e.g.:\n\nobserved_sample <- c(176.86, 169.45, 177.93, 175.89, 169.05, 162.56, 189.29, 196.15, 159.45, 165.69, 186.88, 176.9, 188.52, 164.05, 175.62, 180.89, 193.63, 161.59, 182.74, 184.23)\n\nWhat we can do is either:\n\nA: Simulate lots of sampling via bootstrapping.\nThis uses resampling with replacement1 from our original sample as a means of imitating repeated sampling. Note the replace = FALSE:\n\n# bootstrap means of resamples with replacement of the same size (20) as observed sample\nbootstrap_means <- replicate(1000, mean(sample(observed_sample, size = 20, replace = TRUE)))\n# SE = sd of bootstrap resample means \nsd(bootstrap_means)\n\n[1] 2.437693\n\n\nor B: Estimate the standard error using a formula:\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}}  \\\\\n\\quad \\\\\n\\begin{align}\n& \\text{Where} \\\\\n& \\sigma = \\text{standard deviation} \\\\\n& n = \\text{sample size} \\\\\n\\end{align}\n\\] Note that \\(\\sigma\\) is the standard deviation of the population, which is unknown to us. However, we can use the standard deviation of our sample (\\(\\hat \\sigma\\) or \\(s\\)) as our estimate of this:\n\n# SE = standard deviation / square root of n\nsd(observed_sample)/sqrt(length(observed_sample))\n\n[1] 2.459404\n\n\n\n\n\nConfidence Intervals\nTODO\n\n\nCLT\nNotice that the sampling distributions we have generated above all have similar properties - they are symmetric and bell-shaped. They are normally distributed.\nIn fact, the central limit theorem (CLT) states that when we take sufficiently large random samples from a population, the distribution of the sample means will be approximately normally distributed. This holds regardless of whether the population is normal (or skewed).\n\n\n\n\n\nFigure 1: Population distributions (top) and sampling distributions (bottom)\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nImagine a bag full of coloured marbles. If we sample with replacement, then we take a marble out, record its colour, and put it back. Then we take a marble out, record its colour, and put it back. And so on. This means we might get the same marble more than once.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Univariate Statistics and Methodology in R",
    "section": "",
    "text": "Univariate Statistics and Methodology in R (USMR) is a semester long crash-course aimed at providing Masters students in psychology with a competence in standard statistical methodologies and data analysis using R. Typically the analyses taught in this course are relevant for when there is just one source of variation - i.e. when we are interested in a single outcome measured across a set of independent observations. The first half of the course covers the fundamentals of statistical inference using a simulation-based approach, and introduces students to working with R & RStudio. The latter half of the course focuses on the general linear model, emphasising the fact that many statistical methods are simply special cases of this approach. This course introduces students to statistical modelling and empowers them with tools to analyse richer data and answer a broader set of research questions."
  },
  {
    "objectID": "03_measurement.html",
    "href": "03_measurement.html",
    "title": "Measurement & Distributions",
    "section": "",
    "text": "Reading time: 23 minutes"
  },
  {
    "objectID": "03_measurement.html#categorical",
    "href": "03_measurement.html#categorical",
    "title": "Measurement & Distributions",
    "section": "Categorical",
    "text": "Categorical\n\nCategorical variables tell us what group or category each individual belongs to. Each distinct group or category is called a level of the variable.\n\n\n\n\n\n\n\n\nType\nDescription\nExample\n\n\n\n\nNominal (Unordered categorical)\nA categorical variable with no intrinsic ordering among the levels.\nSpecies: Dog, Cat, Parrot, Horse, …\n\n\nOrdinal (Ordered categorical)\nA categorical variable which levels possess some kind of order\nLevel: Low, Medium, High\n\n\nBinary categorical\nA special case of categorical variable with only 2 possible levels\nisDog: Yes or No.\n\n\n\nIf we want to summarise a categorical variable into a single number, then the simplest approach is to use the mode:\n\nMode: The most frequent value (the value that occurs the greatest number of times).\n\nWhen we have ordinal variables, there is another option, and that is to use the median:\n\nMedian: For ordinal variables only, this is the value for which 50% of observations are lower and 50% are higher. It is the mid-point of the values when they are rank-ordered.\n\nWhen we use the median as our measure of “central tendency” (i.e. the middle of the distribution) and we want to discuss how spread out the spread are around it, then we will want to use quartiles. The Inter-Quartile Range (IQR) is obtained by rank-ordering all the data, and finding the points at which 25% (one quarter) and 75% (three quarters) of the data falls below (this makes the median the “2nd quartile”).\n\nIn our dataset on passwords, we have various categorical variables, such as the type of password (categories like “animal”, “fluffy” etc).\nThere are various ways we might want to summarise categorical variables like this. We have already seen the code to do this in our example of the dice simulation - we can simply counting the frequencies in each level:\n\ntable(pwords$type)\n\n\n             animal          cool-macho              fluffy                food \n                 29                  79                  44                  11 \n               name           nerdy-pop    password-related     rebellious-rude \n                183                  30                  15                  11 \nsimple-alphanumeric               sport \n                 61                  37 \n\n\nThis shows us that the mode (most common) is “name” related passwords.\nWe could also convert these to proportions, by dividing each of these by the total number of observations. For instance, here are the percentages of passwords of each type:\n\ntable(pwords$type) / sum(table(pwords$type)) * 100\n\n\n             animal          cool-macho              fluffy                food \n                5.8                15.8                 8.8                 2.2 \n               name           nerdy-pop    password-related     rebellious-rude \n               36.6                 6.0                 3.0                 2.2 \nsimple-alphanumeric               sport \n               12.2                 7.4 \n\n\n\nOften, if the entries in a variable are characters (letters), then many functions in R (like table()) will treat it the same as if it is a categorical variable. However, this is not always the case, so it is good to tell R specifically that each variable is a categorical variable. There is a special way that we tell R that a variable is categorical - we set it to be a “factor”. Note what happens when we make the “type” and “strength_cat” variables to be a factor:\n\npwords$type <- factor(pwords$type)\npwords$strength_cat <- factor(pwords$strength_cat)\nsummary(pwords)\n\n      rank         password                          type        cracked      \n Min.   :  1.0   Length:500         name               :183   Min.   : 1.290  \n 1st Qu.:125.8   Class :character   cool-macho         : 79   1st Qu.: 3.430  \n Median :250.5   Mode  :character   simple-alphanumeric: 61   Median : 3.720  \n Mean   :250.5                      fluffy             : 44   Mean   : 5.603  \n 3rd Qu.:375.2                      sport              : 37   3rd Qu.: 3.720  \n Max.   :500.0                      nerdy-pop          : 30   Max.   :92.270  \n                                    (Other)            : 66                   \n    strength      strength_cat\n Min.   : 1.000   medium:402  \n 1st Qu.: 6.000   strong: 25  \n Median : 7.000   weak  : 73  \n Mean   : 6.768               \n 3rd Qu.: 8.000               \n Max.   :10.000               \n                              \n\n\nR now recognises that there a set number of possible response options, or “levels”, for these variables. We can see what they are using:\n\nlevels(pwords$strength_cat)\n\n[1] \"medium\" \"strong\" \"weak\"  \n\n\nThe “strength_cat” variable specifically has an ordering to the levels, so we might be better off also telling R about this ordering. We do this like so:\n\npwords$strength_cat <- factor(pwords$strength_cat, ordered = TRUE, levels = c(\"weak\",\"medium\",\"strong\"))\n\n\nSometimes, we might have a variable that we know is categorical, but we might want to treat it as a set of numbers instead. A very common example in psychological research is Likert data (questions measured on scales such as “Strongly Disagree”>>“Disagree”>>…>>“Strongly Agree”).\nIt is often useful to have these responses as numbers (e.g. 1 = “Strongly Disagree” to 5 = “Strongly Agree”), as this allows us to use certain functions in R more easily. For instance, the median() and IQR() functions require the data to be numbers.\nThis will not work:\n\nmedian(pwords$strength_cat)\n\nError in median.default(pwords$strength_cat): need numeric data\n\n\nWhen we ask R to convert a factor to a numeric variable, it will give turn the first category into 1, the second category to 2, and so on. As R knows that our strength_cat variable is the ordered categories “weak”>>“medium”>>“strong”, then as.numeric(pwords$strength_cat) will turn these to 1s, 2s, and 3s.\n\nmedian(as.numeric(pwords$strength_cat))\n\n[1] 2"
  },
  {
    "objectID": "03_measurement.html#numeric",
    "href": "03_measurement.html#numeric",
    "title": "Measurement & Distributions",
    "section": "Numeric",
    "text": "Numeric\n\nNumeric (or quantitative) variables consist of numbers, and represent a measurable quantity. Operations like adding and averaging make sense only for numeric variables.\n\n\n\n\n\n\n\n\nType\nDescription\nExample\n\n\n\n\nContinuous\nVariables which can take any real number within the specified range of measurement\nHeight: 172, 165.2, 183, …\n\n\nDiscrete\nVariables which can only take integer number values. For instance, a counts can only take positive integer values (0, 1, 2, 3, etc.)\nNumber_of_siblings: 0, 1, 2, 3, 4, …\n\n\n\nOne of the most frequently used measures of central tendency for numeric data is the mean. The mean is calculated by summing all of the observations together and then dividing by the total number of obervations (\\(n\\)).\n\nMean: \\(\\bar{x}\\)\nWhen we have sampled some data, we denote the mean of our sample with the symbol \\(\\bar{x}\\) (sometimes referred to as “x bar”). The equation for the mean is:\n\\[\\bar{x} = \\frac{\\sum\\limits_{i = 1}^{n}x_i}{n}\\]\n\n Optional - Help reading mathematical formulae.\n\n\nThis might be the first mathematical formula you have seen in a while, so let’s unpack it.\nThe \\(\\sum\\) symbol is used to denote a series of additions - a “summation”.\nWhen we include the bits around it: \\(\\sum\\limits_{i = 1}^{n}x_i\\) we are indicating that we add together all the terms \\(x_i\\) for values of \\(i\\) between \\(1\\) and \\(n\\):\n\\[\\sum\\limits_{i = 1}^{n}x_i \\qquad = \\qquad x_1+x_2+x_3+...+x_n\\]\nSo in order to calculate the mean, we do the summation (adding together) of all the values from the \\(1^{st}\\) to the \\(n^{th}\\) (where \\(n\\) is the total number of values), and we divide that by \\(n\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we are using the mean as our as our measure of central tendency, we can think of the spread of the data in terms of the deviations (distances from each value to the mean).\nRecall that the mean is denoted by \\(\\bar{x}\\). If we use \\(x_i\\) to denote the \\(i^{th}\\) value of \\(x\\), then we can denote deviation for \\(x_i\\) as \\(x_i - \\bar{x}\\).\nThe deviations can be visualised by the red lines in Figure 2.\n\n\n\n\n\nFigure 2: Deviations from the mean\n\n\n\n\n\nThe sum of the deviations from the mean, \\(x_i - \\bar x\\), is always zero\n\\[\n\\sum\\limits_{i = 1}^{n} (x_i - \\bar{x}) = 0\n\\]\nThe mean is like a center of gravity - the sum of the positive deviations (where \\(x_i > \\bar{x}\\)) is equal to the sum of the negative deviations (where \\(x_i < \\bar{x}\\)).\n\nBecause deviations around the mean always sum to zero, in order to express how spread out the data are around the mean, we must we consider squared deviations.\nSquaring the deviations makes them all positive. Observations far away from the mean in either direction will have large, positive squared deviations. The average squared deviation is known as the variance, and denoted by \\(s^2\\)\n\nVariance: \\(s^2\\)\nThe variance is calculated as the average of the squared deviations from the mean.\nWhen we have sampled some data, we denote the mean of our sample with the symbol \\(\\bar{x}\\) (sometimes referred to as “x bar”). The equation for the variance is:\n\\[s^2 = \\frac{\\sum\\limits_{i=1}^{n}(x_i - \\bar{x})^2}{n-1}\\]\n\n Optional: Why n minus 1?\n\n\nThe top part of the equation \\(\\sum\\limits_{i=1}^{n}(x_i - \\bar{x})^2\\) can be expressed in \\(n-1\\) terms, so we divide by \\(n-1\\) to get the average.\n Example: If we only have two observations \\(x_1\\) and \\(x_2\\), then we can write out the formula for variance in full quite easily. The top part of the equation would be:\n\\[\n\\sum\\limits_{i=1}^{2}(x_i - \\bar{x})^2 \\qquad = \\qquad (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2\n\\]\nThe mean for only two observations can be expressed as \\(\\bar{x} = \\frac{x_1 + x_2}{2}\\), so we can substitute this in to the formula above.\n\\[\n(x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 \\qquad = \\qquad \\left(x_1 - \\frac{x_1 + x_2}{2}\\right)^2 + \\left(x_2 - \\frac{x_1 + x_2}{2}\\right)^2\n\\]\nWhich simplifies down to one value:\n\\[\n\\left(x_1 - \\frac{x_1 + x_2}{2}\\right)^2 + \\left(x_2 - \\frac{x_1 + x_2}{2}\\right)^2 \\qquad = \\qquad  \\left(\\frac{x_1 - x_2}{\\sqrt{2}}\\right)^2\n\\]\n So although we have \\(n=2\\) datapoints (\\(x_1\\) and \\(x_2\\)), the top part of the equation for the variance has only 1 (\\(n-1\\)) units of information. In order to take the average of these bits of information, we divide by \\(n-1\\).\n\n\n\n\nOne difficulty in interpreting variance as a measure of spread is that it is in units of squared deviations. It reflects the typical squared distance from a value to the mean.\nConveniently, by taking the square root of the variance, we can translate the measure back into the units of our original variable. This is known as the standard deviation.\n\nStandard Deviation: \\(s\\)\nThe standard deviation, denoted by \\(s\\), is a rough estimate of the typical distance from a value to the mean.\nIt is the square root of the variance (the typical squared distance from a value to the mean).\n\\[\ns = \\sqrt{\\frac{\\sum\\limits_{i=1}^{n}(x_i - \\bar{x})^2}{n-1}}\n\\]\n\n\nIn the passwords dataset, we only have one continuous variable, and that is the “cracked” variable, which if we recall is the “Time to crack by online guessing”. You might be questioning whether the “strength” variable, which ranges from 1 to 10 is numeric? This depends on whether we think that statements like “a password of strength 10 is twice as strong as a password of strength 5”.\nFor now, we’ll just look at the “cracked” variable.\nTo calculate things like means and standard deviations in R is really easy, because there are functions that do them all for us.\nFor instance, we can do the calculation by summing the cracked variable, and dividing by the number of observations (in our case we have 500 passwords):\n\n# get the values in the \"cracked\" variable from the \"pwords\" dataframe, and\n# sum them all together. Then divide this by 500\nsum(pwords$cracked)/500\n\n[1] 5.60266\n\n\nOr, more easily, we can use the mean() function:\n\nmean(pwords$cracked)\n\n[1] 5.60266\n\n\nWe can get R to calculate the variance and standard deviation with the var() and sd() functions:\n\nvar(pwords$cracked)\n\n[1] 71.16618\n\nsd(pwords$cracked)\n\n[1] 8.436005\n\n\nand just to prove to ourselves:\n\nsd(pwords$cracked)^2 == var(pwords$cracked)\n\n[1] TRUE\n\n\n\nIf a column of our dataset contains only numbers, R will typically just interpret it as a numeric variable. However, we should still be careful; remember what happens if we have just one erroneous entry in there - they can all change to be characters (surrounded by quotation marks):\n\nc(1,3,6,\"peppapig\",3)\n\n[1] \"1\"        \"3\"        \"6\"        \"peppapig\" \"3\"       \n\n\nWe can force a variable to be numeric by using as.numeric(), which will also coerce any non-numbers to be NA (not applicable):\n\nas.numeric(c(1,3,6,\"peppapig\",3))\n\n[1]  1  3  6 NA  3\n\n\nIf there is an NA in the variable, many functions like mean(), var() and sd() will not compute:\n\nx <- c(1, 3, 6, NA, 3)\nmean(x)\n\n[1] NA\n\n\nHowever, we can ask these functions to remove the NAs prior to the computation:\n\nmean(x, na.rm = TRUE)\n\n[1] 3.25"
  },
  {
    "objectID": "03_measurement.html#boxplots",
    "href": "03_measurement.html#boxplots",
    "title": "Measurement & Distributions",
    "section": "Boxplots",
    "text": "Boxplots\nBoxplots provide a useful way of visualising the interquartile range (IQR). You can see what each part of the boxplot represents in Figure Figure 4.\n\n\n\n\n\nFigure 4: Anatomy of a boxplot\n\n\n\n\nWe can create a boxplot of our age variable using the following code:\n\n# Notice, we put strength on the x axis, making the box plot vertical. \n# If we had set aes(y = strength) instead, then it would simply be rotated 90 degrees \nggplot(data = pwords, aes(x = strength)) +\n  geom_boxplot()"
  },
  {
    "objectID": "03_measurement.html#histograms",
    "href": "03_measurement.html#histograms",
    "title": "Measurement & Distributions",
    "section": "Histograms",
    "text": "Histograms\nNow that we have learned about the different measures of central tendency and of spread, we can look at how these map to how visualisations of numeric variables look.\nWe can visualise numeric data using a histogram, which shows the frequency of values which fall within bins of an equal width.\nTo do this, we’re going to use some new data, on 120 participants’ IQ scores (measured on the Wechsler Adult Intelligence Scale (WAIS)), their ages, and their scores on 2 other tests. The data are available at https://uoepsy.github.io/data/wechsler.csv\n\nwechsler <- read_csv(\"https://uoepsy.github.io/data/wechsler.csv\")\n\n\n# make a ggplot with the \"wechsler\" data. \n# on the x axis put the possible values in the \"iq\" variable,\n# add a histogram geom (will add bars representing the count \n# in each bin of the variable on the x-axis)\nggplot(data = wechsler, aes(x = iq)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\nWe can specifiy the width of the bins:\n\nggplot(data = wechsler, aes(x = iq)) + \n  geom_histogram(binwidth = 5)\n\n\n\n\n\n\n\n\nLet’s take a look at the means and standard deviations of participants’ scores on the other tests (the test1 and test2 variables).\nNote how nicely we can do this with our newfound tidyverse skills!\n\nwechsler %>% \n  summarise(\n    mean_test1 = mean(test1),\n    sd_test1 = sd(test1),\n    mean_test2 = mean(test2),\n    sd_test2 = sd(test2)\n  )\n\n# A tibble: 1 × 4\n  mean_test1 sd_test1 mean_test2 sd_test2\n       <dbl>    <dbl>      <dbl>    <dbl>\n1       49.3     7.15       51.2     14.4\n\n\nTests 1 and 2 have similar means (around 50), but the standard deviation of Test 2 is almost double that of Test 1. We can see this distinction in the visualisation below - the histograms are centered at around the same point (50), but the one for Test 2 is a lot wider than that for Test 1."
  },
  {
    "objectID": "03_measurement.html#density",
    "href": "03_measurement.html#density",
    "title": "Measurement & Distributions",
    "section": "Density",
    "text": "Density\nIn addition to grouping numeric data into bins in order to produce a histogram, we can also visualise a density curve.\nBecause there are infinitely many values that numeric variables could take (e.g., 50, 50.1, 50.01, 5.001, …), we could group the data into infinitely many bins. This is essentially what we are doing with a density curve.\nYou can think of “density” as a bit similar to the notion of “relative frequency” (or “proportion”), in that for a density curve, the values on the y-axis are scaled so that the total area under the curve is equal to 1. In creating a curve for which the total area underneath is equal to one, we can use the area under the curve in a range of values to indicate the proportion of values in that range.\n\nggplot(data = wechsler, aes(x = iq)) + \n  geom_density()\n\n\n\n\n\n\n\n\n\nArea under the curve\nThink about the barplots we have been looking at previously:\n\n# our function to simulate the roll of a die/some dice\ndice <- function(num = 1) {\n  sum(sample(1:6, num, replace=TRUE))\n}\n# simulate 1000 rolls of a single die\nroll1000 <- replicate(1000, dice(1))\n# tabulate and plot:\ntable(roll1000) %>%\n  barplot(.,ylab=\"count\")\n\n\n\n\n\n\n\n\nTo think about questions like “what proportion of 1000 rolls does the die land on 6?”, we are simply interested in the count of 6s divided by the count of all rolls:\n\ntab1000 <- table(roll1000)\ntab1000[6] / sum(tab1000)\n\n    6 \n0.161 \n\n\nSo Another way of thinking of this is that we are just dividing the count in each category by the total number. Or, Put another way, imagine we divide the area of each bar by the total area. The area now sums to 1, and our question is asking about the ratio of the red area to the total area (grey + red):\n\n\n\n\n\n\n\n\n\nNothing really changes with a density curve! If we want to ask what proportion of our distribution of IQ scores is >100, then we are asking about the area under the curve that is to the right of 100:\n\n\n\n\n\n\n\n\n\nIt looks like about half. Let’s calculate this proportion directly:\n\nsum(wechsler$iq>110) / length(wechsler$iq)\n\n[1] 0.2\n\n\nIt might seem a little odd to think about area under the curve when we are asking about “what proportion of the data is …?”. If we have the data, then we can just calculate the answer (like we did above). However, a lot of statistics is really concerned with the probability of events. When we discuss probability, we move from talking about a specific set of observed data to thinking about a theoretical/mathematical model that defines the way in which data is generated. This where it becomes more useful to think about distributions in a more abstract sense.\nFor instance, with a fair six-sided die, we have a probability distribution in which each side is given the probability \\(\\frac{1}{6}\\):\n\\[\n\\begin{gather*}\nP(x) = \\begin{cases}\n  \\frac{1}{6} & \\text{if $x \\in \\{1,2,3,4,5,6\\}$}\\\\\n  0 & \\text{otherwise.}\n  \\end{cases}\n\\end{gather*}\n\\]"
  },
  {
    "objectID": "03_measurement.html#defining-moments",
    "href": "03_measurement.html#defining-moments",
    "title": "Measurement & Distributions",
    "section": "Defining moments",
    "text": "Defining moments\nThe “moments” of a distribution are the metrics that relate to the shape of that distribution. We’ve already seen the primary two moments that define the shapes of these distributions: 1. mean, and 2. variance.\nThe mean moves the distribution right or left, and the variance makes the distribution wider or narrower.\nThere are two more, “skewness” and “kurtosis” which tend to be of less focus of investigation (the questions we ask tend to be mainly concerned with means and variances). Skewness is a measure of asymmetry in a distribution. Distributions can be positively skewed or negatively skewed, and this influences our measures of central tendency and of spread to different degrees. The kurtosis is a measure of how “pointy” vs “rounded” the shape of a distribution is."
  },
  {
    "objectID": "ex02.html",
    "href": "ex02.html",
    "title": "Lab 2:",
    "section": "",
    "text": "Calculate the proportion of the population are over 6 foot?\n\n helpful hint.\n\n\n\n# some numbers:\nx1 <- c(3,1,4,2,7)\n# whether or not each value is <5\nx2 <- x1<5\n# x2 is a set of TRUEs and FALSEs\nx2\n\n[1]  TRUE  TRUE  TRUE  TRUE FALSE\n\n# TRUE gets counted as 1, FALSE as 0:\nsum(x2)\n\n[1] 4\n\n# the proportion of TRUEs:\nsum(x2)/length(x2)\n\n[1] 0.8\n\n# or, alternatively:\nmean(x2)\n\n[1] 0.8\n\nmean(x1<5)\n\n[1] 0.8\n\n\n\n\n\nUsing mutate():\n\nrnorm(20, 178, 10) > 182.88\n\n [1]  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE\n\nmean(rnorm(20, 178, 10) > 182.88)\n\n[1] 0.25\n\n\nFor 1000 samples of size \\(n=20\\), calculate the proportion of the sample which is over 6 foot. Plot the distribution of the 1000 sample proportions.\nAt what value would you expect the distribution to be centred?\nWe would expect the distribution of sample proportions to be centered around the population proportion.\n\n#hist(replicate(1000, mean(sample(the_pop$over6foot, size = 20))))\n\n\nQuestion A8\n\n\nPlot the distribution of heights of you and your fellow students.\nIn the last couple of years during welcome week, we have asked students of the statistics courses in the Psychology department to fill out a little survey. Anonymised data are available at https://uoepsy.github.io/data/surveydata_allcourse.csv.\nCan you think of how you might make a separate histogram for the distributions of heights in different courses?\n\n\n\n\n Solution \n\n\n\nsurvey_data <- read_csv(\"https://uoepsy.github.io/data/surveydata_allcourse.csv\")\nggplot(survey_data, aes(x = height)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\nggplot(survey_data, aes(x = height)) +\n  geom_histogram() + \n  facet_wrap(~course)\n\n\n\n\n\n\n\n\n\n\n\n\nStroop Experiment Exercises\n\nThe data we are going to use for these exercises is from an experiment using one of the best known tasks in psychology, the “Stroop task”.\n 130 participants completed an online task in which they saw two sets of coloured words. Participants spoke out loud the colour of each word, and timed how long it took to complete each set. In the first set of words, the words matched the colours they were presented in (e.g., word “blue” was coloured blue). In the second set of words, the words mismatched the colours (e.g., the word “blue” was coloured red, see Figure @ref(fig:stroop)). Participants’ recorded their times for each set (matching and mismatching).\nParticipants were randomly assigned to either do the task once only, or to record their times after practicing the task twice.\n You can try out the experiment at https://faculty.washington.edu/chudler/java/ready.html.\n The data are available at https://uoepsy.github.io/data/strooptask.csv \n\n\n\n\n\nStroop Task - Color word interference. Images from https://faculty.washington.edu/chudler/java/ready.html\n\n\n\n\n\n\nQuestion B1\n\n\nCreate a new heading for these exercises and read in the data. Be sure to assign it a clear name.\n\n\n\n\n Solution \n\n\n\nstroopdata <- read_csv(\"https://uoepsy.github.io/data/strooptask.csv\")\n\n\n\n\n\nQuestion B2\n\n\nusing summarise(), show the minimum, maximum, mean and median of the times taken to read the matching word set, and then do the same for the mismatching word set.\n\n\n\n\n Solution \n\n\nMatching words\n\nstroopdata %>%\n  summarise(\n    min_time = min(matching),\n    max_time = max(matching),\n    mean_time = mean(matching),\n    median_time = median(matching)\n  )\n\n# A tibble: 1 × 4\n  min_time max_time mean_time median_time\n     <dbl>    <dbl>     <dbl>       <dbl>\n1     5.61     31.4      15.1        14.8\n\n\nMismatching words\n\nstroopdata %>%\n  summarise(\n    min_time = min(mismatching),\n    max_time = max(mismatching),\n    mean_time = mean(mismatching),\n    median_time = median(mismatching)\n  )\n\n# A tibble: 1 × 4\n  min_time max_time mean_time median_time\n     <dbl>    <dbl>     <dbl>       <dbl>\n1     4.29     29.7      17.5        17.0\n\n\n\n\n\n\nQuestion B3\n\n\nWhat we are interested in is the differences between these times. For someone who took 10 seconds for the matching set, and 30 seconds for the mismatching set, we want to record the difference of 20 seconds.\nCreate a new variable called stroop_effect which is the difference between the mismatching and matching variables.\nHint: Remember we can use the mutate() function to add a new variable. Recall also that we need to reassign this to the name of your dataframe, to make the changes appear in the environment (rather than just printing them out).\n\nstroopdata <- \n  stroopdata %>%\n  mutate(\n    ?? = ??\n  )\n\n\n\n\n\n Solution \n\n\n\nstroopdata <- \n  stroopdata %>%\n  mutate(\n    stroop_effect = mismatching - matching\n  )\n\n# and print it out:\nstroopdata\n\n# A tibble: 131 × 7\n      id   age practice matching mismatching height stroop_effect\n   <dbl> <dbl> <chr>       <dbl>       <dbl>  <dbl>         <dbl>\n 1     1    41 yes         22.3        16.9     162         -5.4 \n 2     2    24 yes         22.3        19.1     168         -3.2 \n 3     3    40 yes         15.4        13.6     166         -1.81\n 4     4    46 yes          9.9        15.0     165          5.14\n 5     5    36 yes         14.2        16.4     160          2.18\n 6     6    29 yes         19.9        18.0     154         -1.90\n 7     7    45 no          10.2        17.1     179          6.83\n 8     8    44 no          16.2        19.6     162          3.39\n 9     9    47 yes          9.73        6.14    148         -3.59\n10    10    59 no           7.68       11.6     153          3.88\n# … with 121 more rows\n\n\n\n\n\n\nQuestion B4\n\n\nFor the stroop_effect variable you just created, produce both a histogram and a density curve.\nWhat is the more appropriate guess for the mean of this variable?\n\n0\n2\n6\n8\n\n\n\n\n\n Solution \n\n\n\nggplot(data = stroopdata, aes(x = stroop_effect)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nThe default binwidth of the histogram here might lead you astray in guessing the mean value - the highest bar by some distance is at 0 seconds.\nTry changing the binwidth to get a different picture - for example:\n\nggplot(data = stroopdata, aes(x = stroop_effect)) +\n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n\nIn both histograms, you can see that there is quite a lot of data between the values of 0 and 5.\nAn advantage of the density curve is that they are better at displaying the distribution shape as they are not influenced by the number of bins. However, this comes at the expense of no longer having the easily interpreted count on the y-axis. A benefit of a histogram is that the viewer can also gain an idea of how much data there is, whereas a density curve of 10 datapoints could be hard to distinguish from one of 100.\n\nggplot(data = stroopdata, aes(x = stroop_effect)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion B5\n\n\nFilter the data to only participants who are at least 40 years old and did not have any practice, and calculate the mean stroop effect for these participants.\n\n\n\n\n Solution \n\n\n\nstroopdata %>% filter(age >= 40, practice == \"no\") %>%\n  summarise(\n    meanstroop = mean(stroop_effect)\n  )\n\n# A tibble: 1 × 1\n  meanstroop\n       <dbl>\n1       5.34\n\n\n\n\n\n\nQuestion B6\n\n\nCreate a density plot of the stroop effect for those who had no practice.\nIf the experimental manipulation had no effect, what would you expect the mean to be?\nTip: You can pass data to a ggplot using %>%. It means you can do sequences of data → manipulation → plot, without having to store the manipulated data as a named object in R’s memory. For instance:\n\ndata %>% \n  filter(condition) %>% \n  mutate(\n    new_variable = variable1 * variable2\n  )\n  ggplot(aes(x = variable1, y = new_variable)) +\n  geom....\n\n\n\n\n\n Solution \n\n\n\nstroopdata %>% \n  filter(practice == \"no\") %>%\n  ggplot(aes(x = stroop_effect)) + \n  geom_density()\n\n\n\n\n\n\n\n\nIf there wasn’t a difference between the conditions, then we would expect the mean of the variable we just created (the difference between conditions) to be 0.\n\n\n\n\n\nHow tall are you?\nprop of class of theoretical dist\n\n\nsimulate 2 groups"
  },
  {
    "objectID": "ex01.html",
    "href": "ex01.html",
    "title": "Week 1 exercises: Some Data, Some Simulation",
    "section": "",
    "text": "1. Pet Data\nTODO data dict\n\nWrite a line of code that reads in the data to your R session. Then examine the dimensions of the dataset, and take a look at the first few lines lines.\n\nHint: You’ll need the read.csv() function. Remember to assign it a name to store it in your environment.\n\nHint: See where we discuss reading in data from a URL in Chapter 2.\n\nHint: Try dim() and head()\n\nWhat are the names of the 47th and the 200th animals in the dataset?\n\nHint: You’ll probably want to make use of the square brackets data[rows, columns].\n\nSubset the data to only the data for the dogs, and store this object as another named object in your environment. Subset the data to only the data for the cats, and store this object as another named object in your environment.\n\nHint: You’ll want to think about how we access data via asking for those entries that meet a specific condition (see Chapter 2: Basic Data Wrangling)\n\nFind the name and weight of the heaviest cat, and of the lightest dog.\n\nHint: You could do this using the original data you read in from question 1., or you could use the subsets you created in question 3.\n\nHint: You’ll again probably want to supply a condition within some square brackets. You might consider that condition to have something to do with being equal to the min() or the max() of some variable.\n\nDoes the data contain only dogs and cats?\n\nHint: Given what you did in question 3, you might be able to answer this by just looking at your environment.\n\nExtract the entries of the dataset for which the species is neither “Dog” nor “Cat”? What are the names and species of these animals?\n\nHint: This is a slightly complex one. The section of Chapter 2 on more complex conditions might help you here.\n\nCreate a new variable in the data, which contains the weights of all the animals, but rounded to the nearest kg.\n\nHint: Try looking up the help documentation for the function round(). Try playing with it in the console, e.g. round(c(3.5, 4.257, 1.1111)).\n\nHint: You may find Chapter 2: Adding/Changing a variable helpful.\n\nTry giving the dataset to the function summary(). You’ll get out some information on each of the variables. It is likely that you’ll get more useful information for the variables containing information on the animal’s weights than for those containing their names, breeds etc because these variables are vectors of “characters”. We’ll start to look more about different types of data next week.\n\n\n\nSimulating Dice\n\nCopy the code from the lecture which creates a custom function called dice() (copied below). Be sure to run the code (highlight it all with your cursor, and hit “run” in the top right, or press Ctrl/Cmd+Enter).\n\n\ndice <- function(num = 1) {\n  sum(sample(1:6, num, replace=TRUE))\n}\n\n\nWhat did that code do?\nIn a sense, this code does nothing: It won’t give you any output when you run it. What it is actually doing, though, is defining a function called dice(). If you look at your environment panel (top right), you’ll see dice appear when you run the code.\nTo produce some output, we have to call the function dice() (by writing it into code: dice(4), for example). dice() wants to be supplied with some information (in the argument num). If no information is supplied, num will take a default value of 1. (So writing dice() is equivalent to writing dice(1)).\nWhat does dice() do with num? It calls another function, sample(), with 3 arguments. We didn’t write sample(): it’s a function that’s “supplied with” R. To find out more about what sample() does:\n\nclick inside the brackets just after sample() in your R script;\npress TAB (⇥), then F1\nyou should see some help appear in the bottom right-hand panel of RStudio.\n\nYou will find that “sample() takes a sample … from the elements of x …” If you compare the code in RStudio to the code under “Usage” you’ll see that where the help has x, we have 1:6. So what does 1:6 mean? One way to find out is to open the console in RStudio (bottom left) and just type stuff in. What happens when you type 1:6? What about 2:17? (What about 6:1?)\nThe console is the place to “try stuff out” (don’t worry, you can’t break it). Watch the video below and then try it out yourself:\nTODO redo with script not rmd\n\n\n\n\n\nWhat you will discover is that 1:6 creates a vector (list of similar things, in this case numbers) of the numbers 1-6. The next bit of the sample() function is size. In the dice() function, the num passes down to the size of the sample(): Looking through the help, size is the number of items to choose. So sample(1:6, 1) would choose one number from the numbers 1-6 at random; sample(1:6, 3) would choose 3, and so on. The last argument, replace=TRUE, tells sample() what to do with a number once it’s been picked: Does it go ‘back into the bag’ to be picked again (TRUE) or not? (FALSE)?\nAround the outside is sum() which simply sums the numbers on however many (num) dice you “rolled”.\nPutting it all together, our dice() function “throws a die num times” by sample()ing from the numbers 1-6 num times, replaceing each number when it’s been picked, and sums the numbers of all the dice.\n\n\nLook up the function replicate(). We can use it to do something in R lots of times! For instance, replicate(20, 1+1) will evaluate 1+1 twenty times. Use replicate() to simulate 100 rolls of a single dice, and store the results in an object in your environment. Give it an easily identifiable name.\n\nHint: A single dice means num = 1\n\nCreate a barplot showing the frequency with which each number was landed on in the 100 rolls.\n\nHint: the functions table() and barplot() were used to do this in the lecture.\n\n\n\n\n\n\nDo the same for 1,000 rolls, and then for 10,000. What do you notice?\n\n\n\n\n\nCopy the code below into your script and run it. It creates a new function called wdice() which simulates the rolling of num dice which are slightly weighted. Roll a single weighted die 100 times and plot the frequency distribution. Do the same for 1,000 and 10,000 rolls of a single die. Does a pattern emerge? At how many rolls?\n\n\nwdice <- function(num = 1){\n    sum(sample(1:6, num, replace=TRUE, prob = c(0.15,0.15,0.15,0.15,0.15,0.25)))\n}\n\n\n\n\n\nRemember, wdice() and dice() are really just relying on different functions, like sample(). Try playing around with sample() in the console again - what does the prob = c(....) bit do?\nLet’s try to modify the wdice() function. Edit the code for wdice() so that 50% of the time it lands on number 6.\n\nHint: To test out your modified function, you will need to re-run the code which defines the function. When we use wdice() we use the function which is in our environment. If we want to edit the function, we need to overwrite (or “replace”/“reassign”) the object in our environment.\nHint: We need to be careful to remember that the probability of different outcomes should sum to 1 (i.e., it’s not possible to “50% of the time land on 6” as well as “70% of the time land on 5”!).\n\n\n\n\n\n\nCan you observe the weighting in your new die (the one which 50% of the time lands on number 6) in only 100 rolls?\nConceptually, what can we learn from this toy example?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "01_R.html",
    "href": "01_R.html",
    "title": "A first look at R & RStudio",
    "section": "",
    "text": "The best way to learn R is to use it.\nTry following along with this Chapter by typing the code into your R script and running them. You will hopefully get the same output as is presented on this page below each bit of code.\nIf you get errors and warnings, don’t panic - read them!\n\n\nR is a calculator\nWhen we first open RStudio, we should see something which looks more or less like the image in Figure 1, where there are several little windows. We are going to explore what each of these little windows offer by just diving in and starting to do things.\n\n\n\n\n\nFigure 1: RStudio, freshly opened\n\n\n\n\nStarting in the left-hand window, you’ll notice the blue sign >.\nThis is where we R code gets executed.\nType 2+2, and hit Enter ↵.\nYou should discover that R is a calculator - R responds by telling us the answer (4).\nLet’s work through some basic operations (adding, subtracting, etc). For instance, can you work out what R will give you for each of these operations?\n\n\nArithmetic operations\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n2 + 5\n\n\n\n10 - 4\n\n\n\n2 * 5\n\n\n\n10 - (2 * 5)\n\n\n\n(10 - 2) * 5\n\n\n\n10 / 2\n\n\n\n3^2\n(the ^ symbol is “to the power of”)\n\n\n\n\n\nShow me the output\n\n\n\nCode\nOutput\n\n\n\n\n2 + 5\n7\n\n\n10 - 4\n6\n\n\n2 * 5\n10\n\n\n10 - (2 * 5)\n0\n\n\n(10 - 2) * 5\n40\n\n\n10 / 2\n5\n\n\n3^2\n9(the ^ symbol is “to the power of”)\n\n\n\n\n\n\nR can get stuck\nWhenever you see the blue sign >, it means R is ready and waiting for you to provide a command.\nIf you type 10 + and press Enter, you’ll see that instead of > you are left with +. This means that R is waiting for more.\nEither give it more (finish the command), or cancel the command by pressing the Escape key on your keyboard.\n\nAs well as performing arithmetic calculations, we can ask R things for which the answer is TRUE or FALSE, such as “Is 3 less than 5?”. If we type 3 < 5 and press Enter, then R should tell us that the statement we gave it is TRUE.\nThese computations don’t return numbers, but instead return logical values. There are few operators that we need to learn about here:\n\nEquality/Inequality: We use the symbols == to mean “is equal to”, and the symbols != for “is not equal to”.\n\nLess Than/Greater Than: To determine whether a value is less/greater than another value, we have our typical symbols < and >. We also have <= and >= when we want to include “less/greater than or equal to”.\n\nWe can combine these with & for “and”, | for “or”, and ! for “not”, to ask R all sorts of things.\nTry and work out what R should give you for each of these (or try it out yourself!):\n\n\nLogical operations\n\n\n\nCode\nOutput\n\n\n\n\n3 > 5\n\n\n\n3 <= 5\n\n\n\n3 >= 3\n\n\n\n3 == 5\n\n\n\n(2 * 5) == 10\n\n\n\n(2 * 5) != 11\n\n\n\n(2 == 2) & (3 == 4)\n\n\n\n(2 == 2) | (3 == 4)\n\n\n\n(2 == 2) & !(3 == 4)\nTRUE\n\n\n\n\n\nShow me the output\n\n\n\nCode\nOutput\n\n\n\n\n3 > 5\nFALSE\n\n\n3 <= 5\nTRUE\n\n\n3 >= 3\nTRUE\n\n\n3 == 5\nFALSE\n\n\n(2 * 5) == 10\nTRUE\n\n\n(2 * 5) != 11\nTRUE\n\n\n(2 == 2) & (3 == 4)\nFALSE\n\n\n(2 == 2) | (3 == 4)\nTRUE\n\n\n(2 == 2) & !(3 == 4)\nTRUE\n\n\n\n\n\n\nFALSE and TRUE as 0 and 1\nIt will become useful to think of these logical values (TRUE and FALSE) as also having intrinsic numeric values of 0 and 1.\nThis is how R will treat them if you ask it to do something that requires the values to be numeric. For example, the code TRUE + 3 will return 4, and FALSE + 3 will return 3.\n\n\n\n\n\n\nR has a memory\nWe can also store things in R’s memory, and to do that we just need to give them a name. Type x <- 5 and press Enter.\nWhat has happened? We don’t get any answer like we did with calculations such as 2 + 4. What we’ve done is stored in R’s memory something named x which has the value 5. We can now refer to the name and it will give us the value!\n\nAssigning names to things in R\nThe <- symbol, pronounced arrow, is what we use to assign a value to a named object:\n\nname <- value\n\n\nIf we now type x and press Enter, it gives us whatever we assigned to the name “x”. So it gives us the number 5.\nWhat is going to happen when we type x * 3? It will give us 15!\nIf you are working along with us, you might have also noticed that something else happened when we executed the code x <- 5. The thing we named x with a value of 5 suddenly appeared in the top-right window. This is known as the environment (Figure 2), and it shows everything that we store in R.\n\n\n\n\n\nFigure 2: Assigning names to objects stores them in R’s environment.\n\n\n\n\nNote, there are a few rules about names in R:\n\nNo spaces - spaces inside a name are not allowed (the spaces around the <- don’t matter):\nlucky_number <- 5 ✔ lucky number <- 5 ❌\nNames must start with a letter:\nlucky_number <- 5 ✔ 1lucky_number <- 5 ❌\nCase sensitive:\nlucky_number is different from Lucky_Number\nhere is a set of words you can’t use as names, including: if, else, for, in, TRUE, FALSE, NULL, NA, NaN, function (Don’t worry about remembering these, R will tell you if you make the mistake of trying to name a variable after one of these).\n\n\n\n\n\n\nThe Console and The Environment\nWhat we’ve done so far has made use of a couple of the different panes that we see in RStudio. When we’ve been executing R code (e.g. typing 2+5 or x<-5 and pressing Enter), we’ve been doing it in the console. The console is where all R code gets executed. However, as we’ll see below, it isn’t where all R code gets written.\nWe’ve also been learning about how we can store things in R’s memory (the environment) by assigning a name to them using the <- operator. The top-right pane of RStudio shows us the environment, where we can see everything that we have stored in R. Note that this also means we can keep track of what objects we have saved that are available for our use. If we never stored an object named “peppapig”, then R will give us an error when we do something like:\n\n2*peppapig\n\nError in eval(expr, envir, enclos): object 'peppapig' not found\n\n\nNow we have an idea of what the console and the environment are for. If you want a silly analogy, the console is like R’s mouth, where we feed it things, and the environment is just its memory, where it remembers what things are what. We can see these in Figure 3. Note however, that the console has been moved down to the bottom-left, as we are introducing a new pane above it. This is where we move to next.\n\n\n\n\n\nFigure 3: RStudio panes: Code is executed in the console, and objects are stored in the environment.\n\n\n\n\n\n\n\n\n\nR Scripts and the Editor\nWhat if we want to edit our code? Whatever we write in the console just disappears upwards. What if we want to change things we did earlier on?\nWhile the console is where code gets executed, it doesn’t have to be where code gets written.. We can write and edit our code in a separate place before we then send it to the console to be executed!!\nThe standard place to write and edit things is in an R scipt. We can open one by doing File > New File > R script, and a new file will open in the top-left pane of RStudio. The console will be shoved down to the bottom-left.\nIn the R script, we can write code. For instance, we might write:\n\nx <- 210\ny <- 15\nx / y\n\nNotice that nothing happens when we write each line. It’s not like writing in the console where R tells us the answers. This is because this code is not yet being executed. We haven’t actually fed it to R.\nThere are a couple of useful ways we can send the code to R.\n\nPosition your text-cursor (blinking vertical line) on the line of code we wish to run and press Ctrl+Enter (Windows) or Cmd+Enter (MacOS)\n\nPosition your text-cursor (blinking vertical line) on the line of code we wish to run and press the “Run” button in the top right of the script.\n\nWhen we do this, the line of code will be sent down to the console, where it will be executed, and R will do it’s thing.\nFor example, if we had sent the line x <- 210 down to the console, R would then store the number 210 with the name x in our environment (as in Figure 4). Additionally, it will move the text-cursor to the next line, so we can just press Ctrl+Enter again to run the next line (and so on.).\n\n\n\n\n\nFigure 4: Code written in the script can be sent down to the console, where it is executed. In this example, the execution of the code stores an object in the environment.\n\n\n\n\nBy writing our code in a file such as an R script before sending it to the console we can edit, save, and share our code. This makes it so much more useful than just using the console (which is more like writing on scratch paper, where we can’t keep anything).\nFor instance, let’s say we made a mistake earlier, and instead of “x” being 210, it should have been 211. Well, we can just edit the script, and re-run it.\n\nRegularly save your scripts.\nTo save an R script that is open, we just\n\nFile > Save (or Ctrl+S)\nLocate to the folder where we want to save the file.\n\ngive it an appropriate name, and click save.\n\nNOTE: When you save R script files, they terminate with a .R extension.\n\n\nLooking ahead to Rmarkdown\n\nIn addition to R scripts, there is another type of document we can create, known as “Rmarkdown”.\nRmarkdown documents combine the analytical power of R and the utility of a text-processor. We can have one document which contains all of our analysis as well as our written text, and can be compiled into a nicely formatted report. This saves us doing analysis in R and copying results across to Microsoft Word. It ensures our report accurately reflects our analysis. Everything that you’re reading now has all been written in Rmarkdown!\n\n\n\nFigure 5: An example RMarkdown document\n\n\nWe’re going to learn more about Rmarkdown documents and how to write them later on, but the broad idea is that we can writing normal text interspersed with “code-chunks” (i.e., chunks of code!). RMarkdown documents looks much like an R script, only the code is contained within the grey-boxes, and text is written in between (see Figure 5). RMarkdown documents can then be compiled to create a lovely .pdf, .html, or .docx file.\n\n\n\n\n\nFigure 6: RMarkdown Workflow\n\n\n\n\n\n\n\n\n\n\nThe Four RStudio Panes\nWe’ve now seen almost all the different panes in RStudio:\n\n\nThe console is where R code gets executed\nThe environment is R’s memory, you can assign something a name and store it here, and then refer to it by name in your code.\nThe editor is where you can write and edit R code in R scripts and Rmarkdown documents. You can then send this to the console for it to be executed.\n\n\n\n\n\n\n\n\nFigure 7: The Four Panes of RStudio\n\n\n\n\n\nWe are yet to use the bottom-right window, but this is an easy one to explain. It is where we can see any plots that we create, where we can browse our files, and where we can ask R for some help documentation. We’ll make more use of this later on, but for now try typing plot(x = 4, y = 2) into the console and seeing what happens.\n\n\nProjects and file organisation\nWe’re not going to speak too much about this here but one key thing to remember is that R is working from a specific place in your computer. You can find out where by typing getwd() into the console.\nAn easy way to keep things organised is to set up an “R project”. This basically associates a specific folder on your computer with your working in R, and it means it will automatically look for things in that folder.\nFor courses like this one, we recommend starting a project for the entire course, and then for each week writing (and saving!) an R script.\nIf you haven’t already, we suggest you start an R project by using (in the top menu of RStudio), File > New Project and following the instructions.\nYou will now notice that if you click in the “Files” tab in the bottom right pane of RStudio, you can see the project folder!\n\n\n\n\n\n\nGood Habits\nAlong with regular saving of work and organising your files, it will be very useful in the long-run if we get used to always “starting fresh” when we open R.\nWe need to start thinking of the code that we write in an R script as a set of consecutive instructions that we can give to R in order to achieve our goal. It’s just a blank slate on which we write (in language R understands) “do this. now do this. now do this..” and so on.\nThis means that the script contains all the information needed.\nSo we can now:\n\nEmpty our environment\nRestart R\nRun all the code in our script (highlight multiple lines of code to run them all at once)\n\nand we’re back to where we are! This is great for when we make mistakes (we’re going to make many many mistakes!), because we can just clear everything, start at the top of our script, and work downwards to figure out what has gone wrong.\n\nTidying up\n\nTo empty our environment, we can click on the little broomstick icon .\nTo restart the R Session (not always necessary, but good practice) in the top menu, we choose Session > Restart R (or press Ctrl+Shift+F10).\n\n\nThe other very useful thing that we can do in a script is to write comments for ourselves or for others. By starting a line with a #, R will know that that entire line is not code, and so it won’t try to do anything with it. For instance, if we write these lines in our script, and send them both down to the console, nothing happens for the first line:\n\n\nComments\n\n# The line below will add 5 to 2. \n2+5\n\n[1] 7\n\n\n\n\nIf we forget the #\n\nThe line below will add 5 to 2. \n2+5\n\n\nError: unexpected symbol in “The line”\n\n\n\n\n\n\n\n\nUseful Settings\nBelow are a couple of our recommended settings for you to change as you begin your journey in R. After you’ve changed them, take a 5 minute break before moving on to the next chapter.\n\n1. Clean environments\nAs you use R more, you will store lots of things with different names. Throughout this course alone, you’ll probably name hundreds of different things. This could quickly get messy within our project.\nWe can make it so that we have a clean environment each time you open RStudio. This will be really handy.\n\nIn the top menu, click Tools > Global Options…\nThen, untick the box for “Restore .RData into workspace at startup”, and change “Save workspace to .RData on exit” to Never:\n\n\n\n\n2. Wrapping code\nIn the editor, you might end up with a line of code which is really long, but you can make RStudio ‘wrap’ the line, so that you can see it all, without having to scroll:\n\nx <- 1+2+3+6+3+45+8467+356+8565+34+34+657+6756+456+456+54+3+78+3+3476+8+4+67+456+567+3+34575+45+2+6+9+5+6\n\n\nIn the top menu, click Tools > Global Options…\nIn the left menu of the box, click “Code”\nTick the box for “Soft-wrap R source files”"
  },
  {
    "objectID": "02_data.html",
    "href": "02_data.html",
    "title": "More R",
    "section": "",
    "text": "Reading time: 25 minutes"
  },
  {
    "objectID": "02_data.html#accessing-subsets-of-data",
    "href": "02_data.html#accessing-subsets-of-data",
    "title": "More R",
    "section": "Accessing subsets of data",
    "text": "Accessing subsets of data\nWhat if we want to extract certain subsections of our dataset, such as specific observational units or variables? This is where we learn about two important bits of R code used to access parts of data - the dollar sign $, and the square brackets [].\n\nThe dollar sign $\nThe dollar sign allows us to extract a specific variable from a dataframe. For instance, we can pull out the variable named “eye_color” in the data, by using $eye_color after the name that we gave our dataframe.\nRemember that each variable in a dataframe is a vector (a set of values). Once extracted, we will have a vector and not a dataframe.\n\nstarwars2$eye_color\n\n [1] \"blue\"          \"yellow\"        \"red\"           \"yellow\"       \n [5] \"brown\"         \"blue\"          \"blue\"          \"red\"          \n [9] \"brown\"         \"blue-gray\"     \"blue\"          \"blue\"         \n[13] \"blue\"          \"brown\"         \"black\"         \"orange\"       \n[17] \"hazel\"         \"blue\"          \"yellow\"        \"brown\"        \n[21] \"red\"           \"brown\"         \"blue\"          \"orange\"       \n[25] \"blue\"          \"brown\"         \"black\"         \"red\"          \n[29] \"blue\"          \"orange\"        \"orange\"        \"orange\"       \n[33] \"yellow\"        \"orange\"        NA              \"brown\"        \n[37] \"yellow\"        \"pink\"          \"hazel\"         \"yellow\"       \n[41] \"black\"         \"orange\"        \"brown\"         \"yellow\"       \n[45] \"black\"         \"brown\"         \"blue\"          \"orange\"       \n[49] \"yellow\"        \"black\"         \"blue\"          \"brown\"        \n[53] \"brown\"         \"blue\"          \"yellow\"        \"blue\"         \n[57] \"blue\"          \"brown\"         \"brown\"         \"brown\"        \n[61] \"brown\"         \"yellow\"        \"yellow\"        \"black\"        \n[65] \"black\"         \"blue\"          \"unknown\"       \"unknown\"      \n[69] \"gold\"          \"black\"         \"green, yellow\" \"blue\"         \n[73] \"brown\"         \"black\"         NA             \n\n\n\n\nThe square brackets []\nSquare brackets are used to do what is known as indexing (finding specific entries in your data).\nWe can retrieve bits of data by identifying the \\(i^{th}\\) entry(s) inside the square brackets, for instance:\n\n# assign the numbers 10, 20 ... 100 to the name \"somevalues\"\nsomevalues <- c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n\n# pull out the 3rd entry\nsomevalues[3]\n\n[1] 30\n\n\nIn the above example, we have a vector (a single sequence of values), and so we can retrieve entries with the syntax:\n\nvector[entry]\n\n In a dataframe we have an extra dimension - we have rows and columns. Using square brackets with a dataframe needs us to specify both:\n\n\ndataframe[rows, columns]\n\n\nLet’s look at some examples:\n\n\nExamples of Indexing\n\nSpecifying row number and column number:\n\n\n# first row, fourth column\nstarwars2[1, 4]\n# tenth row, first column\nstarwars2[10, 1]\n\n\nIf we leave either rows or columns blank, then we will get out all of them:\n\n\n# tenth row, all columns\nstarwars2[10, ]\n# all rows, 2nd column\nstarwars2[ , 2]\n\n\nThere are is another way to identify column - we can use the name in quotation marks:\n\n\n# first row, \"species\" column\nstarwars2[1, \"species\"]\n\n\nWe can also ask for multiple rows, or multiple columns, or both! To do that, we use c():\n\n\n# the 1st AND the 6th rows, and the 1st AND 3rd columns\nstarwars2[c(1,6), c(1,3)] \n\n\nAnd we can specify a sequence using the colon, from:to:\n\n\n# FROM the 1st TO the 6th row, all columns\nstarwars2[1:6, ] \n\nWhy? Because the colon operator, `from:to`, creates a vector from the value     `from` to the value `to` in steps of 1.\n\n1:6\n\n[1] 1 2 3 4 5 6\n\n\n\nWe can even use the two accessors in combination:\n\n\n# extract the variable called \"name\" and show the 20th entry\nstarwars2$name[20]  \n\nThis represents the 20th name in the data.  \nNote: When we do this, we don't have the comma inside the square brackets. When we use the `$` to pull out a variable, such as `starwars2$name`, we no longer have a dataframe - `starwars2$name` doesn't have rows and columns, it just has a series of values - _it's a vector!_. So when you are using `[]` with a __vector__ (1 dimension) rather than a __dataframe__ (2 dimensions), you don't specify `[rows, columns]`, but simply `[entry]`. \n\n\nShow me the output\n\nSpecifying row number and column number:\n\n\n# first row, fourth column\nstarwars2[1, 4]\n\n[1] \"blue\"\n\n# tenth row, first column\nstarwars2[10, 1]\n\n[1] \"Obi-Wan Kenobi\"\n\n\n\nIf we leave either rows or columns blank, then we will get out all of them:\n\n\n# tenth row, all columns\nstarwars2[10, ]\n\n             name height    hair_color eye_color homeworld species\n10 Obi-Wan Kenobi    182 auburn, white blue-gray   Stewjon   Human\n\n# all rows, 2nd column\nstarwars2[ , 2]\n\n [1] 172 167  96 202 150 178 165  97 183 182 188 180 228 180 173 175 170 180 170\n[20] 183 190 177 175 180 150  88 160 191 170 196 224 206 137 112 170 163 175 180\n[39] 178  94 122 163 188 198 196 171 184 188 264 188 196 185 157 183 183 170 166\n[58] 165 193 191 183 168 198 229 213 167  79 193 191 178 216 234 188 206 180\n\n\n\nThere are is another way to identify column - we can use the name in quotation marks:\n\n\n# first row, \"species\" column\nstarwars2[1, \"species\"]\n\n[1] \"Human\"\n\n\n\nWe can also ask for multiple rows, or multiple columns, or both! To do that, we use c():\n\n\n# the 1st AND the 6th rows, and the 1st AND 3rd columns\nstarwars2[c(1,6), c(1,3)] \n\n            name  hair_color\n1 Luke Skywalker       blond\n6      Owen Lars brown, grey\n\n\n\nAnd we can specify a sequence using the colon, from:to:\n\n\n# FROM the 1st TO the 6th row, all columns\nstarwars2[1:6, ] \n\n            name height  hair_color eye_color homeworld species\n1 Luke Skywalker    172       blond      blue  Tatooine   Human\n2          C-3PO    167        <NA>    yellow  Tatooine   Human\n3          R2-D2     96        <NA>       red     Naboo   Droid\n4    Darth Vader    202        none    yellow  Tatooine   Human\n5    Leia Organa    150       brown     brown  Alderaan   Human\n6      Owen Lars    178 brown, grey      blue  Tatooine   Human\n\n\n\nWe can even use the two accessors in combination:\n\n\n# extract the variable called \"name\" and show the 20th entry\nstarwars2$name[20]  \n\n[1] \"Boba Fett\"\n\n\n\n\n\nThe dollar sign $\nUsed to extract a variable from a dataframe:\n\ndataframe$variable\n\nThe square brackets []\nUsed to extract parts of an R object by identifying rows and/or columns, or more generally, “entries”. Left blank will return all.\n\nvector[entries]\ndataframe[rows, columns]"
  },
  {
    "objectID": "02_data.html#accessing-by-a-condition",
    "href": "02_data.html#accessing-by-a-condition",
    "title": "More R",
    "section": "Accessing by a condition",
    "text": "Accessing by a condition\nWe can also do something really useful, which is to access all the entries in the data for which a specific condition is true.\nLet’s take a simple example to start:\n\nsomevalues <- c(10, 10, 0, 20, 15, 40, 10, 40, 50, 35)\n\nTo only select values which are greater than 20, we can use:\n\nsomevalues[somevalues > 20]\n\n[1] 40 40 50 35\n\n\n\nUnpacking: somevalues[somevalues > 20]\n First, let’s look at what somevalues > 20 does. It returns TRUE for the entries of somevalues which are greater than 20, and FALSE for the entries of somevalues that are not (that is, which are less than, or equal to, 20.\nThis statement somevalues > 20 is called the condition.\n\nsomevalues > 20\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE\n\n\nWe can give a name to this sequence of TRUEs and FALSEs\n\ncondition <- somevalues > 20\ncondition\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE\n\n\nNow consider putting the sequence of TRUEs and FALSEs inside the square brackets in somevalues[]. This returns only the entries of somevalues for which the condition is TRUE.\n\nsomevalues[condition]\n\n[1] 40 40 50 35\n\n\nSo what we can do is use a condition inside the square brackets to return all the values for which that condition is TRUE.\nNote that you don’t have to always give a name to the condition. This works too:\n\nsomevalues[somevalues > 20]\n\n[1] 40 40 50 35\n\n\n\n We can extend this same logic to a dataframe. Let’s suppose we want to access all the entries in our Star Wars data who have the value “Droid” in the species variable. To work out how to do this, we first need a line of code which defines our condition - one which returns TRUE for each entry of the species variable which is “Droid”, and FALSE for those that are not “Droid”.\nWe can use the dollar sign to pull out the species variable:\n\nstarwars2$species\n\n [1] \"Human\"        \"Human\"        \"Droid\"        \"Human\"        \"Human\"       \n [6] \"Human\"        \"Human\"        \"Droid\"        \"Human\"        \"Human\"       \n[11] \"Human\"        \"Human\"        \"Wookiee\"      \"Human\"        \"Rodian\"      \n[16] \"Hutt\"         \"Human\"        \"Human\"        \"Human\"        \"Human\"       \n[21] \"Trandoshan\"   \"Human\"        \"Human\"        \"Mon Calamari\" \"Human\"       \n[26] \"Ewok\"         \"Sullustan\"    \"Neimodian\"    \"Human\"        \"Gungan\"      \n[31] \"Gungan\"       \"Gungan\"       \"Toydarian\"    \"Dug\"          \"unknown\"     \n[36] \"Human\"        \"Zabrak\"       \"Twi'lek\"      \"Twi'lek\"      \"Vulptereen\"  \n[41] \"Xexto\"        \"Toong\"        \"Human\"        \"Cerean\"       \"Nautolan\"    \n[46] \"Zabrak\"       \"Tholothian\"   \"Iktotchi\"     \"Quermian\"     \"Kel Dor\"     \n[51] \"Chagrian\"     \"Human\"        \"Human\"        \"Human\"        \"Geonosian\"   \n[56] \"Mirialan\"     \"Mirialan\"     \"Human\"        \"Human\"        \"Human\"       \n[61] \"Human\"        \"Clawdite\"     \"Besalisk\"     \"Kaminoan\"     \"Kaminoan\"    \n[66] \"Human\"        \"Aleena\"       \"Skakoan\"      \"Muun\"         \"Togruta\"     \n[71] \"Kaleesh\"      \"Wookiee\"      \"Human\"        \"Pau'an\"       \"unknown\"     \n\n\nAnd we can ask R whether each value is equal to “Droid” (Remember: in R, we ask whether something is equal to something else by using a double-equals, ==). A single equal sign would be wrong, as it denotes assignment.\n\nstarwars2$species == \"Droid\"\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[73] FALSE FALSE FALSE\n\n\nFinally, we can use this condition inside our square brackets to access the entries of the data for which this condition is TRUE:\n\n# I would read the code below as: \n\n# \"In the starwars2 dataframe, give me all the rows for which the\n# condition starwars2$species==\"Droid\" is TRUE, and give me all the columns.\"\n\nstarwars2[starwars2$species == \"Droid\", ]\n\n   name height hair_color eye_color homeworld species\n3 R2-D2     96       <NA>       red     Naboo   Droid\n8 R5-D4     97       <NA>       red  Tatooine   Droid"
  },
  {
    "objectID": "02_data.html#more-complex-conditions",
    "href": "02_data.html#more-complex-conditions",
    "title": "More R",
    "section": "More complex conditions",
    "text": "More complex conditions\nThinking back to the previous chapter when we first introduced R, we talked briefly about “logical operators”. Specifically, the operators &, |, and ! (for “and”, “or”,” and “not”), will come in handy now.\nFor instance, we can now extract all those in the dataset which are humans and taller than 190cm:\n\n# \"In the starwars2 dataframe, give me all the rows for which the\n# condition starwars2$species==\"Human\" AND starwars2$height > 190 are TRUE, \n# and give me all the columns.\"\nstarwars2[starwars2$species == \"Human\" & starwars2$height > 190, ]\n\n                  name height hair_color eye_color homeworld species\n4          Darth Vader    202       none    yellow  Tatooine   Human\n59               Dooku    193      white     brown   Serenno   Human\n60 Bail Prestor Organa    191      black     brown  Alderaan   Human\n\n\nOr we can extract all those in the dataset which are either droids or ewoks:\n\n# \"In the starwars2 dataframe, give me all the rows for which the\n# condition starwars2$species==\"Droid\" OR starwars2$species==\"Ewok\" is TRUE, \n# and give me all the columns.\"\nstarwars2[starwars2$species == \"Droid\" | starwars2$species == \"Ewok\", ]\n\n                    name height hair_color eye_color homeworld species\n3                  R2-D2     96       <NA>       red     Naboo   Droid\n8                  R5-D4     97       <NA>       red  Tatooine   Droid\n26 Wicket Systri Warrick     88      brown     brown     Endor    Ewok"
  },
  {
    "objectID": "02_data.html#editing-specific-entries",
    "href": "02_data.html#editing-specific-entries",
    "title": "More R",
    "section": "Editing specific entries",
    "text": "Editing specific entries\nNow that we’ve seen a few ways of accessing sections of data, we can learn how to edit them! One of the most common reasons you will need to modify entries in your data is in data cleaning. This is the process of identifying incorrect/incomplete/irrelevant data, and replacing/modifying/deleting them.\nAbove, we looked at the subsection of the data where the species variable had the entry “Droid”. Some of you may have noticed earlier that we had some data on C3PO. Is he not also a droid?\n\n\n\n(Looks pretty Droid-y to me! disclaimer: I know nothing about Star Wars 🙂 )\nJust as we saw above how to access specific entries, e.g.:\n\n# 2nd row, all columns\nstarwars2[2, ]\n\n   name height hair_color eye_color homeworld species\n2 C-3PO    167       <NA>    yellow  Tatooine   Human\n\n# 2nd row, 6th column (the \"species\" column)\nstarwars2[2,6]\n\n[1] \"Human\"\n\n\nWe can change these by assigning them a new value (remember the <- symbol). In doing so, we replace / overwrite / reassign the entry in the 2nd row and 6th column of the data (starwars2[2,6]) with the value “Droid”.\n\n# C3PO is a droid, not a human\nstarwars2[2,6] <- \"Droid\"\n# Look at the 2nd row now -\n# the entry in the \"species\" column has changed:\nstarwars2[2, ]\n\n   name height hair_color eye_color homeworld species\n2 C-3PO    167       <NA>    yellow  Tatooine   Droid"
  },
  {
    "objectID": "02_data.html#editing-entries-via-a-condition",
    "href": "02_data.html#editing-entries-via-a-condition",
    "title": "More R",
    "section": "Editing entries via a condition",
    "text": "Editing entries via a condition\nWe saw above how to access parts of data by means of a condition, with code such as:\n\n# \"In the starwars2 dataframe, give me all the rows for which the\n# condition starwars2$homeworld==\"Naboo\" is TRUE, and give me all the columns.\"\nstarwars2[starwars2$homeworld==\"Naboo\", ]\n\n            name height hair_color eye_color homeworld species\n3          R2-D2     96       <NA>       red     Naboo   Droid\n19     Palpatine    170       grey    yellow     Naboo   Human\n30 Jar Jar Binks    196       none    orange     Naboo  Gungan\n31  Roos Tarpals    224       none    orange     Naboo  Gungan\n32    Rugor Nass    206       none    orange     Naboo  Gungan\n52  Gregar Typho    185      black     brown     Naboo   Human\n53         Cordé    157      brown     brown     Naboo   Human\n58         Dormé    165      brown     brown     Naboo   Human\n\n\nWhat if we wanted to modify it so that every character from “Naboo” was actually of species “Nabooian”?\nWe can do that in a number of ways, all of which do the same thing - namely, they access parts of the data and assign them the new value “Nabooian”.\nStudy the lines of code below and their interpretations:\n\n# In the starwars2 data, give the rows for which condition \n# starwars2$homeworld==\"Naboo\" is TRUE, and select only the \"species\" column. \n# Assign to these selected entries the value \"Nabooian\".\nstarwars2[starwars2$homeworld==\"Naboo\", \"species\"] <- \"Nabooian\"\n\n# In the starwars2 data, give the rows for which condition \n# starwars2$homeworld==\"Naboo\" is TRUE, and select only the 6th column. \n# Assign to these selected entries the value \"Nabooian\".\nstarwars2[starwars2$homeworld==\"Naboo\", 6] <- \"Nabooian\"\n\n# Extract the species variable from the starwars2 data (it's a vector).\n# Pick the entries for which the condition starwars2$homeworld==\"Naboo\" is TRUE.\n# Assign to these selected entries the value \"Nabooian\".\nstarwars2$species[starwars2$homeworld==\"Naboo\"] <- \"Nabooian\""
  },
  {
    "objectID": "02_data.html#addingchanging-a-variable",
    "href": "02_data.html#addingchanging-a-variable",
    "title": "More R",
    "section": "Adding/Changing a variable",
    "text": "Adding/Changing a variable\nAnother thing we might want to do is change a whole variable (a whole column) in some way.\nThe logic is exactly the same, for instance, we can take the variable “height” from the dataframe “starwars2”, dividing it by 100 via starwars2$height / 100, and then assign the result to the same variable name in the data, i.e. we overwrite the column:\n\nstarwars2$height <- starwars2$height / 100\n\nWe could instead have added a new column named “height_m” with those values if we did not want to overwrite “height”:\n\nstarwars2$height_m <- starwars2$height / 100\n\nThis would have left the “height” variable as-is, and created a new one called “height2” which was the values in “height” divided by 100."
  },
  {
    "objectID": "02_data.html#removing-rows-or-columns",
    "href": "02_data.html#removing-rows-or-columns",
    "title": "More R",
    "section": "Removing rows or columns",
    "text": "Removing rows or columns\nLastly, we might want to change the data by removing a row or a column. Again, the logic remains the same, in that we use <- to assign the edited data to a name (either a new name, thus creating a new object, or an existing name, thereby overwriting that object).\nFor instance, notice that the 35th and 75th rows of our data probably aren’t a valid observation - I’m reasonably sure that Marge and Homer Simpson never appeared in Star Wars:\n\nstarwars2[c(35,75), ]\n\n            name height hair_color eye_color   homeworld species\n35 Marge Simpson    1.7       Blue      <NA> Springfield unknown\n75 Homer Simpson    1.8       <NA>      <NA> Springfield unknown\n\n\nWe can remove a certain row(s) by using a minus sign - inside the square brackets\n\n# everything minus the 75th row\nstarwars2[-75, ]\n# everything minus the (35th and 75th rows)\nstarwars2[-c(35, 75), ]\n\nAnd we can simply re-use the name “starwars2” to overwrite the data and make this change take effect (rather than just print out the result, which the code above did):\n\nstarwars2 <- starwars2[-c(35, 75), ]\n\n(now, in the environment pane of Rstudio, the object named “starwars2” will say 73 observations, rather than 75, which it had before - we’ve removed the 2 rows)\n The same logic applies for columns:\n\n# Create a new object called \"anonymous_starwars2\" and assign it \n# to the values which are the \"starwars2\" dataframe minus the \n# 1st column (the \"name\" column):\nanonymous_starwars2 <- starwars2[, -1]\n# dimensions of our initial data\ndim(starwars2)\n\n[1] 73  6\n\n# the data we just assigned has one fewer columns\ndim(anonymous_starwars2)\n\n[1] 73  5"
  }
]