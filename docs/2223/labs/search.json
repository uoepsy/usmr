[
  {
    "objectID": "01_ex.html",
    "href": "01_ex.html",
    "title": "Week 1 Exercises: Intro R",
    "section": "",
    "text": "Pet Data\n\nWe’re going to play with some data on a sample of licensed pets from the city of Seattle, USA. It can be downloaded (or read directly into R) from https://uoepsy.github.io/data/pets_seattle.csv. It contains information on the license ID, year of issue, as well as the species, breeds and weights of each pet. You can find a data dictionary in @tab-petdict\n\n\n\nSeattle Pets: Data dictionary \n\n\nVariable\nDescription\n\n\n\n\nlicense_year\nYear in which license was issued\n\n\nlicense_number\nUnique license ID number\n\n\nanimals_name\nFull name of pet\n\n\nspecies\nSpecies of pet\n\n\nprimary_breed\nPrimary breed of pet\n\n\nsecondary_breed\nSecondary breed of pet\n\n\nweight_kg\nWeight in kilograms\n\n\n\n\n\n\n\nQuestion 1\n\n\nWrite a line of code that reads in the data to your R session. Then examine the dimensions of the dataset, and take a look at the first few lines lines.\n\nHints: You’ll need the read.csv() function. Remember to assign it a name to store it in your environment. 1B #basic-data-wrangling contains an example of reading in data from a URL. You’ll then want to play with functions like dim() and head().\n\n\n\n\n\n\npetdata<-read.csv(\"https://uoepsy.github.io/data/pets_seattle.csv\")\ndim(petdata)\n\n[1] 1956    7\n\nhead(petdata)\n\n  license_year license_number  animals_name species         primary_breed\n1         2018      LNS150171        Norman     Dog                 Boxer\n2         2017        LN20666         Henry     Dog          Bichon Frise\n3         2018      LN8000658 Vega Williams     Dog                   Mix\n4         2018       LN730940         Molly     Dog   Australian Shepherd\n5         2016       LN964607         Gremy     Dog Chihuahua, Short Coat\n6         2018      LNS117115        Shadow     Dog   Retriever, Labrador\n  secondary_breed weight_kg\n1             Mix     29.15\n2        Havanese     23.70\n3         Unknown     21.13\n4             Mix     18.70\n5         Terrier     20.36\n6         Unknown     11.51\n\n\n\n\n\n\nQuestion 2\n\n\nWhat are the names of the 47th and the 200th animals in the dataset?\n\nHints: You’ll probably want to make use of the square brackets data[rows, columns].\n\n\n\n\n\nLots of different ways. We can get out the entire rows:\n\npetdata[47,]\n\n   license_year license_number animals_name species       primary_breed\n47         2018      LNS140233     Hooligan     Dog Retriever, Labrador\n   secondary_breed weight_kg\n47         Unknown     12.27\n\npetdata[200,]\n\n    license_year license_number animals_name species      primary_breed\n200         2017       LN584186  Maple Syrup     Cat Domestic Shorthair\n    secondary_breed weight_kg\n200         Unknown      4.66\n\n\nOr we can extract the names only:\n\n# These all do the same\npetdata[c(47,200),\"name\"]\npetdata[c(47,200),3]\npetdata$animals_name[c(47,200)]\n\n\n\n[1] \"Hooligan\"    \"Maple Syrup\"\n\n\n\n\n\n\nQuestion 3\n\n\nSubset the data to only the data for the dogs, and store this object as another named object in your environment. Subset the data to only the data for the cats, and store this object as another named object in your environment.\n\nHints: You’ll want to think about how we access data via asking for those entries that meet a specific condition (see 1B #accessing-by-a-condition)\n\n\n\n\n\n\ndogdata <- petdata[petdata$species==\"Dog\", ]\ncatdata <- petdata[petdata$species==\"Cat\", ]\n\n\n\n\n\nQuestion 4\n\n\nFind the name and weight of the heaviest cat, and of the lightest dog.\n\nHints: You could do this using the original data you read in from question 1, or use the subsets you created in question 3. You’ll again want to supply a condition within square brackets. That condition may well have something to do with being equal to the min() or the max() of some variable.\n\n\n\n\n\nWith our new objects:\n\ndogdata[dogdata$weight_kg == min(dogdata$weight_kg), ]\n\n     license_year license_number animals_name species  primary_breed\n1126         2017      LNS139134       Claire     Dog Great Pyrenees\n     secondary_breed weight_kg\n1126         Unknown      0.39\n\ncatdata[catdata$weight_kg == max(catdata$weight_kg), ]\n\n    license_year license_number animals_name species      primary_breed\n414         2018      LNS101014       Smokey     Cat Domestic Shorthair\n    secondary_breed weight_kg\n414             Mix      5.48\n\n\n\n\n\n\nQuestion 5\n\n\nDoes the data contain only dogs and cats?\n\nHints: Given what you did in question 3, you might be able to answer this by just looking at your environment.\n\n\n\n\n\nIn the environment, we can see that the entire dataset has 1956 observations, the Dog’s data frame has 1322, and the Cat’s has 632.\nSo there are 2 missing!\n\n\n\n\nQuestion 6\n\n\nExtract the entries of the dataset for which the species is neither “Dog” nor “Cat”? What are the names and species of these animals?\n\nHints: This is a slightly complex one. 1B #more-complex-conditions might help you here.\n\n\n\n\n\n\npetdata[petdata$species != \"Cat\" & petdata$species != \"Dog\", ]\n\n     license_year license_number     animals_name species primary_breed\n1505         2018      LNS147013    Billy the Kid    Goat     Miniature\n1655         2018      LNS132953 Vincent Van Goat    Goat     Miniature\n     secondary_breed weight_kg\n1505         Unknown    103.48\n1655         Unknown     73.96\n\n\n\n\n\n\nQuestion 7\n\n\nCreate a new variable in the data, which contains the weights of all the animals, but rounded to the nearest kg.\n\nHints: Try looking up the help documentation for the function round(). Try playing with it in the console, e.g. round(c(3.5, 4.257, 1.1111)). You may find it helpful to look back at 1B #adding/changing-a-variable.\n\n\n\n\n\n\npetdata$weight_rounded <- round(petdata$weight_kg)\n\n\n\n\n\nQuestion 8\n\n\nTry giving the dataset to the function summary(). You’ll get out some information on each of the variables. It is likely that you’ll get more useful information for the variables containing information on the animal’s weights than for those containing their names, breeds etc because these variables are vectors of “characters”. We’ll start to look more about different types of data next week.\n\n\n\n\n\nsummary(petdata)\n\n  license_year  license_number     animals_name         species         \n Min.   :2015   Length:1956        Length:1956        Length:1956       \n 1st Qu.:2017   Class :character   Class :character   Class :character  \n Median :2018   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2018                                                           \n 3rd Qu.:2018                                                           \n Max.   :2018                                                           \n primary_breed      secondary_breed      weight_kg       weight_rounded \n Length:1956        Length:1956        Min.   :  0.390   Min.   :  0.0  \n Class :character   Class :character   1st Qu.:  4.707   1st Qu.:  5.0  \n Mode  :character   Mode  :character   Median : 16.630   Median : 17.0  \n                                       Mean   : 15.312   Mean   : 15.3  \n                                       3rd Qu.: 22.500   3rd Qu.: 22.0  \n                                       Max.   :103.480   Max.   :103.0  \n\n\n\n\n\n\n\n\n\n\nSimulating Dice\n\nQuestion 9\n\n\nCopy the code from the lecture which creates a custom function called dice() (copied below). Be sure to run the code (highlight it all with your cursor, and hit “run” in the top right, or press Ctrl/Cmd+Enter).\n\ndice <- function(num = 1) {\n  sum(sample(1:6, num, replace=TRUE))\n}\n\n\n\n\n\nWhat did that code do?\nIn a sense, this code does nothing: It won’t give you any output when you run it. What it is actually doing, though, is defining a function called dice(). If you look at your environment panel (top right), you’ll see dice appear when you run the code.\nTo produce some output, we have to call the function dice() (by writing it into code: dice(4), for example). dice() wants to be supplied with some information (in the argument num). If no information is supplied, num will take a default value of 1. (So writing dice() is equivalent to writing dice(1)).\nWhat does dice() do with num? It calls another function, sample(), with 3 arguments. We didn’t write sample(): it’s a function that’s “supplied with” R. To find out more about what sample() does:\n\nclick inside the brackets just after sample() in your R script;\npress TAB (⇥), then F1\nyou should see some help appear in the bottom right-hand panel of RStudio.\n\nYou will find that “sample() takes a sample … from the elements of x …” If you compare the code in RStudio to the code under “Usage” you’ll see that where the help has x, we have 1:6. So what does 1:6 mean? One way to find out is to open the console in RStudio (bottom left) and just type stuff in. What happens when you type 1:6? What about 2:17? (What about 6:1?)\nThe console is the place to “try stuff out” (don’t worry, you can’t break it). Watch the video below and then try it out yourself:\nTODO redo with script not rmd\n\n\n\n\n\nWhat you will discover is that 1:6 creates a vector (list of similar things, in this case numbers) of the numbers 1-6. The next bit of the sample() function is size. In the dice() function, the num passes down to the size of the sample(): Looking through the help, size is the number of items to choose. So sample(1:6, 1) would choose one number from the numbers 1-6 at random; sample(1:6, 3) would choose 3, and so on. The last argument, replace=TRUE, tells sample() what to do with a number once it’s been picked: Does it go ‘back into the bag’ to be picked again (TRUE) or not? (FALSE)?\nAround the outside is sum() which simply sums the numbers on however many (num) dice you “rolled”.\nPutting it all together, our dice() function “throws a die num times” by sample()ing from the numbers 1-6 num times, replaceing each number when it’s been picked, and sums the numbers of all the dice.\n\n\nQuestion 10\n\n\nLook up the function replicate(). We can use it to do something in R lots of times! For instance, replicate(20, 1+1) will evaluate 1+1 twenty times.\nUse replicate() to simulate 100 rolls of a single dice, and store the results in an object in your environment. Give it an easily identifiable name.\n\nHints: A single dice means num = 1\n\n\n\n\n\n\nrolls100 <- replicate(100, dice(num = 1))\n\n\n\n\n\nQuestion 11\n\n\nCreate a barplot showing the frequency with which each number was landed on in the 100 rolls.\n\nHints: the functions table() and barplot() were used to do this in the lecture.\n\n\n\n\n\nYour plots will look slightly different to these, because all of our dice are random!\n\n# We can get the frequency table using table()\ntable(rolls100)\n\nrolls100\n 1  2  3  4  5  6 \n16 11 16 22 20 15 \n\n# Which we can then pass to the barplot() function:\nbarplot(table(rolls100))\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 12\n\n\nDo the same for 1,000 rolls, and then for 10,000. What do you notice?\n\n\n\n\n\nmorerolls <- replicate(1000, dice(1))\nbarplot(table(morerolls))\n\n\n\n\n\n\n\nmorerolls2 <- replicate(10000, dice(1))\nbarplot(table(morerolls2))\n\n\n\n\n\n\n\n\nThe more rolls we do of the dice, the flatter the graph becomes. This is because there is an equal probability of the die landing on any of the responses - there is a uniform probability.\n\n\n\n\nQuestion 12\n\n\nCopy the code below into your script and run it. It creates a new function called wdice() which simulates the rolling of num dice which are slightly weighted.\nRoll a single weighted die 100 times and plot the frequency distribution. Do the same for 1,000 and 10,000 rolls of a single die. Does a pattern emerge? At how many rolls?\n\nwdice <- function(num = 1){\n    sum(sample(1:6, num, replace=TRUE, prob = c(0.15,0.15,0.15,0.15,0.15,0.25)))\n}\n\n\n\n\n\n\nwdice <- function(num = 1){\n    sum(sample(1:6, num, replace=TRUE, prob = c(0.15,0.15,0.15,0.15,0.15,0.25)))\n}\n\nwd <- replicate(100, wdice(1))\nbarplot(table(wd))\n\n\n\n\n\n\n\nwd <- replicate(1000, wdice(1))\nbarplot(table(wd))\n\n\n\n\n\n\n\nwd <- replicate(10000, wdice(1))\nbarplot(table(wd))\n\n\n\n\n\n\n\n\nThe die is clearly weighted towards landing on 6. However, is 100 rolls enough to reliably observe this? In our 100 rolls above, it landed on 2 quite a bit too! The pattern becomes clearer after 1000 rolls.\n\n\n\n\nQuestion 14\n\n\nRemember, wdice() and dice() are really just relying on different functions, like sample(). Try playing around with sample() in the console again - what does the prob = c(....) bit do?\n\n\n\n\nThe prob bit is defining the probabilities of observing each outcome - i.e. there is a 25% chance of rolling a 6.\n\n\n\n\nQuestion 15\n\n\nLet’s try to modify the wdice() function. Edit the code for wdice() so that 50% of the time it lands on number 6.\n\nHints:\n\nTo test out your modified function, you will need to re-run the code which defines the function. When we use wdice() we use the function which is in our environment. If we want to edit the function, we need to then overwrite (or “replace”/“reassign”) the object in our environment.\n\nWe need to be careful to remember that the probability of different outcomes should sum to 1 (i.e., it’s not possible to “50% of the time land on 6” as well as “70% of the time land on 5”!).\n\n\n\n\n\n\n\nwdice <- function(num = 1){\n    sum(sample(1:6, num, replace=TRUE, prob = c(0.1,0.1,0.1,0.1,0.1,0.5)))\n}\n\n\n\n\n\nQuestion 16\n\n\nCan you observe the weighting in your new die (the one which 50% of the time lands on number 6) in only 100 rolls?\n\n\n\n\n\nwd <- replicate(100, wdice(1))\nbarplot(table(wd))\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 17\n\n\nConceptually, what can we learn from this toy example?\n\n\n\n\nThe bigger the effect, the smaller the sample required to observe it."
  },
  {
    "objectID": "01a_R.html",
    "href": "01a_R.html",
    "title": "1A: A first look at R & RStudio",
    "section": "",
    "text": "R is a calculator\nWhen we first open RStudio, we should see something which looks more or less like the image in Figure 1, where there are several little windows. We are going to explore what each of these little windows offer by just diving in and starting to do things.\n\n\n\n\n\nFigure 1: RStudio, freshly opened\n\n\n\n\nStarting in the left-hand window, you’ll notice the blue sign >.\nThis is where we R code gets executed.\nType 2+2, and hit Enter ↵.\nYou should discover that R is a calculator - R responds by telling us the answer (4).\nLet’s work through some basic operations (adding, subtracting, etc). For instance, can you work out what R will give you for each of these operations?\n\n\nArithmetic operations\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n2 + 5\n\n\n\n10 - 4\n\n\n\n2 * 5\n\n\n\n10 - (2 * 5)\n\n\n\n(10 - 2) * 5\n\n\n\n10 / 2\n\n\n\n3^2\n(the ^ symbol is “to the power of”)\n\n\n\n\n\nShow me the output\n\n\n\nCode\nOutput\n\n\n\n\n2 + 5\n7\n\n\n10 - 4\n6\n\n\n2 * 5\n10\n\n\n10 - (2 * 5)\n0\n\n\n(10 - 2) * 5\n40\n\n\n10 / 2\n5\n\n\n3^2\n9(the ^ symbol is “to the power of”)\n\n\n\n\n\n\nR can get stuck\nWhenever you see the blue sign >, it means R is ready and waiting for you to provide a command.\nIf you type 10 + and press Enter, you’ll see that instead of > you are left with +. This means that R is waiting for more.\nEither give it more (finish the command), or cancel the command by pressing the Escape key on your keyboard.\n\nAs well as performing arithmetic calculations, we can ask R things for which the answer is TRUE or FALSE, such as “Is 3 less than 5?”. If we type 3 < 5 and press Enter, then R should tell us that the statement we gave it is TRUE.\nThese computations don’t return numbers, but instead return logical values. There are few operators that we need to learn about here:\n\nEquality/Inequality: We use the symbols == to mean “is equal to”, and the symbols != for “is not equal to”.\n\nLess Than/Greater Than: To determine whether a value is less/greater than another value, we have our typical symbols < and >. We also have <= and >= when we want to include “less/greater than or equal to”.\n\nWe can combine these with & for “and”, | for “or”, and ! for “not”, to ask R all sorts of things.\nTry and work out what R should give you for each of these (or try it out yourself!):\n\n\nLogical operations\n\n\n\nCode\nOutput\n\n\n\n\n3 > 5\n\n\n\n3 <= 5\n\n\n\n3 >= 3\n\n\n\n3 == 5\n\n\n\n(2 * 5) == 10\n\n\n\n(2 * 5) != 11\n\n\n\n(2 == 2) & (3 == 4)\n\n\n\n(2 == 2) | (3 == 4)\n\n\n\n(2 == 2) & !(3 == 4)\nTRUE\n\n\n\n\n\nShow me the output\n\n\n\nCode\nOutput\n\n\n\n\n3 > 5\nFALSE\n\n\n3 <= 5\nTRUE\n\n\n3 >= 3\nTRUE\n\n\n3 == 5\nFALSE\n\n\n(2 * 5) == 10\nTRUE\n\n\n(2 * 5) != 11\nTRUE\n\n\n(2 == 2) & (3 == 4)\nFALSE\n\n\n(2 == 2) | (3 == 4)\nTRUE\n\n\n(2 == 2) & !(3 == 4)\nTRUE\n\n\n\n\n\n\nFALSE and TRUE as 0 and 1\nIt will become useful to think of these logical values (TRUE and FALSE) as also having intrinsic numeric values of 0 and 1.\nThis is how R will treat them if you ask it to do something that requires the values to be numeric. For example, the code TRUE + 3 will return 4, and FALSE + 3 will return 3.\n\n\n\n\n\n\nR has a memory\nWe can also store things in R’s memory, and to do that we just need to give them a name. Type x <- 5 and press Enter.\nWhat has happened? We don’t get any answer like we did with calculations such as 2 + 4. What we’ve done is stored in R’s memory something named x which has the value 5. We can now refer to the name and it will give us the value!\n\nAssigning names to things in R\nThe <- symbol, pronounced arrow, is what we use to assign a value to a named object:\n\nname <- value\n\n\nIf we now type x and press Enter, it gives us whatever we assigned to the name “x”. So it gives us the number 5.\nWhat is going to happen when we type x * 3? It will give us 15!\nIf you are working along with us, you might have also noticed that something else happened when we executed the code x <- 5. The thing we named x with a value of 5 suddenly appeared in the top-right window. This is known as the environment (Figure 2), and it shows everything that we store in R.\n\n\n\n\n\nFigure 2: Assigning names to objects stores them in R’s environment.\n\n\n\n\nNote, there are a few rules about names in R:\n\nNo spaces - spaces inside a name are not allowed (the spaces around the <- don’t matter):\nlucky_number <- 5 ✔ lucky number <- 5 ❌\nNames must start with a letter:\nlucky_number <- 5 ✔ 1lucky_number <- 5 ❌\nCase sensitive:\nlucky_number is different from Lucky_Number\nhere is a set of words you can’t use as names, including: if, else, for, in, TRUE, FALSE, NULL, NA, NaN, function (Don’t worry about remembering these, R will tell you if you make the mistake of trying to name a variable after one of these).\n\n\n\n\n\n\nThe Console and The Environment\nWhat we’ve done so far has made use of a couple of the different panes that we see in RStudio. When we’ve been executing R code (e.g. typing 2+5 or x<-5 and pressing Enter), we’ve been doing it in the console. The console is where all R code gets executed. However, as we’ll see below, it isn’t where all R code gets written.\nWe’ve also been learning about how we can store things in R’s memory (the environment) by assigning a name to them using the <- operator. The top-right pane of RStudio shows us the environment, where we can see everything that we have stored in R. Note that this also means we can keep track of what objects we have saved that are available for our use. If we never stored an object named “peppapig”, then R will give us an error when we do something like:\n\n2*peppapig\n\nError in eval(expr, envir, enclos): object 'peppapig' not found\n\n\nNow we have an idea of what the console and the environment are for. If you want a silly analogy, the console is like R’s mouth, where we feed it things, and the environment is just its memory, where it remembers what things are what. We can see these in Figure 3. Note however, that the console has been moved down to the bottom-left, as we are introducing a new pane above it. This is where we move to next.\n\n\n\n\n\nFigure 3: RStudio panes: Code is executed in the console, and objects are stored in the environment.\n\n\n\n\n\n\n\n\n\nR Scripts and the Editor\nWhat if we want to edit our code? Whatever we write in the console just disappears upwards. What if we want to change things we did earlier on?\nWhile the console is where code gets executed, it doesn’t have to be where code gets written.. We can write and edit our code in a separate place before we then send it to the console to be executed!!\nThe standard place to write and edit things is in an R scipt. We can open one by doing File > New File > R script, and a new file will open in the top-left pane of RStudio. The console will be shoved down to the bottom-left.\nIn the R script, we can write code. For instance, we might write:\n\nx <- 210\ny <- 15\nx / y\n\nNotice that nothing happens when we write each line. It’s not like writing in the console where R tells us the answers. This is because this code is not yet being executed. We haven’t actually fed it to R.\nThere are a couple of useful ways we can send the code to R.\n\nPosition your text-cursor (blinking vertical line) on the line of code we wish to run and press Ctrl+Enter (Windows) or Cmd+Enter (MacOS)\n\nPosition your text-cursor (blinking vertical line) on the line of code we wish to run and press the “Run” button in the top right of the script.\n\nWhen we do this, the line of code will be sent down to the console, where it will be executed, and R will do it’s thing.\nFor example, if we had sent the line x <- 210 down to the console, R would then store the number 210 with the name x in our environment (as in Figure 4). Additionally, it will move the text-cursor to the next line, so we can just press Ctrl+Enter again to run the next line (and so on.).\n\n\n\n\n\nFigure 4: Code written in the script can be sent down to the console, where it is executed. In this example, the execution of the code stores an object in the environment.\n\n\n\n\nBy writing our code in a file such as an R script before sending it to the console we can edit, save, and share our code. This makes it so much more useful than just using the console (which is more like writing on scratch paper, where we can’t keep anything).\nFor instance, let’s say we made a mistake earlier, and instead of “x” being 210, it should have been 211. Well, we can just edit the script, and re-run it.\n\nRegularly save your scripts.\nTo save an R script that is open, we just\n\nFile > Save (or Ctrl+S)\nLocate to the folder where we want to save the file.\n\ngive it an appropriate name, and click save.\n\nNOTE: When you save R script files, they terminate with a .R extension.\n\n\nLooking ahead to Rmarkdown\n\nIn addition to R scripts, there is another type of document we can create, known as “Rmarkdown”.\nRmarkdown documents combine the analytical power of R and the utility of a text-processor. We can have one document which contains all of our analysis as well as our written text, and can be compiled into a nicely formatted report. This saves us doing analysis in R and copying results across to Microsoft Word. It ensures our report accurately reflects our analysis. Everything that you’re reading now has all been written in Rmarkdown!\n\n\n\nFigure 5: An example RMarkdown document\n\n\nWe’re going to learn more about Rmarkdown documents and how to write them later on, but the broad idea is that we can writing normal text interspersed with “code-chunks” (i.e., chunks of code!). RMarkdown documents looks much like an R script, only the code is contained within the grey-boxes, and text is written in between (see Figure 5). RMarkdown documents can then be compiled to create a lovely .pdf, .html, or .docx file.\n\n\n\n\n\nFigure 6: RMarkdown Workflow\n\n\n\n\n\n\n\n\n\n\nThe Four RStudio Panes\nWe’ve now seen almost all the different panes in RStudio:\n\n\nThe console is where R code gets executed\nThe environment is R’s memory, you can assign something a name and store it here, and then refer to it by name in your code.\nThe editor is where you can write and edit R code in R scripts and Rmarkdown documents. You can then send this to the console for it to be executed.\n\n\n\n\n\n\n\n\nFigure 7: The Four Panes of RStudio\n\n\n\n\n\nWe are yet to use the bottom-right window, but this is an easy one to explain. It is where we can see any plots that we create, where we can browse our files, and where we can ask R for some help documentation. We’ll make more use of this later on, but for now try typing plot(x = 4, y = 2) into the console and seeing what happens.\n\n\nProjects and file organisation\nWe’re not going to speak too much about this here but one key thing to remember is that R is working from a specific place in your computer. You can find out where by typing getwd() into the console.\nAn easy way to keep things organised is to set up an “R project”. This basically associates a specific folder on your computer with your working in R, and it means it will automatically look for things in that folder.\nWe recommend that you start a project for this course (call it something like “usmr”). This will the be project that you open whenever you work on this course (RStudio will usually re-open the previous project you were working on when you closed it).\nWith that project open, we suggest that you start a new script for each week, in which you complete your exercises, and which you then remember to save!\nIf you haven’t already, we suggest you start an R project by using (in the top menu of RStudio), File > New Project and following the instructions. It will create a folder on your computer somewhere of your choosing, and you will now notice that if you click in the “Files” tab in the bottom right pane of RStudio, you can see the project folder!\n\n\n\n\n\n\nGood Habits\nAlong with regular saving of work and organising your files, it will be very useful in the long-run if we get used to always “starting fresh” when we open R.\nWe need to start thinking of the code that we write in an R script as a set of consecutive instructions that we can give to R in order to achieve our goal. It’s just a blank slate on which we write (in language R understands) “do this. now do this. now do this..” and so on.\nThis means that the script contains all the information needed.\nSo we can now:\n\nEmpty our environment\nRestart R\nRun all the code in our script (highlight multiple lines of code to run them all at once)\n\nand we’re back to where we are! This is great for when we make mistakes (we’re going to make many many mistakes!), because we can just clear everything, start at the top of our script, and work downwards to figure out what has gone wrong.\n\nTidying up\n\nTo empty our environment, we can click on the little broomstick icon .\nTo restart the R Session (not always necessary, but good practice) in the top menu, we choose Session > Restart R (or press Ctrl+Shift+F10).\n\n\nThe other very useful thing that we can do in a script is to write comments for ourselves or for others. By starting a line with a #, R will know that that entire line is not code, and so it won’t try to do anything with it. For instance, if we write these lines in our script, and send them both down to the console, nothing happens for the first line:\n\n\nComments\n\n# The line below will add 5 to 2. \n2+5\n\n[1] 7\n\n\n\n\nIf we forget the #\n\nThe line below will add 5 to 2. \n2+5\n\n\nError: unexpected symbol in “The line”\n\n\n\n\n\n\n\n\nUseful Settings\nBelow are a couple of our recommended settings for you to change as you begin your journey in R. After you’ve changed them, take a 5 minute break before moving on to the next reading.\n\n1. Clean environments\nAs you use R more, you will store lots of things with different names. Throughout this course alone, you’ll probably name hundreds of different things. This could quickly get messy within our project.\nWe can make it so that we have a clean environment each time you open RStudio. This will be really handy.\n\nIn the top menu, click Tools > Global Options…\nThen, untick the box for “Restore .RData into workspace at startup”, and change “Save workspace to .RData on exit” to Never:\n\n\n\n\n2. Wrapping code\nIn the editor, you might end up with a line of code which is really long, but you can make RStudio ‘wrap’ the line, so that you can see it all, without having to scroll:\n\nx <- 1+2+3+6+3+45+8467+356+8565+34+34+657+6756+456+456+54+3+78+3+3476+8+4+67+456+567+3+34575+45+2+6+9+5+6\n\n\nIn the top menu, click Tools > Global Options…\nIn the left menu of the box, click “Code”\nTick the box for “Soft-wrap R source files”"
  },
  {
    "objectID": "01b_data.html",
    "href": "01b_data.html",
    "title": "1B: More R",
    "section": "",
    "text": "The best way to learn R is to use it.\nTry following along with this reading by typing the code into your R script and running them. You will hopefully get the same output as is presented on this page below each bit of code.\nIf you get errors and warnings, don’t panic - read them!"
  },
  {
    "objectID": "01b_data.html#accessing-subsets-of-data",
    "href": "01b_data.html#accessing-subsets-of-data",
    "title": "1B: More R",
    "section": "Accessing subsets of data",
    "text": "Accessing subsets of data\nWhat if we want to extract certain subsections of our dataset, such as specific observational units or variables? This is where we learn about two important bits of R code used to access parts of data - the dollar sign $, and the square brackets [].\n\nThe dollar sign $\nThe dollar sign allows us to extract a specific variable from a dataframe. For instance, we can pull out the variable named “eye_color” in the data, by using $eye_color after the name that we gave our dataframe.\nRemember that each variable in a dataframe is a vector (a set of values). Once extracted, we will have a vector and not a dataframe.\n\nstarwars2$eye_color\n\n [1] \"blue\"          \"yellow\"        \"red\"           \"yellow\"       \n [5] \"brown\"         \"blue\"          \"blue\"          \"red\"          \n [9] \"brown\"         \"blue-gray\"     \"blue\"          \"blue\"         \n[13] \"blue\"          \"brown\"         \"black\"         \"orange\"       \n[17] \"hazel\"         \"blue\"          \"yellow\"        \"brown\"        \n[21] \"red\"           \"brown\"         \"blue\"          \"orange\"       \n[25] \"blue\"          \"brown\"         \"black\"         \"red\"          \n[29] \"blue\"          \"orange\"        \"orange\"        \"orange\"       \n[33] \"yellow\"        \"orange\"        NA              \"brown\"        \n[37] \"yellow\"        \"pink\"          \"hazel\"         \"yellow\"       \n[41] \"black\"         \"orange\"        \"brown\"         \"yellow\"       \n[45] \"black\"         \"brown\"         \"blue\"          \"orange\"       \n[49] \"yellow\"        \"black\"         \"blue\"          \"brown\"        \n[53] \"brown\"         \"blue\"          \"yellow\"        \"blue\"         \n[57] \"blue\"          \"brown\"         \"brown\"         \"brown\"        \n[61] \"brown\"         \"yellow\"        \"yellow\"        \"black\"        \n[65] \"black\"         \"blue\"          \"unknown\"       \"unknown\"      \n[69] \"gold\"          \"black\"         \"green, yellow\" \"blue\"         \n[73] \"brown\"         \"black\"         NA             \n\n\n\n\nThe square brackets []\nSquare brackets are used to do what is known as indexing (finding specific entries in your data).\nWe can retrieve bits of data by identifying the \\(i^{th}\\) entry(s) inside the square brackets, for instance:\n\n# assign the numbers 10, 20 ... 100 to the name \"somevalues\"\nsomevalues <- c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n\n# pull out the 3rd entry\nsomevalues[3]\n\n[1] 30\n\n\nIn the above example, we have a vector (a single sequence of values), and so we can retrieve entries with the syntax:\n\nvector[entry]\n\n In a dataframe we have an extra dimension - we have rows and columns. Using square brackets with a dataframe needs us to specify both:\n\n\ndataframe[rows, columns]\n\n\nLet’s look at some examples:\n\n\nExamples of Indexing\n\nSpecifying row number and column number:\n\n\n# first row, fourth column\nstarwars2[1, 4]\n# tenth row, first column\nstarwars2[10, 1]\n\n\nIf we leave either rows or columns blank, then we will get out all of them:\n\n\n# tenth row, all columns\nstarwars2[10, ]\n# all rows, 2nd column\nstarwars2[ , 2]\n\n\nThere are is another way to identify column - we can use the name in quotation marks:\n\n\n# first row, \"species\" column\nstarwars2[1, \"species\"]\n\n\nWe can also ask for multiple rows, or multiple columns, or both! To do that, we use c():\n\n\n# the 1st AND the 6th rows, and the 1st AND 3rd columns\nstarwars2[c(1,6), c(1,3)] \n\n\nAnd we can specify a sequence using the colon, from:to:\n\n\n# FROM the 1st TO the 6th row, all columns\nstarwars2[1:6, ] \n\nWhy? Because the colon operator, `from:to`, creates a vector from the value     `from` to the value `to` in steps of 1.\n\n1:6\n\n[1] 1 2 3 4 5 6\n\n\n\nWe can even use the two accessors in combination:\n\n\n# extract the variable called \"name\" and show the 20th entry\nstarwars2$name[20]  \n\nThis represents the 20th name in the data.  \nNote: When we do this, we don't have the comma inside the square brackets. When we use the `$` to pull out a variable, such as `starwars2$name`, we no longer have a dataframe - `starwars2$name` doesn't have rows and columns, it just has a series of values - _it's a vector!_. So when you are using `[]` with a __vector__ (1 dimension) rather than a __dataframe__ (2 dimensions), you don't specify `[rows, columns]`, but simply `[entry]`. \n\n\nShow me the output\n\nSpecifying row number and column number:\n\n\n# first row, fourth column\nstarwars2[1, 4]\n\n[1] \"blue\"\n\n# tenth row, first column\nstarwars2[10, 1]\n\n[1] \"Obi-Wan Kenobi\"\n\n\n\nIf we leave either rows or columns blank, then we will get out all of them:\n\n\n# tenth row, all columns\nstarwars2[10, ]\n\n             name height    hair_color eye_color homeworld species\n10 Obi-Wan Kenobi    182 auburn, white blue-gray   Stewjon   Human\n\n# all rows, 2nd column\nstarwars2[ , 2]\n\n [1] 172 167  96 202 150 178 165  97 183 182 188 180 228 180 173 175 170 180 170\n[20] 183 190 177 175 180 150  88 160 191 170 196 224 206 137 112 170 163 175 180\n[39] 178  94 122 163 188 198 196 171 184 188 264 188 196 185 157 183 183 170 166\n[58] 165 193 191 183 168 198 229 213 167  79 193 191 178 216 234 188 206 180\n\n\n\nThere are is another way to identify column - we can use the name in quotation marks:\n\n\n# first row, \"species\" column\nstarwars2[1, \"species\"]\n\n[1] \"Human\"\n\n\n\nWe can also ask for multiple rows, or multiple columns, or both! To do that, we use c():\n\n\n# the 1st AND the 6th rows, and the 1st AND 3rd columns\nstarwars2[c(1,6), c(1,3)] \n\n            name  hair_color\n1 Luke Skywalker       blond\n6      Owen Lars brown, grey\n\n\n\nAnd we can specify a sequence using the colon, from:to:\n\n\n# FROM the 1st TO the 6th row, all columns\nstarwars2[1:6, ] \n\n            name height  hair_color eye_color homeworld species\n1 Luke Skywalker    172       blond      blue  Tatooine   Human\n2          C-3PO    167        <NA>    yellow  Tatooine   Human\n3          R2-D2     96        <NA>       red     Naboo   Droid\n4    Darth Vader    202        none    yellow  Tatooine   Human\n5    Leia Organa    150       brown     brown  Alderaan   Human\n6      Owen Lars    178 brown, grey      blue  Tatooine   Human\n\n\n\nWe can even use the two accessors in combination:\n\n\n# extract the variable called \"name\" and show the 20th entry\nstarwars2$name[20]  \n\n[1] \"Boba Fett\"\n\n\n\n\n\nThe dollar sign $\nUsed to extract a variable from a dataframe:\n\ndataframe$variable\n\nThe square brackets []\nUsed to extract parts of an R object by identifying rows and/or columns, or more generally, “entries”. Left blank will return all.\n\nvector[entries]\ndataframe[rows, columns]"
  },
  {
    "objectID": "01b_data.html#accessing-by-a-condition",
    "href": "01b_data.html#accessing-by-a-condition",
    "title": "1B: More R",
    "section": "Accessing by a condition",
    "text": "Accessing by a condition\nWe can also do something really useful, which is to access all the entries in the data for which a specific condition is true.\nLet’s take a simple example to start:\n\nsomevalues <- c(10, 10, 0, 20, 15, 40, 10, 40, 50, 35)\n\nTo only select values which are greater than 20, we can use:\n\nsomevalues[somevalues > 20]\n\n[1] 40 40 50 35\n\n\n\nUnpacking: somevalues[somevalues > 20]\n First, let’s look at what somevalues > 20 does. It returns TRUE for the entries of somevalues which are greater than 20, and FALSE for the entries of somevalues that are not (that is, which are less than, or equal to, 20.\nThis statement somevalues > 20 is called the condition.\n\nsomevalues > 20\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE\n\n\nWe can give a name to this sequence of TRUEs and FALSEs\n\ncondition <- somevalues > 20\ncondition\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE\n\n\nNow consider putting the sequence of TRUEs and FALSEs inside the square brackets in somevalues[]. This returns only the entries of somevalues for which the condition is TRUE.\n\nsomevalues[condition]\n\n[1] 40 40 50 35\n\n\nSo what we can do is use a condition inside the square brackets to return all the values for which that condition is TRUE.\nNote that you don’t have to always give a name to the condition. This works too:\n\nsomevalues[somevalues > 20]\n\n[1] 40 40 50 35\n\n\n\n We can extend this same logic to a dataframe. Let’s suppose we want to access all the entries in our Star Wars data who have the value “Droid” in the species variable. To work out how to do this, we first need a line of code which defines our condition - one which returns TRUE for each entry of the species variable which is “Droid”, and FALSE for those that are not “Droid”.\nWe can use the dollar sign to pull out the species variable:\n\nstarwars2$species\n\n [1] \"Human\"        \"Human\"        \"Droid\"        \"Human\"        \"Human\"       \n [6] \"Human\"        \"Human\"        \"Droid\"        \"Human\"        \"Human\"       \n[11] \"Human\"        \"Human\"        \"Wookiee\"      \"Human\"        \"Rodian\"      \n[16] \"Hutt\"         \"Human\"        \"Human\"        \"Human\"        \"Human\"       \n[21] \"Trandoshan\"   \"Human\"        \"Human\"        \"Mon Calamari\" \"Human\"       \n[26] \"Ewok\"         \"Sullustan\"    \"Neimodian\"    \"Human\"        \"Gungan\"      \n[31] \"Gungan\"       \"Gungan\"       \"Toydarian\"    \"Dug\"          \"unknown\"     \n[36] \"Human\"        \"Zabrak\"       \"Twi'lek\"      \"Twi'lek\"      \"Vulptereen\"  \n[41] \"Xexto\"        \"Toong\"        \"Human\"        \"Cerean\"       \"Nautolan\"    \n[46] \"Zabrak\"       \"Tholothian\"   \"Iktotchi\"     \"Quermian\"     \"Kel Dor\"     \n[51] \"Chagrian\"     \"Human\"        \"Human\"        \"Human\"        \"Geonosian\"   \n[56] \"Mirialan\"     \"Mirialan\"     \"Human\"        \"Human\"        \"Human\"       \n[61] \"Human\"        \"Clawdite\"     \"Besalisk\"     \"Kaminoan\"     \"Kaminoan\"    \n[66] \"Human\"        \"Aleena\"       \"Skakoan\"      \"Muun\"         \"Togruta\"     \n[71] \"Kaleesh\"      \"Wookiee\"      \"Human\"        \"Pau'an\"       \"unknown\"     \n\n\nAnd we can ask R whether each value is equal to “Droid” (Remember: in R, we ask whether something is equal to something else by using a double-equals, ==). A single equal sign would be wrong, as it denotes assignment.\n\nstarwars2$species == \"Droid\"\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[73] FALSE FALSE FALSE\n\n\nFinally, we can use this condition inside our square brackets to access the entries of the data for which this condition is TRUE:\n\n# I would read the code below as: \n\n# \"In the starwars2 dataframe, give me all the rows for which the\n# condition starwars2$species==\"Droid\" is TRUE, and give me all the columns.\"\n\nstarwars2[starwars2$species == \"Droid\", ]\n\n   name height hair_color eye_color homeworld species\n3 R2-D2     96       <NA>       red     Naboo   Droid\n8 R5-D4     97       <NA>       red  Tatooine   Droid"
  },
  {
    "objectID": "01b_data.html#more-complex-conditions",
    "href": "01b_data.html#more-complex-conditions",
    "title": "1B: More R",
    "section": "More complex conditions",
    "text": "More complex conditions\nThinking back to Section 1A when we first introduced R, we talked briefly about “logical operators”. Specifically, the operators &, |, and ! (for “and”, “or”,” and “not”), will come in handy now.\nFor instance, we can now extract all those in the dataset which are humans and taller than 190cm:\n\n# \"In the starwars2 dataframe, give me all the rows for which the\n# condition starwars2$species==\"Human\" AND starwars2$height > 190 are TRUE, \n# and give me all the columns.\"\nstarwars2[starwars2$species == \"Human\" & starwars2$height > 190, ]\n\n                  name height hair_color eye_color homeworld species\n4          Darth Vader    202       none    yellow  Tatooine   Human\n59               Dooku    193      white     brown   Serenno   Human\n60 Bail Prestor Organa    191      black     brown  Alderaan   Human\n\n\nOr we can extract all those in the dataset which are either droids or ewoks:\n\n# \"In the starwars2 dataframe, give me all the rows for which the\n# condition starwars2$species==\"Droid\" OR starwars2$species==\"Ewok\" is TRUE, \n# and give me all the columns.\"\nstarwars2[starwars2$species == \"Droid\" | starwars2$species == \"Ewok\", ]\n\n                    name height hair_color eye_color homeworld species\n3                  R2-D2     96       <NA>       red     Naboo   Droid\n8                  R5-D4     97       <NA>       red  Tatooine   Droid\n26 Wicket Systri Warrick     88      brown     brown     Endor    Ewok"
  },
  {
    "objectID": "01b_data.html#editing-specific-entries",
    "href": "01b_data.html#editing-specific-entries",
    "title": "1B: More R",
    "section": "Editing specific entries",
    "text": "Editing specific entries\nNow that we’ve seen a few ways of accessing sections of data, we can learn how to edit them! One of the most common reasons you will need to modify entries in your data is in data cleaning. This is the process of identifying incorrect/incomplete/irrelevant data, and replacing/modifying/deleting them.\nAbove, we looked at the subsection of the data where the species variable had the entry “Droid”. Some of you may have noticed earlier that we had some data on C3PO. Is he not also a droid?\n\n\n\n(Looks pretty Droid-y to me! disclaimer: I know nothing about Star Wars 🙂 )\nJust as we saw above how to access specific entries, e.g.:\n\n# 2nd row, all columns\nstarwars2[2, ]\n\n   name height hair_color eye_color homeworld species\n2 C-3PO    167       <NA>    yellow  Tatooine   Human\n\n# 2nd row, 6th column (the \"species\" column)\nstarwars2[2,6]\n\n[1] \"Human\"\n\n\nWe can change these by assigning them a new value (remember the <- symbol). In doing so, we replace / overwrite / reassign the entry in the 2nd row and 6th column of the data (starwars2[2,6]) with the value “Droid”.\n\n# C3PO is a droid, not a human\nstarwars2[2,6] <- \"Droid\"\n# Look at the 2nd row now -\n# the entry in the \"species\" column has changed:\nstarwars2[2, ]\n\n   name height hair_color eye_color homeworld species\n2 C-3PO    167       <NA>    yellow  Tatooine   Droid"
  },
  {
    "objectID": "01b_data.html#editing-entries-via-a-condition",
    "href": "01b_data.html#editing-entries-via-a-condition",
    "title": "1B: More R",
    "section": "Editing entries via a condition",
    "text": "Editing entries via a condition\nWe saw above how to access parts of data by means of a condition, with code such as:\n\n# \"In the starwars2 dataframe, give me all the rows for which the\n# condition starwars2$homeworld==\"Naboo\" is TRUE, and give me all the columns.\"\nstarwars2[starwars2$homeworld==\"Naboo\", ]\n\n            name height hair_color eye_color homeworld species\n3          R2-D2     96       <NA>       red     Naboo   Droid\n19     Palpatine    170       grey    yellow     Naboo   Human\n30 Jar Jar Binks    196       none    orange     Naboo  Gungan\n31  Roos Tarpals    224       none    orange     Naboo  Gungan\n32    Rugor Nass    206       none    orange     Naboo  Gungan\n52  Gregar Typho    185      black     brown     Naboo   Human\n53         Cordé    157      brown     brown     Naboo   Human\n58         Dormé    165      brown     brown     Naboo   Human\n\n\nWhat if we wanted to modify it so that every character from “Naboo” was actually of species “Nabooian”?\nWe can do that in a number of ways, all of which do the same thing - namely, they access parts of the data and assign them the new value “Nabooian”.\nStudy the lines of code below and their interpretations:\n\n# In the starwars2 data, give the rows for which condition \n# starwars2$homeworld==\"Naboo\" is TRUE, and select only the \"species\" column. \n# Assign to these selected entries the value \"Nabooian\".\nstarwars2[starwars2$homeworld==\"Naboo\", \"species\"] <- \"Nabooian\"\n\n# In the starwars2 data, give the rows for which condition \n# starwars2$homeworld==\"Naboo\" is TRUE, and select only the 6th column. \n# Assign to these selected entries the value \"Nabooian\".\nstarwars2[starwars2$homeworld==\"Naboo\", 6] <- \"Nabooian\"\n\n# Extract the species variable from the starwars2 data (it's a vector).\n# Pick the entries for which the condition starwars2$homeworld==\"Naboo\" is TRUE.\n# Assign to these selected entries the value \"Nabooian\".\nstarwars2$species[starwars2$homeworld==\"Naboo\"] <- \"Nabooian\""
  },
  {
    "objectID": "01b_data.html#addingchanging-a-variable",
    "href": "01b_data.html#addingchanging-a-variable",
    "title": "1B: More R",
    "section": "Adding/Changing a variable",
    "text": "Adding/Changing a variable\nAnother thing we might want to do is change a whole variable (a whole column) in some way.\nThe logic is exactly the same, for instance, we can take the variable “height” from the dataframe “starwars2”, dividing it by 100 via starwars2$height / 100, and then assign the result to the same variable name in the data, i.e. we overwrite the column:\n\nstarwars2$height <- starwars2$height / 100\n\nWe could instead have added a new column named “height_m” with those values if we did not want to overwrite “height”:\n\nstarwars2$height_m <- starwars2$height / 100\n\nThis would have left the “height” variable as-is, and created a new one called “height2” which was the values in “height” divided by 100."
  },
  {
    "objectID": "01b_data.html#removing-rows-or-columns",
    "href": "01b_data.html#removing-rows-or-columns",
    "title": "1B: More R",
    "section": "Removing rows or columns",
    "text": "Removing rows or columns\nLastly, we might want to change the data by removing a row or a column. Again, the logic remains the same, in that we use <- to assign the edited data to a name (either a new name, thus creating a new object, or an existing name, thereby overwriting that object).\nFor instance, notice that the 35th and 75th rows of our data probably aren’t a valid observation - I’m reasonably sure that Marge and Homer Simpson never appeared in Star Wars:\n\nstarwars2[c(35,75), ]\n\n            name height hair_color eye_color   homeworld species\n35 Marge Simpson    1.7       Blue      <NA> Springfield unknown\n75 Homer Simpson    1.8       <NA>      <NA> Springfield unknown\n\n\nWe can remove a certain row(s) by using a minus sign - inside the square brackets\n\n# everything minus the 75th row\nstarwars2[-75, ]\n# everything minus the (35th and 75th rows)\nstarwars2[-c(35, 75), ]\n\nAnd we can simply re-use the name “starwars2” to overwrite the data and make this change take effect (rather than just print out the result, which the code above did):\n\nstarwars2 <- starwars2[-c(35, 75), ]\n\n(now, in the environment pane of Rstudio, the object named “starwars2” will say 73 observations, rather than 75, which it had before - we’ve removed the 2 rows)\n The same logic applies for columns:\n\n# Create a new object called \"anonymous_starwars2\" and assign it \n# to the values which are the \"starwars2\" dataframe minus the \n# 1st column (the \"name\" column):\nanonymous_starwars2 <- starwars2[, -1]\n# dimensions of our initial data\ndim(starwars2)\n\n[1] 73  6\n\n# the data we just assigned has one fewer columns\ndim(anonymous_starwars2)\n\n[1] 73  5"
  },
  {
    "objectID": "02_ex.html",
    "href": "02_ex.html",
    "title": "Week 2 Exercises: More R; Estimates & Intervals",
    "section": "",
    "text": "Data manipulation & visualisation\n\nQuestion 1\n\n\nCreate a new variable in the dataset which indicates whether people are taller than 6 foot (182cm).\n\nYou might want to use mutate(). Remember to make the changes apply to the objects in your environment, rather than just printing it out.\ndata <- data %>% mutate(...)\n(see 2A #tidyverse-and-pipes)\n\n\n\n\n\n\nlibrary(tidyverse)\nsurveydata <- read_csv(\"https://uoepsy.github.io/data/surveydata_allcourse22.csv\")\n\nsurveydata <- surveydata %>%\n  mutate(\n    over6ft = height > 182\n  )\n\n\n\n\n\nQuestion 2\n\n\nWhat percentage of respondents to the survey are greater than 6 foot tall?\n\nTry table(), and then think about how we can convert the counts to percentages (what does sum() of the table give you?).\nSee also 2A #categorical.\n\n\n\n\n\nWe can divide the table by the sum of the table\n\ntable(surveydata$over6ft) / sum(table(surveydata$over6ft))\n\n\n     FALSE       TRUE \n0.95336788 0.04663212 \n\n\nWe can also use prop.table()\n\nprop.table(table(surveydata$over6ft))\n\n\n     FALSE       TRUE \n0.95336788 0.04663212 \n\n\n\n\n\n\nQuestion 3\n\n\nhow many of USMR students in 2022/23 are born in the same month as you?\n\nThis will involve filtering your data to current USMR students first.\nIn tidyverse you can make a table using ... %>% select(variable) %>% table()\nYou can also try ... %>% count(variable) to get the same information.\n\n\n\n\n\n\nsurveydata %>% \n  filter(course == \"usmr\", year==\"2022\") %>%\n  count(birthmonth)\n\n# A tibble: 1 × 2\n  birthmonth     n\n  <chr>      <int>\n1 jan            1\n\n\n\n\n\n\nQuestion 4\n\n\nCalculate the mean and standard deviation of heights of all respondents to the survey.\nCan you (also) do this using the tidyverse syntax?\n\nWe can do it with mean(data$variable), but it will be useful to practice tidyverse style. You’ll want to summarise() the data.\nWe’re likely to have missing data in here, so na.rm=TRUE will be handy (see 2A #numeric)\n\n\n\n\n\nThis returns us NA:\n\nmean(surveydata$height)\n\n[1] NA\n\n\nSo we need to make sure we use na.rm = TRUE (we can use T as a shorthand for TRUE).\n\nmean(surveydata$height, na.rm = T)\n\n[1] 167.8787\n\nsd(surveydata$height, na.rm = T)\n\n[1] 8.229547\n\nsurveydata %>% \n  summarise(\n    meanheight = mean(height, na.rm = T),\n    sdheight = sd(height, na.rm = T)\n  )\n\n# A tibble: 1 × 2\n  meanheight sdheight\n       <dbl>    <dbl>\n1       168.     8.23\n\n\n\n\n\n\nQuestion 5\n\n\nPlot the distribution of heights of all respondents. Try to make it ‘publication ready’.\n\nhist() won’t cut it here, we’re going to want ggplot, which was introduced in 2A #ggplot.\n\n\n\n\n\n\nggplot(surveydata, aes(x=height)) + \n  geom_histogram(binwidth = 5) + \n  labs(x = \"Height (cm)\", \n       y = \"Frequency\", \n       title = \"Heights of respondents to the survey\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nFor respondents from each of the different courses, calculate the mean and standard deviation of heights.\n\nThis is just like question 4 - we want to summarise our data. Only this time we need to group_by something else first.\n\n\n\n\n\nWe’re using the same code as we did for question 4, but we’ve added in one new line using group_by().\n\nsurveydata %>% \n  group_by(course) %>%\n  summarise(\n    meanheight = mean(height, na.rm = T),\n    sdheight = sd(height, na.rm = T)\n  )\n\n# A tibble: 4 × 3\n  course meanheight sdheight\n  <chr>       <dbl>    <dbl>\n1 dapr1        168.     7.36\n2 dapr2        167.     7.79\n3 rms2         167.     7.98\n4 usmr         168.     9.10\n\n\n\n\n\n\nQuestion 7\n\n\nPlot the distributions of heights for each course.\nBased on your answer to the previous question, can you picture what the distributions are going to look like before you plot them?\n\nTry looking up the documentation for ?facet_wrap. It is an incredibly useful extension of ggplot which allows you to create the same plot for different groups.\nYou might also want to add an extra aesthetic mapping from the course variable to some feature of your plot (e.g. ‘colour’ or ‘fill’).\n\n\n\n\n\n\nggplot(surveydata, aes(x=height, fill = course)) + \n  geom_histogram(binwidth = 5) + \n  facet_wrap(~course) + \n  labs(x = \"Height (cm)\", \n       y = \"Frequency\", \n       title = \"Heights of respondents to the survey\") + \n  guides(fill = \"none\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nWhat proportion of respondents to the survey are taller than you?\n\nRemember that we can sum() a condition as a quick way of counting.\nsum(data$variable == \"thing\") adds up all the TRUE responses.\nWe can actually use this logic inside tidyverse functions like summarise and count too.\n\n\n\n\n\nThere are this many people who are taller than me. We need to ignore the NAs again:\n\nsum(surveydata$height > 177, na.rm = T)\n\n[1] 46\n\n\nAnd if we divide that by the total number of respondents, we get the proportion:\n\nsum(surveydata$height > 177, na.rm = T) / nrow(surveydata)\n\n[1] 0.1167513\n\n\n\n\n\n\n\n\n\n\nEstimates & Intervals\nFor these next exercises we are going to be focusing on self-perceived sleep quality ratings. Our survey contains a set of respondents who completed the question below. We’re going to use this sample to get an estimate of the sleep quality rating in the wider population.\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nWe only asked the sleep quality rating question to students in USMR in the 2022/23 academic year, so to make things easier, let’s create a subset of the dataset which includes only those students.\n\nThis will need some filtering, and assigning (usmrdata <-) to a new name.\n\n\n\n\n\n\nusmrdata <- surveydata %>% \n  filter(course == \"usmr\", year == \"2022\")\ndim(usmrdata)\n\n\n\n\n\nQuestion 10\n\n\nFor the USMR students in the 2022/23 academic cohort, calculate the following:\n\nmean Sleep-Quality rating\nstandard deviation of Sleep-Quality ratings\nnumber of respondents who completed Sleep-Quality rating\n\n\nYou can do this with things like mean(data$variable), or you can do it all in tidyverse (see the example of summarise in the intro to tidyverse: 2A #tidyverse-and-pipes).\nTo find out how many in a variable are not NAs, we might need to use is.na(). A little example for you to play with:\n\nmynumbers <- c(1,5,NA,3,6,NA)\n# for each number, TRUE if it's an NA, otherwise FALSE\nis.na(mynumbers)\n\n[1] FALSE FALSE  TRUE FALSE FALSE  TRUE\n\n# ! means \"not\", so this is asking if each number is \"not\" an NA\n!is.na(mynumbers)\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE FALSE\n\n# how many non-NAs are there? \nsum(!is.na(mynumbers))\n\n[1] 4\n\n\n\n\n\n\n\n\nusmrdata %>% \n  summarise(\n    m_sleep = mean(sleeprating, na.rm = TRUE),\n    sd_sleep = mean(sleeprating, na.rm = TRUE),\n    n_sleep = sum(!is.na(sleeprating)), \n    n_total = n() # n() will give the total count\n  )\n\n\n\n\n\nQuestion 11\n\n\nUsing your answers to the previous question, construct a 95% confidence interval for the average Sleep-Quality rating.\nWhy might it be a bad idea to use this as an estimate of the average Sleep-Quality rating of the general population?\n\nThe previous question gives you all the pieces that you need. You’ll just need to put them together in the way seen in 2B #confidence-intervals.\nThink about who makes up the sample (e.g. USMR students). Are they representative of the population we are trying to generalise to?\n\n\n\n\n\nTODO with data"
  },
  {
    "objectID": "02a_measurement.html",
    "href": "02a_measurement.html",
    "title": "2A: Measurement & Distributions",
    "section": "",
    "text": "Figure 1: Artwork by @allison_horst\n\n\n\n\nIn the dice-rolling example, each roll of the die could take one of a discrete set of responses (1, 2, 3, 4, 5 or 6). A die cannot land on 5.3, or 2.6.\nThere are many different things we can measure / record on observational units, and the data we collect will also have different characteristics. Some data will be similar to rolling a die in that values take on categories, and others could take any value on a continuous scale.\nFor example, in the last couple of years during welcome week, we have asked students of the statistics courses in the Psychology department to fill out a little survey. Amongst other things, we capture data on student heights (we asked for answers in cm, and respondents could be precise as they liked) and the colours of they eyes (we gave a set of options to choose from). We distinguish between these different types of data by talking about variables that are categorical (responses take one of a set of defined categories: “blue”, “green”, and so on..) and those that are numeric (responses are in the form of a number). Within each of these, there also are a few important sub-classes.\n\n\n\n\n\n\n\n\n\nThis reading walks through the various different types of data we might encounter, and some of the metrics we use to summarise variables of different types. For this walkthrough we have a dataset on some of the most popular internet passwords, their strength, and how long it took for an algorithm to crack it. The data are available online at https://uoepsy.github.io/data/passworddata.csv.\n\nData: Passwords\n\npwords <- read.csv(\"https://uoepsy.github.io/data/passworddata.csv\")\n\n\n\n\n\n\n\n\nVariable Name\nDescription\n\n\n\n\nrank\nPopularity in the database of released passwords\n\n\npassword\nPassword\n\n\ntype\nCategory of password\n\n\ncracked\nTime to crack by online guessing\n\n\nstrength\nStrength = quality of password where 10 is highest, 1 is lowest\n\n\nstrength_cat\nStrength category (weak, medium, strong)\n\n\n\n\n\n\n\nCategorical variables tell us what group or category each individual belongs to. Each distinct group or category is called a level of the variable.\n\n\n\n\n\n\n\n\nType\nDescription\nExample\n\n\n\n\nNominal (Unordered categorical)\nA categorical variable with no intrinsic ordering among the levels.\nSpecies: Dog, Cat, Parrot, Horse, …\n\n\nOrdinal (Ordered categorical)\nA categorical variable which levels possess some kind of order\nLevel: Low, Medium, High\n\n\nBinary categorical\nA special case of categorical variable with only 2 possible levels\nisDog: Yes or No.\n\n\n\nIf we want to summarise a categorical variable into a single number, then the simplest approach is to use the mode:\n\nMode: The most frequent value (the value that occurs the greatest number of times).\n\nWhen we have ordinal variables, there is another option, and that is to use the median:\n\nMedian: For ordinal variables only, this is the value for which 50% of observations are lower and 50% are higher. It is the mid-point of the values when they are rank-ordered.\n\nWhen we use the median as our measure of “central tendency” (i.e. the middle of the distribution) and we want to discuss how spread out the spread are around it, then we will want to use quartiles. The Inter-Quartile Range (IQR) is obtained by rank-ordering all the data, and finding the points at which 25% (one quarter) and 75% (three quarters) of the data falls below (this makes the median the “2nd quartile”).\n\nIn our dataset on passwords, we have various categorical variables, such as the type of password (categories like “animal”, “fluffy” etc).\nThere are various ways we might want to summarise categorical variables like this. We have already seen the code to do this in our example of the dice simulation - we can simply counting the frequencies in each level:\n\ntable(pwords$type)\n\n\n             animal          cool-macho              fluffy                food \n                 29                  79                  44                  11 \n               name           nerdy-pop    password-related     rebellious-rude \n                183                  30                  15                  11 \nsimple-alphanumeric               sport \n                 61                  37 \n\n\nThis shows us that the mode (most common) is “name” related passwords.\nWe could also convert these to proportions, by dividing each of these by the total number of observations. For instance, here are the percentages of passwords of each type:\n\ntable(pwords$type) / sum(table(pwords$type)) * 100\n\n\n             animal          cool-macho              fluffy                food \n                5.8                15.8                 8.8                 2.2 \n               name           nerdy-pop    password-related     rebellious-rude \n               36.6                 6.0                 3.0                 2.2 \nsimple-alphanumeric               sport \n               12.2                 7.4 \n\n\n\nOften, if the entries in a variable are characters (letters), then many functions in R (like table()) will treat it the same as if it is a categorical variable. However, this is not always the case, so it is good to tell R specifically that each variable is a categorical variable. There is a special way that we tell R that a variable is categorical - we set it to be a “factor”. Note what happens when we make the “type” and “strength_cat” variables to be a factor:\n\npwords$type <- factor(pwords$type)\npwords$strength_cat <- factor(pwords$strength_cat)\nsummary(pwords)\n\n      rank         password                          type        cracked      \n Min.   :  1.0   Length:500         name               :183   Min.   : 1.290  \n 1st Qu.:125.8   Class :character   cool-macho         : 79   1st Qu.: 3.430  \n Median :250.5   Mode  :character   simple-alphanumeric: 61   Median : 3.720  \n Mean   :250.5                      fluffy             : 44   Mean   : 5.603  \n 3rd Qu.:375.2                      sport              : 37   3rd Qu.: 3.720  \n Max.   :500.0                      nerdy-pop          : 30   Max.   :92.270  \n                                    (Other)            : 66                   \n    strength      strength_cat\n Min.   : 1.000   medium:402  \n 1st Qu.: 6.000   strong: 25  \n Median : 7.000   weak  : 73  \n Mean   : 6.768               \n 3rd Qu.: 8.000               \n Max.   :10.000               \n                              \n\n\nR now recognises that there a set number of possible response options, or “levels”, for these variables. We can see what they are using:\n\nlevels(pwords$strength_cat)\n\n[1] \"medium\" \"strong\" \"weak\"  \n\n\nThe “strength_cat” variable specifically has an ordering to the levels, so we might be better off also telling R about this ordering. We do this like so:\n\npwords$strength_cat <- factor(pwords$strength_cat, ordered = TRUE, levels = c(\"weak\",\"medium\",\"strong\"))\n\n\nSometimes, we might have a variable that we know is categorical, but we might want to treat it as a set of numbers instead. A very common example in psychological research is Likert data (questions measured on scales such as “Strongly Disagree”>>“Disagree”>>…>>“Strongly Agree”).\nIt is often useful to have these responses as numbers (e.g. 1 = “Strongly Disagree” to 5 = “Strongly Agree”), as this allows us to use certain functions in R more easily. For instance, the median() and IQR() functions require the data to be numbers.\nThis will not work:\n\nmedian(pwords$strength_cat)\n\nError in median.default(pwords$strength_cat): need numeric data\n\n\nWhen we ask R to convert a factor to a numeric variable, it will give turn the first category into 1, the second category to 2, and so on. As R knows that our strength_cat variable is the ordered categories “weak”>>“medium”>>“strong”, then as.numeric(pwords$strength_cat) will turn these to 1s, 2s, and 3s.\n\nmedian(as.numeric(pwords$strength_cat))\n\n[1] 2\n\n\n\n\n\n\nNumeric (or quantitative) variables consist of numbers, and represent a measurable quantity. Operations like adding and averaging make sense only for numeric variables.\n\n\n\n\n\n\n\n\nType\nDescription\nExample\n\n\n\n\nContinuous\nVariables which can take any real number within the specified range of measurement\nHeight: 172, 165.2, 183, …\n\n\nDiscrete\nVariables which can only take integer number values. For instance, a counts can only take positive integer values (0, 1, 2, 3, etc.)\nNumber_of_siblings: 0, 1, 2, 3, 4, …\n\n\n\nOne of the most frequently used measures of central tendency for numeric data is the mean. The mean is calculated by summing all of the observations together and then dividing by the total number of obervations (\\(n\\)).\n\nMean: \\(\\bar{x}\\)\nWhen we have sampled some data, we denote the mean of our sample with the symbol \\(\\bar{x}\\) (sometimes referred to as “x bar”). The equation for the mean is:\n\\[\\bar{x} = \\frac{\\sum\\limits_{i = 1}^{n}x_i}{n}\\]\n\n Help reading mathematical formulae.\n\n\nThis might be the first mathematical formula you have seen in a while, so let’s unpack it.\nThe \\(\\sum\\) symbol is used to denote a series of additions - a “summation”.\nWhen we include the bits around it: \\(\\sum\\limits_{i = 1}^{n}x_i\\) we are indicating that we add together all the terms \\(x_i\\) for values of \\(i\\) between \\(1\\) and \\(n\\):\n\\[\\sum\\limits_{i = 1}^{n}x_i \\qquad = \\qquad x_1+x_2+x_3+...+x_n\\]\nSo in order to calculate the mean, we do the summation (adding together) of all the values from the \\(1^{st}\\) to the \\(n^{th}\\) (where \\(n\\) is the total number of values), and we divide that by \\(n\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we are using the mean as our as our measure of central tendency, we can think of the spread of the data in terms of the deviations (distances from each value to the mean).\nRecall that the mean is denoted by \\(\\bar{x}\\). If we use \\(x_i\\) to denote the \\(i^{th}\\) value of \\(x\\), then we can denote deviation for \\(x_i\\) as \\(x_i - \\bar{x}\\).\nThe deviations can be visualised by the red lines in Figure 2.\n\n\n\n\n\nFigure 2: Deviations from the mean\n\n\n\n\n\nThe sum of the deviations from the mean, \\(x_i - \\bar x\\), is always zero\n\\[\n\\sum\\limits_{i = 1}^{n} (x_i - \\bar{x}) = 0\n\\]\nThe mean is like a center of gravity - the sum of the positive deviations (where \\(x_i > \\bar{x}\\)) is equal to the sum of the negative deviations (where \\(x_i < \\bar{x}\\)).\n\nBecause deviations around the mean always sum to zero, in order to express how spread out the data are around the mean, we must we consider squared deviations.\nSquaring the deviations makes them all positive. Observations far away from the mean in either direction will have large, positive squared deviations. The average squared deviation is known as the variance, and denoted by \\(s^2\\)\n\nVariance: \\(s^2\\)\nThe variance is calculated as the average of the squared deviations from the mean.\nWhen we have sampled some data, we denote the mean of our sample with the symbol \\(\\bar{x}\\) (sometimes referred to as “x bar”). The equation for the variance is:\n\\[s^2 = \\frac{\\sum\\limits_{i=1}^{n}(x_i - \\bar{x})^2}{n-1}\\]\n\n Optional: Why n minus 1?\n\n\nThe top part of the equation \\(\\sum\\limits_{i=1}^{n}(x_i - \\bar{x})^2\\) can be expressed in \\(n-1\\) terms, so we divide by \\(n-1\\) to get the average.\n Example: If we only have two observations \\(x_1\\) and \\(x_2\\), then we can write out the formula for variance in full quite easily. The top part of the equation would be:\n\\[\n\\sum\\limits_{i=1}^{2}(x_i - \\bar{x})^2 \\qquad = \\qquad (x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2\n\\]\nThe mean for only two observations can be expressed as \\(\\bar{x} = \\frac{x_1 + x_2}{2}\\), so we can substitute this in to the formula above.\n\\[\n(x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 \\qquad = \\qquad \\left(x_1 - \\frac{x_1 + x_2}{2}\\right)^2 + \\left(x_2 - \\frac{x_1 + x_2}{2}\\right)^2\n\\]\nWhich simplifies down to one value:\n\\[\n\\left(x_1 - \\frac{x_1 + x_2}{2}\\right)^2 + \\left(x_2 - \\frac{x_1 + x_2}{2}\\right)^2 \\qquad = \\qquad  \\left(\\frac{x_1 - x_2}{\\sqrt{2}}\\right)^2\n\\]\n So although we have \\(n=2\\) datapoints (\\(x_1\\) and \\(x_2\\)), the top part of the equation for the variance has only 1 (\\(n-1\\)) units of information. In order to take the average of these bits of information, we divide by \\(n-1\\).\n\n\n\n\nOne difficulty in interpreting variance as a measure of spread is that it is in units of squared deviations. It reflects the typical squared distance from a value to the mean.\nConveniently, by taking the square root of the variance, we can translate the measure back into the units of our original variable. This is known as the standard deviation.\n\nStandard Deviation: \\(s\\)\nThe standard deviation, denoted by \\(s\\), is a rough estimate of the typical distance from a value to the mean.\nIt is the square root of the variance (the typical squared distance from a value to the mean).\n\\[\ns = \\sqrt{\\frac{\\sum\\limits_{i=1}^{n}(x_i - \\bar{x})^2}{n-1}}\n\\]\n\n\nIn the passwords dataset, we only have one continuous variable, and that is the “cracked” variable, which if we recall is the “Time to crack by online guessing”. You might be questioning whether the “strength” variable, which ranges from 1 to 10 is numeric? This depends on whether we think that statements like “a password of strength 10 is twice as strong as a password of strength 5”.\nFor now, we’ll just look at the “cracked” variable.\nTo calculate things like means and standard deviations in R is really easy, because there are functions that do them all for us.\nFor instance, we can do the calculation by summing the cracked variable, and dividing by the number of observations (in our case we have 500 passwords):\n\n# get the values in the \"cracked\" variable from the \"pwords\" dataframe, and\n# sum them all together. Then divide this by 500\nsum(pwords$cracked)/500\n\n[1] 5.60266\n\n\nOr, more easily, we can use the mean() function:\n\nmean(pwords$cracked)\n\n[1] 5.60266\n\n\nWe can get R to calculate the variance and standard deviation with the var() and sd() functions:\n\nvar(pwords$cracked)\n\n[1] 71.16618\n\nsd(pwords$cracked)\n\n[1] 8.436005\n\n\nand just to prove to ourselves:\n\nsd(pwords$cracked)^2 == var(pwords$cracked)\n\n[1] TRUE\n\n\n\nIf a column of our dataset contains only numbers, R will typically just interpret it as a numeric variable. However, we should still be careful; remember what happens if we have just one erroneous entry in there - they can all change to be characters (surrounded by quotation marks):\n\nc(1,3,6,\"peppapig\",3)\n\n[1] \"1\"        \"3\"        \"6\"        \"peppapig\" \"3\"       \n\n\nWe can force a variable to be numeric by using as.numeric(), which will also coerce any non-numbers to be NA (not applicable):\n\nas.numeric(c(1,3,6,\"peppapig\",3))\n\n[1]  1  3  6 NA  3\n\n\nIf there is an NA in the variable, many functions like mean(), var() and sd() will not compute:\n\nx <- c(1, 3, 6, NA, 3)\nmean(x)\n\n[1] NA\n\n\nHowever, we can ask these functions to remove the NAs prior to the computation:\n\nmean(x, na.rm = TRUE)\n\n[1] 3.25"
  },
  {
    "objectID": "02a_measurement.html#boxplots",
    "href": "02a_measurement.html#boxplots",
    "title": "2A: Measurement & Distributions",
    "section": "Boxplots",
    "text": "Boxplots\nBoxplots provide a useful way of visualising the interquartile range (IQR). You can see what each part of the boxplot represents in Figure Figure 4.\n\n\n\n\n\nFigure 4: Anatomy of a boxplot\n\n\n\n\nWe can create a boxplot of our age variable using the following code:\n\n# Notice, we put strength on the x axis, making the box plot vertical. \n# If we had set aes(y = strength) instead, then it would simply be rotated 90 degrees \nggplot(data = pwords, aes(x = strength)) +\n  geom_boxplot()"
  },
  {
    "objectID": "02a_measurement.html#histograms",
    "href": "02a_measurement.html#histograms",
    "title": "2A: Measurement & Distributions",
    "section": "Histograms",
    "text": "Histograms\nNow that we have learned about the different measures of central tendency and of spread, we can look at how these map to how visualisations of numeric variables look.\nWe can visualise numeric data using a histogram, which shows the frequency of values which fall within bins of an equal width.\nTo do this, we’re going to use some new data, on 120 participants’ IQ scores (measured on the Wechsler Adult Intelligence Scale (WAIS)), their ages, and their scores on 2 other tests. The data are available at https://uoepsy.github.io/data/wechsler.csv\n\nwechsler <- read_csv(\"https://uoepsy.github.io/data/wechsler.csv\")\n\n\n# make a ggplot with the \"wechsler\" data. \n# on the x axis put the possible values in the \"iq\" variable,\n# add a histogram geom (will add bars representing the count \n# in each bin of the variable on the x-axis)\nggplot(data = wechsler, aes(x = iq)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\nWe can specifiy the width of the bins:\n\nggplot(data = wechsler, aes(x = iq)) + \n  geom_histogram(binwidth = 5)\n\n\n\n\n\n\n\n\nLet’s take a look at the means and standard deviations of participants’ scores on the other tests (the test1 and test2 variables).\nNote how nicely we can do this with our newfound tidyverse skills!\n\nwechsler %>% \n  summarise(\n    mean_test1 = mean(test1),\n    sd_test1 = sd(test1),\n    mean_test2 = mean(test2),\n    sd_test2 = sd(test2)\n  )\n\n# A tibble: 1 × 4\n  mean_test1 sd_test1 mean_test2 sd_test2\n       <dbl>    <dbl>      <dbl>    <dbl>\n1       49.3     7.15       51.2     14.4\n\n\nTests 1 and 2 have similar means (around 50), but the standard deviation of Test 2 is almost double that of Test 1. We can see this distinction in the visualisation below - the histograms are centered at around the same point (50), but the one for Test 2 is a lot wider than that for Test 1."
  },
  {
    "objectID": "02a_measurement.html#density",
    "href": "02a_measurement.html#density",
    "title": "2A: Measurement & Distributions",
    "section": "Density",
    "text": "Density\nIn addition to grouping numeric data into bins in order to produce a histogram, we can also visualise a density curve.\nBecause there are infinitely many values that numeric variables could take (e.g., 50, 50.1, 50.01, 5.001, …), we could group the data into infinitely many bins. This is essentially what we are doing with a density curve.\nYou can think of “density” as a bit similar to the notion of “relative frequency” (or “proportion”), in that for a density curve, the values on the y-axis are scaled so that the total area under the curve is equal to 1. In creating a curve for which the total area underneath is equal to one, we can use the area under the curve in a range of values to indicate the proportion of values in that range.\n\nggplot(data = wechsler, aes(x = iq)) + \n  geom_density()\n\n\n\n\n\n\n\n\n\nArea under the curve\nThink about the barplots we have been looking at in the exercises where we simulate dice rolling :\n\n# our function to simulate the roll of a die/some dice\ndice <- function(num = 1) {\n  sum(sample(1:6, num, replace=TRUE))\n}\n# simulate 1000 rolls of a single die\nroll1000 <- replicate(1000, dice(1))\n# tabulate and plot:\ntable(roll1000) %>%\n  barplot(.,ylab=\"count\")\n\n\n\n\n\n\n\n\nTo think about questions like “what proportion of 1000 rolls does the die land on 6?”, we are simply interested in the count of 6s divided by the count of all rolls:\n\ntab1000 <- table(roll1000)\ntab1000\n\nroll1000\n  1   2   3   4   5   6 \n162 169 167 189 152 161 \n\ntab1000[6] / sum(tab1000)\n\n    6 \n0.161 \n\n\nSo Another way of thinking of this is that we are just dividing the count in each category by the total number. Or, Put another way, imagine we divide the area of each bar by the total area. The area now sums to 1, and our question is asking about the ratio of the red area to the total area (grey + red):\n\n\n\n\n\n\n\n\n\nNothing really changes with a density curve! If we want to ask what proportion of our distribution of IQ scores is >120, then we are asking about the area under the curve that is to the right of 120:\n\n\n\n\n\n\n\n\n\nIt looks like about a third, maybe a little less. Let’s calculate this proportion directly:\n\nsum(wechsler$iq>110) / length(wechsler$iq)\n\n[1] 0.2\n\n\nIt might seem a little odd to think about area under the curve when we are asking about “what proportion of the data is …?”. If we have the data, then we can just calculate the answer (like we did above). However, a lot of statistics is really concerned with the probability of events. When we discuss probability, we move from talking about a specific set of observed data to thinking about a theoretical/mathematical model that defines the way in which data is generated. This where it becomes more useful to think about distributions in a more abstract sense.\nFor instance, with a fair six-sided die, we have a probability distribution (Figure 5) in which each side is given the probability \\(\\frac{1}{6}\\):\n\\[\n\\begin{gather*}\nP(x) = \\begin{cases}\n  \\frac{1}{6} & \\text{if $x \\in \\{1,2,3,4,5,6\\}$}\\\\\n  0 & \\text{otherwise.}\n  \\end{cases}\n\\end{gather*}\n\\]\nInstead of rolling a die, suppose that we are picking a person off the street and measuring their IQ. Given that IQ scales are designed to have a mean of 100 and standard deviation of 15, what is the probability that we pick a person with an IQ of greater than 110?\n\n\n\n\n\nFigure 5: Left: Discrete probability distribution of a fair six-sided die. Right: Continuous probability distribution of IQ scores"
  },
  {
    "objectID": "02b_sampling.html",
    "href": "02b_sampling.html",
    "title": "2B: Curves & Sampling",
    "section": "",
    "text": "We’ve seen some ways of describing and visualising the distributions of variables that we might observe when we collect data. Such a collection of observations on a single variable is often termed a “sample distribution”.\nAnother type of distribution that will prove to be very useful is a “probability distribution”.\n\nA probability distribution is the (mathematical) description of the probabilities of occurrences of observing the different possible outcomes.\n\nNote an important jump we are making is that we are moving from talking about distributions that we observe, to something more conceptual. Typically, this is because we want to talk more generally about the underlying process which generates the data.\nFor example, the function that governs the behaviour of rolling a single die is uniform in that each possible response has an equal probability (\\(\\frac{1}{6}\\)) of being observed (below left). When we collect data by actually rolling a die 100 times, we will observe a sample distribution (below right).\n\n\n\n\n\n\n\n\n\n\nUniformity\nWhen an equal probability is assigned to each possible response, we have what is known as the uniform distribution.\nFor a fair 6-sided die, the probability of the die landing on each side is 1/6, and the probabilities of all the possible responses sum to 1 (because it has to land on one of the sides).\n\n\n\n\n\n\n\n\n\nThe dice-rolling example is one involving a categorical distribution - i.e. data which has a discrete set of response options. We don’t have to use a 6-sided die - if it follows a uniform probability distribution, and there are \\(n\\) possible responses, then the probability of each response ocurring is \\(1/n\\).\nHowever, the uniform probability distribution can be relevant for a continuous numeric variable as well (e.g. something which as well as taking the values 4 and 5 can also take 4.1, 4.11, 4.1111111111, 4.764968473 etc.. - they can take any real value). We can preserve the idea that probability sums to 1 for this sort of variable by having the probability as \\(\\frac{1}{b-a}\\), where \\(a\\) and \\(b\\) are the lower and upper bounds of the response domain. Why? Because this makes the area of the distribution equal to 1 (area of a rectangle = width \\(\\times\\) height. \\((b-a) \\times \\frac{1}{(b-a)} = \\frac{b-a}{b-a} = 1)\\). This means we can compute areas of parts of the distribution in order to calculate probabilities!"
  },
  {
    "objectID": "02b_sampling.html#the-standard-normal-distribution",
    "href": "02b_sampling.html#the-standard-normal-distribution",
    "title": "2B: Curves & Sampling",
    "section": "The Standard Normal Distribution",
    "text": "The Standard Normal Distribution\nNote that if we translate our “IQ >120” to being in terms of standard deviations - \\(\\frac{120 - 100}{15} = 1\\frac{1}{3}\\) - then we can perform the same computations as we have done above, but comparing against against a normal distribution with mean of 0 and standard deviation of 1 (which are the defaults for the pnorm() function):\n\npnorm((120-100)/15, lower.tail = FALSE)\n\n[1] 0.09121122\n\n\n\n\n\n\n\nFigure 7: pnorm() with the ‘standard normal distribution’: the normal distribution with mean = 0 and sd = 1\n\n\n\n\nWhat we’re doing here is re-expressing the observed distribution into one which has mean of 0 and standard deviation of 1 - we are standardising them. This idea will become incredibly useful. For one thing it makes comparisons possible, for example, consider the two statements below:\n\n“I am 15 IQ points higher than average, and 24cm taller than average”\n“I am 1 standard deviation above the average IQ, and 2 standard deviations above average height”\n\nThe standard normal distribution - the normal distribution with mean = 0, sd = 1, is going to be seen a lot more frequently."
  },
  {
    "objectID": "03_ex.html",
    "href": "03_ex.html",
    "title": "Week 3 Exercises: T-tests",
    "section": "",
    "text": "Heights\n\n\nResearch Question Is the average height of students taking the USMR statistic course in Psychology at Edinburgh University in 2021/2022 is different from 165cm?\n\n\n\n\n\n\n\n\n\n\nThe data for students from all psychology statistics courses last year and USMR this year, are available at https://uoepsy.github.io/data/surveydata_allcourse22.csv.\n\n\nQuestion 6\n\n\nNo more manual calculations of test statistics and p-values for this week.\nConduct a one sample \\(t\\)-test to evaluate whether the average height of students taking the USMR courses in Psychology at Edinburgh University in 2022/23 is different from 165cm.\n\nHints:\n\nThis is real data, and real data is rarely normal! If you conduct a Shapiro-Wilk test, you may well find \\(p<.05\\) and conclude that your data is not normal.\nSo what do we do if a test indicates our assumptions are violated?\nWell, we should bear a couple of things in mind.\n\nA decision rule such as \\(p<.05\\) on Shapiro-Wilk test creates very dichotomous thinking for something which is in reality not black and white. Real life distributions are not either normal or non-normal. Plot the data, and make a judgement!\n\nAs it happens, the t-test is actually reasonably robust against slight deviations from normality! Plot your data and make a judgement!\nThe deeper you get into statistics, the more you discover that it is not simply a case of following step-by-step rules:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead in the data:\nWe need to filter it to just the USMR students this year\n\nsurvey_data <- read_csv(\"https://uoepsy.github.io/data/surveydata_allcourse22.csv\")\n\nusmr_data <- survey_data %>% \n  filter(course==\"usmr\", year==2021)\n\nDescriptives:\n\nusmr_data %>% \n  summarise(\n    mheight = mean(height, na.rm = T),\n    sdheight = sd(height, na.rm = T)\n  )\n\n# A tibble: 1 × 2\n  mheight sdheight\n    <dbl>    <dbl>\n1    168.     8.79\n\n\nAssumptions:\nTODO - update with new data The shapiro.test() suggests that our assumption of normality may be violated!! oh no!\n\nshapiro.test(usmr_data$height)\n\n\n    Shapiro-Wilk normality test\n\ndata:  usmr_data$height\nW = 0.96667, p-value = 0.04306\n\n\nHowever, visualisations are vital here. The histogram below does not look too bad to me.\n\nggplot(data = usmr_data, aes(x = height)) + \n  geom_histogram(bins=15) +\n  # adding our hypothesised mean\n  geom_vline(xintercept = 165)\n\n\n\n\n\n\n\n\nThe t.test is quite robust against slight violations of normality, and our data here doesn’t look too non-normal (this is a judgement call here - over time you will start to get a sense of what you might deem worrisome in these plots!).\nConduct test\n\nt.test(usmr_data$height, mu = 165, alternative = \"two.sided\")\n\n\n    One Sample t-test\n\ndata:  usmr_data$height\nt = 2.5707, df = 75, p-value = 0.01213\nalternative hypothesis: true mean is not equal to 165\n95 percent confidence interval:\n 165.5837 169.6029\nsample estimates:\nmean of x \n 167.5933 \n\n\n\n\n\n\n\nNames and Tips\n\n\nResearch Question Can a server earn higher tips simply by introducing themselves by name when greeting customers?\n\nResearchers investigated the effect of a server introducing herself by name on restaurant tipping. The study involved forty, 2-person parties eating a $23.21 fixed-price buffet Sunday brunch at Charley Brown’s Restaurant in Huntington Beach, California, on April 10 and 17, 1988. Each two-person party was randomly assigned by the waitress to either a name or a no name introduction condition using a random mechanism. The waitress kept track of the two-person party condition and how much the party paid at the end of the meal.\nThe data are available at https://uoepsy.github.io/data/gerritysim.csv. (This is a simulated example based on Garrity and Degelman (1990))\n\n\nQuestion 7\n\n\nConduct an independent samples \\(t\\)-test to assess whether higher tips are earned when the server introduces themselves by name, in comparison to when they do not.\n\nHints:\n\nWe’ll want to check the normality (either visually or with a test) of the variable of interest for each group.\n\nSome researchers suggest using the Welch t-test by default. This means you can relax the assumption of equal variances in the groups. If you want to test whether two variances are equal, try the var.test() function.\n\n\n\n\n\n\nRead in the data\n\ntipdata <- read_csv(\"https://uoepsy.github.io/data/gerritysim.csv\")\n\n#make a \"tip\" column, which is minus the meal amount\ntipdata <- \n  tipdata %>% mutate(\n    tip = paid - 23.21\n  )\n\nDescriptives and a plot\n\ntipdata %>% \n  group_by(condition) %>%\n  summarise(\n    meantip = mean(tip),\n    sdtip = sd(tip)\n  )\n\n# A tibble: 2 × 3\n  condition meantip sdtip\n  <chr>       <dbl> <dbl>\n1 name         4.94  1.88\n2 no name      3.18  1.35\n\nggplot(data = tipdata, aes(x = tip, y = condition)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nAssumptions\nAccording to these tests, we have normally distributed data for both groups, with equal variances.\n\nshapiro.test(tipdata$tip[tipdata$condition==\"name\"])\n\n\n    Shapiro-Wilk normality test\n\ndata:  tipdata$tip[tipdata$condition == \"name\"]\nW = 0.96267, p-value = 0.5985\n\nshapiro.test(tipdata$tip[tipdata$condition==\"no name\"])\n\n\n    Shapiro-Wilk normality test\n\ndata:  tipdata$tip[tipdata$condition == \"no name\"]\nW = 0.94405, p-value = 0.2857\n\nwith(tipdata, var.test(tip ~ condition))\n\n\n    F test to compare two variances\n\ndata:  tip by condition\nF = 1.9344, num df = 19, denom df = 19, p-value = 0.1595\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.7656473 4.8870918\nsample estimates:\nratio of variances \n           1.93437 \n\n\nConduct test:\nBecause the variances do not appear to be unequal, we can actually use the standard t-test with var.equal = TRUE if we want. However, we’ll continue with the Welch t-test.\nRemember that our alternative hypothesis here is that the average tips in the “name” condition is greater than in the “no name” condition.\nR will take the levels in order here (alphabetically), and assume that the alternative is for that group, so we use alternative = \"greater\" here to say that the alternative is \\(\\text{name}-\\text{no name} > 0\\).\n\nwith(tipdata, t.test(tip ~ condition, alternative = \"greater\"))\n\n\n    Welch Two Sample t-test\n\ndata:  tip by condition\nt = 3.4117, df = 34.502, p-value = 0.0008314\nalternative hypothesis: true difference in means between group name and group no name is greater than 0\n95 percent confidence interval:\n 0.8893105       Inf\nsample estimates:\n   mean in group name mean in group no name \n               4.9450                3.1825"
  },
  {
    "objectID": "03a_inference.html",
    "href": "03a_inference.html",
    "title": "3A: Foundations of Inference",
    "section": "",
    "text": "We use statistics primarily to estimate parameters in a population. Whether we are polling people to make predictions about the proportion of people who will vote for a certain party in the next election, or conducting a medical trial and assessing the change in blood pressure for patients given drug X vs those given a placebo in order tp decide whether to put the drug into circulation in health service.\nWe have seen this already last week: We observed a sample of peoples’ life satisfaction ratings (scale 0-100), and we wanted to use these to make some statement about the wider population."
  },
  {
    "objectID": "03a_inference.html#test-statistics-p-values",
    "href": "03a_inference.html#test-statistics-p-values",
    "title": "3A: Foundations of Inference",
    "section": "Test-statistics & p-values",
    "text": "Test-statistics & p-values\nThe p-value is a formal way of testing a statistic against a null hypothesis. To introduce the p-value, instead of thinking first about what we have observed in our sample, we need to think about what we would expect to observe if our null hypothesis is true.\nWith our Stroop Task example, our null hypothesis is that there is no difference between matching and mismatching conditions (\\(H_0: \\mu = 0\\)). Under \\(H_0\\), the average ‘mismatching-matching’ score in the population is zero, and we would expect most of the samples we might take to have a mean ‘mismatching-matching’ score of close to this (not exactly 0, but centered around 0). We saw above that we could express the sampling distribution of means taken from samples of size \\(n=131\\) using the standard error. Under \\(H_0\\) we would expect the samples of \\(n=131\\) we might take to have means that follow something like the distribution in Figure 3. We can think of this as the sampling distribution of \\(\\bar{x}\\), but centered on our null hypothesis (in this case, \\(\\mu = 0\\)). We call this the ‘null distribution’.\n\n\n\n\n\nFigure 3: Sampling distribution for mean of sample size 131, assuming population mean = 0. Observed sample mean shown in red\n\n\n\n\n\nTest-statistic\nThe first step now is to create a test-statistic. That is, a statistic that tell us, in some standardised units, how big our observed effect is from the null hypothesis (i.e. in this case, how far from \\(\\mu=0\\) our sample mean is).\nThe straightforward way to do this is to express how far away from \\(\\mu=0\\) our sample mean is in terms of standard errors. We’ll call our test statistic \\(Z\\):\n\\[\nZ = \\frac{\\text{estimate}-\\text{null}}{SE}\n\\]\nOur mean and standard error are:\n\nmean(stroopdata$diff)\n\n[1] 2.402977\n\nsd(stroopdata$diff) / sqrt(nrow(stroopdata))\n\n[1] 0.4382302\n\n\nSo our test-statistic is\n\\[\nZ = \\frac{2.40 - 0}{0.438} = 5.479\n\\]\n\n\np-value\nWe can now calculate how likely it is to see values at least as extreme as our observed test-statistic, if the null is true. If the null hypothesis is true (there was no ‘mismatching-matching’ difference) then we would expect Z-statistics to be normally distributed with a mean of 0 and a standard deviation of 1.\nWe have seen the process of how we might calculate a probability from a distribution like this already: the pnorm() function gives us the area of a distribution to the one side of a given value:\n\npnorm(??, mean = 0, sd = 1, lower.tail = FALSE)\n\n\n\n\n\n\nFigure 4: pnorm() provides us with a p-value for a z-statistic\n\n\n\n\nRemember, our Z-statistic we calculated above is 5.479. If the null hypothesis were true then the probability that we would see a sample (\\(n=131\\)) with a Z-statistic at least that large is:\n\npnorm(5.479, lower.tail = FALSE)\n\n[1] 2.138682e-08\n\n\nwhich is R’s way of printing 0.00000002138682.\nThere is one last thing, and that the direction of our hypotheses. Recall from earlier that we stated \\(H_0: \\mu = 0\\) and \\(H_1: \\mu \\neq 0\\). This means that we are interested in the probability of getting results this far away from 0 in either direction.\nWe are interested in both tails:\n\n2 * pnorm(5.479, lower.tail = FALSE)\n\n[1] 4.277364e-08\n\n\n\n\n\n\n\nFigure 5: 2*pnorm gives the two tails\n\n\n\n\n\np-value\nThe p-value is the probability4 that we observe a test statistic at least as extreme as the one we observed, assuming the null hypothesis \\(H_0\\) to be true."
  },
  {
    "objectID": "03a_inference.html#making-decisions",
    "href": "03a_inference.html#making-decisions",
    "title": "3A: Foundations of Inference",
    "section": "Making Decisions",
    "text": "Making Decisions\nNow that we have our p-value of 0.00000004277364, we need to use it to make a decision about our hypotheses.\nTypically, we pre-specify the probability level at which we will consider results to be so unlikely to have arisen from the null distribution that we will take them as evidence to reject the null hypothesis. This pre-specified level is commonly referred to as \\(\\alpha\\) (“alpha”). Setting \\(\\alpha = 0.05\\) means that we will reject \\(H_0\\) when we get a result which is extreme enough to only occur 0.05 (5%) of the time or less if the \\(H_0\\) is true.\nIn our case, 0.00000004277364 \\(< 0.05\\), so we reject the null hypothesis that there is no difference in the mismatching/matching conditions of the Stroop Task.\n\nThere’s a lot of convention to how we talk about NHST, but the typical process is as follows:\n\nClearly specify the null and alternative hypotheses.\n\nSpecify \\(\\alpha\\)\nCalculate statistic\nCompute p-value\n\nIf \\(p<\\alpha\\), then reject the null hypothesis.\nIf \\(p\\geq\\alpha\\), then fail to reject* the null hypothesis.\n\n\n*Note, we don’t “accept” anything, we just “reject” or “fail to reject” the null hypothesis. Think of it like a criminal court, and we are trying the null hypothesis - \\(H_0\\) is “innocent until proven guilty”."
  },
  {
    "objectID": "03a_inference.html#making-mistakes",
    "href": "03a_inference.html#making-mistakes",
    "title": "3A: Foundations of Inference",
    "section": "Making Mistakes",
    "text": "Making Mistakes\nWhether our eventual decision is a) reject the null hypothesis, or b) fail to reject the null hypothesis, there’s always a chance that we might be making a mistake. There are actually two different types of mistakes we might make. An often used analogy (Figure 6) is the idea of criminal trials in which an innocent person can be wrongfully convicted, or a guilty person can be set free.\n\n\n\n\n\nFigure 6: Making errors in NHST is like a criminal court making errors in its decision on the defendent\n\n\n\n\nWe can actually quantify the chance that we’re making errors in our different decisions. Thinking back to the definition of a p-value, it is the probability of seeing our results if the null hypothesis is true. If we make a decision to reject the null hypothesis based on whether \\(p<\\alpha\\), then the probability that this decision is a mistake is \\(\\alpha\\).\nThe probability that we the other sort of error (failing to reject the null hypothesis when the null hypothesis is actually false), we denote with \\(\\beta\\).\nDoing statistics is partly a matter of balancing these possibilities. If we used a very low \\(\\alpha\\)-level (e.g. we reject when \\(p<.0001\\) rather than \\(p<.05\\)) then we increase the probability of making a type II error.\n\nTypes of Errors in NHST\n\n\n\n\n\nFigure 7: Probabilities of making different errors in NHST\n\n\n\n\n\n\nPower (\\(1-\\beta\\))\nA key notion in conducting studies is “statistical power”. Studies want to increase the probability of correctly rejecting the null hypothesis (i.e. correctly identifying that there is something more than chance going on).\nThis is the bottom right cell of the tables in Figure 6 and Figure 7. We know that this will depend on the \\(\\alpha\\)-level that we choose, but there are other important factors that influence \\(1-\\beta\\):\n\npower increases as sample size increases\n\ne.g. it’s easier to determine that cats weigh less than dogs if we measure 100 animals vs if we measure only 10 animals\n\npower increases the farther away the true value is from the null hypothesis value\n\ne.g. it’s easier to determine that cats weigh less than elephants than it is to determine that cats weigh less than dogs"
  },
  {
    "objectID": "03b_inference2.html",
    "href": "03b_inference2.html",
    "title": "Practical Inference",
    "section": "",
    "text": "In the previous section we saw how we can apply the logic of Null Hypothesis Significance Testing (NHST), allowing us to draw inferences about parameters in the population, based on statistics computed on the sample we have collected.\nWhile in practice NHST follows the logic described above, there is something important that we have been sweeping under the carpet.\nIn our estimation of the standard error we have used the formula that includes \\(\\sigma\\), which refers to the population standard deviation. However, we never know this value (because we don’t have data for the population), so we have been using the sample standard deviation \\(s\\) instead. This is an approximation, and might be okay when we have a very large \\(n\\) (meaning \\(s\\) provides accurate estimate of \\(\\sigma\\)), but in practice is not always feasible.\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}} \\approx \\frac{s}{\\sqrt{n}}\n\\]"
  },
  {
    "objectID": "03b_inference2.html#one-sample-t-test",
    "href": "03b_inference2.html#one-sample-t-test",
    "title": "Practical Inference",
    "section": "One sample t-test",
    "text": "One sample t-test\n\nPurpose\nThe one sample t-test is what we have already seen above. We use it to test whether the mean is different from/greater than/less than some hypothesised value.\n\nExamples:\n\nIs the mean age of USMR students different from 20?\nIs the mean IQ different from 100?\n\nDo people read more than 250 words per minute?\n\n\nAssumptions:\n\nThe data are continuous (not discrete)\nThe data are independent (i.e. the value of a datapoint does not depend on the value of another datapoint in any way)\nThe data are normally distributed OR the sample size is large enough (rule-of-thumb n = 30) and the data are not strongly skewed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch Question: Do people read more than 250 words per minute?\n\nFifty participants were recruited and tasked with reading a passage of text that was 2000 words long. Their reading times (in words per minute) was recorded, and these are accessible at https://uoepsy.github.io/data/usmr_tread.csv.\n\nwpmtime <- read_csv(\"https://uoepsy.github.io/data/usmr_tread.csv\")\nhead(wpmtime)\n\n# A tibble: 6 × 2\n  id      wpm\n  <chr> <dbl>\n1 ppt_1   307\n2 ppt_2   265\n3 ppt_3   205\n4 ppt_4   300\n5 ppt_5   207\n6 ppt_6   300\n\n\n\n\n The quick and easy way\n\n\nBelow are some quick descriptives, and we should also make sure that our distribution is roughly or less normally distributed:\n\nmean(wpmtime$wpm)\n\n[1] 258.36\n\nsd(wpmtime$wpm)\n\n[1] 32.08646\n\nhist(wpmtime$wpm)\n\n\n\n\n\n\n\nshapiro.test(wpmtime$wpm)\n\n\n    Shapiro-Wilk normality test\n\ndata:  wpmtime$wpm\nW = 0.9636, p-value = 0.1258\n\n\nPaying careful attention to the research question (“Do people read more than 250 words per minute?”), our null hypothesis here is that reading time is \\(\\leq 250\\) words per minute (wpm), and our alternative hypothesis is that it is \\(>250\\) wpm.\nWe specify the alternative in the t.test() function:\n\nt.test(wpmtime$wpm, mu = 250, alternative = \"greater\")\n\n\n    One Sample t-test\n\ndata:  wpmtime$wpm\nt = 1.8423, df = 49, p-value = 0.03574\nalternative hypothesis: true mean is greater than 250\n95 percent confidence interval:\n 250.7523      Inf\nsample estimates:\nmean of x \n   258.36 \n\n\n\nA one-sample t-test was conducted in order to determine if the average reading time was significantly (\\(\\alpha=.05\\)) higher than 250 words per minute (wpm).\nThe sample of 50 participants read on average at 258 words per minute (Mean=258, SD=32). This was significantly above 250 (\\(t(49)=1.84, p = .036\\), one-tailed).\n\n\n\n\n\n Manually\n\n\nOur test-statistic is calculated as\n\\[\nt =  \\frac{\\bar x - \\mu_0}{\\frac{s}{\\sqrt{n}}}\n\\]\nThere’s a lot of brackets here, so go through it piece by piece if you are unsure of how it matches to the formula above\n\n(mean(wpmtime$wpm) - 250 ) / (sd(wpmtime$wpm) / sqrt(nrow(wpmtime)))\n\n[1] 1.842338\n\n\nThe test we are performing is against the null hypothesis that \\(\\mu_0 \\leq 250\\). So we will only reject the null hypothesis if we get a test statistic indicating the mean is \\(>250\\). This means that our p-value will be just the one tail of the \\(t\\)-distribution:\n\npt(1.842338, df = 49, lower.tail = FALSE)\n\n[1] 0.0357404"
  },
  {
    "objectID": "03b_inference2.html#two-sample-t-test",
    "href": "03b_inference2.html#two-sample-t-test",
    "title": "Practical Inference",
    "section": "Two sample t-test",
    "text": "Two sample t-test\n\nPurpose\nThe two sample t-test is used to test whether the mean of one group is different from/greater than/less than the mean of another.\n\nExamples:\n\nIs the mean age of cat people different from the mean age of dog people?\nDo people who identify as “morning people” have a higher average rating of sleep quality than those who identify as “evening people”?\nIs the average reaction time different between people who do and don’t drink caffeinated drinks?\n\n\nAssumptions:\n\nThe data are continuous (not discrete)\nThe data are independent (i.e. the value of a datapoint does not depend on the value of another datapoint in any way)\nThe data are normally distributed for each group, OR the sample size is large enough (rule-of-thumb n = 30) and the data are not strongly skewed\nThe variance is equal across groups*.\n\n*We can relax this assumption by using an adjusted test called the “Welch \\(t\\)-test”, which calculates the standard error slightly differently, and estimates the degrees of freedom differently too. This is actually the default in R, and we change this easily in R using t.test(...., var.equal = FALSE/TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch Question: Is the average reaction time different between people who do and don’t drink caffeinated drinks?\n\nOne hundred participants were recruited and completed a simple reaction time task. They were also surveyed on whether they regularly drank caffeine in any form. The data are accessible at https://uoepsy.github.io/data/usmr_tcaff.csv.\n\ntcaff <- read_csv(\"https://uoepsy.github.io/data/usmr_tcaff.csv\")\nhead(tcaff)\n\n# A tibble: 6 × 2\n     rt caff \n  <dbl> <chr>\n1  482. yes  \n2  389. yes  \n3  484. no   \n4  601. no   \n5  409. yes  \n6  368. no   \n\n\n\n\n The quick and easy way\n\n\nFirst some quick descriptives, and a plot:\n\ntcaff %>% \n  group_by(caff) %>%\n  summarise(\n    m = mean(rt),\n    s = sd(rt)\n  )\n\n# A tibble: 2 × 3\n  caff      m     s\n  <chr> <dbl> <dbl>\n1 no     408.  88.9\n2 yes    465. 109. \n\n\n\nggplot(tcaff, aes(x = rt)) +\n  geom_histogram() + \n  facet_wrap(~caff)\n\n\n\n\n\n\n\n\nThe data look fairly close to normally distributed for each group here. One thing to note is that the variances look like they may be different between the two groups. The caffeine drinkers’ reaction time’s have a standard deviation of 109ms, and the non-caffeine drinkers have an sd of only 89ms.\nHowever, we’ll perform the Welch t-test here, which doesn’t require us to assume equal variances.\nWe can give R the two sets of data in two ways. Either by extracting the relevant entries:\n\nt.test(x = tcaff$rt[tcaff$caff==\"no\"], \n       y = tcaff$rt[tcaff$caff==\"yes\"])\n\nOr using the formula notation, with the ~ (“tilde”) symbol. In R, you can interpret y ~ x as “y is modeled as a function of x”. By splitting the numeric values (rt variable) by the categories of the caff variable, we can conduct a \\(t\\)-test using:\n\nt.test(rt ~ caff, data = tcaff)\n\n\n    Welch Two Sample t-test\n\ndata:  rt by caff\nt = -2.8497, df = 93.971, p-value = 0.005377\nalternative hypothesis: true difference in means between group no and group yes is not equal to 0\n95 percent confidence interval:\n -96.20205 -17.19423\nsample estimates:\n mean in group no mean in group yes \n         408.0505          464.7486 \n\n\n\nAn Welch two sample t-test was used to assess whether the mean reaction time of people who regularly drink caffeine (\\(n = 60\\)) was different to that of people who do not (\\(n=40\\)). There was a significant difference in average reaction time between the caffeine (Mean=465; SD=109) and non-caffeine (Mean=408; SD=89) groups (\\(t(94)=-2.85, p = .005\\), two-tailed). Therefore, we reject the null hypothesis that there is no difference in reaction times between caffeine drinkers and non-caffeine drinkers.\n\n\nCode\nggplot(tcaff, aes(x = caff, y = rt)) +\n  geom_boxplot()+\n  labs(x=\"drinks caffeine\",y=\"reaction time (ms)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Manually\n\n\nOur test statistic here is:\n\\[\n\\begin{align}\n& t =  \\frac{\\bar x_1 - \\bar x_2}{SE}\\\\\n\\ \\\\\n& \\text{where:} \\\\\n& \\bar x_1 : \\text{sample mean group 1} \\\\\n& \\bar x_2 : \\text{sample mean group 2} \\\\\n& SE : \\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}} \\\\\n& s_1 : \\text{sample standard deviation of group 1} \\\\\n& s_2 : \\text{sample standard deviation of group 2} \\\\\n& n_1 : \\text{sample size group 1} \\\\\n& n_2 : \\text{sample size group 2} \\\\\n\\end{align}\n\\]\nWe can calculate each part:\n\ntcaff %>%\n  group_by(caff) %>%\n  summarise(\n    xbar = mean(rt),\n    s = sd(rt),\n    s2 = var(rt),\n    n = n()\n  )\n\n# A tibble: 2 × 5\n  caff   xbar     s     s2     n\n  <chr> <dbl> <dbl>  <dbl> <int>\n1 no     408.  88.9  7906.    40\n2 yes    465. 109.  11892.    60\n\n\nplugging these bits in gives us:\n\\[\n\\begin{align}\nSE & = \\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}} \\\\\n& = \\sqrt{\\frac{7906}{40} + \\frac{11892}{60}} \\\\\n& = \\sqrt{395.85} \\\\\n& = 19.9\n\\end{align}\n\\]\nand\n\\[\n\\begin{align}\n& t =  \\frac{\\bar x_1 - \\bar x_2}{SE} \\\\\n\\qquad \\\\\n& =  \\frac{408 - 465}{19.9} \\\\\n\\qquad \\\\\n& = -2.86 \\\\\n\\end{align}\n\\]\nOur \\(p\\)-value is determined against a \\(t\\)-distribution with a specific number of degrees of freedom. We are estimating two means here, the standard two-sample t-test uses \\(df = n-2\\). However, the Welch t-test, which we performed quickly with t.test(), where we didn’t assume equal variances, makes the calculation of the degrees of freedom much more complicated.\nUsing the same degrees of freedom as was used in the quick use of t.test() above, we get out our same p-value (or thereabouts - we have some rounding error):\n\n2*pt(abs(-2.86), df = 93.971, lower.tail = FALSE)\n\n[1] 0.005219781"
  },
  {
    "objectID": "03b_inference2.html#paired-sample-t-test",
    "href": "03b_inference2.html#paired-sample-t-test",
    "title": "Practical Inference",
    "section": "Paired sample t-test",
    "text": "Paired sample t-test\n\nPurpose\nThe paired sample t-test is used to test whether the mean difference between two sets of paired observations is different from 0.\n\nExamples:\n\nIs the mean cognitive score of participants at age 60 different from when they are re-tested at age 70?\n\nAre scores on test 1 different on average from scores on test 2 (with participants completing both tests).\n\n\nAssumptions:\n\nThe data are continuous (not discrete)\nThe data are independent (i.e. the value of a datapoint does not depend on the value of another datapoint in any way)\nThe differences are normally distributed OR the sample size is large enough (rule-of-thumb n = 30) and the data are not strongly skewed\n\n\n\n\nResearch Question: Is the mean cognitive score of participants at age 60 different from when they are re-tested at age 70?\n\nAddenbrooke’s Cognitive Examination-III (ACE-III) is a brief cognitive test that assesses five cognitive domains: attention, memory, verbal fluency, language and visuospatial abilities. The total score is 100 with higher scores indicating better cognitive functioning. A research project is examining changes in cognitive functioning with age, and administers the ACE-III to a set of participants at age 60, then again at age 70. The data is accessible at https://uoepsy.github.io/data/usmr_tcaff.csv.\n\nacedata <- read_csv(\"https://uoepsy.github.io/data/acedata.csv\")\nhead(acedata)\n\n# A tibble: 6 × 3\n  participant ace_60 ace_70\n  <chr>        <dbl>  <dbl>\n1 sub1            93     85\n2 sub2            95     92\n3 sub3            93     90\n4 sub4            93     95\n5 sub5            96     88\n6 sub6            91     85\n\n\n\n\n The paired t test is the one sample t test in disguise\n\n\nWe can either perform this with the data exactly as it is:\n\nt.test(x = acedata$ace_60, y = acedata$ace_70, \n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  acedata$ace_60 and acedata$ace_70\nt = 2.2542, df = 24, p-value = 0.03359\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.2093364 4.7506636\nsample estimates:\nmean difference \n           2.48 \n\n\nOr we can compute the differences, and perform a one sample test on the mean of those differences being different from 0.\nIt’s just the same result:\n\nacedata <- acedata %>%\n  mutate(diff_score = ace_60 - ace_70)\n\nt.test(acedata$diff_score, mu = 0)\n\n\n    One Sample t-test\n\ndata:  acedata$diff_score\nt = 2.2542, df = 24, p-value = 0.03359\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.2093364 4.7506636\nsample estimates:\nmean of x \n     2.48"
  },
  {
    "objectID": "04_ex.html",
    "href": "04_ex.html",
    "title": "Week 4 Exercises: Chi-Square Tests",
    "section": "",
    "text": "Eye-Colours\n\n\nResearch Question: Do the proportions of people with different eye-colours correspond to those suggested by the internet?\n\nAccording one part of the internet (that reliable source of information!), 76% of people in the world have brown eyes, 10% have blue, 5% hazel, 5% amber, 2% green, 1% grey, and 1% have some other eye colouring (red/violet/heterochromia).\nWe’ll use the same data from the course survey’s here:\n\nsurvey_data <- \n  read_csv(\"https://uoepsy.github.io/data/surveydata_allcourse22.csv\")\n\n\n\nQuestion 7\n\n\nPerform a \\(\\chi^2\\) goodness of fit test to assess the extent to which our sample of students conform to this theorised distribution of eye-colours.\nNo need to do this manually - once is enough. Just go straight to using the chisq.test() function.\n\nHint: Try using chisq.test(..., p = c(?,?,?,...) ).\nWe saw this in the example goodness of fit test, 4A #example\n\n\n\n\n\nLet’s look at the observed counts:\n\ntable(survey_data$eyecolour)\n\n\namber  blue brown green  grey hazel other \n    3    93   176    52     8    43    15 \n\n\nOur theoretical probabilities of different eye colours must match the order in the table which we give chisq.test(). They must also always sum to 1.\n\nchisq.test(table(survey_data$eyecolour), p = c(.05,.1,.76,.02,.01,.05,.01))\n\n\n    Chi-squared test for given probabilities\n\ndata:  table(survey_data$eyecolour)\nX-squared = 452.33, df = 6, p-value < 2.2e-16\n\n\n\n\n\n\nQuestion 8\n\n\nWhat are the observed proportions of our sample with each eyecolour?\nCan you figure out how to use the prop.table() function?\n\n\n\n\nFrom the help documentation (?prop.table()), we see that we can pass prop.table() the argument x, which needs to be a table.\n\nprop.table(table(survey_data$eyecolour))*100\n\n\n     amber       blue      brown      green       grey      hazel      other \n 0.7692308 23.8461538 45.1282051 13.3333333  2.0512821 11.0256410  3.8461538 \n\n\n\nbarplot(prop.table(table(survey_data$eyecolour))*100)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJokes and Tips\n\nData: TipJokes\n\nResearch Question: Can telling a joke affect whether or not a waiter in a coffee bar receives a tip from a customer?\n\nA study published in the Journal of Applied Social Psychology1 investigated this question at a coffee bar of a famous seaside resort on the west Atlantic coast of France. The waiter randomly assigned coffee-ordering customers to one of three groups. When receiving the bill, one group also received a card telling a joke, another group received a card containing an advertisement for a local restaurant, and a third group received no card at all.\nThe data are available at https://uoepsy.github.io/data/TipJoke.csv.\nThe dataset contains the variables:\n\nCard: None, Joke, Ad.\nTip: 1 = The customer left a tip, 0 = The customer did not leave tip.\n\n\n\nQuestion 9\n\n\nProduce a plot and a table to display the relationship between whether or not the customer left a tip, and what (if any) card they received alongside the bill.\nDon’t worry about making it all pretty. Mosaic plots in R are a bit difficult.\n\nHint:\nplot(table(...)) will give you something. You can see one in the example \\(\\chi^2\\) test of independence,4A #example-1.\n\n\n\n\n\n\ntipjoke <- read_csv('https://uoepsy.github.io/data/TipJoke.csv')\n\ntable(tipjoke$Card, tipjoke$Tip)\n\n      \n        0  1\n  Ad   60 14\n  Joke 42 30\n  None 49 16\n\nplot(table(tipjoke$Card, tipjoke$Tip))\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nWhat would you expect the cell counts to look like if there were no relationship between what the waiter left and whether or not the customer tipped?\n\n\n\n\nIn total, 60 customers tipped (14+30+16), and 151 did not. So overall, 0.28 (\\(\\frac{60}{(60+151)}\\)) of customers tip.\n74 customers got an Ad card, 72 customers got a Joke, and 65 got None. If this were independent of whether or not they left a tip, we would expect equal proportions of tippers in each group.\nSo we would expect 0.28 of each group to leave a tip.\nYou can think about observed vs expected by looking at the two-way table along with the marginal row and column totals given:\n\n\n\n\n \n  \n      \n    0 \n    1 \n     \n  \n \n\n  \n    Ad \n     \n     \n    74 \n  \n  \n    Joke \n     \n     \n    72 \n  \n  \n    None \n     \n     \n    65 \n  \n  \n     \n    151 \n    60 \n    211 \n  \n\n\n\n\n\nFor a given cell of the table we can calculate the expected count as \\(\\text{row total} \\times \\frac{\\text{column total}}{\\text{samplesize}}\\):\nExpected:\n\n\n\n\n \n  \n      \n    0 \n    1 \n     \n  \n \n\n  \n    Ad \n    52.96 \n    21.04 \n    74 \n  \n  \n    Joke \n    51.53 \n    20.47 \n    72 \n  \n  \n    None \n    46.52 \n    18.48 \n    65 \n  \n  \n     \n    151.00 \n    60.00 \n    211 \n  \n\n\n\n\n\n(If you’re wondering how we do this in R, we saw in the lectures briefly a complicated bit of code using %o% which could do this for us):\n\nt <- tipjoke %>%\n  select(Card, Tip) %>% table()\n\ne <- rowSums(t) %o% colSums(t) / sum(t)\ne\n\n            0        1\nAd   52.95735 21.04265\nJoke 51.52607 20.47393\nNone 46.51659 18.48341\n\n\n\n\n\n\nQuestion 11\n\n\nJust like we gave the chisq.test() function a table of observed frequencies when we conducted a goodness of fit test in earlier exercises, we can give it a two-way table of observed frequencies to conduct a test of independence.\nTry it now.\n\n\n\n\n\nchisq.test(table(tipjoke$Card, tipjoke$Tip))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(tipjoke$Card, tipjoke$Tip)\nX-squared = 9.9533, df = 2, p-value = 0.006897\n\n\n\n\n\n\n\n\n\n\nSome RMarkdown\nFor one of the \\(t\\)-tests we saw in the previous week’s exercises, we can use an RMarkdown document in which we write our results so that they get compiled to look nice and pretty:\n\n\nWriting this\n\n\n\n\n\n\n\n\n\n\n\nCompiles to this\n\nA one-sided one-sample t-test was conducted in order to determine if the average score on the Procrastination Assessment Scale for Students (PASS) for a sample of 20 students at Edinburgh University was significantly lower (\\(\\alpha = .05\\)) than the average score obtained during development of the PASS.\nEdinburgh University students scored lower (Mean = 30.7, SD = 3.31) than the score reported by the authors of the PASS (Mean = 33). This difference was statistically significant (t(19)=-3.11, p < .05, one-tailed).\n\n\n\nThis is one of the huge benefits of RMarkdown. Imagine we collected more data - we wouldn’t have to edit all the results, we could simply recompile and they would update for us!\nNote how it works:\n\nthe code chunk saves the results of the t.test() function as a named object res2.\nin text, the backticks `r … … … ` are used to execute small bits of R code, and include the output within the text. For instance, the line `r res2$statistic %>% round(2)` gets the t-statistic from the results, and rounds it to 2 decimal places, which get’s printed out as -3.11.\nthe bits between the dollar signs, e.g. $\\alpha$ will get printed as mathematical symbols such as \\(\\alpha\\).\n\n\nRMarkdown documents are self-contained.\nYou need to to put everything that is needed to reproduce your analysis in the correct order.\nFor instance, if you have used the console (bottom left window) to define an object peppapig <- 30, you will have an object in your environment (top right window) called “peppapig” which has the value 30.\nIf you were to refer to that object in your RMarkdown document, you will be able to run a line of code such as peppapig/10 because it will find the “peppapig” object in your environment. BUT you won’t be able to compile the document because it “starts fresh” (i.e., compiles within its own environment). In order for it to compile, you would need to define what “peppapig” is inside your document, and before the document then refers to it.\nThe same applies with using functions in from packages. The RMarkdown document needs to know what packages to load before it uses functions from them. Just because you yourself have loaded a package in your session, it does not mean the compilation process for your RMarkdown has access to it.\n\nIf you want some extra explanations on these aspects of RMarkdown, then please see Lessons 0-3 of our Rmd-bootcamp.\n\nQuestion 12\n\n\nCan you create an RMarkdown document which:\n\nReads in the https://uoepsy.github.io/data/TipJoke.csv data.\nConducts and reports a \\(\\chi^2\\) test of independence examining whether telling a joke affect whether or not a waiter in a coffee bar receives a tip from a customer.\nSuccessfully compiles (“knits”) into an .html file.\n\n\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nGueaguen, N. (2002). The Effects of a Joke on Tipping When It Is Delivered at the Same Time as the Bill. Journal of Applied Social Psychology, 32(9), 1955-1963.↩︎"
  },
  {
    "objectID": "04a_chisq.html",
    "href": "04a_chisq.html",
    "title": "4A: Chi-Square Tests",
    "section": "",
    "text": "Here we continue with our brief explainers of different basic statistical tests. The past few weeks have focused on tests for numeric outcome variables, where we have been concerned with the mean of that variable (e.g. whether that mean is different from some specific value, or whether it is different between two groups). We now turn to investigate tests for categorical outcome variables.\nThe test-statistics for these tests (denoted \\(\\chi^2\\), spelled chi-square, pronounced “kai-square”) are obtained by adding up the standardized squared deviations in each cell of a table of frequencies:\n\\[\n\\chi^2 = \\sum_{all\\ cells} \\frac{(\\text{Observed} - \\text{Expected})^2}{\\text{Expected}}\n\\]\nwhere:"
  },
  {
    "objectID": "04a_chisq.html#example",
    "href": "04a_chisq.html#example",
    "title": "4A: Chi-Square Tests",
    "section": "Example",
    "text": "Example\n\n\n\n\n\nResearch Question: Have proportions of adults suffering no/mild/moderate/severe depression changed from 2019?\n\nIn 2019, it was reported that 80% of adults (18+) experienced no symptoms of depression, 12% experienced mild symptoms, 4% experienced moderate symptoms, and 4% experienced severe symptoms.\nThe dataset is accessible at https://uoepsy.github.io/data/usmr_chisqdep.csv contains data from 1000 people to whom the PHQ-9 depression scale was administered in 2022.\n\ndepdata <- read_csv(\"https://uoepsy.github.io/data/usmr_chisqdep.csv\") \nhead(depdata)\n\n# A tibble: 6 × 3\n  id    dep    fam_hist\n  <chr> <chr>  <chr>   \n1 ID1   severe n       \n2 ID2   mild   n       \n3 ID3   no     n       \n4 ID4   no     n       \n5 ID5   no     n       \n6 ID6   no     n       \n\n\nWe can see our table of observed counts with the table() function:\n\ntable(depdata$dep)\n\n\n    mild moderate       no   severe \n     143       34      771       52 \n\n\n\n\n The quick and easy way\n\n\nWe can perform the \\(\\chi^2\\) test very easily, by simply passing the table to the chisq.test() function, and passing it the hypothesised proportions. If we don’t give it any, it will assume they are equal.\n\nNote: the proportions must be in the correct order as the entries in the table!\n\nThis will give us the test statistic, degrees of freedom, and the p-value:\n\n# note the order of the table is mild, moderate, no, severe. \n# so we put the proportions in that order\nchisq.test(table(depdata$dep), p = c(.12, .04, .8, .04))\n\n\n    Chi-squared test for given probabilities\n\ndata:  table(depdata$dep)\nX-squared = 9.9596, df = 3, p-value = 0.01891\n\n\nIf the distribution of no/mild/moderate/severe depression were as suggested (80%/12%/4%/4%), then the probability that we would obtain a test statistic this large (or larger) by random chance alone is .019. With an \\(\\alpha = 0.05\\), we reject the null hypothesis that the proportion of people suffering from different levels of depression are the same as those indicated previously in 2019.\n\n\\(\\chi^2\\) goodness of fit test indicated that the observed proportions of people suffering from no/mild/moderate/severe depression were significantly different (\\(\\chi^2(3)=9.96, p = .019\\)) from those expected under the distribution suggested from a 2019 study (80%/12%/4%/4%).\n\nWe can examine where the biggest deviations from the hypothesised distribution are by examining the ‘residuals’:\n\nchisq.test(table(depdata$dep))$residuals\n\n\n      mild   moderate         no     severe \n -6.767274 -13.661039  32.950933 -12.522620 \n\n\nThis matches with what we see when we look at the table of counts. With \\(n=1000\\), under our 2019 distribution, we would expect 800 to have no depression, 120 mild, 40 moderate, and 40 severe.\n\ntable(depdata$dep)\n\n\n    mild moderate       no   severe \n     143       34      771       52 \n\n\n\n\n\n\n Manually\n\n\nFirst we calculate the observed counts:\n\ndepdata %>% \n  count(dep)\n\n# A tibble: 4 × 2\n  dep          n\n  <chr>    <int>\n1 mild       143\n2 moderate    34\n3 no         771\n4 severe      52\n\n\nLet’s add to this the expected counts:\n\ndepdata %>% \n  count(dep) %>%\n  mutate(\n    expected = c(.12, .04, .8, .04)*1000\n  )\n\n# A tibble: 4 × 3\n  dep          n expected\n  <chr>    <int>    <dbl>\n1 mild       143      120\n2 moderate    34       40\n3 no         771      800\n4 severe      52       40\n\n\nHow do we measure how far the observed counts are from the expected counts under the null? If we simply subtracted the expected counts from the observed counts and then add them up, you will get 0. Instead, we will square the differences between the observed and expected counts, and then add them up.\nOne issue, however, remains to be solved. A squared difference between observed and expected counts of 100 has a different weight in these two scenarios:\nScenario 1: \\(O = 30\\) and \\(E = 20\\) leads to a squared difference \\((O - E)^2 = 10^2 = 100\\).\nScenario 2: \\(O = 3000\\) and \\(E = 2990\\) leads to a squared difference \\((O - E)^2 = 10^2 = 100\\)\nHowever, it is clear that a squared difference of 100 in Scenario 1 is much more substantial than a squared difference of 100 in Scenario 2. It is for this reason that we divide the squared differences by the the expected counts to “standardize” the squared deviation.\n\\[\n\\chi^2 = \\sum_{i} \\frac{(\\text{Observed}_i - \\text{Expected}_i)^2}{\\text{Expected}_i}\n\\]\nWe can calculate each part of the equation:\n\ndepdata %>% \n  count(dep) %>%\n  mutate(\n    expected = c(.12, .04, .8, .04)*1000,\n    sq_diff = (n - expected)^2,\n    std_sq_diff = sq_diff/expected\n  )\n\n# A tibble: 4 × 5\n  dep          n expected sq_diff std_sq_diff\n  <chr>    <int>    <dbl>   <dbl>       <dbl>\n1 mild       143      120     529        4.41\n2 moderate    34       40      36        0.9 \n3 no         771      800     841        1.05\n4 severe      52       40     144        3.6 \n\n\nThe test-statistic \\(\\chi^2\\) is obtained by adding up all the standardized squared deviations:\n\ndepdata %>% \n  count(dep) %>%\n  mutate(\n    expected = c(.12, .04, .8, .04)*1000,\n    sq_diff = (n - expected)^2,\n    std_sq_diff = sq_diff/expected\n  ) %>% \n  summarise(\n    chi = sum(std_sq_diff)\n  )\n\n# A tibble: 1 × 1\n    chi\n  <dbl>\n1  9.96\n\n\nThe p-value for a \\(\\chi^2\\) Goodness of Fit Test is computed using a \\(\\chi^2\\) distribution with \\(df = \\text{nr categories} - 1\\).\nWe calculate our p-value by using pchisq() and we have 4 levels of depression, so \\(df = 4-1 = 3\\).\n\npchisq(9.959583, df=3, lower.tail=FALSE)\n\n[1] 0.01891284"
  },
  {
    "objectID": "04a_chisq.html#example-1",
    "href": "04a_chisq.html#example-1",
    "title": "4A: Chi-Square Tests",
    "section": "Example",
    "text": "Example\n\n\nResearch Question: Is severity of depression associated with having a family history of depression?\n\nThe dataset accessible at https://uoepsy.github.io/data/usmr_chisqdep.csv contains data from 1000 people to whom the PHQ-9 depression scale was administered in 2022, and for which respondents were asked a brief family history questionnaire to establish whether they had a family history of depression.\n\ndepdata <- read_csv(\"https://uoepsy.github.io/data/usmr_chisqdep.csv\")\nhead(depdata)\n\n# A tibble: 6 × 3\n  id    dep    fam_hist\n  <chr> <chr>  <chr>   \n1 ID1   severe n       \n2 ID2   mild   n       \n3 ID3   no     n       \n4 ID4   no     n       \n5 ID5   no     n       \n6 ID6   no     n       \n\n\nWe can create our contingency table:\n\ntable(depdata$dep, depdata$fam_hist)\n\n          \n             n   y\n  mild      93  50\n  moderate  23  11\n  no       532 239\n  severe    37  15\n\n\nAnd even create a quick and dirty visualisation of this too:\n\nplot(table(depdata$dep, depdata$fam_hist))\n\n\n\n\n\n\n\n\n\n\n The quick and easy way\n\n\nAgain, we can perform this test very easily by passing the table to the chisq.test() function. We don’t need to give it any hypothesised proportions here - it will work them out based on the null hypothesis that the two variables are independent.\n\nchisq.test(table(depdata$dep, depdata$fam_hist))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(depdata$dep, depdata$fam_hist)\nX-squared = 1.0667, df = 3, p-value = 0.7851\n\n\nIf there was no association between depression severity and having a family history of depression, then the probability that we would obtain a test statistic this large (or larger) by random chance alone is 0.79. With an \\(\\alpha=.05\\), we fail to reject the null hypothesis that there is no association between depression severity and family history of depression.\n\nA \\(\\chi^2\\) test of independence indicated no significant association between severity and family history (\\(\\chi^2(3)=1.07, p=.785\\)), suggesting that a participants’ severity of depression was not dependent on whether or not they had a family history of depression.\n\nWe can see the expected and observed counts:\n\nchisq.test(table(depdata$dep, depdata$fam_hist))$expected\n\n          \n                 n       y\n  mild      97.955  45.045\n  moderate  23.290  10.710\n  no       528.135 242.865\n  severe    35.620  16.380\n\nchisq.test(table(depdata$dep, depdata$fam_hist))$observed\n\n          \n             n   y\n  mild      93  50\n  moderate  23  11\n  no       532 239\n  severe    37  15\n\n\n\n\n\n\n Manually\n\n\nWe have our observed table:\n\ntable(depdata$dep, depdata$fam_hist)\n\n          \n             n   y\n  mild      93  50\n  moderate  23  11\n  no       532 239\n  severe    37  15\n\n\nTo work out our expected counts, we have to do something a bit tricky. Let’s look at the variables independently:\n\ntable(depdata$fam_hist)\n\n\n  n   y \n685 315 \n\ntable(depdata$dep)\n\n\n    mild moderate       no   severe \n     143       34      771       52 \n\n\nWith \\(\\frac{315}{315+685} = 0.315\\) of the sample having a family history, then if depression severity is independent of family history, we would expect that 0.315 of each severity group to have a family history of depression. For example, for the mild depression, with 143 people, we would expect \\(143 \\times 0.315 = 45.045\\) people in that group to have a family history of depression.\nFor a given cell of the table we can calculate the expected count as \\(\\text{row total} \\times \\frac{\\text{column total}}{\\text{samplesize}}\\).\nOr, quickly in R:\n\nobs <- table(depdata$dep, depdata$fam_hist)\nexp <- rowSums(obs) %o% colSums(obs) / sum(obs)\nexp\n\n               n       y\nmild      97.955  45.045\nmoderate  23.290  10.710\nno       528.135 242.865\nsevere    35.620  16.380\n\n\nNow that we have our table of observed counts, and our table of expected counts, we can actually fit these into our formula to calculate the test statistic:\n\nsum ( (obs - exp)^2 / exp )\n\n[1] 1.066686\n\n\nThe p-value is computed using a \\(\\chi^2\\) distribution with \\(df = (\\text{nr rows} - 1) \\times (\\text{nr columns} - 1)\\).\nWhy is this? Well, remember that the degrees of freedom is the number of values that are free to vary as we estimate parameters. In a table such as the one below, where we have 4 rows and 2 columns, the degrees of freedom is the number of cells in the table that can vary before we can simply calculate the values of the other cells (where we’re constrained by the need to sum to our row/column totals).\nWe have 4 rows, and 2 columns, so \\(df = (4-1) \\times (2-1) = 3\\).\n\npchisq(1.066686, df = 3, lower.tail=FALSE)\n\n[1] 0.7851217"
  },
  {
    "objectID": "04b_revistnhst.html",
    "href": "04b_revistnhst.html",
    "title": "4B: Revisiting NHST",
    "section": "",
    "text": "Step 1. We have been starting by considering what a given statistic is likely to be if a given hypothesis (the null) were true.\n\nFor the \\(t\\)-tests, if the null hypothesis is true (there is no difference between group means/between our observed mean and some value), then our \\(t\\)-statistics (if we could do our study loads of times) will mainly fall around 0, and follow a \\(t\\)-distribution. The precise \\(t\\)-distribution depends on the degrees of freedom, which in turn depends on how much data we have.\n\nFor the \\(\\chi^2\\) tests, if the null hypothesis is true and there is no difference between the observed and expected frequencies, then our \\(\\chi^2\\)-statistics will follow the \\(\\chi^2\\) distribution (i.e., with 2 categories, most of them will be between 0 and 2, with fewer falling >2, see the yellow line in Figure 1).\n\nStep 2. We calculate our statistic from our observed data.\nStep 3. We ask what the probability is of getting a statistic at least as extreme as we get from Step 2, assuming the null hypothesis we stated in Step 1.\n\n\n\n\n\n\n\n\nFigure 1: Chi-Square Distributions\n\n\n\n\n\nIf you’re finding the programming easy, but the statistical concepts difficult\nAnother way which might help to think about this is that if we can make a computer do something over and over again, we can do stats! You may already be familiar with this idea from exercises with the function replicate()!\n\n\nmake the computer generate random data, based on some null hypothesis. Do it lots of times.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwhat proportion of the simulations produce results similar to the observed data (i.e., as extreme or more extreme)? This is \\(p\\). The only difference between this and “statistics” is that we calculate \\(p\\) using math, rather than having to generate random data.\n\n\n\n\n\n\nStatistical vs Practical Significance\nLet’s suppose that an agricultural company is testing out a new fertiliser they have developed to improve tomato growth. They know that, on average, for every 5cm taller a tomato plant is, it tends to provide 1 more tomato. Taller plants = more tomatoes.\nThey plant 1000 seeds (taken from the same tomato plant) in the same compost and place them in positions with the same amount of sunlight. 500 of the plants receive 100ml of water daily, and the other 500 receive a 100ml of the fertiliser mixed with water. After 100 days, they measure the height of all the tomato plants (in cm).\n\n\n\n\n\n\n\n\n\nYou can find the data at https://uoepsy.github.io/data/tomatogrowth.csv.\nWe want to conduct the appropriate test to determine whether the fertiliser provides a statistically significant improvement to tomato plant growth.\nOur outcome variable is growth, which is continuous, and our predictor variable is the grouping (whether they received fertiliser or not). So we’re looking at whether there is a difference in mean growth between the two groups. A t-test will do here.\nOur alternative hypothesis is that the difference in means \\((treatment - control)\\) is greater than 0 (i.e., it improves growth). The t.test() function will use alphabetical ordering of the group variable, so if we say alternative=\"less\" then it is the direction we want \\((control - treatment < 0)\\):1:\n\ntomato <- read_csv(\"https://uoepsy.github.io/data/tomatogrowth.csv\")\nt.test(tomato$height ~ tomato$group, alternative = \"less\")\n\n\n    Welch Two Sample t-test\n\ndata:  tomato$height by tomato$group\nt = -2.0085, df = 997.97, p-value = 0.02243\nalternative hypothesis: true difference in means between group control and group treatment is less than 0\n95 percent confidence interval:\n       -Inf -0.2296311\nsample estimates:\n  mean in group control mean in group treatment \n               115.1955                116.4692 \n\n\n\n\n\nHooray, it is significant! So should we use this fertiliser on all our tomatoes? We need to carefully consider the agricultural company’s situation: given that the fertiliser is comparitively pricey for them to manufacture, is it worth putting into production?\nWhile the fertiliser does improve plant growth to a statistically significant (at \\(\\alpha=0.05\\)) degree, the improvement is minimal. The difference in means is only 1.2737cm. Will this result in many more tomatoes? Probably not.\nFurthermore, if we take a look at the confidence interval provided by the t.test() function, we can see that a plausible value for the true difference in means is 0.23cm, which is tiny!\n\n\n\n\n\nFurther Thoughts\nThe above example is just a silly demonstration that whether or not our p-value is below some set criteria (e.g., .05, .01, .001) is only a small part of the picture. There are many things which are good to remember about p-values:\n\nWith a big enough sample size, even a tiny tiny effect is detectable at <.05. For example, you might be interested in testing if the difference in population means across two groups is 0 (\\(\\mu_1 - \\mu_2 = 0\\). Your calculated sample difference could be \\(\\bar{x}_1 - \\bar{x}_2 = 0.00002\\) but with a very small p-value of 0.00000001. This would tell you that there is strong evidence that the observed difference in means (0.00002) is significantly different from 0. However, the practical difference, that is - the magnitude of the distance between 0.00002 and 0 - is negligible and of pretty much no interest to practitioners. This is the idea we saw in the tomato-plant example.\nThe criteria (\\(\\alpha\\)) which we set (at .05, .01, etc.), is arbitrary.\nTwo things need to be kept in mind: there is the true status of the world (which is unknown to us) and the collected data (which are available and reveal the truth only in part).\nAn observed p-value smaller than the chosen alpha does not imply the true presence of an effect. The observed difference might be due to sampling variability.\n\n\n\n\n\n\nFigure 2: Two possible samples (blue dots) drawn from two populations with same mean. On the left, the selected sample shows a big difference. On the right, the sample shows no difference. Samples such as that on the left are very unlikely to happen (e.g., 5% of the time). It is for these unlikely samples that we would reject the null hypothesis incorrectly 5% of the time.\n\n\n\n\n\nEven if a null hypothesis about the population is actually true, then 5% (if \\(\\alpha\\) = 0.05) of the test-statistics computed on different samples from that population would result in a p-value <.05. If you were to obtain 100 random samples from that population, five out of the 100 p-values are likely to be <.05 even if the null hypothesis about the population was actually true.\nIf you have a single dataset, and you perform several tests of hypotheses on those data, each test comes with a probability of incorrectly rejecting the null (making a type I error) of 5%. Hence, considering the entire family of tests computed, your overall type I error probability will be larger than 5%. In simple words, this means that if you perform enough tests on the same data, you’re almost sure to reject one of the null hypotheses by mistake. This concept is known as multiple comparisons.\n\n\n\n\n\n\nFurther Reading (Optional)\nThere are many different competing approaches to doing statistical analyses.\nIn this course we are learning about what is known as the frequentist framework. Roughly speaking, this is where probabilities are defined as “long-run frequencies” (i.e., the probability of \\(x\\) happening over many many trials2). Even within the frequentist approach, there are different views as to how to how this definition of probability is best utilised.\nThe following links provide some introductory readings to some of the different schools of thought:\n\nPerezgonzalez, J. D. (2015). Fisher, Neyman-Pearson or NHST? A tutorial for teaching data testing. Frontiers in Psychology, 6, 223.\nCalin-Jageman, R. J., & Cumming, G. (2019). The new statistics for better science: ask how much, how uncertain, and what else is known. The American Statistician, 73(sup1), 271-280.\nThe correctly-used p value needs an effect size and CI - don’t worry too much about the background of this blog, but it offers some useful visualisations to show how important it is to remember about the uncertainty in our estimates.\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nWe could instead make the group variable a factor and specify the order of the levels↩︎\nFor those of you who are interested in what alternative definitions there are, do a google search for “frequentist vs bayesian”. Be prepared that this will open a big can of worms!↩︎"
  },
  {
    "objectID": "05_ex.html",
    "href": "05_ex.html",
    "title": "Week 5 Exercises: Cov, Cor, Models",
    "section": "",
    "text": "Q1: Go to http://guessthecorrelation.com/ and play the “guess the correlation” game for a little while to get an idea of what different strengths and directions of \\(r\\) can look like.\n\n\n\n\nSleepy time\n\nData: Sleep levels and daytime functioning\nA researcher is interested in the relationship between hours slept per night and self-rated effects of sleep on daytime functioning. She recruited 50 healthy adults, and collected data on the Total Sleep Time (TST) over the course of a seven day period via sleep-tracking devices.\nAt the end of the seven day period, participants completed a Daytime Functioning (DTF) questionnaire. This involved participants rating their agreement with ten statements (see @tab-sleepitems). Agreement was measured on a scale from 1-5. An overall score of daytime functioning can be calculated by:\n\nreversing the scores for items 4,5 and 6 (because those items reflect agreement with positive statements, whereas the other ones are agreement with negative statement);\nsumming the scores on each item; and\nsubtracting the sum score from 50 (the max possible score). This will make higher scores reflect better perceived daytime functioning.\n\nThe data is available at https://uoepsy.github.io/data/sleepdtf.csv.\n\n\n# A tibble: 10 × 2\n   Item    Statement                                        \n   <chr>   <chr>                                            \n 1 Item_1  I often felt an inability to concentrate         \n 2 Item_2  I frequently forgot things                       \n 3 Item_3  I found thinking clearly required a lot of effort\n 4 Item_4  I often felt happy                               \n 5 Item_5  I had lots of energy                             \n 6 Item_6  I worked efficiently                             \n 7 Item_7  I often felt irritable                           \n 8 Item_8  I often felt stressed                            \n 9 Item_9  I often felt sleepy                              \n10 Item_10 I often felt fatigued                            \n\n\n\n\nQuestion 2\n\n\nRead in the data, and calculate the overall daytime functioning score, following the criteria outlined above. Make this a new column in your dataset.\n\nTo reverse items 4, 5 and 6, we we need to make all the scores of 1 become 5, scores of 2 become 4, and so on… What number satisfies all of these equations: ? - 5 = 1, ? - 4 = 2, ? - 3 = 3?\nTo quickly sum accross rows, you might find the rowSums() function useful (you don’t have to use it though)\n\n\n\n\n\n\nsleepdtf <- read_csv(\"https://uoepsy.github.io/data/sleepdtf.csv\")\nsummary(sleepdtf)\n\n      TST             item_1         item_2         item_3         item_4    \n Min.   : 4.900   Min.   :1.00   Min.   :1.00   Min.   :1.00   Min.   :1.00  \n 1st Qu.: 7.225   1st Qu.:1.00   1st Qu.:2.00   1st Qu.:1.25   1st Qu.:1.00  \n Median : 7.900   Median :1.00   Median :2.00   Median :2.00   Median :1.00  \n Mean   : 8.004   Mean   :1.58   Mean   :2.46   Mean   :2.38   Mean   :1.26  \n 3rd Qu.: 9.025   3rd Qu.:2.00   3rd Qu.:3.00   3rd Qu.:3.00   3rd Qu.:1.00  \n Max.   :11.200   Max.   :3.00   Max.   :5.00   Max.   :5.00   Max.   :3.00  \n     item_5         item_6         item_7         item_8        item_9    \n Min.   :1.00   Min.   :1.00   Min.   :1.00   Min.   :1.0   Min.   :1.00  \n 1st Qu.:2.00   1st Qu.:2.00   1st Qu.:1.00   1st Qu.:2.0   1st Qu.:2.00  \n Median :2.00   Median :3.00   Median :2.00   Median :2.5   Median :3.00  \n Mean   :2.36   Mean   :2.78   Mean   :2.04   Mean   :2.5   Mean   :2.96  \n 3rd Qu.:3.00   3rd Qu.:4.00   3rd Qu.:3.00   3rd Qu.:3.0   3rd Qu.:4.00  \n Max.   :4.00   Max.   :5.00   Max.   :4.00   Max.   :4.0   Max.   :5.00  \n    item_10    \n Min.   :1.00  \n 1st Qu.:2.00  \n Median :3.00  \n Mean   :2.54  \n 3rd Qu.:3.00  \n Max.   :5.00  \n\n\nTo reverse the items, we can simply do 6 minus the score:\n\nsleepdtf <- \n  sleepdtf %>% mutate(\n    item_4=6-item_4,\n    item_5=6-item_5,\n    item_6=6-item_6\n  ) \n\nNow we can use rowSums(), and subtract the sum scores from from 50 (the max score):\n\nsleepdtf$dtf = 50-rowSums(sleepdtf[, 2:11])\n\nAn alternative way to do this would be:\n\nsleepdtf %>% \n  mutate(\n    dtf = 50 - (item_1 + item_2 + item_3 + item_4 + item_5 + item_6 + item_7 + item_8 + item_9 + item_10)\n  )\n\n\n\n\n\nQuestion 3\n\n\nCalculate the correlation between the total sleep time (TST) and the overall daytime functioning score calculated in the previous question.\nConduct a test to establish the probability of observing a correlation this strong in a sample of this size assuming the true correlation to be 0.\nWrite a sentence or two summarising the results.\n\nHint: You can do this all with one function, see 5A #correlation-test.\n\n\n\n\n\n\ncor.test(sleepdtf$TST, sleepdtf$dtf)\n\n\n    Pearson's product-moment correlation\n\ndata:  sleepdtf$TST and sleepdtf$dtf\nt = 6.244, df = 48, p-value = 1.062e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4807039 0.7989417\nsample estimates:\n      cor \n0.6694741 \n\n\n\nThere was a strong positive correlation between total sleep time and self-reported daytime functioning score (\\(r\\) = 0.67, \\(t(48)\\) = 6.24, \\(p < .001\\)) in the current sample. As total sleep time increased, levels of self-reported daytime functioning increased.\n\n\n\n\n\nQuestion 4 (open-ended)\n\n\nThink about this relationship in terms of causation.\n Claim: Less sleep causes poorer daytime functioning.\n Why might it be inappropriate to make the claim above based on these data alone? Think about what sort of study could provide stronger evidence for such a claim.\n\nThings to think about:\n\ncomparison groups.\n\nrandom allocation.\n\nmeasures of daytime functioning.\n\nmeasures of sleep time.\n\nother (unmeasured) explanatory variables.\n\n\n\n\n\n\n\n\n\n\nFunctions and Models\n\nQuestion 5\n\n\nThe Scottish National Gallery kindly provided us with measurements of side and perimeter (in metres) for a sample of 10 square paintings.\nThe data are provided below:\n\nsng <- tibble(\n  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),\n  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)\n)\n\nPlot the data from the Scottish National Gallery using ggplot(), with the side measurements of the paintings on the x-axis, and the perimeter measurements on the y-axis.\nWe know that there is a mathematical model for the relationship between the side-length and perimeter of squares: \\(perimeter = 4 \\times \\ side\\).\nTry adding the following line to your plot:\n\n  stat_function(fun = ~.x * 4)\n\n\n\n\n\n\nsng <- tibble(\n  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),\n  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)\n)\n\nggplot(data = sng, aes(x = side, y = perimeter)) +\n  geom_point(colour = 'black', alpha = 0.5, size = 3) +\n  labs(x = 'Side (m)', y = 'Perimeter (m)')+\n  stat_function(fun = ~.x * 4)\n\n\n\n\nFigure 1: The exact relationship between side and perimeter of squares.\n\n\n\n\nThe above plot shows perfect agreement between the observed data and the model.\n\n\n\n\nQuestion 6\n\n\nUse our mathematical model to predict the perimeter of a painting with a side of 1.5 metres.\n\nHint:\nWe don’t have a painting with a side of 1.5 metres within the random sample of paintings from the Scottish National Gallery, but we can work out the perimeter of an hypothetical square painting with 1.5m sides, using our model - either using the plot from the previous question, or calculating it algebraically.\n\n\n\n\n\nVisual approach\n\n\n\n\n\n\n\n\n\nSometimes we can directly read a predicted value from the graph of the functional relationship.\nConsider the plot created in the previous question. First, we need to check where x = 1.5. Then, we draw a vertical dashed line until it meets the blue line. The y value corresponding to x = 1.5 can be read off the y-axis.\nHowever, in this case it is not that easy to read it from the drawing… Let’s try the next approach.\n Algebraic approach\nYou can substitute the x value in the formula and calculate the corresponding y value.\n\\[\n\\begin{align}\nperimeter &= 4 \\times \\ side \\\\\n&= 4 \\times \\ (1.5) \\\\\n&= 6\n\\end{align}\n\\]\n\n\nThe predicted perimeter of squared paintings having a 1.5m side is 6m.\n\nNOTE: Don’t forget to always include the measurement units when reporting/writing-up results!\n\n\n\n\nData: HandHeight\nThis dataset, from Jessican M Utts and Robert F Heckard. 2015. Mind on Statistics (Cengage Learning)., records the height and handspan reported by a random sample of 167 students as part of a class survey.\nThe variables are:\n\nheight, measured in inches\nhandspan, measured in centimetres\n\nThe data are available at https://uoepsy.github.io/data/handheight.csv\n\n\nQuestion 7\n\n\nConsider the relationship between height (in inches) and handspan (in cm).\nRead the handheight data into R, and investigate (visually) how handspan varies as a function of height for the students in the sample.\nDo you notice any outliers or points that do not fit with the pattern in the rest of the data?\nComment on any main differences you notice between this relationship and the relationship between sides and perimeter of squares.\n\n\n\n\nThe handheight data set contains two variables, height and handspan, which are both numeric and continuous. We display the relationship between two numeric variables with a scatterplot.\nWe can also add marginal boxplots for each variable using the package ggExtra. Before using the package, make sure you have it installed via install.packages('ggExtra').\n\nhandheight <- read_csv(file = 'https://uoepsy.github.io/data/handheight.csv')\n\nlibrary(ggExtra)\n\nplt <- ggplot(handheight, aes(x = height, y = handspan)) +\n  geom_point(size = 3, alpha = 0.5) +\n  labs(x = 'Height (in.)', y = 'Handspan (cm)')\n\nggMarginal(plt, type = 'boxplot')\n\n\n\n\nFigure 2: The statistical relationship between height and handspan.\n\n\n\n\nOutliers are extreme observations that do not seem to fit with the rest of the data. This could either be:\n\nmarginally along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate;\njointly: observations that do not fit with the rest of the point cloud.\n\nThe boxplots in fig-handheight-scatterplot do not highlight any outliers in the marginal distributions of height and handspan. Furthermore, from the scatterplot we do not notice any extreme observations or points that do not fit with the rest of the point cloud.\nWe notice a moderate, positive (that is, increasing) linear relationship between height and handspan.\nRecall Figure 1, displaying the relationship between side and perimeters of squares. In the plot we notice two points on top of each other, reflecting the fact that two squares having the same side will always have the same perimeter. In fact, the data from the Scottish National Gallery include two squared paintings with a side of 1.1m, both having a measured perimeter of 4.4m.\nfig-handheight-scatterplot, instead, displays the relationship between height and handspan of a sample of students. The first thing that grabs our attention is the fact that students having the same height do not necessarily have the same handspan. Rather, we clearly see a variety of handspan values for students all having a height of, for example, 70in. To be more precise, the seven students who are 70 in. tall all have differing handspans.\n\n\n\n\nQuestion 8\n\n\nHopefully, as part of the previous question, you created a scatterplot of handspans against heights. If not, make one now.\nTry adding the following line of code to the scatterplot. It will add a best-fit line describing how handspan varies as a function of height. For the moment, the argument se = FALSE tells R to not display uncertainty bands.\n\ngeom_smooth(method = lm, se = FALSE)\n\nThink about the differences you notice with between this and Figure 1.\n\n\n\n\n\nggplot(handheight, aes(x = height, y = handspan)) +\n  geom_point(size = 3, alpha = 0.5) +\n  geom_smooth(method = lm, se = FALSE) +\n  labs(x = 'Height (in.)', y = 'Handspan (cm)')\n\n\n\n\nFigure 3: The best-fit line.\n\n\n\n\nThe line representing the relationship between side and perimeter of squares (Figure 1) is able to predict the actual perimeter value from the measurement of the side of a square. This is possible because the relationship between side and perimeter is an exact one. That is, any squares having the same side will have the same perimeter, and there will be no variation in those values.\nThe line that best fits the relationship between height and handspan (Figure 3) is only able to predict the average handspan for a given value of height. This is because there will be a distribution of handspans at each value of height. The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.\n\n\n\n\nRelationships such as that between height and handspan show deviations from an “average pattern”. To model this, we need need to create a model that allows for deviations from the linear relationship. This is called a statistical model.\nA statistical model includes both a deterministic function and a random error term:\n\\[\nHandspan = \\beta_0 + \\beta_1 \\ Height + \\epsilon\n\\]\nor, in short,\n\\[\ny = \\underbrace{\\beta_0 + \\beta_1 \\ x}_{f(x)} + \\underbrace{\\epsilon}_{\\text{random error}}\n\\]\nThe deterministic function \\(f(x)\\) need not be linear if the scatterplot displays signs of nonlinearity, but in this course we focus primarily on linear relationships.\nIn the equation above, the terms \\(\\beta_0\\) and \\(\\beta_1\\) are numbers specifying where the line going through the data meets the y-axis and its slope (rate of increase/decrease).\n\n\nQuestion 9\n\n\n\n\n\nThe line of best-fit is given by:1\n\\[\n\\widehat{Handspan} = -3 + 0.35 \\ Height\n\\]\nWhat is your best guess for the handspan of a student who is 73in tall?\nAnd for students who are 5in?\n\n\n\n\nThe predicted average handspan for students who are 73in tall is \\(-3 + 0.35 * 73 = 22.55\\)cm.\nThe predicted average handspan for students who are 5in tall is \\(-3 + 0.35 * 5 = -1.25\\)cm. But wait, handspan can not be negative… This does not make any sense! That’s right, we went too far off the range of the available data on heights, which were between 57in and 78in. We extrapolated. This is very dangerous…\n\n\n\n\n\nFigure 4: Source: Randall Munroe, xkcd.com\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nYes, the error term is gone. This is because the line of best-fit gives you the prediction of the average handspan for a given height, and not the individual handspan of a person, which will almost surely be different from the prediction of the line.↩︎"
  },
  {
    "objectID": "05a_covcor.html",
    "href": "05a_covcor.html",
    "title": "Covariance, Correlation, and Modelling",
    "section": "",
    "text": "Correlation Test\nNow that we’ve seen the formulae for covariance and correlation, as well as how to quickly calculate them in R using cov() and cor(), we can use a statistical test to establish the probability of finding an association this strong by chance alone.\n\nHypotheses\nThe hypotheses of the correlation test are, as always, statements about the population parameter (in this case the correlation between the two variables in the population - i.e., \\(\\rho\\)).\nNull Hypothesis:\n\n\\(H_0: \\rho = 0\\). There is not a linear relationship between \\(x\\) and \\(y\\) in the population.\n\nAlternative Hypothesis:\n\n\\(H_1: \\rho > 0\\) There is a positive linear relationship between \\(x\\) and \\(y\\).\n\\(H_1: \\rho < 0\\) There is a negative linear relationship between \\(x\\) and \\(y\\).\n\\(H_1: \\rho \\neq 0\\) There is a linear relationship between \\(x\\) and \\(y\\).\n\nTest Statistic\nThe test statistic for this test here is another \\(t\\) statistic, the formula for which depends on both the observed correlation (\\(r\\)) and the sample size (\\(n\\)):\n\\[t = r \\sqrt{\\frac{n-2}{1-r^2}}\\]\np-value\nWe calculate the p-value for our \\(t\\)-statistic as the long-run probability of a \\(t\\)-statistic with \\(n-2\\) degrees of freedom being less than, greater than, or more extreme in either direction (depending on the direction of our alternative hypothesis) than our observed \\(t\\)-statistic.\nAssumptions\nFor a test of Pearson’s correlation coefficient \\(r\\), we need to make sure a few conditions are met:\n\nBoth variables are quantitative\nBoth variables should be drawn from normally distributed populations.\nThe relationship between the two variables should be linear.\n\n\nIn R\nWe can test the significance of the correlation coefficient really easily with the function cor.test():\n\ncor.test(recalldata$recall_accuracy, recalldata$recall_confidence)\n\n\n    Pearson's product-moment correlation\n\ndata:  recalldata$recall_accuracy and recalldata$recall_confidence\nt = 4.1512, df = 18, p-value = 0.0005998\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3719603 0.8720125\nsample estimates:\n      cor \n0.6993654 \n\n\n\n\n Optional: Manually conducting the correlation test\n\n\nOr, if we want to calculate our test statistic manually:\n\n#calculate r\nr = cor(recalldata$recall_accuracy, recalldata$recall_confidence)\n\n#get n\nn = nrow(recalldata)\n\n#calculate t    \ntstat = r * sqrt((n - 2) / (1 - r^2))\n\n#calculate p-value for t, with df = n-2 \n2*(1-pt(tstat, df=n-2))\n\n[1] 0.0005998222\n\n\n\n\n\n\n\n\n\n\n\nCautions!\nCorrelation is an invaluable tool for quantifying relationships between variables, but must be used with care.\nBelow are a few things to be aware of when we talk about correlation.\n\nCorrelation can be heavily affected by outliers. Always plot your data!\nThe two plots below only differ with respect to the inclusion of one observation. However, the correlation coefficient for the two sets of observations is markedly different.\n\n\n\n\n\n\n\n\n\n\n\nr = 0 means no linear association. The variables could still be otherwise associated. Always plot your data!\nThe correlation coefficient in Figure 1 below is negligible, suggesting no linear association. The word “linear” here is crucial - the data are very clearly related.\n\n\n\n\n\nFigure 1: Unrelated data?\n\n\n\n\nSimilarly, take look at all the sets of data in Figure 2 below. The summary statistics (means and standard deviations of each variable, and the correlation) are almost identical, but the visualisations suggest that the data are very different from one another.\n\n\n\n\n\nFigure 2: Datasaurus! From Matejka, J., & Fitzmaurice, G. (2017, May): Same stats, different graphs: generating datasets with varied appearance and identical statistics through simulated annealing.\n\n\n\n\n\n\nCorrelation does not imply causation!\n\n\n\n\n\nFigure 3: https://twitter.com/quantitudepod/status/1309135514839248896\n\n\n\n\nYou will have likely heard the phrase “correlation does not imply causation”. There is even a whole wikipedia entry devoted to the topic.\nJust because you observe an association between x and y, we should not deduce that x causes y\nAn often cited paper which appears to fall foul of this error took a correlation between a country’s chocolate consumption and its number of nobel prize winners (see Figure 4) to suggest a causal relationship between the two (“chocolate intake provides the abundant fertile ground needed for the sprouting of Nobel laureates”):\n\n\n\n\n\nFigure 4: Chocolate consumption causes more Nobel Laureates?"
  },
  {
    "objectID": "06_wt.html",
    "href": "06_wt.html",
    "title": "WalkThrough: Advanced Data Wrangling",
    "section": "",
    "text": "For this reason, we’re going to take a little detour away from statistics to get some more practice wrangling and cleaning data in R. Don’t worry about the trying to remember all of the new R functions introduced in this topic - there are a lot. Use them as a means of learning about some of the different ways of doing things in R.\n\nStudy Background & Data\nThe data we’re going to look at now is from an experiment on language comprehension, looking at whether people perceive blinking as a sign of lying.\n\nResearch Question: Is the rate of blinking during speech interpreted as a sign of dishonesty (in the context of a lie-detection game)?\n\nParticipants were informed that they were going to take part in a lie-detection game. They were presented with audiovisual recordings of a speaker stating behind which of two objects (displayed on screen) there was hidden treasure. Utterances took the form of “The treasure is behind the [target name]”.\nOver 20 trials, participants were tasked with using the mouse to click on the object they believed the treasure to be behind. They were told that the speaker in the video was attempting to mislead them, meaning that sometimes they told the truth, and sometimes they lied. Crucially, in the videos presented of the speaker producing the utterances, we manipulated the number of times the speaker blinked (from 1 to 10 times). Participants eyes were tracked for the duration of the experiment, with the time spent looking at either object taken as an implicit indication of perceiving a truthful utterance (in which the participant looks at and clicks on the ‘target object’ (the one identified by the speaker as hiding the treasure)) or a dishonest one (in which the participant would look at and click on the alternative ‘distractor’ object).\n\nblink_setup.csv\n\nThe data from the experimental design are available at https://uoepsy.github.io/data/blink_setup.csv. In this data, each participant is a row, and the information about what video is presented in each trial are presented in separate columns for each trial. The first bit of the data looks like this:\n\n\n\n\n\n\n\n\n\n\n\n\n1\nsubject_1\n/files/vids/blinks_1.mp4\n/files/vids/blinsk_8.mp4\n…\n\n\n2\nsubject_2\n/files/vids/blinks_2.mp4\n/files/vids/blinks_4.mp4\n…\n\n\n3\nsubject_3\n/files/vids/blinks_4.mp4\n/files/vids/blinks_5.mp4\n…\n\n\n4\nsubject_4\n/files/vids/blinks_4.mp4\n/files/vids/blinks_7.mp4\n…\n\n\n5\nsubject_5\n/files/vids/blinks_1.mp4\n/files/vids/blinks_4.mp4\n…\n\n\n6\nsubject_6\n/files/vids/blinks_2.mp4\n/files/vids/blinks_3.mp4\n…\n\n\n…\n…\n…\n…\n…\n\n\n…\n…\n…\n…\n…\n\n\n\n\n\n\nblink_eyegaze.xlsx\n\nThe data from the eye-tracker, which has been processed to show the proportion of time spent looking at the distractor object in each trial, can be found at https://uoepsy.github.io/data/blink_eyegaze.xlsx. In contrast to the blink_setup.csv data, in this data each trial is a row, so we have 20 rows per participant.\n\n\n\n\n\n\n\n\n\nvariable_names\ndescription\n\n\n\n\nsub\nParticipant number\n\n\ntrial_no\nTrial number\n\n\ndistractor_fix\nTime spent looking at distractor object (measured in milliseconds from onset of noun phrase)\n\n\nrt\nTime taken to click on an object (measured in milliseconds from the onset of the noun phrase\n\n\n\n\n\nThe top of the data looks like this:\n\n\n\n\n\nsub\ntrial_no\ndistractor_fix\nrt\n\n\n\n\n1\n1\n503.990657311976\n2812\n\n\n1\n2\n2810.1367654\n2974\n\n\n1\n3\n706.739099152984\n2257\n\n\n1\n4\nNA\nNA\n\n\n1\n5\n223.327680772201\n4546\n\n\n1\n6\nNA\nNA\n\n\n…\n…\n…\n…\n\n\n…\n…\n…\n…\n\n\n\n\n\n\n\nDifferent Data Formats\nData can come in lots of different formats, meaning that we need lots of different ways to read data into R. Below is some information on some of the more common functions for reading and writing different types of data.\nText based files\n\n\n\n\n\n\n\n\n\nfiletype\ndescription\nreading\nwriting\n\n\n\n\n.csv\ncomma separated values\ntidyverse - read_csv()read.csv()read.table(..., sep = \",\")\ntidyverse - write_csv()write.csv()write.table(..., sep=\",\")\n\n\n.tsv\ntab separated values\ntidyverse - read_tsv()read.table(..., sep = \"\\t\")\ntidyverse - write_tsv()write.table(..., sep = \"\\t\")\n\n\n.txt\nanything-separated values!\nread.table(..., sep = ...)\nwrite.table(..., sep = ...)\n\n\n\nR files\n\n\n\n\n\n\n\n\n\nfiletype\ndescription\nreading\nwriting\n\n\n\n\n.RDS\n1 file = a single R object\nreadRDS()\nsaveRDS()\n\n\n.RData\n1 file = a collection of R objects\nload()\nsave()save.image() - to save all objects in the environment)\n\n\n\nExcel files\nThe package readxl provides a variety of functions for reading in different types of Microsoft Excel spreadsheet, such as read_excel(), read_xls(), read_xlsx().\nOther software\nThe package haven provides functions for files which have been saved from other statistical software, for instance with read_spss()/read_sav() and read_sas() for files from SPSS and SAS.\nGoogle sheets\nThe googlesheets4 package can read in data directly from a spreadsheet stored on google drive. You simply find the id of the sheet (it’s the big long string of numbers & letters in the url of your google sheet), and pass it to read_sheet().\nIt will prompt you to authenticate your account via your browser, but it’s really easy!\n\n\n\n\nRead in the two data-sets. Take care to look at the file extension (e.g., .csv, .tsv, .xlsx) as indicators of what function to try.\nMake sure you assign them identifiable names.\nOnce you’ve loaded the data-set, take a look at them using functions like summary(), str(), dim()/nrow(), or viewing them by clicking on them in the environment.\n\nHints:\n\nSome functions like read_excel() don’t allow you to download directly from a url, like we have been doing with .csv files.\n\nSolution 1:\n\nDownload the data to your computer\nupload to the rstudio server if you are using it\nDirect the function to read it from the place you stored it.\n\nSolution 2:\n\nMake R download the data directly to somewhere in your working directory (see download.file()).\n\n\nDo both the data-sets have column names? By default R will assume the first row is the name of the column. Look in the help documentation to see how to stop this from happening.\n\n\n\n\n\n\n Solution \n\n\n\nlibrary(tidyverse)\nlibrary(readxl)\n\ndownload.file('https://uoepsy.github.io/data/blink_eyegaze.xlsx', 'data/blink_eyegaze.xlsx', mode=\"wb\")\neyedata <- read_excel(path = 'data/blink_eyegaze.xlsx')\n\nsetupdata <- read_csv(\"https://uoepsy.github.io/data/blink_setup.csv\", col_names = FALSE)\n\n\n\n\n\n\nRenaming Columns\nYou can access the column names from a data-set using names() or colnames().\n\nnames(data)\ncolnames(data)\n\nAnd we can easily rename these using indexing:\n\n#name the third column \"peppapig\"\nnames(data)[3]<-\"peppapig\"\n\nOr in tidyverse, using rename():\n\ndata %>%\n  rename(newname = currentname)\n\n\n\n\n\nProblem\nThe blink_setup.csv file doesn’t have any column names!\nWe know that there are 20 trials for each participant, and we can see that the 2nd column has information about which subject it is.\nColumns 3:22 are trials 1 to 20.\n\nhead(setupdata)\n\n\n\n   X1        X2                       X3 ...\n1   1 subject_1 /files/vids/blinks_1.mp4 ...\n2   2 subject_2 /files/vids/blinks_2.mp4 ...\n3   3 subject_3 /files/vids/blinks_4.mp4 ...\n4   4 subject_4 /files/vids/blinks_4.mp4 ...\n5   5 subject_5 /files/vids/blinks_1.mp4 ...\n6   6 subject_6 /files/vids/blinks_2.mp4 ...\n7 ...       ...                      ... ...\n8 ...       ...                      ... ...\n\n\nTask\n\nRemove the first column\nRename columns 2 to 22 with sensible names.\n\n\nHints:\n\nnames(setupdata) # what are the names\nnames(setupdata)[2] # what is the 2nd name\nnames(setupdata) <- c(\"...\", \"...\", \"...\",..) # set the names\n\n\nc(\"kermit\", paste(\"peppapig\", 1:3, sep=\"_\"))\n\n[1] \"kermit\"     \"peppapig_1\" \"peppapig_2\" \"peppapig_3\"\n\n\n\n\n\n\n\n Solution \n\n\nremove the first column\n\nsetupdata <- setupdata[,-1]\n\nSet the names\n\nnames(setupdata) <- c(\"sub\",paste(\"trial\", 1:20, sep = \"_\"))\n\nCheck:\n\nhead(setupdata)\n\n\n\n        sub                  trial_1 ...\n1 subject_1 /files/vids/blinks_1.mp4 ...\n2 subject_2 /files/vids/blinks_2.mp4 ...\n3 subject_3 /files/vids/blinks_4.mp4 ...\n4 subject_4 /files/vids/blinks_4.mp4 ...\n5 subject_5 /files/vids/blinks_1.mp4 ...\n6 subject_6 /files/vids/blinks_2.mp4 ...\n7       ...                      ... ...\n8       ...                      ... ...\n\n\n\n\n\n\n\nReshaping data\nPivot!\nOne of the more confusing things to get to grips with is the idea of reshaping a dataframe.\nFor different reasons, you might sometimes want to have data in wide, or in long format.\n\n\n\n\n\nSource: https://fromthebottomoftheheap.net/2019/10/25/pivoting-tidily/\n\n\n\n\nWhen the data is wide, we can make it long using pivot_longer(). When we make data longer, we’re essentially making lots of columns into 2 longer columns. Above, in the animation, the wide variable x, y and z go into a new longer column called name that specifies which (x/y/z) it came from, and the values get put into the val column.\nThe animation takes a shortcut in the code it displays above, but you could also use pivot_longer(c(x,y,z), names_to = \"name\", values_to = \"val\"). To reverse this, and put it back to being wide, we tell R which columns to take the names and values from: pivot_wider(names_from = name, values_from = val).\n\n\n\n\nProblem\nThe blink_setup.csv file has the data in a different shape to the blink_eyegaze.xlsx file.\n\nblink_setup.csv : one row per participant\n\nblink_eyegaze.xlsx : one row per trial\n\nTask\nReshape the data to make it so that there is one row per trial.\n\nHint\n\nin the tidyverse functions, you can specify all columns between column x and column z by using the colon, x:z.\n\n\n\n\n\n\n Solution \n\n\n(Note that this will depend on what you called your columns in the previous question - we just called them “trial_1”, … , “trial_20”).\n\nsetuplong <- \n  setupdata %>%\n  pivot_longer(trial_1:trial_20, names_to = \"trial_number\", values_to = \"video\")\n\nsetuplong\n\n# A tibble: 460 × 3\n   sub       trial_number video                    \n   <chr>     <chr>        <chr>                    \n 1 subject_1 trial_1      /files/vids/blinks_1.mp4 \n 2 subject_1 trial_2      /files/vids/blinsk_8.mp4 \n 3 subject_1 trial_3      /files/vids/blinks_1.mp4 \n 4 subject_1 trial_4      /files/vids/blinks_5.mp4 \n 5 subject_1 trial_5      /files/vids/blinks_4.mp4 \n 6 subject_1 trial_6      /files/vids/blinks_10.mp4\n 7 subject_1 trial_7      /files/vids/blinks_1.mp4 \n 8 subject_1 trial_8      /files/vids/blinks_5.mp4 \n 9 subject_1 trial_9      /files/vids/blinks_6.mp4 \n10 subject_1 trial_10     /files/vids/blinks_4.mp4 \n# … with 450 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\n\n\n\nDealing with character strings\nThere are loads of functions we can use to do various things with character strings in R.\nHere are a few examples:\n\n gsub()\n\n\nsubstitute a string of characters for another string:\n\ngsub(\"don't like\",\"love\", \"i really really really don't like statistics!\")\n\n[1] \"i really really really love statistics!\"\n\n\n\n\n\n\n separate()\n\n\nseparate a column into multiple columns by splitting at a set of characters\n\nmupsimp <- read_csv(\"https://uoepsy.github.io/data/muppet_simp.csv\")\nmupsimp\n\n# A tibble: 18 × 1\n   show_name                     \n   <chr>                         \n 1 simpsons_Marge Simpson        \n 2 muppets_Scooter               \n 3 muppets_Rowlf the Dog         \n 4 muppets_Fozzie Bear           \n 5 simpsons_Abraham Simpson      \n 6 muppets_Walter                \n 7 muppets_Pepe the King Prawn   \n 8 muppets_Gonzo                 \n 9 simpsons_Santa's Little Helper\n10 simpsons_Snowball II/V        \n11 simpsons_Maggie Simpson       \n12 simpsons_Lisa Simpson         \n13 simpsons_Bart Simpson         \n14 muppets_Animal                \n15 simpsons_Homer Simpson        \n16 muppets_Miss Piggy            \n17 muppets_Rizzo the Rat         \n18 muppets_Kermit the Frog       \n\nmupsimp %>% \n  separate(show_name, into = c(\"show\",\"name\"), sep = \"_\")\n\n# A tibble: 18 × 2\n   show     name                 \n   <chr>    <chr>                \n 1 simpsons Marge Simpson        \n 2 muppets  Scooter              \n 3 muppets  Rowlf the Dog        \n 4 muppets  Fozzie Bear          \n 5 simpsons Abraham Simpson      \n 6 muppets  Walter               \n 7 muppets  Pepe the King Prawn  \n 8 muppets  Gonzo                \n 9 simpsons Santa's Little Helper\n10 simpsons Snowball II/V        \n11 simpsons Maggie Simpson       \n12 simpsons Lisa Simpson         \n13 simpsons Bart Simpson         \n14 muppets  Animal               \n15 simpsons Homer Simpson        \n16 muppets  Miss Piggy           \n17 muppets  Rizzo the Rat        \n18 muppets  Kermit the Frog      \n\n\n\n\n\n\n substr()\n\n\nExtract or replace substrings in a character vector.\n\n# get the first 3 letters\nsubstr(mupsimp$show_name, 1, 3)\n\n [1] \"sim\" \"mup\" \"mup\" \"mup\" \"sim\" \"mup\" \"mup\" \"mup\" \"sim\" \"sim\" \"sim\" \"sim\"\n[13] \"sim\" \"mup\" \"sim\" \"mup\" \"mup\" \"mup\"\n\n\nCan be combined with functions like nchar() (to find the number of characters in each string). Additionally, can be used in tidyverse easily:\n\nmupsimp %>%\n  mutate(\n    first3 = substr(show_name, 1, 3),\n    last3 = substr(show_name, nchar(show_name)-2, nchar(show_name))\n  )\n\n# A tibble: 18 × 3\n   show_name                      first3 last3\n   <chr>                          <chr>  <chr>\n 1 simpsons_Marge Simpson         sim    son  \n 2 muppets_Scooter                mup    ter  \n 3 muppets_Rowlf the Dog          mup    Dog  \n 4 muppets_Fozzie Bear            mup    ear  \n 5 simpsons_Abraham Simpson       sim    son  \n 6 muppets_Walter                 mup    ter  \n 7 muppets_Pepe the King Prawn    mup    awn  \n 8 muppets_Gonzo                  mup    nzo  \n 9 simpsons_Santa's Little Helper sim    per  \n10 simpsons_Snowball II/V         sim    I/V  \n11 simpsons_Maggie Simpson        sim    son  \n12 simpsons_Lisa Simpson          sim    son  \n13 simpsons_Bart Simpson          sim    son  \n14 muppets_Animal                 mup    mal  \n15 simpsons_Homer Simpson         sim    son  \n16 muppets_Miss Piggy             mup    ggy  \n17 muppets_Rizzo the Rat          mup    Rat  \n18 muppets_Kermit the Frog        mup    rog  \n\n\n\n\n\n\n paste()\n\n\npaste() can quickly combine two character vectors:\n\npaste(\"hello\",\"everyone\",sep=\" \")\n\n[1] \"hello everyone\"\n\n\nYou can also use it to collapse a vector into a single string:\n\npaste(mupsimp$show_name, collapse=\" \")\n\n[1] \"simpsons_Marge Simpson muppets_Scooter muppets_Rowlf the Dog muppets_Fozzie Bear simpsons_Abraham Simpson muppets_Walter muppets_Pepe the King Prawn muppets_Gonzo simpsons_Santa's Little Helper simpsons_Snowball II/V simpsons_Maggie Simpson simpsons_Lisa Simpson simpsons_Bart Simpson muppets_Animal simpsons_Homer Simpson muppets_Miss Piggy muppets_Rizzo the Rat muppets_Kermit the Frog\"\n\n\nand paste0() is a quick shortcut for using sep=\"\":\n\npaste0(\"hello\",\"everyone\")\n\n[1] \"helloeveryone\"\n\n\n\n\n\n\n\n\n\nProblem\nIf you look at what data was captured by the software to indicate which video was used in each trial, there is a lot of unnecessary data there. The number of the filename indicates how many blinks are in the video. This is the only bit of information we want.\n\nhead(setuplong$video)\n\n[1] \"/files/vids/blinks_1.mp4\"  \"/files/vids/blinsk_8.mp4\" \n[3] \"/files/vids/blinks_1.mp4\"  \"/files/vids/blinks_5.mp4\" \n[5] \"/files/vids/blinks_4.mp4\"  \"/files/vids/blinks_10.mp4\"\n\n\nTask\n\nIn your (now reshaped to long) blink_setup.csv data, make a new, or edit an existing column, which is a numeric variable containing the number of blinks presented in the video in each trial\n\n\nHints:\n\nthere are lots of different ways you could do this.\n\nyou can substitute out multiple different strings by separating them with the | symbol:\n\n\n  gsub(\"dog|cat\", \"horse\", \"I have a dog and a cat and the dogs name is Graham\")\n\n[1] \"I have a horse and a horse and the horses name is Graham\"\n\n\n\n\n\n\n\n Solution \n\n\n\nsetuplong <- setuplong %>%\n  mutate(\n    nr_blinks = as.numeric(gsub(\"/files/vids/|blinks_|blinsk_|.mp4\",\"\",video))\n  )\n\nsetuplong\n\n# A tibble: 460 × 4\n   sub       trial_number video                     nr_blinks\n   <chr>     <chr>        <chr>                         <dbl>\n 1 subject_1 trial_1      /files/vids/blinks_1.mp4          1\n 2 subject_1 trial_2      /files/vids/blinsk_8.mp4          8\n 3 subject_1 trial_3      /files/vids/blinks_1.mp4          1\n 4 subject_1 trial_4      /files/vids/blinks_5.mp4          5\n 5 subject_1 trial_5      /files/vids/blinks_4.mp4          4\n 6 subject_1 trial_6      /files/vids/blinks_10.mp4        10\n 7 subject_1 trial_7      /files/vids/blinks_1.mp4          1\n 8 subject_1 trial_8      /files/vids/blinks_5.mp4          5\n 9 subject_1 trial_9      /files/vids/blinks_6.mp4          6\n10 subject_1 trial_10     /files/vids/blinks_4.mp4          4\n# … with 450 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\n\n\n\nJoining/merging\nNow comes a fun bit.\nRecall that the research question is interested in the relationship between the number of times the speaker was seen to blink, and the time the participants spent looking at the distractor object (indicating perceived dishonesty).\nYou may have noticed that these variables are currently in different data-sets! The blink_setup.csv contains information about the numbers of blinks in the videos, and the blink_eyegaze.xlsx contains the data on the fixations.\nSolution: we need to join them together!\nNote that because both data-sets contain information on participant number and trial number, which uniquely identifies each observation, we can join them together matching on these variables!\nThere are lots of different ways to join data-sets, depending on whether we want to keep rows from one data-set or the other, or keep only those in both data-sets etc.\n\n\n\n\n\nCheck out the help documentation for them all using ?full_join.\n\n\n\n\n\n\n\n\nProblem\nVariables are in different data-sets.\nTask\n\nJoin the two data-sets (the reshaped-to-long blink_setup.csv data, and the blink_eyegaze.xlsx data) together, and store the joined data in a new object (you can use your own name, but the solutions will use the name blinks_full).\n\n\nHints:\nWe want to match the observations based on two columns which are present in each data-set, indicating which participant, and which trial.\n\nRemember that R doesn’t have your intelligence - it doesn’t know that in one data-set the variable is called e.g., trial_no and in the other it is called trial_number.\n\nAnother thing which R doesn’t know is that “subject_1” in setup data is the same participant as “1” in the eye gaze data. It needs to match the same symbols, and what is more, it needs the variables to be the same type (character, numeric, factor etc).\n\nyou might want to make use of the skills you learned for manipulating character strings.\n\n\n\n\n\n\n\n Solution \n\n\nIn this solution, let’s build up a sequence step by step. Work through the steps, adding lines of code each time. Between each step, run the code to quickly see what the output looks like at each step.\n\nFirst, let’s see how we can remove the “subject_” from “subject_1” etc..\n::: {.cell layout-align=“center”}\nsetuplong %>%\n  mutate(\n    sub = gsub(\"subject_\",\"\",sub)\n  )\n:::\nBut we also want it to be numeric, to match the sub variable in the eyegaze data, so let’s edit it to:\n::: {.cell layout-align=“center”}\nsetuplong %>%\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub))\n  )\n:::\nWe’ll also need to do the same for the trial_number variable, so let’s add that line too:\n::: {.cell layout-align=“center”}\nsetuplong %>%\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  )\n:::\nAnd then, we’ll note that we need to have the same name for variables indicating trial number in both data-sets, so lets rename it:\n::: {.cell layout-align=“center”}\nsetuplong %>%\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) %>%\n  rename(trial_no = trial_number)\n:::\nAnd now… add the join!\n::: {.cell layout-align=“center”}\nsetuplong %>%\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) %>%\n  rename(trial_no = trial_number) %>%\n  full_join(x = ., y = eyedata)\n:::\n\nNOTE the solution has x = ., y = eyedata to make it clear that we are ‘piping in’ (using %>%) the thing coming out of the previous lines of code, and putting it where the . is. .... %>% full_join(eyedata) would do the same.\nWe use full_join here because we want to keep all the data, but left_join would do the same. right_join would be slightly different, because there are 3 observations in the setup data (when reshaped to long, n = 460) which aren’t in the eye gaze data (n = 457). You can see which ones they are by using anti_join.\n6. Finally - we need to give the whole output a name to store it in our environment!\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nblinks_full <- \n  setuplong %>%\n  mutate(\n    sub = as.numeric(gsub(\"subject_\",\"\",sub)),\n    trial_number = as.numeric(gsub(\"trial_\",\"\",trial_number))\n  ) %>%\n  rename(trial_no = trial_number) %>%\n  full_join(x = ., y = eyedata)\n```\n:::\n\n\n\n\n\nImpossible Values\nIt’s important to check that there are no values in the data which are impossible, given what you know about how the data was measured. This is where exploratory plots and descriptive statistics come in handy.\n\nhist(as.numeric(blinks_full$distractor_fix))\n\n\n\n\n\n\n\n\nIn some trials, participants spent less that 0ms fixating on the distractor object!?!?!?\nWe have a couple of options as to how to deal with them.\n\nDelete the entire row\nChange the specific entry/s in that variable to be NA (Not Applicable) - this has the benefit of keeping the rows should we consider those row to have a valid observation in other variables (for instance the rt - reaction time?)\n\nSome of the tools we learned in the Reading 1B will come in handy here.\n\n\n\n\nProblem\nSome impossible values in the distractor_fix variable.\nTask\n- Assign the entries of the distractor_fix variable which are < 0 to be NA.\n- Are there any other impossible values (or combinations of values) in the data?\n\nHints:\n\nWhile you’re there, why not convert any variables to the right type (numeric, factor, etc).\n\nWe might not have come across this before, but there is a really useful function called ifelse().\nPlay around with the below code to learn:\n\n\ntibble(x = 1:10) %>%\n  mutate(\n    new_variable = ifelse(x>5,1,0),\n    another_new_variable = ifelse(x>5,\"peppapig\",\"kermit\"),\n    morevariables = ifelse(another_new_variable == \"kermit\",\"kermit the frog\", another_new_variable)\n  )\n\n\n\n\n\n\n Solution \n\n\nBelow we’ve taken similar steps for both the distractor_fix and rt variables. Neither can be <0 or >5000.\nHowever, we know that the distractor_fix variable has no entries >5000 (because of the histogram above).\n\nblinks_full <- \n  blinks_full %>%\n  mutate(\n    distractor_fix = as.numeric(distractor_fix),\n    distractor_fix = ifelse(distractor_fix<0, NA, distractor_fix),\n    rt = ifelse(as.numeric(rt)>5000 | as.numeric(rt)<0, NA, as.numeric(rt))\n  )\n\nNote how two steps (making it numeric, and replacing values with NAs) are combined for the rt variable. Note also how we have specified that we replace with NAs entries which meet either on condition (>5000) or (using |) another (<0).\n\n\n\n\n\nMissing Data in R\nMissing data can be a big problem for statistics. For those of you thinking of taking Multivariate Statistics & Methodology in R next semester, you can look forward to discussions around this sort of issue.\nHere, however, we are simply going to discuss the practicalities of how to make R code work when some of your values are NAs.\nConsider:\n\nvec <- c(1,2,3,4,NA)\nmean(vec)\n\n[1] NA\n\n\nThink about why this is:\n\\[\n\\text{mean(vec)} = \\frac{1+2+3+4+\\text{NA}}{5} = \\frac{\\text{??}}{5} = \\text{??}\n\\]\nThere are numerous different ways that functions in R cope with missing values, but if you’re ever in doubt, try na.rm = TRUE. This will basically tell R to “remove the NAs before doing the calculation”.\n\nmean(vec, na.rm=T)\n\n[1] 2.5\n\n\nOther functions include na.omit(), which remove any row with has an NA anywhere in it:\n\ncomplete_data <- na.omit(data)\n\n\n\nOutliers\nOutliers are the extreme - but plausible - values in variables. There is no one way to identify what is extreme enough to consider and outlier, nor is there one way to handle them.\nSome outliers could be considered important observations which we would not want to exclude. However, being an outlier can (but not always) result in an observation exerting too great an influence on our analysis.\n\nSome common approaches to identifying outliers:\n\nobservations which are \\(> 3\\) (sometimes \\(> 2.5\\)) standard deviations away from the mean.\nobservations greater than \\(1.5 \\times IQR\\) below the first quartile \\(Q_1\\) or above the third quartile \\(Q_3\\).\n\nSome common approaches to handling outliers:\n\nExclude now - for instance, set as NA\n“Winsorize” - set to a specified percentile. For example, all observations below the 5th percentile set to the 5th percentile, and all observations above the 95th percentile set to the 95th percentile\nExclude from analysis later, based on measures of influence (we’ll learn about this in future topics)\n\n\n\n\n\n\nMake a bloxplot of the distractor_fix variable. Does it look like there might be any outliers?\n\n\n\n\n Solution \n\n\nThe last line of this is there just because I personally don’t like the default look of geom_boxplot where it is really wide, so this line changes the limits of the x-axis (and also removes the ticks).\n\nggplot(data = blinks_full, aes(y = distractor_fix)) +\n  geom_boxplot()+\n  scale_x_continuous(limits = c(-2,2), breaks = NULL)\n\n\n\n\n\n\n\n\nIt looks like there are possibly some outliers at the upper end of the distribution. One of them looks really quite anomalous!\n\n\n\n\n\nCustom Functions\n\n\n\n\nWriting your own function\nWe already saw some custom functions in the first week, where we made some called dice() and wdice().\nCan you write a function which, given a vector, returns TRUE if it is an outlier and FALSE if it is not, based on the criterion of being \\(>3\\) sd away from the mean.\n\noutliers <- function(obs){\n ...\n ...\n ...\n}\n\n\n\n\n\n Solution \n\n\n\n Working out the internal code\n\n\nLet’s do the calculation on a little vector, keeping it all outside of a function first:\n\n# a random vector (length = 20)\nvec <- rnorm(n = 20, mean = 0, sd = 1)\n# pick two random entries and make them outliers (one in each direction)\nvec[3] <- 150\nvec[16] <- -150\nvec\n\n [1]   -0.3044178    0.5719631  150.0000000   -0.5347949   -0.1636259\n [6]   -0.2142080    0.8871272    0.3398005   -0.3103592    1.0362158\n[11]   -0.3149294   -0.2797405    0.4751645   -0.3124426   -1.4676446\n[16] -150.0000000    1.9775188    0.8872577   -0.7182226   -1.0305862\n\n# deviations from each point to mean\nvec - mean(vec)\n\n [1]   -0.3306216    0.5457593  149.9737962   -0.5609987   -0.1898297\n [6]   -0.2404118    0.8609234    0.3135967   -0.3365630    1.0100120\n[11]   -0.3411332   -0.3059443    0.4489607   -0.3386464   -1.4938484\n[16] -150.0262038    1.9513150    0.8610539   -0.7444264   -1.0567900\n\n# and three times the standard deviation\n3 * sd(vec)\n\n[1] 146.0184\n\n# but this won't work because some are below, rather than above the mean. \n(vec - mean(vec)) > (3 * sd(vec))\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n# instead we want the ABSOLUTE value \nabs(vec - mean(vec)) > (3 * sd(vec))\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n\n\n\n\n\n\n Writing it as a function\n\n\nOkay, now that we’ve worked out the code, we want to make this a function. The template function in the question had an input called obs:\n\noutliers <- function(obs){\n\n}\n\nSo we would want to add our code to the function, but change it to use obs (which is whatever we give the function)\n\noutliers <- function(obs){\n  abs(obs - mean(obs)) > (3 * sd(obs))\n}\n\n\n\n\n\n Testing the function\n\n\nwe can test it on the vec object we created earlier.\n\noutliers(obs = vec)\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n\n\nWe can use it to access and edit those entries:\n\nvec[outliers(vec)]\n\n[1]  150 -150\n\nvec[outliers(vec)] <- NA\n\n\n\n\n\n Extra - adding more arguments\n\n\nWe could edit the function so that we can also vary how many standard deviations away we are wanting to identify!\n\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs)) > (x * sd(obs))\n}\n\nthe x = 3 means that the function will default to looking 3 standard deviations away, but if we wanted to use outliers(obs = vec, x = 2) we could identify those which are 2 away!\n\n\n\n\n\n\n\n\n\n\nLook through the solutions to question B8 above, and make sure that you are comfortable with how writing a function works.\nCan you edit the outliers() function you wrote to make it work with vectors which include NAs?\n\n\n\n\n Solution \n\n\n\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs, na.rm=TRUE)) > (x * sd(obs, na.rm=TRUE))\n}\n\n\n\n\n\n\n\n\nProblem\nPossible outliers in the distractor_fix variable.\nTask\n\nReplace any values of the distractor_fix variable which are \\(>3\\) standard deviations from the mean with NA.\n\nMake a new boxplot of the variable\n\n\n If you skipped questions A8 and A9\n\n\nIf you skipped questions B8 and B9, then copy and run this code into your document. It will give you a function which takes a vector and returns TRUEs and FALSEs based on whether each entry is greater than 3 standard deviations from the mean.\n\noutliers <- function(obs, x = 3){\n  abs(obs - mean(obs, na.rm=TRUE)) > (x * sd(obs, na.rm=TRUE))\n}\n\n\n\n\n\n\n\n\n Solution \n\n\n\nblinks_full$distractor_fix[outliers(blinks_full$distractor_fix)]<- NA\n\nggplot(data = blinks_full, aes(y = distractor_fix)) +\n  geom_boxplot()+\n  scale_x_continuous(limits = c(-2,2), breaks = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAggregating\nTODO"
  },
  {
    "objectID": "07_ex.html",
    "href": "07_ex.html",
    "title": "Week 7 Exercises: Linear Regression",
    "section": "",
    "text": "Basic Tests are Linear Models!\n\nQuestion 12\n\n\nWe’ve actually already seen a way to analyse questions of this sort (“is the average income different between those with and those without a degree?”)\nRun the following t-test, and consider the statistic, p value etc. How does it compare to the model in the previous question?\n\nt.test(income ~ degree, data = riverview, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  income by degree\nt = -4.6408, df = 30, p-value = 6.412e-05\nalternative hypothesis: true difference in means between group no and group yes is not equal to 0\n95 percent confidence interval:\n -27.15051 -10.55673\nsample estimates:\n mean in group no mean in group yes \n         46.08284          64.93646 \n\n\n\n\n\n\nIt is identical! the \\(t\\)-statistics are the same, the p-values are the same, the degrees of freedom. Everything!\nThe two sample t-test is actually just a special case of the linear model, where we have a numeric outcome variable and a binary predictor!\nAnd… the one-sample t-test is the linear model without any predictors, so just with an intercept.\n\nt.test(riverview$income, mu = 0)\n\n\n    One Sample t-test\n\ndata:  riverview$income\nt = 20.89, df = 31, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 48.49519 58.98906\nsample estimates:\nmean of x \n 53.74213 \n\ninterceptonly_model <- lm(income ~ 1, data = riverview)\nsummary(interceptonly_model)$coefficients\n\n            Estimate Std. Error  t value     Pr(>|t|)\n(Intercept) 53.74212    2.57264 20.88988 7.995568e-20"
  },
  {
    "objectID": "07a_slr.html",
    "href": "07a_slr.html",
    "title": "7A: Simple Linear Regression",
    "section": "",
    "text": "In its simplest form, linear regression is a way to make a model of the relationship between two variables. When both variables are continuous, it is nice and intuitive to envisage this as the ‘line of best fit’ on a scatterplot. For instance, in Figure 1 we see two variables y and x, and our linear regression model is the blue line.\n\n\n\n\n\nFigure 1: y regressed onto x.\n\n\n\n\nWe’re going to use the data in this plot for the remainder of the reading. If you wish to play around with it yourself, it is available at https://uoepsy.github.io/data/usmr_slr.csv, and contains a sample of 100 observations on variables x and y.\n\nlibrary(tidyverse)\nmy_data <- read_csv(\"https://uoepsy.github.io/data/usmr_slr.csv\")\nhead(my_data)\n\n# A tibble: 6 × 2\n      x     y\n  <dbl> <dbl>\n1  3.19  4.42\n2  2.57  4.48\n3  3.91  2.72\n4  4.79  5.39\n5  4.00  3.85\n6  4.11  4.42\n\n\nFigure 1, above, highlights a linear relationship, where the data points are scattered around an underlying linear pattern with a roughly-constant spread as we move along x.\nIn 5A: Covariance & Correlation we have already talked about one way to describe this relationship, by calculating either the covariance or the correlation between x and y.\nHowever, as we will see in the coming weeks, the linear model provides us with the scope to extend our analysis to many more situations - it is the building block of many more complex analytical methods.\nThe simple linear regression model takes the form:\n\\[\n\\begin{align}\n& y = b_0 + b_1 \\ x + \\epsilon \\quad \\\\\n\\end{align}\n\\]\n\n\nYou will see a variety of different ways of specifying the linear model form in different resources, some use \\(\\beta\\), some use \\(b\\). Sometimes you will see \\(\\alpha\\) instead of \\(b_0\\).\nWe typically refer to the outcome (‘dependent’) variable with the letter \\(y\\) and to our predictor (‘explanatory’/‘independent’) variables with the letter \\(x\\). When we construct a linear model we are trying to re-express our outcome variable \\(y\\) with some linear transformation of our predictor variable \\(x\\).\nYou can think of this in broader terms as:\n\\[\n\\begin{align}\n& \\color{red}{Outcome}\\color{} = \\color{blue}{Model}\\color{black}{} + Error\\\\\n\\end{align}\n\\]\n\n\nWhen we fit a simple regression model, the bit we refer to as the ‘model’ is the line that is defined by two numbers:\n\nthe intercept, denoted \\(b_0\\).\nThis is the point at which the line hits the y-axis (i.e. where \\(x=0\\))\nthe slope, denoted \\(b_1\\).\nThis is the angle of the line. It is the amount which the line increases for every 1 increase in \\(x\\).\n\n\n\n\n\n\nFigure 2: Simple linear regression model, with the systematic part of the model in blue\n\n\n\n\nThis line implies some predicted values for our observed \\(x\\) values. For instance, we can see that when \\(x=3\\), the model (the blue line) will predict that \\(y\\) is approximately 4. If we take each of our datapoints, and project them up/down to the line, then we get our fitted values (Figure 3). We often denote these as \\(\\hat y\\) (or “y hat”), with the hat indicating that they are the model-estimated values of \\(y\\).\n\\[\n\\begin{align}\n\\color{red}{Outcome}\\color{black} \\qquad=\\qquad & \\color{blue}{Model}\\color{black}{} & +\\qquad Error\\\\\n\\color{red}{y}\\color{black} \\qquad = \\qquad & \\color{blue}{\\hat y}\\color{black} & +\\qquad \\epsilon \\quad \\\\\n\\color{red}{y}\\color{black} \\qquad = \\qquad & \\color{blue}{b_0 + b_1 \\ (x)}\\color{black} & +\\qquad \\epsilon \\quad \\\\\n\\end{align}\n\\]\n\n\n\n\n\nFigure 3: Simple linear regression model, fitted values in blue\n\n\n\n\n\n Optional: Regression Slope vs Covariance\n\n\nWith simple linear regression, the fitted line we are describing is actually a scaled version of our covariance.\nRemember that covariance is the average of the products of \\((x_{i}-\\bar{x})(y_{i}-\\bar{y})\\), which is a bit like the average area of the rectangles in Figure 4. If we think about what the average width of these rectangles is, it is the average of \\((x_{i}-\\bar{x})\\), which is actually just the variance of \\(x\\)!\n\n\n\n\n\nFigure 4: Covariance\n\n\n\n\nWe can divide the area of the average rectangle (\\(cov(x, y)\\)) by its width (\\(var(x)\\)), thereby scaling it so that the width is 1. What we’re getting from our coefficient is the area of this new rectangle which has width = 1. Because width = 1, the area is also the height (\\(\\text{area} = \\text{width} \\times \\text{height} = 1 \\times \\text{height}\\)). So what we get is the amount that \\(y\\) increases (the height) as \\(x\\) increases by 1 (the width).\nWe can see this working:\n\ncov(my_data$x, my_data$y)\n\n[1] 0.6877738\n\nvar(my_data$x)\n\n[1] 0.8823097\n\n\nThis calculation gives us the same linear regression slope of 0.78 that we see when we fit the model lower down this page.\n\ncov(my_data$x, my_data$y)/var(my_data$x)\n\n[1] 0.7795152\n\n\n\n\n\n\n\n\nOur model is not perfect. It is a model - i.e. it is a simplification of the world, and so is inherently going to be inaccurate for individuals. This innaccuracy can be seen in the plots above: some points are higher than the model predicts, some lower. These deviations (shown by the red lines in Figure 5) from the model are the random error component \\(\\hat \\epsilon\\), or “residuals”.\n\n\n\n\n\nFigure 5: Simple linear regression model, with the systematic part of the model in blue, and residuals in red\n\n\n\n\nIn full, we should really write our linear regression model out as:\n\\[\n\\begin{align}\n& y = b_0 + b_1 \\ x + \\epsilon \\quad \\\\\n& \\text{where} \\\\\n& \\epsilon \\sim N(0, \\sigma) \\text{ independently}\n\\end{align}\n\\]\nThe new bit here: “\\(\\epsilon \\sim N(0, \\sigma) \\text{ independently}\\)” means that the errors around the line have mean zero and constant spread as x varies (we’ll read more about what this means later in this course, when we discuss the assumptions underlying regression). You can think of \\(\\sim N(0, \\sigma)\\) as meaning “normally distributed with a mean of zero and a standard deviation of \\(\\sigma\\)”.\nThe standard deviation of the errors, denoted by \\(\\sigma\\) is an important quantity that our model estimates. It measures how much individual data points tend to deviate above and below the regression line. A small \\(\\sigma\\) indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large \\(\\sigma\\) suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\n\\(\\sigma\\) is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root:\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{SS_{Residual}}{n - 2}} \\\\\n\\qquad \\\\\n& \\text{where} \\\\\n& SS_{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2}\n\\end{align}\n\\]"
  },
  {
    "objectID": "07a_slr.html#lm",
    "href": "07a_slr.html#lm",
    "title": "7A: Simple Linear Regression",
    "section": "lm()",
    "text": "lm()\nIn R it is very easy to fit linear models, we just need to use the lm() function.\nThe syntax of the lm() function is:\nmodel_name <- lm(outcome ~ 1 + predictor, data = dataframe)\nWe don’t have to include the 1 + when we specify the model, as this will be included by default, so we can also simply write:\nmodel_name <- lm(outcome ~ predictor, data = dataframe)\n\n What is the ~1 + doing?\n\n\nThe fitted model can be written as\n\\[\n\\hat y = \\hat b_0 + \\hat b_1 x\n\\]\nThe predicted values for the outcome are equal to our intercept, \\(\\hat b_0\\), plus our slope \\(\\hat b_1\\) multiplied by the value on our explanatory variable \\(x\\).\nThe intercept is a constant. That is, we could write it as multiplied by 1:\n\\[\n\\hat y = \\color{blue}{\\hat b_0}\\color{black}{}(\\color{green}{1}\\color{black}{})\\color{blue}{ + \\hat b_1 }\\color{black}{}(\\color{green}{x}\\color{black}{})\n\\]\nWhen we specify the linear model in R, we include after the tilde sign ~ all the things which appear to the right of each of the \\(\\hat b\\)s (the bits in green in the equartion above). That’s why the 1 is included. It is just saying “we want the intercept, \\(b_0\\), to be estimated”."
  },
  {
    "objectID": "07a_slr.html#model-summary",
    "href": "07a_slr.html#model-summary",
    "title": "7A: Simple Linear Regression",
    "section": "Model Summary",
    "text": "Model Summary\nWe can then view lots of information by giving our model to the summary() function:\n\n\n\n\n\nFigure 6: Output of lm() for a simple regression in R\n\n\n\n\nThe intercept \\(b_0\\) is the point at which the line hits the y-axis (i.e. where \\(x=0\\)), and the slope \\(b_1\\) is the amount which the line increases for every 1 increase in \\(x\\). We can see the estimated values of these in Figure 6, providing us with our fitted line:\n\\[\n\\begin{align}\ny &= 1.54 + 0.78 (x) + \\varepsilon \\\\\n\\end{align}\n\\]\n\n\n\n\n\nFigure 7: Simple linear regression model, estimated intercept and slope included"
  },
  {
    "objectID": "07a_slr.html#model-predictions",
    "href": "07a_slr.html#model-predictions",
    "title": "7A: Simple Linear Regression",
    "section": "Model Predictions",
    "text": "Model Predictions\nFurthermore, we can get out the model predicted values for \\(y\\), the “y hats” (\\(\\hat y\\)), using functions such as:\n\npredict(my_model)\nfitted(my_model)\nfitted.values(my_model)\nmy_model$fitted.values\n\nA nice package which will come in handy is the broom package. It allows us to use the function augment(), which gives us out lots of information, such as the model predicted values, the residuals, and many more:\n\nlibrary(broom)\naugment(my_model)\n\n# A tibble: 100 × 8\n       y     x .fitted .resid   .hat .sigma  .cooksd .std.resid\n   <dbl> <dbl>   <dbl>  <dbl>  <dbl>  <dbl>    <dbl>      <dbl>\n 1  4.42  3.19    4.03  0.388 0.0102  0.935 0.000903      0.420\n 2  4.48  2.57    3.54  0.941 0.0130  0.931 0.00681       1.02 \n 3  2.72  3.91    4.59 -1.87  0.0180  0.916 0.0378       -2.03 \n 4  5.39  4.79    5.28  0.107 0.0438  0.935 0.000319      0.118\n 5  3.85  4.00    4.66 -0.809 0.0197  0.932 0.00776      -0.878\n 6  4.42  4.11    4.74 -0.327 0.0222  0.935 0.00143      -0.355\n 7  4.30  2.72    3.66  0.638 0.0114  0.933 0.00274       0.689\n 8  5.94  4.02    4.68  1.26  0.0202  0.927 0.0193        1.37 \n 9  1.70  3.05    3.92 -2.22  0.0100  0.908 0.0291       -2.40 \n10  4.79  4.58    5.11 -0.318 0.0358  0.935 0.00224      -0.348\n# … with 90 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nWe can also compute model-predicted values for other (unobserved) data. For instance, what about for an observation where \\(x=10\\), or \\(20\\)?\n\n# make a dataframe with values for the predictor:\nsome_newdata <- data.frame(x=c(10, 20))\n# model predicted values of y, for the values of x inside the 'some_newdata' object:\npredict(my_model, newdata = some_newdata)\n\n       1        2 \n 9.33792 17.13307 \n\n\nGiven that our fitted model takes the form below, we can work this out ourselves as well:\n\\[\n\\begin{align}\ny &= 1.54 + 0.78\\cdot x \\\\\ny &= 1.54 + 0.78\\cdot 10 \\\\\ny &= 1.54 + 7.80\\\\\ny &= 9.34 \\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "07a_slr.html#partitioning-variance",
    "href": "07a_slr.html#partitioning-variance",
    "title": "7A: Simple Linear Regression",
    "section": "Partitioning Variance",
    "text": "Partitioning Variance\nWe might ask ourselves if the model is useful in explaining the variance in our outcome variable \\(y\\). To quantify and assess model utility, we split the total variability of the outcome variable into two terms: the variability explained by the model plus the variability left unexplained in the residuals.\n\\[\n\\begin{align}\n& \\qquad \\qquad \\qquad \\qquad \\text{total variability in response } =  \\\\\n& \\text{variability explained by model } + \\text{unexplained variability in residuals}\n\\end{align}\n\\]\nThe illustration in Figure 11 gets at the intuition behind this: the top panel shows the total variability in the outcome variable \\(y\\) - for each datapoint we see the distance from the mean of y. These distances can be split into the bit from the mean to the model predicted value (seen in the bottom left panel of Figure 11), and the bit from that value to the actual value (bottom right panel).\nEach term can be quantified by a sum of squares:\n\\[\n\\begin{aligned}\nSS_{Total} &= SS_{Model} + SS_{Residual} \\\\\n\\sum_{i=1}^n (y_i - \\bar y)^2 &= \\sum_{i=1}^n (\\hat y_i - \\bar y)^2 + \\sum_{i=1}^n (y_i - \\hat y_i)^2 \\\\\n\\quad \\\\\n\\text{Where:} \\\\\n& y_i = \\text{observed value} \\\\\n&\\bar{y} = \\text{mean} \\\\\n& \\hat{y}_i = \\text{model predicted value} \\\\\n\\end{aligned}\n\\]\n\n\n\n\n\nFigure 11: Total Sums of Squares = Model Sums of Squares + Residual Sums of Squares"
  },
  {
    "objectID": "07a_slr.html#r2",
    "href": "07a_slr.html#r2",
    "title": "7A: Simple Linear Regression",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nA useful statistic is the \\(R^2\\), which shows us the proportion of the total variability in the outcome (y) that is explained by the linear relationship with the predictor (x).\n\nThe \\(R^2\\) coefficient is defined as the proportion of the total variability in the outcome variable which is explained by our model:\n\\[\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Residual}}{SS_{Total}}\n\\]\n\nWe can find the \\(R^2\\) easily in the summary() of the model!\n\nsummary(my_model)\n\n\nCall:\nlm(formula = y ~ x, data = my_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4383 -0.6593  0.1075  0.5945  2.1867 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.54277    0.32005   4.820 5.24e-06 ***\nx            0.77952    0.09959   7.827 5.92e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9308 on 98 degrees of freedom\nMultiple R-squared:  0.3847,    Adjusted R-squared:  0.3784 \nF-statistic: 61.26 on 1 and 98 DF,  p-value: 5.918e-12\n\n\nThe output of summary() displays the R-squared value in the following line:\nMultiple R-squared:  0.3847\n\n\nFor the moment, ignore “Adjusted R-squared”. We will come back to this later on.\n\nApproximately 38% of the total variability in y is explained by the linear association with x.\n\n\n Optional - Manual calculation of R-Squared\n\n\n\nmy_model_fitted <- my_data %>%\n  mutate(\n    y_hat = predict(my_model),\n    resid = y - y_hat\n  )\nhead(my_model_fitted)\n\n# A tibble: 6 × 4\n      x     y y_hat  resid\n  <dbl> <dbl> <dbl>  <dbl>\n1  3.19  4.42  4.03  0.388\n2  2.57  4.48  3.54  0.941\n3  3.91  2.72  4.59 -1.87 \n4  4.79  5.39  5.28  0.107\n5  4.00  3.85  4.66 -0.809\n6  4.11  4.42  4.74 -0.327\n\nmy_model_fitted %>%\n  summarise(\n    SSModel = sum( (y_hat - mean(y))^2 ),\n    SSTotal = sum( (y - mean(y))^2 )\n  ) %>%\n  summarise(\n    RSquared = SSModel / SSTotal\n  )\n\n# A tibble: 1 × 1\n  RSquared\n     <dbl>\n1    0.385"
  },
  {
    "objectID": "07a_slr.html#the-f-statistic",
    "href": "07a_slr.html#the-f-statistic",
    "title": "7A: Simple Linear Regression",
    "section": "The \\(F\\) Statistic",
    "text": "The \\(F\\) Statistic\nThis will become more relevant in coming weeks, but we can also perform a test to investigate if the model is ‘useful’ — that is, a test to see if the explanatory variable is a useful predictor of the outcome.\nWe test the following hypotheses:\n\\[\n\\begin{aligned}\nH_0 &: \\text{the model is ineffective, } b_1 = 0 \\\\\nH_1 &: \\text{the model is effective, } b_1 \\neq 0\n\\end{aligned}\n\\]\n\nThe relevant test-statistic is the F-statistic:\n\\[\n\\begin{split}\nF = \\frac{MS_{Model}}{MS_{Residual}} = \\frac{SS_{Model} / 1}{SS_{Residual} / (n-2)}\n\\end{split}\n\\]\nwhich compares the amount of variation in the response explained by the model to the amount of variation left unexplained in the residuals.\nThe sample F-statistic is compared to an F-distribution with \\(df_{1} = 1\\) and \\(df_{2} = n - 2\\) degrees of freedom.3\n\n Optional: Another formula for the F-test.\n\n\nWith some algebra we can also show that:\n\\[\nF = \\frac{R^2 / 1}{(1 - R^2) / (n - 2) } = \\frac{R^2 / df_{Model}}{(1 - R^2) / df_{Residual} }\n\\]\nProof:\n\\[\n\\begin{aligned}\nF = \\frac{SS_{Model} / 1}{SS_{Residual} / (n - 2)}\n= \\frac{\\frac{SS_{Model}}{SS_{Total}}}{\\frac{SS_{Residual}}{SS_{Total}} \\cdot \\frac{1}{(n - 2)}}\n= \\frac{R^2 / 1}{(1 - R^2) / (n - 2)}\n\\end{aligned}\n\\]\n\n\n\n\nLike the \\(R^2\\), the summary() of our model prints out the \\(F\\)-statistic, degrees of freedom, and p-value. These are right at the bottom of the summary output, printed as:\nF-statistic: 61.26 on 1 and 98 DF,  p-value: 5.918e-12\n\nThe F-test of model utility was significant (\\(F(1,98) = 61.26,\\ p <.001\\)) suggesting that the model is effective in explaining variance in outcome \\(y\\).\n\nNote that the p-value here is exactly the same as the one for the coefficient. This is because in testing “the model is (in)effective”, the “model” is really only the relationship between the outcome and our one predictor. When we move to adding more predictors into our model, we have more \\(b\\)’s, and the \\(F\\)-test will be testing jointly whether \\(b_1 = b_2 =\\ ...\\ = b_k = 0\\).\n\n Optional: When only one predictor variable, the F-test is equivalent to the t-test of the slope\n\n\nIn simple linear regression only (where we have just one predictor), the F-statistic for overall model significance is equal to the square of the t-statistic for \\(H_0: b_1 = 0\\).\nYou can check that the squared t-statistic is equal, up to rounding error, to the F-statistic:\n\nsummary(my_model)$fstatistic['value']\n\n   value \n61.26497 \n\nsummary(my_model)$coefficients['x','t value']\n\n[1] 7.827194\n\n\n\\[\nt^2 = F \\\\\n7.827194^2 = 61.26497\n\\]\nHere we will show the equivalence of the F-test for model effectiveness and t-test for the slope.\nRecall the formula of the sum of squares due to the model. We will rewrite it in an equivalent form below:\n\\[\n\\begin{aligned}\nSS_{Model} &= \\sum_i (\\hat y_i - \\bar y)^2 \\\\\n&= \\sum_i (\\hat b_0 + \\hat b_1 x_i - \\bar y)^2 \\\\\n&= \\sum_i (\\bar y - \\hat b_1 \\bar x + \\hat b_1 x_i - \\bar y)^2 \\\\\n&= \\sum_i (\\hat b_1 (x_i - \\bar x))^2 \\\\\n&= \\hat b_1^2 \\sum_i (x_i - \\bar x)^2\n\\end{aligned}\n\\]\nThe F-statistic is given by:\n\\[\n\\begin{aligned}\nF = \\frac{SS_{Model} / 1}{SS_{Residual} / (n - 2)}\n= \\frac{\\hat b_1^2 \\sum_i (x_i - \\bar x)^2}{\\hat \\sigma^2}\n= \\frac{\\hat b_1^2 }{\\hat \\sigma^2 / \\sum_i (x_i - \\bar x)^2}\n\\end{aligned}\n\\]\nNow recall the formula of the t-statistic,\n\\[\nt = \\frac{\\hat b_1}{SE(\\hat b_1)} = \\frac{\\hat b_1}{\\hat \\sigma / \\sqrt{\\sum_i (x_i - \\bar x)^2}}\n\\]\nIt is evident that the latter is obtained as the square root of the former."
  },
  {
    "objectID": "08a_mlr.html",
    "href": "08a_mlr.html",
    "title": "8A: Multiple Linear Regression",
    "section": "",
    "text": "The simple linear regression model with a single predictor - lm(y ~ x1) - is a useful introduction to the idea of model-based thinking, but it’s not clear how much benefit this gives us as it is actually equivalent to the basic statistical tests we have already seen.\nThe real power of regression models comes into effect when we start to concern ourselves with more than just “one outcome explained by one predictor”."
  },
  {
    "objectID": "08a_mlr.html#adjusted-r2",
    "href": "08a_mlr.html#adjusted-r2",
    "title": "8A: Multiple Linear Regression",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\nWe know from our work on simple linear regression that the R-squared can be obtained as:\n\\[\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Residual}}{SS_{Total}}\n\\]\nIf we briefly return to the venn diagrams we used above, the \\(R^2\\) is capturing all variance in \\(y\\) that is explained by the predictors (including the overlapping bits between \\(x_1\\) and \\(x_2\\)).\nTODO\nr2 venn\nHowever, when we add more and more predictors into a multiple regression model, \\(SS_{Residual}\\) cannot increase, and may decrease by pure chance alone, even if the predictors are unrelated to the outcome variable. Because \\(SS_{Total}\\) is constant, the calculation \\(1-\\frac{SS_{Residual}}{SS_{Total}}\\) will increase by chance alone.\nAn alternative, the Adjusted-\\(R^2\\), does not necessarily increase with the addition of more explanatory variables, by including a penalty according to the number of explanatory variables in the model. It is not by itself meaningful, but can be useful in determining what predictors to include in a model.\n\\[\nAdjusted{-}R^2=1-\\frac{(1-R^2)(n-1)}{n-k-1} \\\\\n\\quad \\\\\n\\begin{align}\n& \\text{Where:} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\nIn R, you can view the mutiple and adjusted \\(R^2\\) at the bottom of the output of summary(<modelname>):\nTODO\n\n\n\n\n\nFigure 3: Multiple regression output in R, summary.lm(). R-squared highlighted"
  },
  {
    "objectID": "08a_mlr.html#joint-test",
    "href": "08a_mlr.html#joint-test",
    "title": "8A: Multiple Linear Regression",
    "section": "Joint test",
    "text": "Joint test\nAs in simple linear regression, the F-statistic is used to test the null hypothesis that all regression slopes are zero (it is just that now that we have multiple predictors, so “all” is more than 1).\n\\[\n\\begin{aligned}\nH_0: & \\text{the model is ineffective, } \\\\\n& b_1, ..., b_k = 0 \\\\\nH_1: &\\text{the model is effective, } \\\\\n& \\text{any of }b_1, ..., b_k \\neq 0\n\\end{aligned}\n\\]\nThe \\(F\\)-statistic is sometimes called the F-ratio because it is the ratio of the how much of the variation is explained by the model (per parameter) versus how much of the variation is unexplained (per remaining degrees of freedom).\nWe extend the formula for the \\(F\\)-statistic for simple regression to encompass situations where there are more predictors:\n\\[\n\\begin{align}\n& F_{df_{model},df_{residual}} = \\frac{MS_{Model}}{MS_{Residual}} = \\frac{SS_{Model}/df_{Model}}{SS_{Residual}/df_{Residual}} \\\\\n& \\quad \\\\\n& \\text{Where:} \\\\\n& df_{model} = k \\\\\n& df_{error} = n-k-1 \\\\\n& n = \\text{sample size} \\\\\n& k  = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\nIn R, at the bottom of the output of summary(<modelname>), you can view the F ratio, along with an hypothesis test against the alternative hypothesis that the at least one of the coefficients \\(\\neq 0\\) (under the null hypothesis that all coefficients = 0, the ratio of explained:unexplained variance should be approximately 1):\nTODO\n\n\n\n\n\nFigure 4: Multiple regression output in R, summary.lm(). F statistic highlighted"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Univariate Statistics and Methodology in R",
    "section": "",
    "text": "Univariate Statistics and Methodology in R (USMR) is a semester long crash-course aimed at providing Masters students in psychology with a competence in standard statistical methodologies and data analysis using R. Typically the analyses taught in this course are relevant for when there is just one source of variation - i.e. when we are interested in a single outcome measured across a set of independent observations. The first half of the course covers the fundamentals of statistical inference using a simulation-based approach, and introduces students to working with R & RStudio. The latter half of the course focuses on the general linear model, emphasising the fact that many statistical methods are simply special cases of this approach. This course introduces students to statistical modelling and empowers them with tools to analyse richer data and answer a broader set of research questions."
  }
]