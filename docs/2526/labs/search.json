[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Univariate Statistics and Methodology in R Workbook",
    "section": "",
    "text": "This site contains weekly exercises for the USMR course.\nAt the end of each week, solutions (where these are not already available) will be made visible directly beneath each question.\n\nAbout USMR\nUnivariate Statistics and Methodology in R (USMR) is a semester long crash-course aimed at providing Masters students in psychology with a competence in standard statistical methodologies and data analysis using R. Typically the analyses taught in this course are relevant for when there is just one source of variation - i.e. when we are interested in a single outcome measured across a set of independent observations. The first half of the course covers the fundamentals of statistical inference using a simulation-based approach, and introduces students to working with R & RStudio. The latter half of the course focuses on the general linear model, emphasising the fact that many statistical methods are simply special cases of this approach. This course introduces students to statistical modelling and empowers them with tools to analyse richer data and answer a broader set of research questions."
  },
  {
    "objectID": "04_ex.html",
    "href": "04_ex.html",
    "title": "Exercises: Binomial & Chi-Square Tests",
    "section": "",
    "text": "Research Question: Is the probability that a student prefers Dogs over Cats greater than 50%?\n\n\nData: Past Surveys\nIn the last few years, we have asked students of the statistics courses in the Psychology department to fill out a little survey.\nAnonymised data are available at https://uoepsy.github.io/data/usmr25survey_historical.csv\nNote: this does not contain the responses from this year.\n\nsurveydata &lt;- \n  read_csv(\"https://uoepsy.github.io/data/usmr25survey_historical.csv\")\n\n\n\nQuestion 1\n\n\nCalculate the proportion of students who chose cats vs dogs in the survey. If the probability that a student prefers dogs to cats is 50%, what would we expect to see?\n\n\n\n\n\n\nHints\n\n\n\n\n\ntable() |&gt; prop.table() might be the quickest way here.\n\n\n\n\n\n\n\nI sometimes like adding a |&gt; print() |&gt; in the middle of these sequences of pipes to print out the intermediary output as well:\n\ntable(surveydata$catdog) |&gt;\n  print() |&gt;\n  prop.table()\n\n\ncat dog \n252 348 \n\n\n\n cat  dog \n0.42 0.58 \n\n\nIf the probability was 50%, or 0.5, then we would expect the numbers to be equal. We have 600 responses here, so we would expect 300 to be team cats, and 300 to be team dogs!\n\n\n\n\nQuestion 2\n\n\n\nResearch Question: Is the probability that a student prefers Dogs over Cats greater than 50%?\n\nConduct a test to address the research question.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nNote the “tailedness” of the question. Just like t.test(), the function we use here should allow us to specify our hypothesis.\n\nYou can see an example of this test in Chapter 7 #binomials.\n\n\n\n\n\n\n\n\nWe’re going to want to use the binom.test() function. This is just like the reading, where we tested the proportion of our sample who were left-handed.\nWe can either type in the numbers of “Dog” people out of our total number:\n\nbinom.test(317, 539, p = 0.5, alternative = \"greater\")\n\n\n    Exact binomial test\n\ndata:  317 and 539\nnumber of successes = 317, number of trials = 539, p-value = 2.468e-05\nalternative hypothesis: true probability of success is greater than 0.5\n95 percent confidence interval:\n 0.5520308 1.0000000\nsample estimates:\nprobability of success \n             0.5881262 \n\n\nOr give the function a table.\nBUT we need to make sure that it is picking up the right value as “successes”.\nNotice that this gives us a different result:\n\n\n\n    Exact binomial test\n\ndata:  table(surveydata$catdog)\nnumber of successes = 252, number of trials = 600, p-value = 1\nalternative hypothesis: true probability of success is greater than 0.5\n95 percent confidence interval:\n 0.3863705 1.0000000\nsample estimates:\nprobability of success \n                  0.42 \n\n\nThis is because it is taking the first entry as the number of successes. So it is saying that Cat people = 1 and Dog people = 0. But we want it the other way around! You could either create a different table (or switch its order), or simply switch to the alternative being “less” (because in this unrealistic binary world, the question “is the probability of being Dog person &gt;0.5?” is the same thing as “is probability of being Cat person &lt;0.5?”)"
  },
  {
    "objectID": "04_ex.html#cats-n-dogs",
    "href": "04_ex.html#cats-n-dogs",
    "title": "Exercises: Binomial & Chi-Square Tests",
    "section": "",
    "text": "Research Question: Is the probability that a student prefers Dogs over Cats greater than 50%?\n\n\nData: Past Surveys\nIn the last few years, we have asked students of the statistics courses in the Psychology department to fill out a little survey.\nAnonymised data are available at https://uoepsy.github.io/data/usmr25survey_historical.csv\nNote: this does not contain the responses from this year.\n\nsurveydata &lt;- \n  read_csv(\"https://uoepsy.github.io/data/usmr25survey_historical.csv\")\n\n\n\nQuestion 1\n\n\nCalculate the proportion of students who chose cats vs dogs in the survey. If the probability that a student prefers dogs to cats is 50%, what would we expect to see?\n\n\n\n\n\n\nHints\n\n\n\n\n\ntable() |&gt; prop.table() might be the quickest way here.\n\n\n\n\n\n\n\nI sometimes like adding a |&gt; print() |&gt; in the middle of these sequences of pipes to print out the intermediary output as well:\n\ntable(surveydata$catdog) |&gt;\n  print() |&gt;\n  prop.table()\n\n\ncat dog \n252 348 \n\n\n\n cat  dog \n0.42 0.58 \n\n\nIf the probability was 50%, or 0.5, then we would expect the numbers to be equal. We have 600 responses here, so we would expect 300 to be team cats, and 300 to be team dogs!\n\n\n\n\nQuestion 2\n\n\n\nResearch Question: Is the probability that a student prefers Dogs over Cats greater than 50%?\n\nConduct a test to address the research question.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nNote the “tailedness” of the question. Just like t.test(), the function we use here should allow us to specify our hypothesis.\n\nYou can see an example of this test in Chapter 7 #binomials.\n\n\n\n\n\n\n\n\nWe’re going to want to use the binom.test() function. This is just like the reading, where we tested the proportion of our sample who were left-handed.\nWe can either type in the numbers of “Dog” people out of our total number:\n\nbinom.test(317, 539, p = 0.5, alternative = \"greater\")\n\n\n    Exact binomial test\n\ndata:  317 and 539\nnumber of successes = 317, number of trials = 539, p-value = 2.468e-05\nalternative hypothesis: true probability of success is greater than 0.5\n95 percent confidence interval:\n 0.5520308 1.0000000\nsample estimates:\nprobability of success \n             0.5881262 \n\n\nOr give the function a table.\nBUT we need to make sure that it is picking up the right value as “successes”.\nNotice that this gives us a different result:\n\n\n\n    Exact binomial test\n\ndata:  table(surveydata$catdog)\nnumber of successes = 252, number of trials = 600, p-value = 1\nalternative hypothesis: true probability of success is greater than 0.5\n95 percent confidence interval:\n 0.3863705 1.0000000\nsample estimates:\nprobability of success \n                  0.42 \n\n\nThis is because it is taking the first entry as the number of successes. So it is saying that Cat people = 1 and Dog people = 0. But we want it the other way around! You could either create a different table (or switch its order), or simply switch to the alternative being “less” (because in this unrealistic binary world, the question “is the probability of being Dog person &gt;0.5?” is the same thing as “is probability of being Cat person &lt;0.5?”)"
  },
  {
    "objectID": "04_ex.html#birth-months",
    "href": "04_ex.html#birth-months",
    "title": "Exercises: Binomial & Chi-Square Tests",
    "section": "Birth-Months",
    "text": "Birth-Months\n\nResearch Question: Are students more likely to be born in certain months than others?\n\n\nData: Past Surveys\nIn the last few years, we have asked students of the statistics courses in the Psychology department to fill out a little survey.\nAnonymised data are available at https://uoepsy.github.io/data/usmr25survey_historical.csv\nNote: this does not contain the responses from this year.\n\nsurveydata &lt;- \n  read_csv(\"https://uoepsy.github.io/data/usmr25survey_historical.csv\")\n\n\n\nQuestion 3\n\n\nWhat is your intuition about the distribution of all students’ birth-months?\nDo you think they will be spread uniformly across all months of the year (like a fair 12-sided dice), or do you think people are more likely to be born in certain months more than others?\nPlot the distribution and get an initial idea of how things are looking.\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou can do this quickly with barplot() and table(), or you could create try using ggplot() and looking into geom_bar().\n\n\n\n\n\n\n\nThe quick and dirty way to plot:\n\nbarplot(table(surveydata$birthmonth))\n\n\n\n\n\n\n\n\nA ggplot option:\n\nggplot(data = surveydata, aes(x = birthmonth)) +\n    geom_bar() +\n    labs(x = \"- Birth Month -\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nWe’re going to perform a statistical test to assess the extent to which our data conforms to the hypothesis that people are no more likely to be born on one month than another.\nUnder this hypothesis, what would be the proportional breakdown of observed births in each of the months?\n\n\n\n\nIf people are no more likely to be born in one month than another, then we would expect the same proportion of observed births in each month.\nThere are 12 months, so we would expect \\(\\frac{1}{12}\\) observations in each month.\nWe can write these as: \\[\n\\begin{align}\n& p_{jan} = 1/12 \\\\\n& p_{feb} = 1/12 \\\\\n& ... \\\\\n& p_{dec} = 1/12 \\\\\n\\end{align}\n\\]\n\n\n\n\nQuestion 5\n\n\nHow many observations in our sample would we expect to find with a birthday in January? And in February? … and so on?\n\n\n\n\n\n\nHints\n\n\n\n\n\nHow many responses (i.e. not missing values) do we have for this question?\n\n\n\n\n\n\n\nThere are 606 people who have non-NA values (sum(!is.na(surveydata$birthmonth))).\nUnder the null hypothesis, we would expect \\(\\frac{1}{12} \\times\\) 606 = 50.5 observations born in each month.\n\n\n\n\nQuestion 6\n\n\nThe code below creates counts for each month. Before doing that, it removes the rows which have an NA in them for birthmonth:\n\nsurveydata |&gt;\n  filter(!is.na(birthmonth)) |&gt;\n  group_by(birthmonth) |&gt;\n  summarise(\n      observed = n()\n  )\n\n(A shortcut for this would be surveydata |&gt; filter(!is.na(birthmonth)) |&gt; count(birthmonth))\nAdd to the code above to create columns showing:\n\nthe expected counts \\(E_i\\)\nobserved-expected (\\(O_i - E_i\\))\nthe squared differences \\((O_i - E_i)^2\\)\nthe standardised square differences \\(\\frac{(O_i - E_i)^2}{E_i}\\)\n\nThen calculate the \\(\\chi^2\\) statistic (the sum of the standardised squared differences).\nIf your observed counts matched the expected counts perfectly, what would the \\(\\chi^2\\) statistic be?\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis was all done in the step-by-step example of a \\(\\chi^2\\) test in Chapter 7 #chi2-goodness-of-fit-test\n\n\n\n\n\n\n\n\nchi_table &lt;- \n    surveydata |&gt;\n    filter(!is.na(birthmonth)) |&gt;\n    group_by(birthmonth) |&gt;\n    summarise(\n        observed = n(),\n        expected = sum(!is.na(surveydata$birthmonth))/12,\n        diff = observed-expected,\n        sq_diff = diff^2,\n        std_sq_diff = sq_diff / expected\n    )\nchi_table\n\n# A tibble: 12 × 6\n   birthmonth observed expected  diff sq_diff std_sq_diff\n   &lt;chr&gt;         &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n 1 apr              45     50.5  -5.5   30.2      0.599  \n 2 aug              48     50.5  -2.5    6.25     0.124  \n 3 dec              48     50.5  -2.5    6.25     0.124  \n 4 feb              40     50.5 -10.5  110.       2.18   \n 5 jan              52     50.5   1.5    2.25     0.0446 \n 6 jul              56     50.5   5.5   30.2      0.599  \n 7 jun              53     50.5   2.5    6.25     0.124  \n 8 mar              53     50.5   2.5    6.25     0.124  \n 9 may              53     50.5   2.5    6.25     0.124  \n10 nov              54     50.5   3.5   12.2      0.243  \n11 oct              54     50.5   3.5   12.2      0.243  \n12 sep              50     50.5  -0.5    0.25     0.00495\n\n\nAnd we can calculate our \\(\\chi^2\\) test statistic by simply summing the values in the last column we created:\n\nsum(chi_table$std_sq_diff)\n\n[1] 4.534653\n\n\nIf all our observed counts are equal to our expected counts, then the diff column above will be all \\(0\\), and \\(0^2=0\\), and \\(\\frac{0}{E_i}\\) will be \\(0\\). So \\(\\chi^2\\) will be \\(0\\).\n\n\n\n\nQuestion 7\n\n\nYou can see the distribution of \\(\\chi^2\\) statistics with different degrees of freedom below.\n\n\n\n\n\n\n\n\nFigure 1: Chi-Square Distributions\n\n\n\n\n\nWe can find out the proportion of the distribution which falls to either side of a given value of \\(\\chi^2\\) using pchisq(). We need to give it our calculated \\(\\chi^2\\) statistic, our degrees of freedom (df), which is equal to the number of categories minus 1. We also need to specify whether we want the proportion to the left (lower.tail=TRUE) or to the right (lower.tail=FALSE).\n\nUsing pchisq(), calculate the probability of observing a \\(\\chi^2\\) statistic as least as extreme as the one we have calculated.\n\nCheck that these results match with those provided by R’s built-in function: chisq.test(table(surveydata$birthmonth)) (the table function will ignore NAs by default, so we don’t need to do anything extra for this).\n\n\n\n\n\n\nsum(chi_table$std_sq_diff)\n\n[1] 4.534653\n\npchisq(sum(chi_table$std_sq_diff), df = 11, lower.tail = FALSE)\n\n[1] 0.951597\n\n\n\nchisq.test(table(surveydata$birthmonth))\n\n\n    Chi-squared test for given probabilities\n\ndata:  table(surveydata$birthmonth)\nX-squared = 4.5347, df = 11, p-value = 0.9516\n\n\n\n\n\n\nQuestion 8\n\n\nWhich months of year had the highest contributions to the chi-square test statistic?\n\n\n\n\n\n\nHints\n\n\n\n\n\nThink about your standardised squared deviations.\n\n\n\n\n\n\n\nStandardized squared deviations\nOne possible way to answer this question is to look at the individual contribution of each category to the \\(\\chi^2\\) statistic. We computed these values in an earlier question.\n\nchi_table |&gt;\n  select(birthmonth, std_sq_diff)\n\n# A tibble: 12 × 2\n   birthmonth std_sq_diff\n   &lt;chr&gt;            &lt;dbl&gt;\n 1 apr            0.599  \n 2 aug            0.124  \n 3 dec            0.124  \n 4 feb            2.18   \n 5 jan            0.0446 \n 6 jul            0.599  \n 7 jun            0.124  \n 8 mar            0.124  \n 9 may            0.124  \n10 nov            0.243  \n11 oct            0.243  \n12 sep            0.00495\n\n\nFrom the barplot we created earlier on, we can see which months make up higher/lower proportions than expected:\n\nggplot(chi_table, aes(x = birthmonth, y = observed/nrow(surveydata))) +\n  geom_col(fill = 'lightblue') +\n  geom_hline(yintercept = 1/12, color = 'red') +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nPearson residuals\nEquivalently, you could answer by looking at Pearson residuals:\n\nchisq.test(table(surveydata$birthmonth))$residuals\n\n\n        apr         aug         dec         feb         jan         jul \n-0.77395730 -0.35179877 -0.35179877 -1.47755484  0.21107926  0.77395730 \n        jun         mar         may         nov         oct         sep \n 0.35179877  0.35179877  0.35179877  0.49251828  0.49251828 -0.07035975 \n\n\nThe greatest absolute values are for feb and apr, showing that for these months the deviations from expected to observed were the greatest."
  },
  {
    "objectID": "04_ex.html#childrens-favourite-colours",
    "href": "04_ex.html#childrens-favourite-colours",
    "title": "Exercises: Binomial & Chi-Square Tests",
    "section": "Children’s Favourite Colours",
    "text": "Children’s Favourite Colours\n\nResearch Question: Do childrens’ favourite colours correspond to the those suggested by the internet?\n\n\nAccording to one part of the internet, 30% of children have red as their favourite colour, 20% have blue, 15% yellow, 11% purple, 9% green, and 15% prefer some other colour.\nWe collected data from 50 children aged between 2 and 5, and got them to choose one of a set of objects that were identical apart from colour. You can see the data in Table 1\n\n\n\n\nTable 1: Colour preferences of 50 children aged between 2 and 5\n\n\n\n\n\n\n\n\n\ncolour\nFreq\n\n\n\n\nblue\n10\n\n\ngreen\n6\n\n\nother\n3\n\n\npurple\n8\n\n\nred\n8\n\n\nyellow\n15\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nPerform a \\(\\chi^2\\) goodness of fit test to assess the extent to which our sample of children conform to this theorised distribution of colour preferences.\nNo need to do this manually - once is enough. Just go straight to using the chisq.test() function.\nHowever, we will need to get the numbers into R somehow..\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou can make a table from scratch using, for example: as.table(c(1,2,3,4,5)).\nFor the test, try using chisq.test(..., p = c(?,?,?,...) ).\nWe saw the use of chisq.test() in the example goodness of fit test, Chapter 7 #chi2-goodness-of-fit-test\n\n\n\n\n\n\n\nLet’s get the data in:\n\nchildcols &lt;- as.table(c(10,6,3,8,8,15))\nnames(childcols) &lt;- c(\"blue\",\"green\",\"other\",\"purple\",\"red\",\"yellow\")\nchildcols\n\n  blue  green  other purple    red yellow \n    10      6      3      8      8     15 \n\n\nOur theoretical probabilities of different colours must match the order in the table which we give chisq.test(). They must also always sum to 1.\n\nchisq.test(childcols, p = c(.20,.09,.15,.11,.30,.15))\n\nWarning in chisq.test(childcols, p = c(0.2, 0.09, 0.15, 0.11, 0.3, 0.15)):\nChi-squared approximation may be incorrect\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  childcols\nX-squared = 15.103, df = 5, p-value = 0.009931\n\n\nNote, we get a warning here of “Chi-squared approximation may be incorrect”. This is because some of the expected cell counts are &lt;5.\n\nchisq.test(childcols, \n           p = c(.20,.09,.15,.11,.30,.15))$expected\n\n  blue  green  other purple    red yellow \n  10.0    4.5    7.5    5.5   15.0    7.5 \n\n\nThere are a couple of options here, but the easiest is to use the functionality of chisq.test() that allows us to compute the p-value by using a simulation (similar to the idea we saw in Chapter 4 #sampling-&-sampling-distributions), rather than by comparing it to a theoretical \\(\\chi^2\\) distribution. We can do this by using:\n\nchisq.test(childcols, p = c(.20,.09,.15,.11,.30,.15),\n           simulate.p.value = TRUE)\n\n\n    Chi-squared test for given probabilities with simulated p-value (based\n    on 2000 replicates)\n\ndata:  childcols\nX-squared = 15.103, df = NA, p-value = 0.01249\n\n\n\n\n\n\nQuestion 10\n\n\nWhat are the observed proportions of children who prefer each colour?\n\n\n\n\n\n\nHints\n\n\n\n\n\nLook up the prop.table() function?\n\n\n\n\n\n\n\nFrom the help documentation (?prop.table()), we see that we can pass prop.table() the argument x, which needs to be a table.\n\nprop.table(childcols)*100\n\n  blue  green  other purple    red yellow \n    20     12      6     16     16     30 \n\n\n\nbarplot(prop.table(childcols)*100)"
  },
  {
    "objectID": "04_ex.html#jokes-and-tips",
    "href": "04_ex.html#jokes-and-tips",
    "title": "Exercises: Binomial & Chi-Square Tests",
    "section": "Jokes and Tips",
    "text": "Jokes and Tips\n\nData: TipJokes\n\nResearch Question: Can telling a joke affect whether or not a waiter in a coffee bar receives a tip from a customer?\n\nA study published in the Journal of Applied Social Psychology1 investigated this question at a coffee bar of a famous seaside resort on the west Atlantic coast of France. The waiter randomly assigned coffee-ordering customers to one of three groups. When receiving the bill, one group also received a card telling a joke, another group received a card containing an advertisement for a local restaurant, and a third group received no card at all.\nThe data are available at https://uoepsy.github.io/data/TipJoke.csv\nThe dataset contains the variables:\n\nCard: None, Joke, Ad.\nTip: 1 = The customer left a tip, 0 = The customer did not leave tip.\n\n\n\nQuestion 11\n\n\nProduce a plot and a table to display the relationship between whether or not the customer left a tip, and what (if any) card they received alongside the bill.\nDon’t worry about making it all pretty. Mosaic plots in R are a bit difficult.\n\n\n\n\n\n\nHints\n\n\n\n\n\nplot(table(...)) will give you something. You can see one in the example \\(\\chi^2\\) test of independence,Chapter 7 #chi2-test-of-independence.\n\n\n\n\n\n\n\n\ntipjoke &lt;- read_csv('https://uoepsy.github.io/data/TipJoke.csv')\n\ntable(tipjoke$Card, tipjoke$Tip)\n\n      \n        0  1\n  Ad   60 14\n  Joke 42 30\n  None 49 16\n\nplot(table(tipjoke$Card, tipjoke$Tip))\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 12\n\n\nWhat would you expect the cell counts to look like if there were no relationship between what the waiter left and whether or not the customer tipped?\n\n\n\n\n\n\nHints\n\n\n\n\n\nThink about what proportion of customers tipped. Then work out how many customers got each type of card. If there were no relationship, then the proportions would be the same in each group.\n\n\n\n\n\n\n\nIn total, 60 customers tipped (14+30+16), and 151 did not. So overall, 0.28 (\\(\\frac{60}{(60+151)}\\)) of customers tip.\n74 customers got an Ad card, 72 customers got a Joke, and 65 got None. If this were independent of whether or not they left a tip, we would expect equal proportions of tippers in each group.\nSo we would expect 0.28 of each group to leave a tip.\n\n\n\n\n\n\nsome calculations\n\n\n\n\n\nYou can think about observed vs expected by looking at the two-way table along with the marginal row and column totals given:\n\n\n\n\n\n\n0\n1\n\n\n\n\n\nAd\n\n\n74\n\n\nJoke\n\n\n72\n\n\nNone\n\n\n65\n\n\n\n151\n60\n211\n\n\n\n\n\n\n\nFor a given cell of the table we can calculate the expected count as \\(\\text{row total} \\times \\frac{\\text{column total}}{\\text{samplesize}}\\):\nExpected:\n\n\n\n\n\n\n0\n1\n\n\n\n\n\nAd\n52.96\n21.04\n74\n\n\nJoke\n51.53\n20.47\n72\n\n\nNone\n46.52\n18.48\n65\n\n\n\n151.00\n60.00\n211\n\n\n\n\n\n\n\nIf you’re wondering how we do this in R.. here’s our table:\n\nt &lt;- tipjoke |&gt;\n  select(Card, Tip) |&gt; table()\nt\n\n      Tip\nCard    0  1\n  Ad   60 14\n  Joke 42 30\n  None 49 16\n\n\nHere are the row totals:\n\nrowSums(t)\n\n  Ad Joke None \n  74   72   65 \n\n\nand column totals divided by total:\n\ncolSums(t) / sum(t)\n\n        0         1 \n0.7156398 0.2843602 \n\n\nthere’s a complicated bit of code using %o% which could do this for us. You don’t need to remember %o%, it’s very rarely used):\n\ne &lt;- rowSums(t) %o% colSums(t) / sum(t)\ne\n\n            0        1\nAd   52.95735 21.04265\nJoke 51.52607 20.47393\nNone 46.51659 18.48341\n\n\nOr, alternatively, do it one by one:\n\nrowSums(t) * (colSums(t) / sum(t))[1]\n\n      Ad     Joke     None \n52.95735 51.52607 46.51659 \n\nrowSums(t) * (colSums(t) / sum(t))[2]\n\n      Ad     Joke     None \n21.04265 20.47393 18.48341 \n\n\n\n\n\n\n\n\n\nQuestion 13\n\n\nJust like we gave the chisq.test() function a table of observed frequencies when we conducted a goodness of fit test in earlier exercises, we can give it a two-way table of observed frequencies to conduct a test of independence.\nTry it now.\n\n\n\n\n\nchisq.test(table(tipjoke$Card, tipjoke$Tip))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(tipjoke$Card, tipjoke$Tip)\nX-squared = 9.9533, df = 2, p-value = 0.006897"
  },
  {
    "objectID": "04_ex.html#footnotes",
    "href": "04_ex.html#footnotes",
    "title": "Exercises: Binomial & Chi-Square Tests",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGueaguen, N. (2002). The Effects of a Joke on Tipping When It Is Delivered at the Same Time as the Bill. Journal of Applied Social Psychology, 32(9), 1955-1963.↩︎"
  },
  {
    "objectID": "02_ex.html",
    "href": "02_ex.html",
    "title": "W2: More R; Estimates & Intervals",
    "section": "",
    "text": "Question 0"
  },
  {
    "objectID": "02_ex.html#optional-extras",
    "href": "02_ex.html#optional-extras",
    "title": "W2: More R; Estimates & Intervals",
    "section": "Optional Extras",
    "text": "Optional Extras\n\nOptional Extra\n\n\nNote that the confidence interval from the previous question is concerned with describing the abstract and theoretical distribution of “what the mean sleep quality rating would look like from all possible samples of this size that I could take”. In order to do this we used a formula to describe the spread of this distribution, and in doing so had to assume that the standard deviation of our sample is a good approximation of the standard deviation of the population, and that the population is normally distributed.\nWe can also avoid ever using the standard deviation of our sample (sd(usmr2022on$sleeprating)), and instead approximate the sampling distribution of the mean by “bootstrapping” - taking repeated resamples with replacement from the original sample (see Chapter 4 #standard-error.\n\nbootstrap_means &lt;- replicate(1000, mean(sample(observed_sample, replace = TRUE)))\n\n\nCreate an object that contains the 10,000 means from 10,000 resamples of our sleep ratings.\n\nThe distribution of resample means is the ‘bootstrap distribution’. Plot a histogram of it. What is the standard deviation? How does it compare to the standard error you calculated in the previous question with the formula?\n\nAt what values does the middle 95% of the bootstrap distribution fall?\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nFor 3, look up quantile(). We saw this in Chapter 4 #confidence-intervals.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 14. \n\n\nResample means\nHere is our sample of sleep ratings:\n\nsleeprates &lt;- usmr2022on$sleeprating\n\nAnd we can get rid of the NA’s:\n\nsleeprates &lt;- sleeprates[!is.na(sleeprates)]\n\nWe can resample with replacement from this set of numbers by using the replace = TRUE argument in the sample() function.\nNote, we’re leaving size = blank, which means it will stop at the same length as the original vector we give it.\n\nsample(sleeprates, replace = TRUE)\n\nand the mean of a given resample is calculated by wrapping mean() around the above code:\n\nmean(sample(sleeprates, replace = TRUE))\n\n[1] 67.52558\n\n\nfinally, we’ll do it lots and lots of times, using replicate():\n\nBSmeans &lt;- replicate(10000, mean(sample(sleeprates, replace = TRUE)))\n\n\n\nBootstrap Distribution\nHere’s the histogram of the bootstrap distribution:\n\nhist(BSmeans)\n\n\n\n\n\n\n\n\nAnd here’s the standard deviation of that distribution. This is a bootstrapped estimate of the standard error.\n\nsd(BSmeans)\n\n[1] 1.538259\n\n\nRecall our standard error calculated using \\(\\frac{s}{\\sqrt{n}}\\) from the previous question was 1.52\n\n\nPercentiles\nWe can get the 2.5% and 97.5% percentiles (i.e. getting the middle 95%), using the code below. Recall our confidence intervals that we computed analytically were 63.38 and 69.34.\n\nquantile(BSmeans, c(.025,.975))\n\n    2.5%    97.5% \n63.21384 69.28837 \n\n\n\n\n\n\n\n\n\n\n\nbootstraps\n\n\n\n\n\nBootstrapping is a great way to learn about sampling variability because it allows us to actually plot, summarise and describe what would otherwise be an abstract conceptual distribution.\nIt can also be a useful tool in practice, but it doesn’t come without its own problems/complexities. One important thing to note is that it often works worse than traditional methods for small samples, especially skewed samples (i.e. bootstrapping a “95% CI” for a small sample will often be too narrow and &lt;95%)."
  },
  {
    "objectID": "01_ex.html",
    "href": "01_ex.html",
    "title": "W1: Intro R",
    "section": "",
    "text": "First things\nThe very first things to do are to open RStudio and get a blank script ready for writing your code!\n\n\nOur recommendation is that you have an R project for this course, and use a new script for each week of work. See the tip about “R projects” in Chapter 1.\n\n\nPet Data\n\nWe’re going to play with some data on a sample of licensed pets from the city of Seattle, USA. It can be downloaded (or read directly into R) from https://uoepsy.github.io/data/pets_seattle.csv. It contains information on the license ID, year of issue, as well as the species, breeds and weights of each pet. You can find a data dictionary in Table 1\n\n\n\n\nTable 1: Seattle Pets: Data dictionary\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nlicense_year\nYear in which license was issued\n\n\nlicense_number\nUnique license ID number\n\n\nanimals_name\nFull name of pet\n\n\nspecies\nSpecies of pet\n\n\nprimary_breed\nPrimary breed of pet\n\n\nsecondary_breed\nSecondary breed of pet\n\n\nweight_kg\nWeight in kilograms\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nWrite a line of code that reads in the data to your R session. Then examine the dimensions of the dataset, and take a look at the first few lines.\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou’ll need the read.csv() function. Remember to assign it a name to store it in your environment.\nChapter 2 #basic-data-wrangling contains an example of reading in data from a URL. You’ll then want to play with functions like dim() and head().\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 1. We’re going to call it petdata in our environment here. Don’t forget the quotation marks around the url (otherwise R will look for an object in your environment called https://..., which isn’t there).\n\npetdata&lt;-read.csv(\"https://uoepsy.github.io/data/pets_seattle.csv\")\ndim(petdata)\n\n[1] 1956    7\n\n\nWe can see there are 1956 rows and 7 columns.\nAnd we can see the first few rows here:\n\nhead(petdata)\n\n  license_year license_number  animals_name species         primary_breed\n1         2018      LNS150171        Norman     Dog                 Boxer\n2         2017        LN20666         Henry     Dog          Bichon Frise\n3         2018      LN8000658 Vega Williams     Dog                   Mix\n4         2018       LN730940         Molly     Dog   Australian Shepherd\n5         2016       LN964607         Gremy     Dog Chihuahua, Short Coat\n6         2018      LNS117115        Shadow     Dog   Retriever, Labrador\n  secondary_breed weight_kg\n1             Mix     29.15\n2        Havanese     23.70\n3         Unknown     21.13\n4             Mix     18.70\n5         Terrier     20.36\n6         Unknown     11.51\n\n\n\n\n\n\nQuestion 2\n\n\nWhat are the names of the 47th and the 200th animals in the dataset? (use R code to find out)\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou’ll probably want to make use of the square brackets data[rows, columns].\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 2. There are lots of different ways to do this. We can get out the entire rows, either individually:\n\npetdata[47,]\npetdata[200,]\n\nOr together:\n\npetdata[c(47,200),]\n\n    license_year license_number animals_name species       primary_breed\n47          2018      LNS140233     Hooligan     Dog Retriever, Labrador\n200         2017       LN584186  Maple Syrup     Cat  Domestic Shorthair\n    secondary_breed weight_kg\n47          Unknown     12.27\n200         Unknown      4.66\n\n\nOr we can extract the names only:\n\n# These all do the same\npetdata[c(47,200),\"animals_name\"]\npetdata[c(47,200),3]\npetdata$animals_name[c(47,200)]\n\nThe will all give us these names:\n\n\n[1] \"Hooligan\"    \"Maple Syrup\"\n\n\nIn the last one, we use the $ to access the animals_name variable. In this case, we don’t need to specify [rows, columns] inside the square brackets, because it’s a single variable - there are no columns.\n\ndataframe[rows, columns]\n\nvariable[entries]\n\n\n\n\n\nQuestion 3\n\n\nSubset the data to only the animals which are dogs, and store this subset as another named object in your environment.\nDo the same for the cats.\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou’ll want to think about how we access data via asking for those entries that meet a specific condition (see Chapter 2 #accessing-by-a-condition)\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 3. We can ask “which entries of species variable are equal to ‘Dog’?” by using pet$species==\"Dog\".\nThis will give us a TRUE for each dog, and a FALSE for each non-dog.\nWe can then use this set of TRUEs and FALSEs to access those rows for which it is TRUE in our data:\n\ndogdata &lt;- petdata[petdata$species==\"Dog\", ]\ncatdata &lt;- petdata[petdata$species==\"Cat\", ]\n\n\n\n\n\nQuestion 4\n\n\nFind the name and weight of the heaviest cat, and of the lightest dog.\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou could do this using the original data you read in from question 1, or use the subsets you created in question 3. You’ll again want to supply a condition within square brackets data[?==?]. That condition may well have something to do with being equal to the min() or the max() of some variable.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 4. We can use min() and max() to return the minimum and maximum of a variable:\n\nmin(dogdata$weight_kg)\n\n[1] 0.39\n\nmax(catdata$weight_kg)\n\n[1] 5.48\n\n\nWe could then ask for each entry “is this cat’s weight the maximum cat’s weight?” with catdata$weight_kg == max(catdata$weight_kg) and then use that condition to access the rows in our dataset where the weight_kg variable is at its maximum:\n\ncatdata[catdata$weight_kg == max(catdata$weight_kg), ]\n\n    license_year license_number animals_name species      primary_breed\n414         2018      LNS101014       Smokey     Cat Domestic Shorthair\n    secondary_breed weight_kg\n414             Mix      5.48\n\ndogdata[dogdata$weight_kg == min(dogdata$weight_kg), ]\n\n     license_year license_number animals_name species  primary_breed\n1126         2017      LNS139134       Claire     Dog Great Pyrenees\n     secondary_breed weight_kg\n1126         Unknown      0.39\n\n\n\n\n\n\nQuestion 5\n\n\nDoes the original dataset contain only dogs and cats?\n\n\n\n\n\n\nHints\n\n\n\n\n\nGiven what you did in question 3, you might be able to answer this by just looking at your environment.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 5. In the environment, we can see that the entire dataset has 1956 observations, the Dog’s data frame has 1322, and the Cat’s has 632.\nSo there are 2 missing!\n\n\n\n\nQuestion 6\n\n\nExtract the entries of the original dataset for which the species is neither “Dog” nor “Cat”?\nWhat are the names and species of these animals?\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis is a slightly complex one. Chapter 2 #more-complex-conditions might help you here.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 6. As always, there are lots of different ways.\nHere are three:\n\n\n“not a dog AND not a cat”\nWe can ask if something is not a dog by using petdata$species != \"Dog\". But we want the rows where the species is not a dog and it’s not a cat. So it’s two conditions:\n\npetdata[petdata$species != \"Cat\" & petdata$species != \"Dog\", ]\n\n     license_year license_number     animals_name species primary_breed\n1505         2018      LNS147013    Billy the Kid    Goat     Miniature\n1655         2018      LNS132953 Vincent Van Goat    Goat     Miniature\n     secondary_breed weight_kg\n1505         Unknown    103.48\n1655         Unknown     73.96\n\n\n\n\n“not (dog OR cat)”\nWe could also do this in other ways, such as asking for all the entries which are either “Dog” or “Cat”, and then negating them:\n\npetdata[!(petdata$species == \"Cat\" | petdata$species == \"Dog\"), ]\n\n     license_year license_number     animals_name species primary_breed\n1505         2018      LNS147013    Billy the Kid    Goat     Miniature\n1655         2018      LNS132953 Vincent Van Goat    Goat     Miniature\n     secondary_breed weight_kg\n1505         Unknown    103.48\n1655         Unknown     73.96\n\n\n\n\n“not one of [Dog, Cat]”\nAnother clever little operator is the %in% operator, which asks whether something is in a set of things. Unfortunately, we can’t use !%in% to mean “not in”, so we need to put the ! right at the start of the condition:\n\npetdata[!petdata$species %in% c(\"Cat\",\"Dog\"), ]\n\n     license_year license_number     animals_name species primary_breed\n1505         2018      LNS147013    Billy the Kid    Goat     Miniature\n1655         2018      LNS132953 Vincent Van Goat    Goat     Miniature\n     secondary_breed weight_kg\n1505         Unknown    103.48\n1655         Unknown     73.96\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nCreate a new variable in the data, which contains the weights of all the animals, but rounded to the nearest kg.\n\n\n\n\n\n\nHints\n\n\n\n\n\nTry looking up the help documentation for the function round(). Try playing with it in the console, e.g. round(c(3.5, 4.257, 1.1111)). You may find it helpful to look back at Chapter 2 #adding/changing-a-variable.\n\n“to the nearest kg” would mean we want no decimal points. Note that round() has a digits argument. e.g. round(22.324, digits = 2) and round(22.324, digits = 1) do different things.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 7. We’re wanting this variable as a new column in the data, so don’t forget the dataframe$newvariable &lt;- ...... bit.\n\npetdata$weight_rounded &lt;- round(petdata$weight_kg)\n\n\n\n\n\nQuestion 8\n\n\nTry giving the dataset to the function summary(). You’ll get out some information on each of the variables. It is likely that you’ll get more useful information for the variables containing information on the animal’s weights than for those containing their names, breeds etc because these variables are vectors of “characters”. We’ll start to look more about different types of data next week.\n\n\n\n\n\nSolution\n\n\n\nSolution 8. Easy to do!\n\nsummary(petdata)\n\n  license_year  license_number     animals_name         species         \n Min.   :2015   Length:1956        Length:1956        Length:1956       \n 1st Qu.:2017   Class :character   Class :character   Class :character  \n Median :2018   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2018                                                           \n 3rd Qu.:2018                                                           \n Max.   :2018                                                           \n primary_breed      secondary_breed      weight_kg       weight_rounded \n Length:1956        Length:1956        Min.   :  0.390   Min.   :  0.0  \n Class :character   Class :character   1st Qu.:  4.707   1st Qu.:  5.0  \n Mode  :character   Mode  :character   Median : 16.630   Median : 17.0  \n                                       Mean   : 15.312   Mean   : 15.3  \n                                       3rd Qu.: 22.500   3rd Qu.: 22.0  \n                                       Max.   :103.480   Max.   :103.0  \n\n\n\n\n\n\n\n\n\n\nSimulating Dice\n\nQuestion 9\n\n\nCopy the code from the lecture which creates a custom function called dice() (copied below).\nBe sure to run the code (highlight it all with your cursor, and hit “run” in the top right, or press Ctrl/Cmd+Enter).\n\ndice &lt;- function(num = 1) {\n  sum(sample(1:6, num, replace=TRUE))\n}\n\n\n\n\n\nWhat did that code do?\nIn a sense, this code does nothing: It won’t give you any output when you run it. What it is actually doing, though, is defining a function called dice(). If you look at your environment panel (top right), you’ll see dice appear when you run the code.\nTo produce some output, we have to call the function dice() (by writing it into code: dice(4), for example). dice() wants to be supplied with some information (in the argument num). If no information is supplied, num will take a default value of 1. (So writing dice() is equivalent to writing dice(1)).\nWhat does dice() do with num? It calls another function, sample(), with 3 arguments. We didn’t write sample(): it’s a function that’s “supplied with” R. To find out more about what sample() does:\n\nclick inside the brackets just after sample() in your R script;\npress TAB (⇥), then F1\nyou should see some help appear in the bottom right-hand panel of RStudio.\n\nYou will find that “sample() takes a sample … from the elements of x …” If you compare the code in RStudio to the code under “Usage” you’ll see that where the help has x, we have 1:6. So what does 1:6 mean? One way to find out is to open the console in RStudio (bottom left) and just type stuff in. What happens when you type 1:6? What about 2:17? (What about 6:1?)\nRemember: The console is the place to “try stuff out” (don’t worry, you can’t break it).\nWhat you will discover is that 1:6 creates a vector (list of similar things, in this case numbers) of the numbers 1-6. The next bit of the sample() function is size. In the dice() function, the num passes down to the size of the sample(): Looking through the help, size is the number of items to choose. So sample(1:6, 1) would choose one number from the numbers 1-6 at random; sample(1:6, 3) would choose 3, and so on. The last argument, replace=TRUE, tells sample() what to do with a number once it’s been picked: Does it go ‘back into the bag’ to be picked again (TRUE) or not? (FALSE)?\nAround the outside is sum() which simply sums the numbers on however many (num) dice you “rolled”.\nPutting it all together, our dice() function “throws num dice” by sample()ing from the numbers 1-6 num times, replaceing each number when it’s been picked, and sums the numbers of all the dice.\n\n\nQuestion 10\n\n\nUse the function you just made to ‘roll a die’ a few times. Check that it works like you expect.\n\n\n\n\n\n\nHints\n\n\n\n\n\nYou just need to run dice() a few times. A single die means num = 1, which is the default.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 9. \n\ndice()\n\n[1] 3\n\ndice()\n\n[1] 4\n\ndice()\n\n[1] 2\n\ndice()\n\n[1] 3\n\n\n\n\n\n\nQuestion 11\n\n\nLook up the function replicate(). We can use it to do something in R lots of times! For instance, replicate(20, 1+1) will evaluate 1+1 twenty times.\nUse replicate() to simulate 20 rolls of a single die, and store the results in an object in your environment. Give it an easily identifiable name.\nWhat does each value in this object represent?\n\n\n\n\n\nSolution\n\n\n\nSolution 10. \n\nrolls20 &lt;- replicate(20, dice(num = 1))\nrolls20\n\n [1] 6 3 1 2 5 3 3 2 4 3 3 3 5 6 1 2 3 3 5 4\n\n\nEach value in rolls20 represents the simulated roll of a single die. We roll our die, and get a 6, we roll it again and get 3, the third roll we get 1, and so on..\n\n\n\n\nQuestion 12\n\n\nCreate a barplot showing the frequency with which each number was landed on in the 20 rolls.\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe functions table() and barplot() were used to do this in the lecture.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 11. Your plots will look slightly different to these, because all of our dice are random!\n\n# We can get the frequency table using table()\ntable(rolls20)\n\nrolls20\n1 2 3 4 5 6 \n2 3 8 2 3 2 \n\n# Which we can then pass to the barplot() function:\nbarplot(table(rolls20))\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 13\n\n\nDo the same for 100 rolls, and then for 1,000. What do you notice?\n\n\n\n\n\nSolution\n\n\n\nSolution 12. \n\nmorerolls &lt;- replicate(100, dice(1))\nbarplot(table(morerolls))\n\n\n\n\n\n\n\nmorerolls2 &lt;- replicate(1000, dice(1))\nbarplot(table(morerolls2))\n\n\n\n\n\n\n\n\nThe more rolls we do of the dice, the flatter the graph becomes. This is because there is an equal probability of the die landing on any of the responses - there is a uniform probability.\n\n\n\n\nQuestion 14\n\n\nCopy the code below into your script and run it. It creates a new function called wdice() which simulates the rolling of num dice which are slightly weighted.\nRoll a single weighted die 20 times and plot the frequency distribution. Do the same for 100 and 1,000 rolls of a single die. Does a pattern emerge? At how many rolls?\n\nwdice &lt;- function(num = 1){\n    sum(sample(1:6, num, replace=TRUE, prob = c(0.15,0.15,0.15,0.15,0.15,0.25)))\n}\n\n\n\n\n\n\nSolution\n\n\n\nSolution 13. \n\nwdice &lt;- function(num = 1){\n    sum(sample(1:6, num, replace=TRUE, prob = c(0.15,0.15,0.15,0.15,0.15,0.25)))\n}\n\nwd &lt;- replicate(20, wdice(1))\nbarplot(table(wd))\n\n\n\n\n\n\n\nwd &lt;- replicate(1000, wdice(1))\nbarplot(table(wd))\n\n\n\n\n\n\n\nwd &lt;- replicate(10000, wdice(1))\nbarplot(table(wd))\n\n\n\n\n\n\n\n\nThe die is clearly weighted towards landing on 6. However, is 20 rolls enough to reliably observe this? In our 20 rolls above, it landed on 3 quite a bit too (yours will be different)! The pattern becomes clearer after 1000 rolls.\n\n\n\n\nQuestion 15\n\n\nRemember, wdice() and dice() are really just relying on different functions, like sample(). Try playing around with sample() in the console again - what does the prob = c(....) bit do?\n\n\n\n\n\nSolution\n\n\n\nSolution 14. The prob bit is defining the probabilities of observing each outcome - i.e. there is a 25% chance of rolling a 6.\n\n\n\n\nQuestion 16\n\n\nLet’s try to modify the wdice() function. Edit the code for wdice() so that 50% of the time it lands on number 6.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nTo test out your modified function, you will need to re-run the code which defines the function. When we use wdice() we use the function which is in our environment. If we want to edit the function, we need to then overwrite (or “replace”/“reassign”) the object in our environment.\n\nWe need to be careful to remember that the probability of different outcomes should sum to 1 (i.e., it’s not possible to “50% of the time land on 6” as well as “70% of the time land on 5”!).\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 15. \n\nwdice &lt;- function(num = 1){\n    sum(sample(1:6, num, replace=TRUE, prob = c(0.1,0.1,0.1,0.1,0.1,0.5)))\n}\n\n\n\n\n\nQuestion 17\n\n\nCan you observe the weighting in your new die (the one which 50% of the time lands on number 6) in only 20 rolls?\n\n\n\n\n\nSolution\n\n\n\nSolution 16. \n\nwd &lt;- replicate(20, wdice(1))\nbarplot(table(wd))\n\n\n\n\n\n\n\n\nThe die is very clearly weighted to land on 6. We can see this in just 20 rolls. Presumably it will become even clearer if we increased how many times we roll it.\n\n\n\n\nQuestion 18\n\n\nConceptually, what can we learn from this toy example?\n\n\n\n\n\nSolution\n\n\n\nSolution 17. The more highly weighted a die is, the less we have to roll it in order to observe that weighting."
  },
  {
    "objectID": "03_ex.html",
    "href": "03_ex.html",
    "title": "W3: T-tests",
    "section": "",
    "text": "Question 1\n\n\nAt the end of last week’s exercises, we estimated the mean sleep-quality rating, and computed a confidence interval, using the formula below.\n\\[\n\\begin{align}\n\\text{95\\% CI: }& \\bar x \\pm 1.96 \\times SE \\\\\n\\end{align}\n\\]\nCan you use R to show where the 1.96 comes from?\n\n\n\n\n\n\nHints\n\n\n\n\n\nqnorm! (see the end of Chapter 5 #uncertainty-due-to-sampling)\n\n\n\n\n\n\n\nThe 1.96 comes from 95% of the normal distribution falling within 1.96 standard deviations of the mean:\n\nqnorm(c(0.025, 0.975))\n\n[1] -1.959964  1.959964\n\n\n\n\n\n\nQuestion 2\n\n\nAs we learned in Chapter 6 #t-distributions, the sampling distribution of a statistic has heavier tails the smaller the size of the sample it is derived from. In practice, we are better using \\(t\\)-distributions to construct confidence intervals and perform statistical tests.\nThe code below creates a dataframe that contains the number of books read by 7 people in 2024.\n(Note tibble is just a tidyverse version of data.frame):\n\nbookdata &lt;- \n  tibble(\n    person = c(\"Martin\",\"Umberto\",\"Monica\",\"Emma\",\"Josiah\",\"Dan\",\"Aja\"),\n    books_read = c(12,19,9,11,8,28,13)\n  )\n\nCalculate the mean number of books read in 2024, and construct an appropriate 95% confidence interval.\n\n\n\n\nHere is our estimated average number of books read:\n\nmean(bookdata$books_read)\n\n[1] 14.28571\n\n\nAnd our standard error is still \\(\\frac{s}{\\sqrt{n}}\\):\n\nsd(bookdata$books_read)/sqrt(nrow(bookdata))\n\n[1] 2.652171\n\n\nWith \\(n = 7\\) observations, and estimating 1 mean, we are left with \\(6\\) degrees of freedom.\nFor our 95% confidence interval, the \\(t^*\\) in the formula below is obtained via:1\n\nqt(0.975, df = 6)\n\n[1] 2.446912\n\n\nOur confidence interval is therefore:\n\\[\n\\begin{align}\n\\text{CI} &= \\bar{x} \\pm t^* \\times SE \\\\\n\\text{95\\% CI} &= 14.286 \\pm 2.447 \\times 2.652 \\\\\n\\text{95\\% CI} &= [7.80,\\, 20.78] \\\\\n\\end{align}\n\\]\n\n\n\n\nQuestion 3\n\n\nWill a 90% confidence interval be wider or narrow?\nCalculate it and see.\n\n\n\n\nA 90% confidence interval will be narrower:\n\nqt(0.95, df = 6)\n\n[1] 1.94318\n\n\n\\[\n\\begin{align}\n\\text{CI} &= \\bar{x} \\pm t^* \\times SE \\\\\n\\text{90\\% CI} &= 14.286 \\pm 1.943 \\times 2.652 \\\\\n\\text{90\\% CI} &= [9.13,\\, 19.44] \\\\\n\\end{align}\n\\]\nThe intuition behind this is that our level of confidence is inversely related to the width of the interval.\nTake it to the extremes:\n\nI have 100% confidence that the interval \\([-Infinity, +Infinity]\\) contains the true population mean.\nIf I want an narrower interval, then I have to sacrifice confidence. e.g. a 10% CI: \\([13.94, 14.63]\\)\n\nImagine playing a game of ringtoss. A person throwing a 2-meter diameter hoop will have much more confidence that they are going to get it over the pole than a person throwing a 10cm diameter ring."
  },
  {
    "objectID": "03_ex.html#footnotes",
    "href": "03_ex.html#footnotes",
    "title": "W3: T-tests",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Why 97.5? and not 95? We want the middle 95%, and \\(t\\)-distributions are symmetric, so we want to split that 5% in half, so that 2.5% is on either side. We could have also used qt(0.025, df = 6), which will just give us the same number but negative: -2.4469119)↩︎"
  },
  {
    "objectID": "csstests.html",
    "href": "csstests.html",
    "title": "Tests",
    "section": "",
    "text": "Notes for Wizards\n\n\n\n\n\nhere’s a note!\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\n\n\n\n\nlearning obj\n\n\nimportant\n\n\nsticky\n\n\n\n\n\nr tips\n\n\nstatbox\n\n\ninterprtation interprtation interprtation\n\n\nQuestion\n\n\nquestion\nwhat is your name?\nwhat is your favourite colour?\n\n\n\n\n\nSolution\n\n\n\nSolution 1. solution\nhello\n\n2+2\n\n[1] 4\n\n\n\n\n\n\n\nOptional hello my optional friend\n\n\n\nit’s nice to see you again\n\n\n\n\n\nthis is not a panel\n\n\nthis is a panel\n\n\nthis is a panel"
  }
]