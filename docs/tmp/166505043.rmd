---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
  html_document: default
params:
  examnumber: "B194187"
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
library(pander)
library(broom)
library(psych)
library(sjPlot)

# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0
<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->


```{r cleaning, include = FALSE}
# clean impossible values
couchto5k$missing <- NA
couchto5k$missing[couchto5k$age > 100] <- "crazy age"
couchto5k$age[couchto5k$age > 100] <- NA
couchto5k$missing[couchto5k$selfmot < 5] <- "invalid selfmot score"
couchto5k$selfmot[couchto5k$selfmot < 5] <- NA

# clean incorrect values
couchto5k$cleaned <- NA
couchto5k$cleaned[couchto5k$season == 'autunm'] <- "autumn misspelled"
couchto5k$season[couchto5k$season == 'autunm'] <- 'autumn'
couchto5k$cleaned[couchto5k$week_stopped > 9] <- "week_stp > 9"
couchto5k$week_stopped[couchto5k$week_stopped > 9] <- 9

# add new dummy var for finishing program
couchto5k$finished <- as.factor(ifelse(couchto5k$week_stopped == 9, 1, 0))

# tables for missing and cleaned data
ctab <- table(couchto5k$cleaned)
mtab <- table(couchto5k$missing)
# remove observations with missing data
couchto5k <- couchto5k %>% filter(is.na(missing))
total <- count(couchto5k)
```

The data couchto5k is from an NHS-sponsored fitness program which lasts 9 weeks. Participants are from 2 cities, Edinburgh and Glasgow. At the beginning of the program participants were asked to complete questionnaires on their self-perceived  level of accountability and self-motivation (selfmot). The questionnaires each had 5 questions and asked participants to give themselves a ranking on the question from 1-7 giving scores a range of 5-35. Upon ending the program, either by way of completing the 9 weeks or dropping out early, participants were asked to give a self-reported happiness score in the range of 0-100 and a 'health' measure in the range of 0-100 based on a number of physiological tests. Also recorded for each participant was their age, the season they joined the program (Spring, Summer, Autumn, Winter), and the week they ended the program.

The data were inspected and missing, mistaken or unlikely values were corrected or assigned NA. The observations with missing data were removed after consideration that the missing observations would affect testing in later parts of analysis. Some of the research questions require comparing different variables and if the number of observations are different the comparison won't be possible. The observations with corrected data were kept in the data set.
The data has `r total` observations for analysis. Table 1 and Table 2 give a summary of cleaned data.

```{r table1}
ctab %>% pander(caption="Summary of corrected values.")
```

```{r table2}
mtab %>% pander(caption="Summary of missing values.")
```

Two observation had age values over one hundred, 107 and 141. The observation with age 141 was removed as an impossible value and the observation with age 107, though not an impossible age, would have been an extreme outlier and therefore removed as well.
There were two observations removed that had 'selfmot' scores that were less than five, which is out of the range of possible values.
One observation recorded a value of 14 for 'week_stopped'. Since the research is only interested in whether the 9 week program was completed, the value was change to 9 to align with others that finished the program.
Five observations recorded 'season' as 'autunm' which was changed to 'autumn'.
Eleven observation recorded a value of zero for happiness, which seems extremely low on a scale from 0-100, however it was decided that the score is still valid and should be kept in the data set as is.
A new variable called 'finished' was added to the data with levels 0 for if the participant ended the program before week 9 and 1 for if the participant completed the 9 week program.

Bivariate correlations show a strong negative correlation between age and health, which is expected. There is a moderate positive correlation between self-motivation and happiness as well as between self-motivation and finishing the program. There is also a moderate positive correlation between season and finishing the program (see Figure 1).

```{r descriptives}
library(psych)
couchto5k %>% 
  select(age, accountability, selfmot, health, happiness, season, finished) %>%
  pairs.panels()

```
Figure 1: Bivariate scatter plots (below diagonal), histograms (diagonal), and Pearson correlation coefficient (above diagonal), of health and wellness scores, seasons result of program.

Table 3 shows a summary of statistics for the main variables of analysis.

```{r summary}
couchto5k %>%
  select(age, accountability, selfmot, health, happiness, season, city, week_stopped) %>%
  mutate(season = factor(season))%>%
  mutate(city = factor(city))%>%
  summary() %>%
  pander(caption="Summary of couchto5k variables")
```


# Question 1 

## Question 1a

```{r q1a}
# add new variable
couchto5k <- couchto5k %>%
    mutate(
      q1a = ifelse(week_stopped < 9, "no9", "finish"),
      q1a = ifelse(week_stopped < 5, 'no5', q1a)
    )
# goodness of fit
# order is finish, no5, no9
gof <- chisq.test(table(couchto5k$q1a), p=c(0.45, 0.45, 0.1))
pfinish <- table(couchto5k$q1a)/sum(table(couchto5k$q1a))

```
To test whether the sample given matches the the same pattern researches found in a previous survey a new variable was created with three levels: those that gave up before week 5 ('no5'), those that gave up after week five but before finishing in week 9 ('no9'), and those that finished the program in week 9 ('finish'). A Chi-Squared Goodness of Fit test was performed to check if the new variable matched the distribution specified as follows: 45% quit before week 5, 10% quit between week 5 and 9, and 45% finished.
The results from the test are given in Table 5.
```{r}
gof %>% pander(caption="Chi-squared test for given probabilities with previous survey distribution")
```

With a p-value of `r gof$p.value` < 0.05 the hypothesis that the data fit the given proportions is rejected and it can be conclude that this data is statistically different than the previous survey. Table 6 shows the proportional distribution of the given data.

```{r}
pfinish %>% pander(caption="Proportional distribution of how far participants got in the program")
```


## Question 1b

```{r q1b}
city_drop <- table(couchto5k$city, couchto5k$q1a)
indp <- chisq.test(city_drop)

```
To test whether the rates of attrition differ by city we can use a Chi-Squared test of Independence, with the null hypothesis being that the two cities have the same attrition rates. The results of the test are in Table 7.
```{r}
indp %>% pander(caption="Pearson's Chi-squared test of independence for rates of attrition by city")
```

With a p-value of `r indp$p.value` > 0.05 there is not enough evidence to reject the null hypothesis. We conclude that there is no significant difference between the attrition rates by city.

## Question 1c

```{r q1c}
aget <- t.test(couchto5k$age ~ couchto5k$city)
shap <- shapiro.test(couchto5k$age)
```
To test whether the average ages of participants differ by city we can conduct a t-test to compare different group means. Before that we can look at a boxplot of the data comparing the two cities and see that group means for age are close (Figure 2).

```{r}
ggplot(data = couchto5k, aes(x=city, y=age))+
  geom_boxplot(outlier.alpha = FALSE)+
  geom_jitter(alpha=.3)+
  labs(title = 'Figure 2: Boxplot of Age vs City')

```

The results of the t-test, with a null hypothesis that the difference between the group means is zero, are in Table 8.
```{r}
aget %>% pander(caption="Welch Two Sample t-test of mean age by city")
```


With a p-value of `r aget$p.value` < 0.05 there is enough evidence to reject the null hypothesis and conclude that the mean age of participants is statistically different between the two cities. The Shapiro-Wilk normality test did not indicate violation of the assumption of normality (W=`r shap$statistic`, p=`r shap$p.value`).


# Question 2

## Question 2a

```{r q2a}
lmh_s <- lm(happiness ~ season, data = couchto5k)
ahs <- anova(lmh_s)
```
The research question asks how season influences happiness scores. To begin, the relationship can be visualizes by a boxplot (Figure 3).

```{r}
ggplot(data = couchto5k, aes(x=season, y=happiness))+
  geom_boxplot()+
  labs(title = 'Figure 3: Boxplot of Happiness scores vs Season')
```

From the boxplot alone, it appears Autumn and Winter have similar means to each other, while Spring and Summer have similar means to each other and different means from Autumn and Winter. Furthermore, there appears to be more variation in happiness scores for Spring and Summer than there is in Winter and Autumn. To analyze this relationship further, a linear model was built predicting happiness scores based on season (lmh_s), with details in the Table 10.

```{r}
lmh_s %>% pander(caption="Fitting linear model: happiness ~ season")
```

The the intercept (`r lmh_s$coefficients[1]`) in the table above represents the mean happiness score of the reference season level, which in this case is Autumn. Because season is a categorical variable, all other model parameters (i.e. coefficients) are based on the reference level. For example, the parameter for "seasonspring" is `r lmh_s$coefficients[2]`, meaning the mean happiness score for observations taken in spring is `r lmh_s$coefficients[2]` points higher on the happiness scale from the reference level (`r lmh_s$coefficients[2]`). Essentially, this means the mean happiness score for observations recorded in Spring should be `r lmh_s$coefficients[1]`+`r lmh_s$coefficients[2]`=`r sum(lmh_s$coefficients[2],lmh_s$coefficients[1])`, which we can see is true in Figure 3. The same goes for the other levels in the season variable.
The p-value for the intercept (i.e. Autumn) is from the t-test with the hypothesis that the true mean is zero - which we reject in this case since 0.007 < 0.05. The p-values associated with each level of season is from a two sample t-test, testing each level parameter estimate against the reference level parameter (i.e. the intercept). Therefore, the parameters for Spring and Summer are significantly different from Autumn, but not necessarily  statistically significant from each other. The parameter for Winter is not significantly different from Autumn (p-val = 0.465), however it is not tested against the other parameters that it would likely be significant against.

Overall, the model shows that for observations taken in Spring there is a mean increase `r lmh_s$coefficients[2]` in happiness scores over the mean of Autumn and a mean increase of `r lmh_s$coefficients[3]` in happiness scores over the mean of Autumn for observations in Summer. The mean increase of `r lmh_s$coefficients[4]` in Winter over Autumn is non-significant.

## Question 2b

```{r q2b}
lmh_a <- lm(happiness ~ age, data = couchto5k)
lmh_sa <- lm(happiness ~ season + age, data = couchto5k)
aha <- anova(lmh_a)
ahsa <- anova(lmh_sa)
ahs_hsa <-anova(lmh_s, lmh_sa)
p1 <- ahs_hsa$`Pr(>F)`[2]
lmh_sa %>% pander(caption="Fitting linear model: happiness ~ season + age")
```

To test the affects of age on happiness scores over and above the affects of season we can add age to the previous model lmh_s to get the model lmh_sa, the results of which are in Table 11. It can be concluded that the coefficient for age in the model is non-significant (p-value 0.635 > 0.05). The affect of age on happiness in a model without season also resulted in a non-significant p-value (0.51). Age does not appear to improve the fit of the model over and above the explanatory power of season. This can be concluded with an incremental ANOVA test of the two models, lmh_s and lmh_sa (Table 12). The model that includes age (lmh_sa) does not have a significant p-value on the F-Test F(`r ahs_hsa$Df[2]`, `r ahs_hsa$Res.Df[2]`)=`r ahs_hsa$F[2]`, p-value = `r p1`>0.05.


```{r}
# compare the two with anova, talk about f-scores
ahs_hsa %>% pander(caption="Analysis of Variance Table for model lmh_s compared to lmh_sa")
```


## Question 2c
The baseline model chosen to model happiness is the model with seasons (lmh_s). The model fit is better than the model with age as mentioned above. Continuing with lmh_s, model assumptions were checked and there were egregious violations which can be seen in the model plots in Figure 4.

```{r q2c}
par(mfrow=c(2,2))
plot(lmh_s)
```
Figure 4: Plots for model lmh_s

It should be noted that there were some outliers and potentially influential points identified in the plots that were analyzed further using summary(influence.measures(lmh_s)) to look at the points R deems potentially influential. Most, if not all, are from Autumn and Winter, likely because they have far few observation than Summer and Spring, which can be seen in the summary Table 3. This means that data points in these two groups have more potential to affect the mean of their respective group. None of the outliers or influential points were removed. This issue potentially arises from the fact that the 0-100 scale for happiness is both rather arbitrary and a rather large range. A better defined and smaller scale might have increased accuracy for the happiness measure.


# Question 3

## Question 3a

```{r q3a}
lmh_sf <- lm(happiness~season+finished, data = couchto5k)
lmh_f <- lm(happiness~ finished, data = couchto5k)
ahsf <- anova(lmh_s, lmh_sf)
p2 <- ahsf$`Pr(>F)`[2]
```
To test the affects of finishing the program on happiness scores over and above the affects of season we can add the dummy variable finish to the baseline model lmh_s to get the model lmh_sf. Finishing the program does not appear to improve the fit of the model over and above the explanatory power of season. This can be concluded with an incremental ANOVA test of the two models, lmh_s and lmh_sf (Table 13). The model that includes finish (lmh_sf) does not have a significant p-value on the F-Test F(`r ahsf$Df[2]`, `r ahsf$Res.Df[2]`) = `r ahsf$F[2]`, p-value = `r p2` > 0.05.
The affect of finishing the program on happiness in a model without season also resulted in a non-significant p-value (0.51).
```{r}
ahsf %>% pander(caption="Analysis of Variance Table for model lmh_s compared to lmh_sf")
```


## Question 3b

```{r q3b}
lmh_sh <- lm(happiness~season + health, data = couchto5k)
ahsh <- anova(lmh_s, lmh_sh)
p3 <- ahsh$`Pr(>F)`[2]
```

To test the affects of health scores on happiness scores over and above the affects of season we can add the health variable to the baseline model lmh_s to get the model lmh_sh. Health scores do not appear to improve the fit of the model over and above the explanatory power of season. This can be concluded with an incremental ANOVA test of the two models, lmh_s and lmh_sh (Table 14). The model that includes health (lmh_sh) does not have a significant p-value on the F-Test F(`r ahsh$Df[2]`, `r ahsh$Res.Df[2]`) = `r ahsh$F[2]`, p-value = `r p3` > 0.05.


```{r}
ahsh %>% pander(caption="Analysis of Variance Table for model lmh_s compared to lmh_sh")
```


## Question 3c

```{r q3c}
lmh_shw <- lm(happiness~season + health*week_stopped, data = couchto5k)
ahshw <- anova(lmh_s, lmh_shw)
p4 <- ahshw$`Pr(>F)`[2]
```

To test whether the happiness of participant who got further in the program is more affected by the health metric than those who stopped earlier we can add an interaction term between health and week_stopped to the baseline model and see if it improves the fit of the model. Though on its own the health metric did not improve the fit of the baseline model, together with the week_stopped variable it appears to have a significant affect.
Table 15 shows the model estimates and it appears the new model parameters for health, week_stopped and the interaction term have significant coefficients. Based on the ANOVA test (Table 16) it can be concluded that the new model does improve the fit of the baseline model with a significant p-value on the F-Test F(`r ahshw$Df[2]`, `r ahshw$Res.Df[2]`) = `r ahshw$F[2]`, p-value = `r p4` < 0.05.

Therefore, it can be concluded that the health metric does effect the happiness of participants who got further in the program more than those who stopped earlier, as proven by the significant interaction coefficient.


```{r}
lmh_shw %>% pander(caption="Fitting linear model: happiness ~ season + health * week_stopped")
ahshw %>% pander(caption="Analysis of Variance Table for model lmh_s compared to lmh_shw")
```


## Question 3d
It can be concluded that neither age nor completion of the program had any significant affect on the happiness scores of participants over and above the baseline effects of season, as shown in the tests above.
The season had a significant affect on happiness scores, as did health contingent on the week the participant stopped the program.


# Question 4

```{r q4}
couchto5kf <- couchto5k %>%
  filter(
    finished == 1
  )

ggplot(data = couchto5kf, aes(x = season, y= happiness, colour = city))+
  geom_point(stat = "summary", fun = "mean", size = 3)+
  ylab('average happiness')+
  labs(title = 'Figure 5: Average happiness of articipants that finished the program grouped by season and city')
  
```

Figure 5 shows the average happiness score of participants that finished the program grouped by season and city.

# Question 5
## Question 5a

```{r q5a}
glmf_s <- glm(finished ~ season, data = couchto5k, family = 'binomial' )
glmf_self <- glm(finished ~ I(selfmot - 5), data = couchto5k, family = 'binomial' )
glmf_a <- glm(finished ~ age, data = couchto5k, family = 'binomial' )
glmf_ss <- glm(finished ~ selfmot + season , data = couchto5k, family = 'binomial' )
glmf_ss2 <- glm(finished ~ season + selfmot , data = couchto5k, family = 'binomial' )
```
Whether the participant finished the program is a binary outcome so we can try to model it with a generalized linear model. It should be noted that the variable 'finished' codes 1 for those that finished in week 9 and 0 for those that dropped out early. Looking at the correlations in Figure 1 we might start by building models that include season, selfmot and age to see if there is a significant relationship. After testing various models the best model was finished ~ selfmot. However, the intercept of that model would  not be very useful because a score of 0 on the selfmot test is an impossible value. Instead we can shift the intercept to get the intercept when selfmot is 5 (the lowest possible value), which is summarized in Table 17.

```{r}
glmf_self %>% pander(caption="Fitting generalized binomial linear model: finished ~ I(selfmot - 5)")
```



## Question 5b

The model predicts that with every 1 point increase on the selfmot scale, the log-odds of finishing the program increases by `r glmf_self$coefficients[2]` with a significance level of 0.04. Therefore, the log-odds of dropping out is -`r glmf_self$coefficients[2]`, the negative of the coefficient for selfmot.
The intercept has been shifted so that the coefficient `r glmf_self$coefficients[1]` represents the log-odds of finishing the program when the selfmot score is the lowest possible score of 5.
To make the coefficient more intuitive we can convert it from log-odds to odds. The model therefore predicts that with every 1 point increase on the selfmot scale, the odds of finishing the program increases by `r exp(glmf_self$coefficients[2])` and the odds of finishing the program for selfmot score of 5 is `r exp(glmf_self$coefficients[1])`:1.
The deviance is summarized in the Table 18.

```{r}
anova(glmf_self) %>% pander(caption="Analysis of Deviance for glm finished ~ I(selfmot - 5)")
```


## Question 5c

```{r q5c, message=FALSE, warning=FALSE}
couchto5k <- 
  couchto5k %>%
  mutate(
    predprobs = predict.glm(glmf_self, newdata = couchto5k, type = 'response')
  )
ggplot(data = couchto5k, aes(x = selfmot, y = 1-predprobs)) +
  scale_x_continuous(breaks=seq(5,35))+
  scale_y_continuous(breaks=seq(0,1,by=0.1))+
  geom_smooth(method="glm",method.args=list(family=binomial))+
  geom_jitter(size=2,width=0,height=.2,alpha=.2) +
  labs(y="predicted probability of quitting program", title = 'Figure 6: Predicted probabilities of quitting vs self-motivation')
  
  
```

Figure 6 is a graph of the predicted probabilities of participants quitting against their self-motivation scores. The predicted probabilities were calculated for each observation using the generalized linear model developed above and stored in a new variable in the data set. Since the model predicts the probability of finishing, to graph the relationship based on quitting the calculated probability is inverted by taking 1 - predicted probability to get the probability of quitting.
