---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
params:
  examnumber: "B200607"
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

Couch to 5k is a 9-week running programme that is supported by NHS. Data was obtained from https://uoepsy.github.io/data/usmr_2122_data.R. This dataset includes 123 participants with 9 variables (i.e., pptID, age, accountability, selfmot, health, happiness, season, city, and week_stopped). pptID is a random ID number for each participant. Participants were recruited from two cities, Edinburgh and Glasgow. At week 0, all participants were asked to complete a 7-point questionnaire, which consists of 5 items for accountability and 5 items for self-motivation. Items were summed for each participant. After dropping out (<week 9) or completing (= week 9) the programme, participants filled out a questionnaire reporting their subjective happiness and completed a health test. The scale for both measurements range from 1 to 100. Moreover, the season variable represents which season of the year participants were interviewed in. participants’ age and which week they dropped out were also included. 

Now, the researchers are interested in what psychological factors would affect the participants’ completion of the programme and in whether taking the programme would affect participants’ health and wellbeing.



```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)

# this line means all numeric output gets rounded to 3 dp
options(digits=3)

# load any other packages that you require here:
library(tidyverse)
library(pander)
library(broom)
library(dbplyr)
library(psych)
library(car)
library(sjPlot)

# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0
<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->


```{r cleaning, include = FALSE}
# Neither output nor code from this chunk will be shown in the compiled document. 

summary(couchto5k)

couchto5k <- 
  couchto5k %>%
  mutate(
    age = ifelse(as.numeric(age)>90, NA, as.numeric(age)),
    selfmot = ifelse(as.numeric(selfmot)<5, NA, as.numeric(selfmot)),
    week_stopped = ifelse(as.numeric(week_stopped)>9, NA, as.numeric(week_stopped))
  )

new_data <- na.omit(couchto5k)

ggplot(data = new_data, aes(y = age)) +
  geom_boxplot()+
  scale_x_continuous(limits = c(-2,2), breaks = NULL)

ggplot(data = new_data, aes(y = accountability)) +
  geom_boxplot()+
  scale_x_continuous(limits = c(-2,2), breaks = NULL)

ggplot(data = new_data, aes(y = selfmot)) +
  geom_boxplot()+
  scale_x_continuous(limits = c(-2,2), breaks = NULL)

ggplot(data = new_data, aes(y = health)) +
  geom_boxplot()+
  scale_x_continuous(limits = c(-2,2), breaks = NULL)

ggplot(data = new_data, aes(y = happiness)) +
  geom_boxplot()+
  scale_x_continuous(limits = c(-2,2), breaks = NULL)

summary(new_data)


```

```{r descriptives}
# Code will not be shown from this chunk (because we set echo = FALSE in the very first chunk)
# the output from this code will be shown. 
new_data$season<- replace(new_data$season, new_data$season %in% c('autunm'),'autumn')

dp_data<-
  new_data%>%
  select(age,accountability,selfmot,health,happiness,week_stopped)

pander(describe(dp_data))
table(new_data$season, new_data$city)

new_data %>% 
  select(age,accountability,selfmot,health,happiness,week_stopped,season, city) %>%
  pairs.panels()



```

We have loaded several packages (e.g., tidyverse, pander, car) to help analyse our data. Preliminary analyses revealed that there was no missing data. However, there were some impossible data that needed to be excluded. I excluded 5 participants for impossible ages (> 90), impossible self-motivation scores (< 5), and impossible weeks (> 9). As for the outliers, no overly influential data was found and therefore no outliers were excluded. Then, based on the new dataset (no impossible data), we conduct a descriptive analysis for different types of variables. During analysis, we found that, in season column, three participants spelled “autumn” to “autnm”. Therefore, we corrected the spelling for these three. Effects will be considered statistically significant at α=0.05.

The first table above presents the results of the descriptive statistics for the numeric data in the present study. It is worth noting that the skew and kurtosis values are all within the interval from −2 to 1, indicating that the data are normally distributed. As for the categorical data, season and city, the second table above demonstrates the frequency of each combined category.

Furthermore, the correlation analysis (see the matrix plot above) shows that the correlation coefficients between variables are small except for age and health, self-motivation and happiness, stopped week and season. Specifically, age is positively correlated with accountability, happiness, stopped week, season and city, but negatively correlated with self-motivation and health. Accountability is positively correlated with happiness and city, but negatively correlated with self-motivation, health, stopped week, and season. Self-motivation is positively correlated with health, happiness stopped week, and city, but negatively correlated with season. Health is positively correlated with happiness and stopped week, but negatively correlated with season and city. Happiness is positively correlated with stopped week, but negatively correlated with season and city. Stopped week is positively correlated with season, but negatively correlated with city. Last, season and city are positively correlated.



# Question 1 

## Question 1a

```{r q1a}

new_data <- 
  new_data%>%
  mutate(week_last = week_stopped)

new_data$week_last <- replace(new_data$week_last,new_data$week_last %in% c('1','2','3','4'),"1_before5")
new_data$week_last <- replace(new_data$week_last,new_data$week_last %in% c('5','6','7','8'),"2_after5")
new_data$week_last <- replace(new_data$week_last,new_data$week_last %in% c('9'),"3_completed")

table(new_data$week_last)
barplot(table(new_data$week_last))

chisq.test(table(new_data$week_last),p = c(.45,.10,.45))

```

Based on question 1a, we hypothesised that the frequency of continuing on the programme in our present study was the same as that in the previous nationwide survey. Thus, Chi-square test would be used to test this hypothesis. 

First, in case that the original data would be lost, I created a variable called “week_last” to replicate the “week_stopped” variable and analysed based on it.  Second, three categories need to be classified: stopped before week 5, stopped after week 5, and completed. Thus, we recoded the week of programme participants stopped in into three categories, which were 1_before5 (participants stopped in week 1,2,3,4), 2_after5 (participants stopped in week 5,6,7,8) and 3_completed (participants completed in week 9). Then, I performed a table and bar plot to display how many participants were in each category. Lastly, the Chi-square test was computed.

The result of Chi-square test indicates that the frequency of continuing on the programme in our present study is not in line with the frequency from the previous study (χ2(2) =6, p= .04). Hence, the patterns of attrition are different in our present study from the previous nationwide survey.



## Question 1b

```{r q1b}

table(new_data$week_last,new_data$city)
plot(table(new_data$week_last, new_data$city))

chisq.test(table(new_data$week_last,new_data$city))

```

Based on question 1b, we hypothesised that the patterns of attrition rates differed by city. Thus, Chi-square test would be used to test this hypothesis.

The two cities are Edinburgh and Glasgow and the three categories of attrition are stopped before week 5, stopped after week 5, and completed. I ran a table and a bar plot to see the distribution of the participants in different attrition categories by city. Then, the Chi-square test was computed, demonstrating that there was no difference of the patterns of attrition rates in two cities (χ2 (2) = 0.8, p = 0.7). Hence, the patterns of attrition rates did not differ by city.


## Question 1c

```{r q1c}
ggplot(data = new_data, aes(x = age, y = city)) +
  geom_boxplot()

t.test(new_data$age ~ new_data$city,alternative = "two.sided")

```

Based on question 1c, an independent sample t-test was conducted, testing the hypothesis that the average ages of participants who participated in the programme differed by city.

First, a box plot was performed to visualise the difference of participants’ ages in Edinburgh and Glasgow, illustrating that the mean ages were very close for two cities. Second, Shapiro-Wilk normality tests were conducted to examine whether the ages were normally distributed in both cities. Next, an F test was conducted to see if the two variances in two cities were the same. Last, the t-test was conducted.

The average age of participants in Edinburgh was 37.0 and the average age of participants in Glasgow was 37.7. However, this difference between the average ages was not statistically significant (t (48) = −0.3, p = 0.8). Therefore, the average ages of participants who participated in the programme do not differ by city.



# Question 2

## Question 2a

```{r q2a}

new_data$season <- factor(new_data$season)
contrasts(new_data$season)

ggplot(data = new_data, aes(x = season, y = happiness)) +
  geom_point(alpha = 0.5) +
  labs(x = "season", 
       y = "happiness")

mod_data <- new_data[-c(29,115),]
mod_2a <- lm(happiness ~ 1 + season, data = mod_data)

summary(mod_2a)

```

According to question 2a, we need to build a linear regression model to describe how season (predictor) would influence happiness (outcome). 

First, since season is a categorial variable with 4 levels, we need to transform it into dummy variables before taking it to a liner regression analysis. Second, we performed a plot to roughly see the relationship between season and happiness. The plot shows that happiness scores have different distributions in four seasons. Numerically, there was a small correlation between season and happiness (r = −.12). After excluding two influential data (29,115), we conducted a linear regression model to examine the relationship between season and happiness. 

Results showed that season predicted happiness: The F-test for overall significance of the regression was significant (F (3, 112) = 5.38, p < .01), and the model explained approximately 10.3% of the variability in happiness outcomes. With autumn as the reference level, spring (b = 27.0, t = 2.19, p = .030) and summer (b = 26.6, t = 2.11, p = .04) positively predict happiness outcomes, but winter (b = −4.0, t= −.28, p = .78) does not significantly influence happiness. Therefore, season is an effective predictor of happiness.



## Question 2b

```{r q2b}
new_data$season <- factor(new_data$season)
contrasts(new_data$season)

mod_2b <- lm(happiness ~ 1 + season + age , data = mod_data)
summary(mod_2b)

```

Similarly, we need to code the season variable first. There was a small correlation between age and happiness (r = .02). After excluding two influential data (29, 115), we conducted a linear regression model to examine the relationship between age and happiness, accounting for effects of season. The effect of age on happiness was not statistically significant (b = 0.03, t = 0.15, p = 0.88), suggesting that participants’ age would not affect their happiness. The F-test for overall significance of the regression was significant (F (4, 111) = 4.01, p < .01), and the model explained approximately 9.47% of the variability in happiness outcomes.

## Question 2c

```{r q2c}

null_mod<- lm(happiness ~ 1, data = mod_data)
anova(null_mod,mod_2a, mod_2b)

```

Comparing model_2a and model_2b, it is clear that the season is a significant predictor to happiness while age is not. And the adjusted R2 decreased as age to the regression model, suggesting that age reduced model’s explanatory power. Moreover, the result of model comparison reveals that, compared with the null model, the addition of season improved model fit (F (3, 111) = 5.34, p < .01), but further adding age did not improve model fit (F (1, 111) = .02, p = .88). Taken together, mod_2a would be an appropriate baseline model, with season as one predictor.


# Question 3

## Question 3a

```{r q3a}

new_data <- 
  new_data%>%
  mutate(
    completion = week_stopped>8
  )

new_data$completion <- factor(new_data$completion)
contrasts(new_data$completion)

new_data$season <- factor(new_data$season)
contrasts(new_data$season)

mod_data <- new_data[-c(29,115),]
mod_3a <- lm(happiness ~ 1 + season + completion, data = mod_data)

summary(mod_3a)
pander(mod_3a)

```

Before conducting the regression analysis, I created a new variable called “completion”, which classified the participants as completed the programme or not. Then, completion variable was coded it to a dummy variable (0 and 1). Building on the baseline model, we entered completion as another predictor of the model. The F-test for the overall significance of the regression showed strong evidence to support our model (F (4,111) = 4.74, p < .01), and the model explained approximately 11.5 % of the variability in happiness outcomes. However, the t-test for the effect of completion on happiness was not significant (b =10.32, t = 1.61, p = .11), showing that whether or not participants have completed the programme would not affect their feeling of happiness.


## Question 3b

```{r q3b}

new_data$season <- factor(new_data$season)
contrasts(new_data$season)

mod_data <- new_data[-c(29,115),]
mod_3b <- lm(happiness ~ 1 + season + health, data = mod_data)

summary(mod_3b)
pander(mod_3b)
```

The correlations between variables have been shown before.Due to the nonsignificant effect of completion, I excluded it for the following analysis. I built a multiple regression model with season and health as predictors and happiness as an outcome variable. The F-test for the overall significance of the regression supported at least one of the coefficients did not equal to 0 (F (4,111) = 4.18, p < .01), and the model explained approximately 9.97 % of the variability in happiness outcomes. However, the t-test for the effect of health on happiness was not statistically significant, (b = .21, t = .80, p = .43), showing that participants’ health metrics would not affect their happiness outcomes.  


## Question 3c

```{r q3c}

ggplot(data = new_data, aes(x = health, y = happiness)) + 
  geom_point() + 
  facet_wrap(~completion)

new_data$completion <- factor(new_data$completion)
contrasts(new_data$completion)

new_data$season <- factor(new_data$season)
contrasts(new_data$season)

mod_3c <- lm(happiness ~ 1 + season + health * completion, data = mod_data)

summary(mod_3c)
confint(mod_3c)
pander(mod_3c)

plot_model(mod_3c, type="int")

```

A plot was conducted to see the relation of happiness scores and health metrics in different completion conditions, showing a somewhat difference of health scores distributions in two conditions.Then, I performed a regression model to examine whether the interaction of health and completion would influence happiness. The F-test for model utility is significant (F (6, 109) = 4.8, p < .01), and the model explained approximately 16.5 % of the variability in happiness outcomes. Moreover, there was a significant interaction between health and completion (b = 1.53, t = 2.92, p < .01). Therefore, it is supported that having a healthy body would make participants who completed the programme feel happier.


## Question 3d

To recap, the multiple regression model for happiness was found significant (F (6,109) = 4.80, p < .001), with four predictors (i.e., season, completion, health, interaction of completion and health) explaining 16.5% of the variance. Compared with autumn (the reference level), spring (b = 29.65, t = 3.06, p < .01, 95% CI [ 13.99, 65.32]) and summer (b = 34.21, t = 2.74, p < .01, 95% CI [ 9.49, 58.92]) positively predict happiness outcomes, but winter (b = −1.93, t= −.137, p = .891, 95% CI [ −26.04, −29.90]) does not significantly influence happiness. Happiness was negatively predicted by completion (b= −76.59, t= −2.54, p = .013, 95% CI [ −136.44, −16.75]). However, the interaction of completion and health (b = 1.53, t = 2.92, p < .01, 95% CI [ .49, 2.56]) positively affected happiness outcomes (see the plot of interaction). Moreover, health (b = −.64, t = −1.74, p = .09, 95%CI [ −1.38, .09]) did not show a significant predicting effect on happiness. Therefore, completing the programme may lead to fewer happy feelings, but with the influence of a healthy body, participants who completed the programme would feel much happier.


# Question 4

```{r q4}
com_data <-
  new_data%>%
  filter(week_stopped==9)%>%
  select(happiness,season,city)

plot_data<-
  com_data%>%
  group_by(season,city) %>%
  summarise(hp_mean=mean(happiness))

ggplot(plot_data, aes(x=season, y=hp_mean, fill=city)) +
    geom_bar(stat='identity', position='dodge')+
    labs(x = "Season", 
       y = "Average Happiness")

```

To create a subset of the data, we selected the participants who completed the programme, and their happiness, season when interviewed, and city where they were recruited. Then we group the data by season and city, calculating the means of happiness scores for each cell. Last, I output a bar plot to demonstrate the difference of happiness. The plot shows that: (1) in Edinburgh, the average happiness ranks in the descending order of summer, spring, autumn, winter. (2) in Glasgow, the average happiness ranks in the descending order of spring, summer, autumn, winter. Therefore, participants who were interviewed in spring felt happiest but who were interviewed in winter had the lowest level of happiness. 


# Question 5

## Question 5a

```{r q5a}
new_data <-
  new_data%>%
  mutate(lh_quit=10-week_stopped)

mod5_data <- new_data[-c(79),]

mod_5a1 <- lm(lh_quit ~ 1 + age + accountability + selfmot + happiness + health, mod5_data)
summary(mod_5a1)

mod_5a2 <- lm(lh_quit ~ 1 + age + accountability + selfmot + health, mod5_data)
summary(mod_5a2)

#linearity 
plot(mod_5a2, which=1)

#normality 
plot(mod_5a2, which=2)

#independence 
dwt(mod_5a2)

#homogeneity 
ncvTest(mod_5a2)

#multicollinearity
vif(mod_5a2)


```

As we mentioned before, one of the aims of this study is to explore the psychological factors that make participants continue on the programmes. Hence, we would include the possible intrapersonal factors (i.e., age, accountability, self-motivation, health and happiness) as predictors into our proposed regression model. We reversely coded week_stopped variable as an indicator for the likelihood of dropping out (lh_quit), with higher scores representing higher probability of quitting. 

The correlations between variables have been shown before.After excluding the overly influential data (79), we entered all 5 predictors and 1 outcome variable (probability of quitting) into the model (mod_5a1). The results shows that happiness is not a significant predictor for the probability of quitting, therefore, we exclude happiness and build another model(mod_5a2). The second model has four predictors: age, accountability, self-motivation, and health. The results demonstrate that every predictor significantly affects the probability of quitting, which makes it a suitable model for predicting the likelihood of dropping out.

Besides, the model met the four assumptions: (1) linearity, the plot of model residuals vs fitted values shows that the mean of the residuals is close to zero across the predicted values on the linear predictor. (2) normality of errors, the plot of model Normal Q-Q demonstrates that the distribution of residuals is close to a normal distribution, (3) independence of errors, a Durbin-Watson test for autocorrelation of residuals revealed DW = 2.05, p = .8, and (4) equal variances, Non-constant variance score test revealed χ2(1) = 2.56, p = .1. Moreover, VIF values < 2 indicates that multicollinearity is not negatively affecting the model estimates. Taken together, the regression model named mod_5a2 is an appropriate model to predict likelihood of dropping out. 



## Question 5b

```{r q5b}

summary(mod_5a2)
confint(mod_5a2)
pander(mod_5a2)

```

The multiple regression model for likelihood of dropping out was found significant (F (4, 112) = 6.8, p < .001), with an adjusted R2 of 16.7 %. The coefficient analysis revealed that likelihood of dropping out is positively predicted by accountability (b= .17, t= 2.55, p = .01, 95% CI [ .04, .30]), and is negatively predicted by age (b= − .11, t= −3.58, p < .01, 95% CI [−.16, −.05]), self-motivation (b= − .20, t= −2.36, p = .02, 95% CI [−.36, −.03]), health (b= − .14, t= −3.72, p < .01, 95% CI [−.21, −.06]). Overall, participants with a higher level of accountability would be more likely to quit the programme. Meanwhile, older participants may get through many difficulties throughout their lives, which help them develop resilience and continue on the programme. Likewise, self-motivated participants would be more positive and self-encouraged to fulfil the programme. Last, a healthy body provides the essential condition for taking part in the programme and reduces the possibility of dropping out.


## Question 5c

```{r q5c}

mod_5c1 <- lm(lh_quit ~1 + selfmot, new_data)
summary(mod_5c1)

ggplot(data = new_data, aes(x=selfmot, y=lh_quit)) +
  geom_point()+
  geom_smooth(formula = 'y ~ x',method="lm")+
  labs(x = "Self-motivation", 
       y = "Probability of Quitting")


```

I formed a regression model of self-motivation predicting the probability of quitting. The result suggests that the F-test for the overall significance of the regression showed strong evidence to support our model (F (1,116) = 6.05, p = .02), and the model explained approximately 4.14 % of the variability in happiness outcomes. The t-test for the effect of self-motivation on probability of quitting was significant (b = −.22, t = −2.46, p = 0.02). Therefore, self-motivation positively predicted the probability of quitting. Then, I produced a plot based on this relationship, showing that the probability of quitting dropped as self-motivation increased.







