---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
  word_document: default
params:
  examnumber: B173823
---
```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
library(pander)
library(broom)
library(psych) 
library(car) 
library(sjPlot)
library(lattice)
library(robustbase)
# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0

```{r cleaning, include = FALSE}
# Neither output nor code from this chunk will be shown in the compiled document. 
couchto5k$city<-as.factor(couchto5k$city)
couchto5k$missingdata <- NA
couchto5k$missingdata[couchto5k$age>100]<- "Impossible age"
couchto5k$missingdata[couchto5k$selfmot<5]<- "Impossible Self. Mot. score"
couchto5k$missingdata[couchto5k$week_stopped>10]<- "Impossible number of weeks"
mtab<-table(couchto5k$missingdata)
couchto5k<- couchto5k %>% filter(is.na(missingdata))
total<-count(couchto5k)


```
```{r season, include=FALSE}
miscoded <- sum(couchto5k$season=="autunm")
couchto5k$season[couchto5k$season=="autunm"]<-"autumn"
couchto5k$season<-as.factor(couchto5k$season)
```
Data was obtained from https://uoepsy.github.io/data/usmr_2122_data.R: a dataset containing information on 138 participants in two cities, Edinburgh and Glasgow, who started the Couch to 5k programme, an NHS-sponsored fitness programme which lasts 9 weeks, across the course of a year. It includes scores of questionnaires that measured psychometric factors of accountability and self-motivation which were taken during the begging of the programme. Participants were also assessed with questionnaires which included a measure of their self-reported happiness, and a “health” measure derived from a number of physiological tests. For all of these measures, only total scores were available. Items in both the accountability and self-motivation were measured on a 7-point scale, giving minimum and maximum possible scores of 5 and 35 respectively. Likewise, the self-reported happiness and "health" both have score ranges from 0 to 100. 

The data was inspected and missing or unlikely values were removed, resulting in `r total` observations for analysis. Upon further examination, `r miscoded` "Season" entries were initially miss coded as "autunm" and were re coded as "autumn". Table 1 gives a summary of removed data while Table 2 gives a summary of the scores for all questionnaires.


```{r include=FALSE}
mtab2<-describe(couchto5k %>% select(accountability, selfmot, health, happiness))[,c(2:4,8:9)]%>%round(2)
```

```{r results='asis' }
mtab %>% pander(caption="Table 1: Summary of missing values.")
```

```{r results='asis'}
mtab2 %>% pander(caption="Table 2: Descriptive statistics for all questionnaires.")
```


Bivariate correlations showed a strong negative relationship between Age and Health scores; a moderate positive relationship between Happiness scores and Self-Motivation scores; a weak positive relationship between Health scores and Self-Motivation scores, and a weak positive relationship between Health scores and Happiness scores (see Figure 1)

```{r figure, fig.cap="Figure 1:Bivariate scatter plots (below diagonal), histograms (diagonal), and Pearson correlation coefficient (above diagonal), of age and Accountability, Self-Motivation, Happiness and Health scores."}
pairs.panels(couchto5k %>% select(-missingdata, -pptID, -season, -city, -week_stopped))
```


# Question 1 

### Question 1a
```{r include=FALSE}
couchto5k$q1 <- NA
couchto5k$q1[couchto5k$week_stopped<6]<- "Before"
couchto5k$q1[couchto5k$week_stopped==6]<- "After"
couchto5k$q1[couchto5k$week_stopped==7]<- "After"
couchto5k$q1[couchto5k$week_stopped==8]<- "After"
couchto5k$q1[couchto5k$week_stopped==9]<- "Completed"
couchto5k$q1<-as.factor(couchto5k$q1)
couchto5k$q1 <- relevel(couchto5k$q1, "Before")
q1a<-chisq.test(table(couchto5k$q1), p = c(.45,.1,.45))
```

In an earlier nationwide survey, researchers found that 45% of participants abandoned the programme before the halfway point in week 5, and a further 10% gave up before the end of the programme. We performed a $\chi^2$ goodness of fit test to assess the extent to which our sample conform to this theorized distribution of dropouts. Effects were considered statistically significant at $\alpha < 0.05$. 
The hypothesis were as follows:

$H_0: \beta_7 = 0$. There is no difference between the observed and the expected values of dropouts. 

$H_1: \beta_7 \neq 0$.There is a significant difference between the observed and the expected values of dropouts. 


We found that there was no significant deviation from the hypothesized values, $\chi^2$(df=`r chisq.test(table(couchto5k$q1), p = c(.45,.1,.45))$parameter`) = `r chisq.test(table(couchto5k$q1), p = c(.45,.1,.45))$statistic %>% round(2)` , $p$ = `r chisq.test(table(couchto5k$q1), p = c(.45,.1,.45))$p.value %>% round(2)`.  We couldn't reject the null hypothesis, indicating that our observations followed the expected distribution of dropouts.    

### Question 1b

```{r q1b, include=FALSE}
q1b <- couchto5k %>% select(city, q1)%>%table()
q1b
chisq.test(q1b)
```


We also examined whether the patterns of attrition rates differed by city by performing a chi-square test of independence. Effects were considered statistically significant at $\alpha < 0.05$. The hypothesis were as follows: 

$H_0: \beta_7 = 0$. There is no difference between the patterns of attrition rates for each city.  

$H_1: \beta_7 \neq 0$.There is a significant difference between the patterns of attrition rates for each city.

The relation between these variable was not significant, $\chi^2$ (df=`r chisq.test(q1b)$parameter`, $N$ = `r nrow(couchto5k)`) = `r chisq.test(q1b)$statistic %>% round(3)` , $p$ = `r chisq.test(q1b)$p.value %>% round(3)`. Therefor we couldn't reject the null hypothesis, suggesting that knowing about the city does not inform us about the rates of attrition of the program in our data. . Figure 2 shows a mosaic plot of the distribution for both categories. 

```{r figure2, fig.cap="Figure 2: Distribution of frequencies of Rates of Attrition by City."}
mosaicplot(q1b, xlab='City', ylab='Rate of Attrition', main='Rates of Attrition by City', col='orange')
```

### Question 1c

```{r assumption check q1c, include=FALSE}
shapiro.test(couchto5k$age[couchto5k$city=="Edinburgh"])
shapiro.test(couchto5k$age[couchto5k$city=="Glasgow"])
```

We also evaluated whether the average ages of participants who commenced the programme differed by city. Effects were considered statistically significant at $\alpha < 0.05$. Our hypothesis were as follows:

$H_0: \beta_7 = 0$. There is no difference between average ages of participants whom started the programme in Edinburgh compared to the group that started in Glasgow 

$H_1: \beta_7 \neq 0$.There is a difference between average ages of participants whom started the programme in Edinburgh compared to the group that started in Glasgow. 


In order to test this we began exploring if assumptions of normality were maintained by our data. The Shappiro-Wilk test for normality suggested that our assumption of normality was not met for both groups (For Edinburgh: $W$=`r shapiro.test(couchto5k$age[couchto5k$city=="Edinburgh"])$statistic`, $p$=`r shapiro.test(couchto5k$age[couchto5k$city=="Edinburgh"])$p.value %>% round(3) `; for Glasgow: $W$=`r shapiro.test(couchto5k$age[couchto5k$city=="Glasgow"])$statistic`, $p$= `r shapiro.test(couchto5k$age[couchto5k$city=="Glasgow"])$p.value %>% round(3) `). Figure 3 shows a QQ-plot comparing the two probability distributions of ages according to city, and through visual inspection we judged that the even though residuals followed close enough to a normal distribution, we were not confident in using parametric test to evaluate the relationship between both variables. Therefore we decided to conducted the Mann-Whitney U test, a non-parametric test that compares differences between two independent groups. 
```{r results='hide', figure3, fig.cap="Figure 3: QQ-plot displaying age distribution divided by city"}
qplot(sample = age, data = couchto5k, color=city, shape=city)+
    labs(title="Age in years \n according to City",
         y = "Age")
p + theme_classic()
```

The Mann-Whitney U test showed that there was a significant difference ($W$= `r wilcox.test(couchto5k$age ~ couchto5k$city)$statistic`, $p$ = `r wilcox.test(couchto5k$age ~ couchto5k$city)$p.value`) between the average ages from the Edinburgh group compared to the Glasgow group. Our data suggests that the median age was larger for the Edinburgh group (`r median(couchto5k$age[couchto5k$city=="Edinburgh"])` years) compared to median age (`r median(couchto5k$age[couchto5k$city=="Glasgow"])` years) for the Glasgow group.


```{r table}
q1c<-wilcox.test(couchto5k$age ~ couchto5k$city)
pander(q1c, caption="Table 3: Mann-Whitney test of independance")
```



# Question 2

### Question 2a
```{r include=FALSE}
q2a<-lm(happiness~season, data=couchto5k)
plot(q2a)
t2a<-shapiro.test(residuals(q2a))
r2a<-residualPlots(q2a)
n2a<-ncvTest(q2a)
d2a<-dwt(q2a)

```

To investigate if participants Happiness ratings were affected by the season they were interviewed, total scores for Happiness were modeled using a general linear regression using the season category as a predictor. 
The model was fitted to 
$$
\text{Happiness} = \beta_0 + \beta_1 \text{S} + \epsilon  \\
\begin{align}
\text{Where} \\
& \text{S = Season} \\
\end{align}
$$
We considered the hypothesis test that the interaction coefficient is equal to zero, where

$H_0: \beta_7 = 0$. The interaction between Happiness and seasons is equal to zero. 

$H_1: \beta_7 \neq 0$. The interaction between Happiness and seasons is not equal to zero.

We began inspecting our assumptions for the model, and found that the Shapiro-Wilk test indicated evidence against the null hypothesis that the residuals were drawn from a normally distributed population ($W$=`r round(t2a$statistic,2)`, $p$=`r round(t2a$p,3)`). Assumptions for linearity (Figure 4), homoscedasticity (non-constant variance test, $\chi^2(1)$=`r round(n2a$ChiSquare, 2)`, $p$=`r round(n2a$p, 3)`), and independence of errors (Durbin-Watson test for autocorrelation of residuals: $DW$=`r round(d2a$dw,2)`, $p$=`r round(d2a$p,3)`) were sufficiently met.

We then proceeded to plot the residuals and check for potential outliers and we decided to make a judgment call based the plotted Cook’s Distance values (Figure 5) and keep all the observations for the final analysis, since visual inspection of the plot suggested that higher values did not look too influential in relation to the rest of observations, and also based on the fact that excluding observations made other observations appeared as more influential and therfore liable for exclusion as well. We also decided to carry on with our analysis taking into consideration that visual inspection of the QQ-plot of the residuals showed them as following a distribution that was close enough to normal (Figure 6). 

```{r message=FALSE, figure4, fig.cap="Figure 4:Residuals vs Fitted plot"}
crPlots(q2a)
```
```{r figure5, fig.cap= "Figure 5: Plot of Cook's Distance values"}
plot(q2a, which=4)
```
```{r figure6, fig.cap="Figure 6: QQ-plot of residuals of the Happiness model"}
plot(q2a, which=2, title(main="QQ-Plot of residuals", xlab = "Theoretical Quantiles", ylab = "Standardized residuals"))
```

Full regression results including 95% Confidence Intervals are shown in Table 4. Effects were considered statistically significant at $\alpha < 0.05$. 
The F-test for model utility was significant (F(`r summary(q2a)$fstatistic[2]`,`r summary(q2a)$fstatistic[3]`)=`r summary(q2a)$fstatistic[1]`, p<.001), and the model explained approximately `r round(summary(q2a)$adj.r.squared * 100, 1)`% of the variability in Happiness scores. 

Results showed a significant association between Happiness scores and the season in which participants were interviewed. The intercept corresponds to the Autumn season. The first coefficient indicated that when holding all other variables equal, there is an estimated increase of `r coefficients(q2a)[2]%>%round(2)` points on average in the Happiness scale if interviewed during Spring. The next coefficient indicated that there was an estimated increase of `r coefficients(q2a)[3]%>%round(2)` points on average in the Happiness scale if interviewed during Summer, holding all other variables equal. Winter season, however, did not show any significant change in scores. 

```{r tabmodel, echo=FALSE}
tab_model(q2a, dv.labels = c("Happiness"), pred.labels = c("(Intercept)","Spring","Summer","Winter"), title = "Table 4: Regression table for Happiness Scores")
```




### Question 2b
```{r include=FALSE}
q2b<-lm(happiness~season+age, data=couchto5k)
q2b2<-anova(q2b)
```

Accounting for the effects of seasons on Happiness scores, we proceeded to examine if age affected scores as well. We included Age as a predictor to our model and performed an analysis of variance, where we found that age does not significantly improve our ability to explain the data over the null model (F(`r q2b2$Df[2]`,`r q2b2$Df[3]`)= 0.40, $p$=0.53) as shown in Table 5. 

```{r q2b}
pander(q2b2, caption= "Table 5: Type I Sum of Square")
```

### Question 2c
```{r include=FALSE}
couchto5k <- 
  couchto5k %>% 
  mutate(
    zhealth = (health-mean(health))/sd(health)
  )
couchto5k<-couchto5k%>%
  mutate(fin=ifelse(week_stopped==9, 1,0))
couchto5k$fin<-as.factor(couchto5k$fin)
q2c<-lm(happiness~zhealth*fin+season, data=couchto5k)
plot(q2c)
t2c<-shapiro.test(residuals(q2c))
r2c<-residualPlots(q2c)
plot(q2c, which=2)
n2c<-ncvTest(q2c)
d2c<-dwt(q2c)
v2c<-vif(q2c)
q2c2<-Anova(q2c)
```

Since the researchers were interested psychological factors involved in continuing with the programme, and also in the effects of taking the programme on health and wellbeing, we decided to take into account the interaction between Health scores (Z-scored) and Completion of Programme after controlling for the seasons in which participants were interviewed as predictors of Happiness scores. For this, we created an addition variable that mapped whether or not participants finished the Couch to 5k programme. 

We included the interaction because we wanted to explore if full engagement with the program moderated the relationship between Health measures and Happiness scores. We dropped Age as a predictor since we already saw in the previous questions that knowing about it does not improve our ability to explain our data over the null model.

The reason why we used standardized scores was in order to be able to compare these measures in a comprehensible way, since we do not really have enough information about the nature of all the tests in question. Effects will be considered statistically significant at $\alpha = 0.05$. 
The final model took the form of:

$$
\text{Happiness} = \beta_0 + \beta_1 \text{H} \cdot \text{C} +\beta_2 \text{A} +   \epsilon  \\
\begin{align}
\text{Where} \\
& \text{H = Health} \\
& \text{C = Completion of Programme} \\
& \text{S = Season} \\
\end{align}
$$
We inspected the assumptions for our new model and noted that even though linearity (Figure 7), homoscedasticity ($\chi^2(1)$=`r round(n2c$ChiSquare, 2)`, $p$=`r round(n2c$p, 3)`), and independence of errors ($DW$=`r round(d2c$dw,2)`, $p$=`r round(d2c$p,3)`) were sufficiently met, normality of distributions for residuals was not($W$=`r round(t2c$statistic,2)`, $p$=`r round(t2c$p,3)`). Nevertheless, we proceeded with our model based on the same criteria we used for our previous model. 
```{r figure7, message=FALSE, fig.cap="Figure 7: Residual vs Fitted plot"}
tibble(residuals = resid(q2c),fitted = fitted(q2c)) %>%
  ggplot(aes(x=fitted, y=residuals)) +
  geom_point() + 
  geom_smooth(method = "loess", se=FALSE) +
  labs(title = "Residuals vs Fitted", y = "Model residuals", x = "Model fitted values")
```


Full regression results including 95% Confidence Intervals are shown in Table 6. Effects were considered statistically significant at $\alpha < 0.05$. The F-test for model utility was significant (F(`r summary(q2c)$fstatistic[2]`,`r summary(q2c)$fstatistic[3]`)=`r summary(q2c)$fstatistic[1]`, p<.001), and the model explained approximately `r round(summary(q2c)$adj.r.squared * 100, 1)`% of the variability in Happiness scores.


```{r q3a, tabmodel2}
tab_model(q2c, dv.labels = c("Happiness"), pred.labels = c("(Intercept)","Health","Completion of Programme","Spring", "Summer","Winter", "Health:Completion"), title = "Table 6: Regression table for Happiness model. Outcome variable is raw total score on Happiness scale, Health predictors are Z-scored.")

```


# Question 3

### Question 3a

```{r q3a, include=FALSE}
res <- summary(q2c)$coefficients %>% as.data.frame
res[,1:3]<-round(res[,1:3],2)
res[,5] <- ifelse(res[,4]<.01, "<.01",paste0("= ",round(res[,4],3)))
```

We proceeded to analyze if participants’ Happiness ratings were affected by whether or not they completed the programme. Our hypothesis were as follows:

$H_0: \beta_7 = 0$. The effect of Completion of Programme on happiness scores is equal to zero. 

$H_1: \beta_7 \neq 0$.The effect of Completion of Programme on happiness scores is not equal to zero.

Following Table 6, our model showed that we do not have sufficient evidence to reject the null hypothesis, suggesting that Completion of the Programme does not predict changes on Happiness ratings in our data ($\beta$ = `r res[3,1]`,SE = `r res[3,2]`, p `r res[3,5]`) when holding the rest of predictors constant. 

## Question 3b
We then proceeded to assess if the Health metric had any effect on Happiness scores. Effects were considered statistically significant at $\alpha < 0.05$. Our hypothesis were as follow: 

$H_0: \beta_7 = 0$. The effect of Health scores on Happiness scores is equal to zero. 

$H_1: \beta_7 \neq 0$.The effect of Health scores on Happiness scores is not equal to zero.

Following Table 6, results showed no significant conditional association between Happiness scores and Health scores (Z-scored) ($\beta$ = `r res[2,1]`,SE = `r res[2,2]`, p `r res[2,5]`) when holding the other predictors constant, which meant that we do not have evidence to reject the null hypothesis. 

## Question 3c
To address the research question of whether Completion of Programme moderated the effect Health scores on Happiness scores, we considered the hypothesis test that the interaction coefficient is equal to zero, where:

$H_0: \beta_7 = 0$. The interaction between Completion of Programme and Health is equal to zero. 

$H_1: \beta_7 \neq 0$.The interaction between Completion of Programme and Health is not equal to zero.

Effects were be considered statistically significant at $\alpha < 0.05$.
Following Table 6, results showed that the association between Happiness scores and Health scores was found to be dependent upon whether or not participants completed the programme, with a better positive association between the two for those who completed the programme ($\beta$ = `r res[7,1]`,SE = `r res[7,2]`, p `r res[7,5]`), Which means that for every increase of 1 standard deviation in Health scores, the change in Happiness scores associated with Completion of Programme was adjusted by `r res[7,1]` This interaction is visually presented in Figure 8. 

```{r figure8, fig.cap="Figure 8: Predicted Happiness scores across Health scores, for Completion of Programme"}
plot_model(q2c, type="pred", terms = c("zhealth","fin")) +
  labs(x = "Health scores (Z-scored)",
       y = "Happiness scores", colour ="Completion")
```

## Question 3d
In general, the results presented here indicate that, for our sample, the association between happiness and health may depend upon participant's engagement with the fitness programme, where better scores on physiological tests lead to higher scores on self-reported happiness only for those who engaged fully with the Coach to 5k fitness programme. It is also interesting to note that even though the season in which participant was interviewed had and effect on Happiness scores and that such predictor improved our ability to explain some of the variance of the data (F(`r q2c2$Df[3]`,`r q2c2$Df[5]`)= `r q2c2$F[3]`, $p$=0.01), the interaction between completion and health scores explained a bigger portion of the variance in our data (F(`r q2c2$Df[4]`,`r q2c2$Df[5]`)= `r q2c2$F[4]`, $p$<0.001).    


# Question 4
Create a subset of the data, including only those participants who completed the programme. Create a plot of the average happiness ratings grouped by season and city, that can be used in a presentation to the funders of the project.
```{r fig9, fig.cap="Figure 9: Happiness scores in averages of participants that completed the program for each season, divided by City"}
q4<-select(filter(couchto5k, fin == 1),c(happiness,season,city))
ggplot(q4, aes(x = season, y = happiness))+ 
  stat_summary(geom='bar', fun='mean')+
  labs(x="Seasons", y="Average Happiness Scores ")+
  facet_grid(. ~ city)+
  theme_bw()

```


# Question 5

## Question 5a
For this question, we proceeded to build a model that could describe the likelihood of dropping out of the programme. For that, we tested different variables that could predict the probability of completion for our data, and chose Season, Self Motivation scores, Health scores and Age as predictors for our model. 

```{r include=FALSE }
q5a<-glm(fin~season+selfmot+age+health, data=couchto5k, family="binomial")
q5b<-anova(q5a, test="Chisq")
```
```{r table7 }
tab_model(q5a, transform = NULL, dv.labels = c("Completion"), pred.labels = c("Intercept", "Spring", "Summer", "Winter", "Self Motivation", "Age", "Health"), title = "Table 7: Logistic Regression Model for Programme Completion.")
```

## Question 5b
In our model (Table 7), we saw that Spring, Self Motivation scores, Age and Health Scores showed  statistically significant associations with predicting completion of the programme . Finishing the program during spring increased the log odds by `r q5a$coefficients[2]%>% round(2)` holding the other variables constant; a unit increase in Self Motivation increased the log odds by `r q5a$coefficients[5]`, holding the rest constant; a unit increase in Age increased the log odds by `r q5a$coefficients[6]%>% round(2)`, holding other variables constant; and finally, a unit increase in Health scores increased the log odds by `r q5a$coefficients[7]%>% round(2)`, holding the other variables constant. The Anova table (Table 8) showed the difference between the null deviance and the residual deviance, which we can use to evaluate how our model is doing against the null model. Analyzing it, we saw a drop in deviance for each variable, with Season reducing the most residual deviance by `r q5b$Deviance[2]%>% round(2)`. The rest of the variables contributed to to reduce the residual deviance by marginal amounts. Furthermore, even though age had a significant association with predicting completion, Anova table shows that it did not help explain changes in residual deviance (p=0.16). 


```{r q5b}
pander(q5b, caption="Table 8: Analysis of Deviance Table")
```

## Question 5c
```{r include=FALSE}
couchto5k<-couchto5k%>%
  mutate(fin2=ifelse(week_stopped==9, 1,0))
```

We plotted a graph that represents the probability of quitting as a function of how self motivated participants were at the beginning of the programme. The variable, however, was not an likely predictor of dropping out from the programme by itself, only as a predictor in our previous model. Nevertheless, we show the plot recognizing that it didn't seem to follow a sigmoidal shape, since our dependent variable was not logistically related to the outcome. 
```{r figure10, message=FALSE, fig.cap="Figure 10: Plot of the probability of quitting as a function of Self Motivation. Zero (y axis) represents quitting the programme."}
couchto5k %>% ggplot(aes(x=selfmot,y=fin2)) +
    labs(x="Self Motivation", y="Completion (probability)") +
    geom_jitter(size=3,width=0,height=.08,alpha=.1) +
    geom_smooth(method="glm",method.args=list(family=binomial)) +
    scale_y_continuous(breaks=seq(0,1,by=.2))+
  theme_bw()
```










