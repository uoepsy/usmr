---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
params:
  examnumber: B119417
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
library(gridExtra)
library(car)
library(psych)
library(pander)
library(broom)
library(summarytools)
library(sjPlot)
# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0
<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->


```{r cleaning, include = FALSE}
# Neither output nor code from this chunk will be shown in the compiled document. 
summary(couchto5k)

couchto5k$missing <- NA
couchto5k$missing[couchto5k$age>100] <- "Unlikely age (x > 100)"
couchto5k$missing[couchto5k$selfmot<5] <- "Impossible self motivation score (x < 5)"
couchto5k$missing[couchto5k$week_stopped>9] <- "Impossible value of week stopped (x > 9)"

missing_table <- table(couchto5k$missing)
couchto5k <- couchto5k %>% filter(is.na(missing))
total <- count(couchto5k)
```

Data was inspected and unlikely and impossible values were removed, resulting in `r total` observations. Table 1 provides a summary of the removed data.


```{r Table 1, results="asis"}
missing_table %>% pander(caption = "Table 1. Summary of unlikely or impossible values.")
```

```{r data cleaning, include=FALSE}
miscoded <- sum(couchto5k$season == "autunm")

couchto5k <- couchto5k %>% mutate(
  age = as.numeric(age),
  selfmot = as.numeric(selfmot),
  season = ifelse(season == "autunm", "autumn", season),
  season = as.factor(season),
  city = as.factor(city),
  week_stopped = as.numeric(week_stopped)
)

summary(couchto5k)
```

`r miscoded` season entries were initially misentered as "autunm" and they were re-coded as "autumn". 


```{r descriptives, include=FALSE}
# Code will not be shown from this chunk (because we set echo = FALSE in the very first chunk)


age_plot <- ggplot(data = couchto5k, aes(x = age)) +
  geom_density() +
  labs( x = "Age", y = "Density", title = "Distribution of the participants' age") +
  theme_minimal()


week_plot <- ggplot(data = couchto5k, aes(x = week_stopped)) +
  geom_bar() +
  labs( x = "Final Week of the Programme", y = "Count") +
   scale_x_continuous(breaks=1:9) + 
  theme_minimal()

season_plot <- ggplot(data = couchto5k, aes(x = season)) +
  geom_bar() +
  labs( x = "Season", y = "Count") +
  theme_minimal()

city_plot <- ggplot(data = couchto5k, aes(x = city)) +
  geom_bar() +
  labs( x = "City", y = "Count") +
  theme_minimal()

accountability_plot <- ggplot(data = couchto5k, aes(x = accountability)) +
                        geom_density()+
                        geom_boxplot(width = 1/100) +
                        labs(x="Accountability", y = "Density", title = "Distribution of Accountability Scores") +
                        theme_minimal()

selfmot_plot <- ggplot(data = couchto5k, aes(x = selfmot)) +
                geom_density() +
                geom_boxplot(width = 1/100) +
                labs(x = "Self Motivation", y = "Density", title = "Distribution of Self Motivation Scores") +
                theme_minimal()

health_plot <- ggplot(data = couchto5k, aes(x = health)) +
                geom_density() +
                geom_boxplot(width = 1/100) +
                labs(x = "Health", y = "Density", title = "Distribution of Health Scores") +
                theme_minimal()

happiness_plot <- ggplot(data = couchto5k, aes(x = happiness)) +
                geom_density() +
                geom_boxplot(width = 1/400) +
                labs(x = "Happiness", y = "Density", title = "Distribution of Happiness Scores") +
                theme_minimal()


grid.arrange(age_plot, week_plot, ncol = 2)
grid.arrange(accountability_plot, selfmot_plot,ncol = 2)
grid.arrange(health_plot, happiness_plot, ncol = 2)

```

Descriptive statistics for the variables of accountability, age, health and self-motivation are privided in Table 2.
Figure 1 shows the distribution of the happiness variable and Figure 2 shows the frequencies of the week in which participants stopped the programme, the season and the city in which they participated in the programme.
```{r, results='asis'}
numerical_var <- couchto5k[, c(2,3,4,5)]
pander(descr(numerical_var, 
      headings = F,
      stats = c("mean", "sd", "min", "max"),
      transpose = T), caption = "Descriptive Statistics")

happiness_plot

# categorical_vars <- couchto5k 
# categorical_vars$week_stopped <- as.factor(categorical_vars$week_stopped)

# freq(c(categorical_vars$season),
#      report.nas = F,
#      totals = F,
#      cumul = F,
#      headings = F)

grid.arrange(week_plot, season_plot, city_plot, ncol = 3)

```

Table 3 shows the correlation matrix of the numerical variables of interest.

```{r descriptives - continued, results = "asis"}

#relationship between variables
couchto5k %>% select(accountability, selfmot, health, happiness, week_stopped) %>% cor() %>% pander(caption = "Table 3. Correlation matrix")


```

# Question 1 

## Question 1a

```{r q1a, include=FALSE}
couchto5k <- couchto5k %>% mutate(week_category =
                       as.factor(case_when(week_stopped < 5 ~ "before_w5",
                                 week_stopped >= 5 & week_stopped < 9 ~ "after_w5",
                                 week_stopped == 9 ~ "completed"))
)

couchto5k$week_category <- factor(couchto5k$week_category, levels = c("before_w5", "after_w5", "completed"))

table(couchto5k$week_category)
chiq1a <- chisq.test(table(couchto5k$week_category), p = c(0.45, 0.10, 0.45))
chiq1a
```
A chi-square goodness of fit test was performed to investigate whether the data from the current sample was in line with an earlier nationwide survey where 45% of the participants abandoned the programme before week 5 and a further 10% abandoned before week 9. Results were not significant (χ2(`r chiq1a$parameter`) = `r chiq1a$statistic`, p = `r chiq1a$p.value`) therefore we cannot reject the null that the proportions of participants in each category (dropped before week 5, dropped between week 5 and week 9, completed the programme) do not differ between surveys. 

Figure 3 shows the observed proportions of participants in the three categories.

```{r}
proportion_table <- prop.table(table(couchto5k$week_category))*100
barplot(proportion_table, xlab = "Week in which Participants Stopped the Programme", ylab = "Proportion of Participants")
```

## Question 1b

```{r q1b, include =FALSE}
chiq1b <-chisq.test(table(couchto5k$week_category, couchto5k$city))
chiq1b
```
A Chi-squared test was performed in order to investigate whether the pattern of attrition rates differed between Edinburgh and Glasgow. Figure 4 shows the proportion of participants who dropped out before week 5, between week 5 and week 9 and who completed the programme, by city. Results were not significant (χ2(2) = `r chiq1b$statistic`, p = `r chiq1b$p.value` ) therefore we cannot reject the null that attrition rates are equal between cities.

```{r }
plot(table(couchto5k$week_category, couchto5k$city), main = "Attrition Rates by City")
```


## Question 1c
Figure 5 shows the participants' age by city.

```{r }
ggplot(data = couchto5k, aes(x = age, y = city)) +
  geom_boxplot() +
  labs(x = "Age", y = "City", title = "Participant's Age by City") +
  theme_minimal()
```


```{r q1c, include=FALSE}

shapiro.test(couchto5k$age[couchto5k$city == "Edinburgh"]) #indicates violation of normality
shapiro.test(couchto5k$age[couchto5k$city == "Glasgow"]) #indicates violation of normality

hist(couchto5k$age[couchto5k$city == "Edinburgh"]) #indicates violation of normality
hist(couchto5k$age[couchto5k$city == "Glasgow"]) #indicates violation of normality

#Running a linear model predicting age from city

contrasts(couchto5k$city)
mod1c <- lm(age ~ 1 + city, data = couchto5k)

# Checking that assumptions are met

#Linearity
plot(mod1c, which = 1)

#Equal variance
residualPlots(mod1c)
breusch_mod1c <- ncvTest(mod1c)
breusch_mod1c

#Independence
durbin_mod1c <- dwt(mod1c)
durbin_mod1c

#Normality of errors
plot(mod1c, which = 2)
shapiro_mod1c <- shapiro.test(residuals(mod1c))
shapiro_mod1c

#Observations with high influence
plot(mod1c, which = c(4,5))


summary(mod1c)

```

A linear model was run predicting the participants' age from city in order to investigate whether the average age of the participants commencing the programme differed by city. Results will be considered statistically significant at α=0.05. The model is summarised in Table 4. 

```{r model 1c summary, results='asis'}
pander(mod1c, caption = "Table 4. Linear Model predicting Age from City")
descr_mod1c <- tidy(mod1c)
```

The overall regression was not statistically significant (R2 = .005, F(1,115) = .565, p > .05). Results suggest there was no statistically significant difference between the mean age of participants in Edinburgh compared to Glasgow (p = `r descr_mod1c$p.value[2]`).

The linear model met the assumptions. Visual inspection suggests that the average residual approximates 0 across fitted values, suggesting that the assumption of linearity is met. Visual inspection of the QQ-plot of residuals suggests that residuals follow close to a normal distribution, despite the Shapiro-Wilk test yielding significant results which would lead us to reject the null that residuals are normally distributed (W = `r shapiro_mod1c$statistic`, p = `r shapiro_mod1c$p.value`). The Breusch-Pagan test failed to reject the null that error variance does not change across the fitted values (χ2(`r breusch_mod1c$Df`)=`r breusch_mod1c$ChiSquare`, p= `r breusch_mod1c$p`) and visual inspection of the residuals plot does not show non linear trends, suggesting that the assumption of homogeneity of variance is met. A Durbin-Watson test failed to reject the null hypothesis that there is no serial dependence in the error (DW = `r durbin_mod1c$dw`, p = `r durbin_mod1c$p`). Finally, visual inspection of a plot of Cook's distance values suggests that there are no overly influential points.

# Question 2

## Question 2a

Figure 6 shows the relationship between season and happiness scores.
```{r }
ggplot(data = couchto5k, aes(x = season, y = happiness)) +
  geom_boxplot() +
  labs(x = "Season", y = "Happiness") +
  theme_minimal()

```

```{r q2a, include=FALSE}
contrasts(couchto5k$season)

#setting winter as the reference level
couchto5k <- couchto5k %>% mutate(season = relevel(season, ref = "winter"))

#running the model
mod2a <- lm(happiness ~ 1 + season, data = couchto5k)


#Checking model assumptions:

#Linearity
plot(mod2a, which = 1)

#Equal variance
residualPlots(mod2a)
breusch_mod2a <- ncvTest(mod2a) 
breusch_mod2a

#Normality of errors
plot(mod2a, which = 2)

#Independence
durbin_mod2a <- dwt(mod2a) #p = .78
durbin_mod2a

#Observations with high influence
plot(mod2a, which = c(4,5))

cooks_mod2a <- cooks.distance(mod2a)[c(41, 62)]

mod2a2 <- lm(happiness ~ 1 + season, data = couchto5k[-c(41,62),])
plot(mod2a2)
plot(mod2a2, which = c(4,5))


summary(mod2a)
summary(mod2a2)
```
A linear regression model was used to investigate whether season significantly predicted the participants' happiness scores. The model is summarised in Table 5. 

```{r Model 2a Summary, results='asis'}
pander(mod2a, caption = "Model Predicting Happiness from Season")
descr_mod2a <- tidy(mod2a)
```

The overall model was statistically significant (R2 = .085, F(3,113) = 3.48, p = .018). Results show that, compared to the average happiness score of participants that participated in the programme in winter, participants who participated in spring scored on average `r descr_mod2a$estimate[3]`  higher on the happiness measure. Moreover, compared to the average happiness score of participants that participated in the programme in winter, participants who participated in summer scored on average `r descr_mod2a$estimate[4]` higher on the happiness measure. Finally, people who participated in the programme in autumn scored on average `r descr_mod2a$estimate[2]` higher on the happiness scale compared to the average happiness score of participants that participated in the programme in winter, however this difference was not statistically significant.

The linear regression model met the parametric assumptions. Visual inspection suggests that the average residual approximates 0 across fitted values, suggesting that the assumption of linearity is met. Visual inspection of the QQ-plot of residuals suggests that residuals follow close to a normal distribution, although it provides some evidence of heavier tails. The Breusch-Pagan test failed to reject the null hypothesis that error variance does not change across the fitted values (χ2(`r breusch_mod2a$Df`)=`r breusch_mod2a$ChiSquare`, p= `r breusch_mod2a$p`) and visual inspection of the residuals plot does not show non linear trends, suggesting that the assumption of homogeneity of variance is met. The Durbin-Watson test failed to reject the null hypothesis that there is no serial dependence in the error (DW = `r durbin_mod2a$dw`, p = `r durbin_mod2a$p`). A further linear regression was run excluding two observations which might have been overly influential (Cook's D = `r cooks_mod2a[1]`, Cook's D = `r cooks_mod2a[2]`), however the results did not substantially change from the original model, therefore they are not reported here.

## Question 2b

```{r q2b, include=FALSE}

mod2b <- lm(happiness ~ 1 + season + age, data = couchto5k)

#Checking model assumptions:

#Linearity
crPlots(mod2b)
plot(mod2b, which = 1)

#Equal variance
residualPlots(mod2b)
breusch_mod2b <- ncvTest(mod2b) 
breusch_mod2b

#Normality of errors
plot(mod2b, which = 2)

#Independence
durbin_mod2b <- dwt(mod2b) 
durbin_mod2b

#multicollinearity
vif(mod2b)

#Observations with high influence
plot(mod2b, which = c(4,5))

cooks_mod2b <- cooks.distance(mod2b)[c(41, 62)]
cooks_mod2b
mod2b2 <- lm(happiness ~ 1 + season + age, data = couchto5k[-c(41,62),])
summary(mod2b2)

```
A further regression model was run to investigate whether happiness ratings were affected by the participants' age, controlling for the season in which participants took part in the programme. The model is summarised in Table 6.

```{r Model 2b Summary, results='asis'}
pander(mod2b, caption = "Table 6. Model Predicting Happiness from Season and Age")
descr_mod2b <- tidy(mod2b)
```
The overall model was significant (R2 = .085, F(4,112) = 2.58, p = .041). The results show that, after controlling for the season in which participants took part in the programme, age is not a statistically significant predictor of happiness (p > .05), suggesting that, after controlling for season, happiness ratings are not significantly affected by age.

Visual inspection of the component-residual plots did not highlight deviations from linearity. Partial residuals plots did not show non-linear trends between residuals and predictors and the Breusch-Pagan test failed to reject the null hypothesis that error variance does not change across the fitted values (χ2(`r breusch_mod2b$Df`)=`r breusch_mod2b$ChiSquare`, p= `r breusch_mod2b$p`); this suggests that the assumption of constant variance is met. The Q-Q plot of the residuals showed that they follow close to a normal distribution, despite being slightly light tailed. The Durbin-Watson test failed to reject the null hypothesis that there is no autocorrelation in the error terms (DW = `r durbin_mod2b$dw`, p = `r durbin_mod2b$p`), suggesting that the assumption of independence is met. Variance Inflation Factor (VIF) values (< 5) suggested that multicollinearity is not adversely affecting model estimates. As for the previous regression model, a further multiple regression was fitted excluding two observations which were judged to potentially be overly influential (Cook's Distance = `r cooks_mod2b[1]`, Cook's Distance = `r cooks_mod2b[2]`); results did not substantially change compared to the original model therefore they were not reported here.

Figure 7 shows the relationship between happiness scores and age by season.
```{r message=FALSE}
ggplot(data = couchto5k, aes( x = age, y = happiness, colour = season)) +
  geom_point(color = "grey") +
  geom_smooth(method = "lm") +
  theme_minimal()
```

## Question 2c

```{r q2c_continued, include=FALSE}
q2c_anova <- tidy(anova(mod2b))
q2c_anova
```

An analysis of variance was conducted to investigate whether the model predicting happiness from season and age significantly explains more of the variance in happiness scores compared to a model including season as the only predictor. Results are summarised in Table 7. The results suggests that adding age as a predictor does not explain any additional variance compared to a model predicting happiness from season alone (p = `r q2c_anova$p.value[2]`). The baseline model that is selected for further analyses is therefore a model that includes season, but not age, as a predictor variable of happiness.

```{r q2c, results='asis'}
pander(anova(mod2b), caption = "Table 7. Analysis of Variance Table")
```


# Question 3

## Question 3a

```{r q3a, include = F}
couchto5k <- couchto5k %>% mutate(
  completion = as.factor(ifelse(couchto5k$week_category == "completed", "completed", "uncompleted"))
)

couchto5k <- couchto5k %>% mutate(completion = relevel(completion, ref = "uncompleted"))
contrasts(couchto5k$completion)

mod3a <- lm(happiness ~ 1 + season + completion, data = couchto5k)

#Checking assumptions

#linearity
crPlots(mod3a)
plot(mod3a, which = 1)

#equal variances
residualPlots(mod3a)
breusch_mod3a <- ncvTest(mod3a) 
breusch_mod3a

#normality 
plot(mod3a, which = 2)

#independence
durbin_mod3a <- dwt(mod3a) 
durbin_mod3a

#multicollinearity
vif(mod3a)

#Observations with high influence
plot(mod3a, which = c(4,5))
cooks_mod3a <- cooks.distance(mod3a)[41]

mod3a2 <- lm(happiness ~ 1 + season + completion, data = couchto5k[-c(41),])
summary(mod3a2)
summary(mod3a)

```
A further model was run to investigate whether the participants' happiness scores were affected by whether or not the participants completed the programme, controlling for season. The results of the model are summarised in Table 8.

```{r model 3a summary, results='asis'}
pander(mod3a, caption = "Table 8. Linear Model predicting Happiness from Season and Programme Completion")
descr_mod3a <- tidy(mod3a)
```

The overall model was statistically significant (R2 = 0.0977, F(4,112) = 3.03, p = 0.0205). Results suggest that, after controlling for the season in which the participants took part in the programme, the happiness scores of the participants that did not complete the programme did not significantly differ from those of participants that completed it (b = `r descr_mod3a$estimate[5]`, p > .05). This finding suggests that programme completion did not have a significant effect on the participants' happiness scores, after controlling for season.

The multiple regression model met the parametric assumptions. Visual inspection suggests that the average residual approximates 0 across fitted values, suggesting that the assumption of linearity is met. Visual inspection of the Q-Q plot of residuals suggests that residuals follow close to a normal distribution, although it provides some evidence of heavier tails. The Breusch-Pagan test failed to reject the null hypothesis that error variance does not change across the fitted values (χ2(`r breusch_mod3a$Df`)=`r breusch_mod3a$ChiSquare`, p= `r breusch_mod3a$p`) and visual inspection of the partial residual plots does not show non-linear trends between residuals and predictors, suggesting that the assumption of homogeneity of variance is met. The Durbin-Watson test failed to reject the null hypothesis that there is no autocorrelation in the error terms (DW = `r durbin_mod3a$dw`, p = `r durbin_mod3a$p`). VIF values (< 5) suggested that multicollinearity is not adversely affecting model estimates. Finally, visual inspection of a plot of Cook's Distance values suggested that one observation might have been overly influential (Cook's Distance = `r cooks_mod3a`) therefore the model was fitted again excluding this observation. Results of the regression model excluding this observation did not substantially differ from those of the first model therefore they are not reported here.

## Question 3b

```{r q3b, include = F}
mod3b <- lm(happiness ~ 1 + season + completion + I(health-mean(health)), data = couchto5k)

#Checking assumptions

#linearity
plot(mod3b, which = 1)

#equal variances
residualPlots(mod3b)
breusch_mod3b <- ncvTest(mod3b) # p = .9
breusch_mod3b

#normality 
plot(mod3b, which = 2)

#independence
durbin_mod3b <- dwt(mod3b) # p = .738
durbin_mod3b

#multicollinearity
vif(mod3b)


#Observations with high influence
plot(mod3b, which = c(4,5))
cooks_mod3b <- cooks.distance(mod3b)[41] #D = 0.183


mod3b2 <- lm(happiness ~ 1 + season + completion + I(health - mean(health)), data = couchto5k[-41,])

summary(mod3b)
summary(mod3b2)
```


A multiple linear regression was run predicting happiness scores from season, from programme completion (that is whether the participants completed the programme or not) and from the participants' health scores, which were mean-centered. This analysis was run in order to investigate whether happiness scores were affected by the participants' scores on the health metric, while controlling for season and programme completion. The model is summarised in Table 9.

```{r model 3b summary, results='asis'}
pander(mod3b, caption = "Table 9. Linear Model predicting Happiness from Season, Programme Completion and Health.")
descr_mod3b <- tidy(mod3b)
```

The overall model was statistically significant (R2 = .0999, F(5,111) = 2.46, p = .0372). Results show that, after controlling for season and programme completion, the participants' health scores did not significantly predict happiness scores (b = `r descr_mod3b$estimate[6]`, p > .05). 

The Component-residual plots did not highlight deviations from linearity, suggesting that the linearity assumption is met. Partial residual plots do not show clear non-linear trends between residuals and predictors and the Breusch-Pagan test failed to reject the null hypothesis that error variance does not change across the fitted values (χ2(`r breusch_mod3b$df`) = `r breusch_mod3b$ChiSquare`, p = `r breusch_mod3b$p`). The Q-Q plot of residuals shows that residuals follow close to a normal distribution, although with evidence of heavier tails. The Durbin-Watson test failed to reject the null hypothesis that there is no autocorrelation in the error terms (DW = `r durbin_mod3b$dw`, p = `r durbin_mod3b$p`). VIF values (< 5) suggested that multicollinearity is not adversely affecting model estimates. Visual inspection of the plot of Cook's Distance values suggests that one observation might be overly influential (Cook's Distance = `r cooks_mod3b`); a model was therefore run excluding this observation from the dataset. Results of the regression model excluding this observation did not substantially differ from those of the first model therefore they are not reported here.


## Question 3c

```{r q3c, include=FALSE}

mod3c <- lm(happiness ~ 1 + season + completion*I(health - mean(health)), data = couchto5k)

#Checking assumptions

#linearity 
plot(mod3c, which = 1)

#equal variances
residualPlots(mod3c)
breusch_mod3c <- ncvTest(mod3c) # p = .9
breusch_mod3c

#normality 
plot(mod3c, which = 2)
shapiro.test(residuals(mod3c)) 

#independence
durbin_mod3c <- dwt(mod3c) 
durbin_mod3c

#multicollinearity
vif(mod3c)

#Observations with high influence
plot(mod3c, which = c(4,5))
cooks.distance(mod3c)[41] #D = .29


mod3c2 <- lm(happiness ~ 1 + season + completion*I(health - mean(health)), data = couchto5k[-41,])

#Checking assumptions

#linearity 
plot(mod3c2, which = 1)

#equal variances
residualPlots(mod3c2)
breusch_mod3c2 <- ncvTest(mod3c2) 
breusch_mod3c2

#normality 
plot(mod3c2, which = 2)
shapiro_mod3c2 <- shapiro.test(residuals(mod3c2)) 

#independence
durbin_mod3c2 <- dwt(mod3c2) 
durbin_mod3c2

#multicollinearity
vif(mod3c2)

#Observations with high influence
plot(mod3c2, which = c(4,5))

summary(mod3c2)
```

A multiple linear regression was conducted in order to investigate whether the effect of the health metric on the happiness scores was dependent upon whether the participants completed the programme or not, while controlling for season. The health variable was mean centered, this reduces multicollinearity due to the correlation between the individual predictors and the interaction between those predictors. One observation was excluded from the final analysis as it was judged to be too influential on the model (Cook's Distance = .29), as shown by the plots of Cook's Distance values in Figure 8. The results of the model are summarised in Table 10.

```{r}
plot(mod3c, which = 4)
```


```{r model 3c2 summary, results='asis'}
pander(mod3c2, caption = "Table 10. Linear Model predicting Happiness from Season, Programme Completion, Health and the interaction between Programme Completion and Health.")
descr_mod3c2 <- tidy(mod3c2)
```

The overall model was statistically significant (R2 = .241, F(6,109) = 5.76, p < .05). Results suggest that, after controlling for season, the happiness scores of people that completed the programme were differentially affected by the health metric compared to those of people that did not complete the programme (b = `r descr_mod3c2$estimate[7]`, p = `r descr_mod3c2$p.value[7]`). Figure 8 illustrates the relationship between health scores and happiness scores for participants that completed the programme and for those who did not complete the programme. Figure 9 shows that, for participants who completed the programme, higher health scores were associated with higher scores on the happiness measure. On the other hand, for participants who did not complete the programme, higher health scores were associated with lower happiness scores. These findings suggest that health has a more positive effect on happiness for participants who completed the programme, as opposed to participants who did not complete the programme.

```{r q3c interaction visualisation, message=FALSE}

ggplot(couchto5k) +
  aes(x = health, y = happiness, color = completion) +
  geom_point(color = "grey") +
  geom_smooth(method = "lm")
```


The final model met the parametric assumptions. As shown in Figure 10, visual inspection suggests that the average residual approximates 0 across fitted values, suggesting that the assumption of linearity is met. 

```{r model 3c2 linearity}
#linearity 
plot(mod3c2, which = 1, )

```

As shown in Figure 11, partial residuals plots did not show non-linear trends between residuals and predictors and the Breusch-Pagan test failed to reject the null hypothesis that error variance does not change across the fitted values (χ2(`r breusch_mod3c2$df`) = `r breusch_mod3c2$ChiSquare`, p = `r breusch_mod3c2$p`), suggesting that the assumption of constant variance is met. 

```{r model 3c2 equal variance}
#equal variances
residualPlots(mod3c2)

```

As shown in Figure 12, Q-Q plot of residuals shows that residuals follow a normal distribution, although it provides evidence of heavier tails. Moreover, the Shapiro-Wilks test failed to reject the null hypothesis that residuals were sampled from a normally distributed population (W = `r shapiro_mod3c2$statistic `, p = `r shapiro_mod3c2$p.value`), suggesting that the assumption of normality of residuals is met. 

```{r model 3c2 normality}
#normality 
plot(mod3c2, which = 2)

```

The Durbin-Watson test failed to reject the null hypothesis that there is no autocorrelation in the error terms (D-W = `r durbin_mod3c2$dw`, p = `r durbin_mod3c2$p`), suggesting that the assumption of independence of errors is met. Moreover, VIF values < 5 suggest that model estimates are not adversely affected by multicollinearity. Finally, plots of Cook's Distance values, shown in Figure 13 and Figure 14, show that there is not a small number of observations with exceptionally high values of Cook's D relative to the others, suggesting that there are no overly influential observations.

```{r model 3c2 influence}
#Observations with high influence
plot(mod3c2, which = c(4,5))

```


## Question 3d
To conclude, results of the multiple regression analysis showed that, after controlling for the season in which participants took part in the Couch to 5k programme, a significant conditional effect of health was found such that, for participants who did not complete the programme, a 1 unit increase in the health score was associated with a decrease of `r descr_mod3c2$estimate[6]` in happiness scores (b = `r descr_mod3c2$estimate[6]`, p = `r descr_mod3c2$p.value[6]`). Importantly, the association between health and happiness was found to be dependent on whether or not the participants completed the programme: in people who completed the programme, 
greater health scores were found to be associated with greater happiness scores (b = `r descr_mod3c2$estimate[7]`, p = `r descr_mod3c2$p.value[7]`).


# Question 4


```{r q4, results='asis'}
#create subset with only participants that completed the programme
programme_completed <- couchto5k[couchto5k$completion == "completed",]

#create plot of average happiness grouped by season and city
ggplot(data = programme_completed, aes(x = season, y = happiness, fill = city)) +
  geom_bar(stat = "summary", fun = "mean", position = "dodge") +
  labs(title = "Average Happiness Grouped By Season and City") +
  theme_minimal()

edi_spring <- mean(programme_completed[programme_completed$season == "spring" & programme_completed$city == "Edinburgh",]$happiness)

glas_winter <- mean(programme_completed[programme_completed$season == "winter" & programme_completed$city == "Glasgow",]$happiness)

glas_autumn <- mean(programme_completed[programme_completed$season == "autumn" & programme_completed$city == "Glasgow",]$happiness)

edi_autumn <- mean(programme_completed[programme_completed$season == "autumn" & programme_completed$city == "Edinburgh",]$happiness)
```
Figure 15 shows the average happiness scores of participants that completed the Couch to 5k programme by season and city (Edinburgh or Glasgow). The graph shows that the highest average happiness score was the one of participants who completed the programme in Edinburgh in the spring (y = `r edi_spring`); on the other hand, the lowest average happiness score was that of participants who completed the programme in Glasgow in winter (y = `r glas_winter`). Moreover, the average happiness scores were higher for participants in Edinburgh in all seasons apart from autumn, when the average happiness score was higher for participants in Glasgow (y = `r glas_autumn`) compared to those in Edinburgh (y = `r edi_autumn`).

# Question 5

## Question 5a
Figure 16 shows the relationship between programme completion and the two variables of accountability and self motivation.

```{r q5a visualisation}

account_completion_plot <- ggplot(data = couchto5k, aes(x = accountability, y = completion)) +
  geom_jitter() +
  labs(x = "Accountability", y = "Programme Completion", main = "Relationship between Programme Completion and Accountability")

selfmot_completion_plot <- ggplot(data = couchto5k, aes(x = selfmot, y = completion)) +
  geom_jitter() +
  labs(x = "Self Motivation", y = "Programme Completion", main = "Relationship between Programme Completion and Self Motivation")

grid.arrange(account_completion_plot, selfmot_completion_plot,ncol = 2)
```


```{r q5a, include=FALSE}

#Predicting programme completion from self motivation and accountability
contrasts(couchto5k$completion)
couchto5k <- couchto5k %>% mutate(
  completion = relevel(completion, ref = "completed"))

contrasts(couchto5k$completion)

mod5a <- glm(completion ~ selfmot + accountability, family = binomial, data = couchto5k)
summary(mod5a) #the probability of dropping out decreases as self motivation increases 
descr_mod5a <- tidy(mod5a)
descr_mod5a

#Model evaluation
evaluation_mod5a <- anova(mod5a, test = "Chisq")
#Adding Self motivation, but not Accountability to the model helps us explain more of the deviance compared to the reduced model.
p_selfmot <- evaluation_mod5a$`Pr(>Chi)`[2]
p_acc <- evaluation_mod5a$`Pr(>Chi)`[3]

#Predicting drop out from self motivation
mod5a2 <- glm(completion ~ selfmot, family = binomial, data = couchto5k)
summary(mod5a2)
#the probability of dropping out decreases as self motivation increases


```

Whether the participants completed the programme or not was modelled using logistic regression, with accountability and self motivation as predictors. The results of the model found that, controlling for accountability, self motivation significantly predicted programme drop out (b = `r descr_mod5a$estimate[2]`, p = `r descr_mod5a$p.value[2]`). On the other hand, accountability was not found to be a significant predictor of programme drop out (b = `r descr_mod5a$estimate[3]`, p = `r descr_mod5a$p.value[3]`). Analysis of deviance showed that including self motivation as a predictor of programme drop out helps explain significantly more deviance compared to the null model (p = `r p_selfmot `). On the other hand, accountability as a predictor did not help explain more of the deviance compared to the reduced model including only self motivation as the predictor variable (p = `r p_acc`). The final model that was selected therefore only included self motivation as a predictor variable of programme drop out. The final model is summarised in Table 11.

```{r, results='asis'}
pander(mod5a2, caption = "Table 11. Logistic Regression Predicting Programme Drop Out from Self Motivation")
```


## Question 5b

```{r q5b, include=FALSE}
odds_selfmot <- exp(coef(mod5a2))[2]
#for every unit increase in self motivation, the odds of dropping out decreased by a factor of.855.

couchto5k <- couchto5k %>% mutate(
  completion = ifelse(completion == "uncompleted", 1,0)
)
guess <- predict(mod5a2)
guess <- ifelse(guess>0,1,0)
hits <- sum(guess == couchto5k$completion)
hits/length(couchto5k$completion)
accuracy <- hits/length(couchto5k$completion) *100
```
Results of the logistic regression showed that, for people with 0 self motivation, the odds of dropping out are `r exp(coef(mod5a2))[1]`. Self motivation was found to be a significant predictor of programme drop out: for every unit increase in self motivation, the odds of dropping out decreased by a factor of `r odds_selfmot`. The present model correctly predicts `r accuracy`% of the observations.

## Question 5c

Figure 17 shows the probability of dropping out of the programme as a function of self motivation. The graph shows that, as self motivation increases, the probability of programme drop out decreases.

```{r q5c, message=FALSE}

couchto5k %>% ggplot(aes(x = selfmot, y = completion)) +
  labs(y = " Probability of Programme Drop Out", x = "Self Motivation", main = "Relationship between Self Motivation and Probability of Programme Drop Out") +
  geom_jitter(size = 3, width = 0, height = .2, alpha = .1) +
  geom_smooth(method = "glm", method.args = list(family = binomial)) +
  scale_y_continuous(breaks = seq(0,1, by =.2))
```













