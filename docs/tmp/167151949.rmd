---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
  pdf_document: default
params:
  examnumber: "197710"
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=2)
# load any other packages that you require here:
library(tidyverse)
library(pander)
library(broom)
library(sjPlot)
library(interactions)
library(psych)
library(standardize)
library(lsr)
# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0

```{r 0, include = FALSE}
summary(couchto5k)
hist(couchto5k$age)
hist(couchto5k$selfmot)
hist(couchto5k$week_stopped)
table(couchto5k$season)
table(couchto5k$city)

couchto5k[which(couchto5k$age>60),] 
couchto5k <- 
  couchto5k %>%
  mutate(
    age = ifelse(age>60, NA, age) 
  )
couchto5k[which(couchto5k$selfmot<0),]
couchto5k <- 
  couchto5k %>%
  mutate(
    selfmot = ifelse(selfmot<0, NA, selfmot) 
  )
couchto5k[which(couchto5k$week_stopped>9),] 
couchto5k <- 
  couchto5k %>%
  mutate(
    week_stopped = ifelse(week_stopped>9, NA, week_stopped) 
  )

couchto5k <- couchto5k %>%
  mutate(season = replace(season,season == "autunm", "autumn"))
couchto5k$season <- factor(couchto5k$season, levels=c("spring","summer", "autumn","winter"))
levels(couchto5k$season)
```

Firstly, it was a between-subject study design, and this information was used in the further analytical decisions. 

The dataset includes 133 subjects and contains 9 variables in total. Six of them are numerical: Age, Accountability, Self-motivation, Health, Happiness and Week stopped. The remaining three variables are categorical: PptID, Season and City. Participants started to take part in the fitness program Couch to 5k, which lasted 9 weeks. The variable Week Stopped shows the week of programme participants stopped in participation in the fitness programme (from 1-9 week respectively). The data has been collected from the subjects in two cities: Glasgow and Edinburgh. The data is also included information about participants ages. Subjects were interviewed in one of four seasons (winter, spring, summer, autumn). 

At the initial step of the analysis, the output was shown the absence of the missing values across the 9 variables. However, the impossible values were found in the three numerical variables: 

* Age: subject's ID113 aged 146 and subject's ID125 aged 107;

* Self-motivation: -99 score for the psychometric measure of self-motivation in two subjects with ID13 and ID85. It is impossible values because the smallest score on this test is 5;

* Week stopped: one subject with ID85 stopped the programme on the 12 week. It is impossible value because the participants completed the programme on the 9 week.

These specific entries were converted to Not Applicable (NA) because most of the remaining values in these rows are correct and may be beneficial for the future analyses. 

The impossible values were found in one categorical variable Season: this variable showed 5 levels, while it should demonstrate only 4 levels as maximum. It looked like that there was a typo in the name of the season (autu*nm* instead of autumn). This typo was fixed by replacing the misspelling value and changing it with the value that was written properly. Also, the variable season was converted to the factor and changed the order of levels. This specific order will be necessary to answer the 2a question.

The final analysis of the structure of the data showed that the amendments were made.

# Question 1 

## Question 1a

```{r q1a, include = FALSE}
couchto5k$week_levels=if_else(couchto5k$week_stopped<5, "before_5",if_else(couchto5k$week_stopped<9, "after_5","completed"))
table(couchto5k$week_levels)
chisq.test(table(couchto5k$week_levels), p = c(.45,.1,.45))
```

Firstly, the new variable Week Levels with 3 levels was created.

Secondly, the Chi-square goodness of fit test was calculated to assess the extent to which sample of participants from the fitness program Couch to 5k conforms to the distribution of attrition rates from the earlier survey. It was hypothesized that the proportion of participants from the Couch to 5k who abandoned the programme before week 5, after week 5 and also completed the programme on week 9 is 45%, 10% and 45% respectively. 

**Conclusion**: Significant deviation from the hypothesized values was found (χ^2^(2)= 108, *p* < .01). The observed proportions of attrition rates in the sample of participants from the fitness program Couch to 5k are significantly different from the specified proportions of attrition rates from the earlier survey.

## Question 1b

```{r q1b, include = FALSE}
conttable=table(couchto5k$week_levels,couchto5k$city)
head(conttable)
fisher.test(conttable)
res1b <- tidy(fisher.test(conttable))
```

The two assumptions for the Chi-square test of independence were explored:

1. In the given dataset the observations are independent;
2. The contingency table was created. The expected frequencies for one category were equal to 2 (the participants from Glasgow who abandoned the programme after week 5). Because this expected value is less than 5, I decided to avoid using the Chi-square test of independence and instead performed Fisher’s exact test, which is based on the hypergeometric distribution.

**Conclusion**: Fisher's exact test was calculated comparing the patterns of attrition rates by cities. There was no significant association between the patterns of attrition rates by week (i.e., participants who abandoned the programme before week 5, after week 5 and completed the programme on week 9) and cities (i.e., Glasgow and Edinburgh) (*p* = `r res1b$p.value[1]`, two-sided Fisher's exact test). The patterns of attrition rates by cities appear to be independent events.

## Question 1c

```{r q1c, include = FALSE}
ggplot(couchto5k, aes(x=city, y=age, fill=city))+
geom_boxplot()+
geom_jitter(shape=16, position=position_jitter(0.2))+
scale_fill_brewer(palette="Blues")+
xlab("City") +
ylab("Age (in years)") 

summary(couchto5k$age [couchto5k$city=="Edinburgh"])
summary(couchto5k$age [couchto5k$city=="Glasgow"])
sd (couchto5k$age [couchto5k$city=="Edinburgh"],na.rm = T)
sd (couchto5k$age [couchto5k$city=="Glasgow"])
hist(couchto5k$age [couchto5k$city=="Edinburgh"])
hist(couchto5k$age [couchto5k$city=="Glasgow"])
qqnorm(couchto5k$age [couchto5k$city=="Edinburgh"])
qqline(couchto5k$age [couchto5k$city=="Edinburgh"])
qqnorm(couchto5k$age [couchto5k$city=="Glasgow"])
qqline(couchto5k$age [couchto5k$city=="Glasgow"])
shapiro.test(couchto5k$age [couchto5k$city=="Edinburgh"])
shapiro.test(couchto5k$age [couchto5k$city=="Glasgow"])

with(couchto5k, var.test(age ~ city))
t.test(age~city,couchto5k) 
res1c <- tidy(t.test(age~city,couchto5k))
```

Before conducting two-tailed independent samples t-test, three assumptions were checked:

1. Data of the dependent variable (Age) are measured in the ratio scale;

2. Both normality tests are lower than the significance level of 0.05 (*p* < 0.01 for the sample of people from Edinburgh and *p* = 0.002 for the sample of people from Glasgow). The histograms and Q-Q plots of these groups were built. It looks like the shape of the statistical data in the Edinburgh group is skewed left, while the shape of the statistical data in the Glasgow group is skewed right. Thus, the histograms and Q-Q plots also supported the outputs of the statistical tests. However, the independent samples t-test is valid for large samples even from non-normal distributions;

3. Moreover, the F - test (*p* = .02) indicates that there is not enough evidence to conclude the variances are different. If the assumption of equal variances is satisfied, it is possible to conduct t-test despite the unequal sample sizes between the two comparison groups.

Therefore, the independent samples t-test (two-tailed) instead of using a nonparametric test - Mann-Whitney was performed.

**Conclusion**: A two-tailed independent samples t-test was conducted in order to determine if the average age for a sample of 99 participants from Edinburgh is significantly differ (*α*=.05) than the the average age for a sample of 33 participants from Glasgow. On average, the participants' age from Edinburgh is higher (M = 42, *SD* = 13), than the participants' age from Glasgow (M = 37, *SD* = 10). This difference is significant, t(`r res1c$parameter[1]`) = `r res1c$statistic[1]`, *p* = `r res1c$p.value[1]`.

# Question 2

## Question 2a

```{r q2a, include = FALSE}
levels(couchto5k$season)
model1<-lm(happiness~season, data = couchto5k)
summary(model1)
confint(model1)
plot_model(model1, show.values = TRUE, value.offset = .3)
coef(model1)
anova(model1)
res2a <- tidy(anova(model1))
```

Since the experimental design is not balanced, the largest category in the Season (spring) was chosen as the reference category in dummy coding.

**Conclusion**: A simple linear regression was calculated to predict Happiness scores based on the season when participants were interviewed in. A significant regression equation was found (F(3,`r res2a$df[2]`) = `r res2a$statistic[1]`, p = `r res2a$p.value[1]`), with an R^2^ of .05. The variable Season is a significant predictor of happiness. A categorical variable Season is related to a dependent variable Happiness in the following way: 

Happiness score = 50.27 + 11.44Summer - 14.22Autumn - 9.77Winter  + ϵ

## Questions 2b

```{r q2b, include = FALSE}
model2<-lm(happiness~season+age, data = couchto5k)
summary(model2)
plot(model2, which = 1:4)
#couchto5k<-couchto5k [-c(42,115,116),]
#model2<-lm(happiness~season+age, data = couchto5k)
plot(model2, which = 1:4)
hist(couchto5k$age)
hist(couchto5k$happiness)

remove_outliers <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}

couchto5k$age=remove_outliers(couchto5k$age)
couchto5k$happiness=remove_outliers(couchto5k$happiness)
plot(model2, which = 1:4)

res2b <- tidy(anova(model2))
```

The second model with two predictors (Season and Age) was assessed to ensure that it meets all the underlying assumptions. Initial inspection revealed that the plot (residuals vs fitted) has a straight red line, the QQplot of residuals have some outliers, the scale location plot has a bit wiggly red line and a Cook's distance showed three influential observations. However, the interquartile range (IQR) method did not identify them as the outliers, therefore it was decided not to delete them from the dataset. 

**Conclusion**: A multiple linear regression was calculated to predict participants’ happiness score based on the season when participants were interviewed and their age. The analysis revealed that the regression equation was not significant (F (4,126) = 2.09, *p* > .05) with an adjusted R^2^ of .03. The variable Age is not a significant predictor of happiness (β = - .04, *p* > .05). 

## Question 2c

```{r q2c, include = FALSE}
any(is.na(couchto5k$age))
model1 <- update(model1, subset = !is.na(age))
anova(model1, model2)
pander(model1)
```

For comparing two models, the incremental F-test was used. There are some NA in the Age variable. The solution was to re-fit the first regression with the same data as was used for the second. Adding the Age predictor did not improve the model further over one which included season (F(1,`r res2b$df[3]`) = `r res2b$statistic[2]`, p<1). Therefore, the model without Age variable was chosen as a baseline model for future analysis.  

# Question 3

## Question 3a

```{r q3a, include = FALSE}
couchto5k <- couchto5k %>%
mutate(is_completed = ifelse(couchto5k$week_stopped==9, "yes", "no"))

model3<-lm(happiness~season+is_completed, data = couchto5k)
summary(model3)
plot(model3, which = 1:4)
#couchto5k<-couchto5k [-c(28,42,115),]
#model3<-lm(happiness~season+is_completed, data = couchto5k)
plot(model3, which = 1:4)
hist(couchto5k$happiness)


remove_outliers <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}
# source of this function: https://stackoverflow.com/questions/4787332/how-to-remove-outliers-from-a-dataset

couchto5k$happiness=remove_outliers(couchto5k$happiness)
plot(model3, which = 1:4)

coef(model3)
anova(model3)
res3a <- tidy(anova(model3))
```

The new binominal variable with two levels (participants who completed and who did not complete the program) was created.

The third model with two predictors (Season and Programme completion) was assessed to ensure that it meets all the underlying assumptions. Initial inspection revealed that the plot (residuals vs fitted) has a straight red line, the QQplot of residuals have some outliers, the scale location plot has a bit wiggly red line and a Cook's distance showed three influential observations. However, the interquartile range (IQR) method did not identify them as the outliers, therefore it was decided not to delete them from the dataset. 


**Conclusion**: A multiple linear regression was calculated to predict participants’ happiness score based on the season when participants were interviewed in and programme completion. The analysis revealed that the regression equation was significant (F (4,127) = 3.28, *p* = .01) with an adjusted R^2^ of .06. The variable Programme completion is not a significant predictor of happiness (β = 13.21, *p* > .05). The variable Programme Completion is related to a dependent variable Happiness in the following way: 

Happiness score = 46.83 + 3.80Summer - 23.33Autumn - 16.60Winter + 13.21Is_completed + ϵ


## Question 3b

```{r q3b, include = FALSE}
model4<-lm(happiness~season+health, data = couchto5k)
summary(model4)
plot(model4, which = 1:4)
#couchto5k<-couchto5k [-c(42,59,115),]
#model4<-lm(happiness~season+is_completed, data = couchto5k)
plot(model4, which = 1:4)
hist(couchto5k$health)

remove_outliers <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}
# source of this function: https://stackoverflow.com/questions/4787332/how-to-remove-outliers-from-a-dataset

couchto5k$health=remove_outliers(couchto5k$health)
plot(model4, which = 1:4)

anova(model4)
res3b <- tidy(anova(model4))

```

The fourth model with two predictors (Season and Health) was assessed to ensure that it meets all the underlying assumptions. Initial inspection revealed that the plot (residuals vs fitted) has a straight red line, the QQplot of residuals have some outliers, the scale location plot has a bit wiggly red line and a Cook's distance showed three influential observations. However, the interquartile range (IQR) method did not identify them as the outliers, therefore it was decided not to delete them from the dataset.

**Conclusion**: A multiple linear regression was calculated to predict participants’ happiness score based on the season when participants were interviewed in and health. The analysis revealed that the regression equation was significant (F (4,127) = 2.79, *p* = .03) with an adjusted R^2^ of .03. The variable Health is not a significant predictor of happiness (β = .28, *p* > .05).

## Question 3c

```{r q3c, include = FALSE}
model5 <- lm(happiness~season+health*is_completed, data = couchto5k)
summary(model5)
plot(model5, which = 1:4)
anova(model5)
#couchto5k<-couchto5k [-c(59,71,106),]
#model5<-lm(happiness~season+is_completed, data = couchto5k)
plot(model4, which = 1:4)

remove_outliers <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}
# source of this function: https://stackoverflow.com/questions/4787332/how-to-remove-outliers-from-a-dataset

couchto5k$health=remove_outliers(couchto5k$health)
plot(model4, which = 1:4)
anova(model5)
res3с <- tidy(anova(model5))
#interact_plot(model5, pred = health, modx = is_completed)
plot_model(model5, type="int")
```

The fifth model with four predictors was assessed to ensure that it meets all the underlying assumptions. Initial inspection revealed that the Residuals vs Fitted plot has a straight red line with some outliers, the QQplot of residuals fairly normally distributed (with some outliers), the scale location plot has a bit wiggly red line and a Cook's distance showed three influential observations. However, the interquartile range (IQR) method did not identify them as the outliers, therefore it was decided not to delete them from the dataset.

**Conclusion**: Multiple linear regression was calculated to predict participants’ happiness score based on the season when participants were interviewed, health, programme completion and the interaction between participants' health and the programme completion. The analysis revealed that the regression equation was significant (F (6,124) = 3.46, *p* = .003) with an adjusted R^2^ of .1. The level of health depended on whether participants completed the programme or not because in interaction these variables significantly predicted the happiness score (β = 1.40, *p* = .02). The relationship between the health scores and happiness scores is increasing for participants who completed the programme. In contrast, the relationship between the health scores and happiness scores is decreasing for participants who abandoned the programme.

## Question 3d

The happiness effect depends on the Season when the participants have been interviewed and the interaction between Programme Completion and the participants' Health. Neither Age nor Health and Programme Completion are the significant predictors of happiness.

The model including Season and he interaction between Programme Completion and the participants' Health is summarized below.

```{r q3d, include = TRUE}
pander (model5)
```

# Question 4

```{r q4, include = TRUE}
table4 <- couchto5k[couchto5k$is_completed=="yes", ]
table4 = table4 [complete.cases(table4),]

ggplot(data = table4, aes(season, happiness, col = city))+
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.1, size = 1, position = position_dodge(0.3))+
  stat_summary(fun = mean, geom = "point", size = 6, shape = 22, fill = "white", position = position_dodge(0.3))+
  xlab("Season")+
  ylab("Happiness score") 
```

Fig. 1. The interval plot of the average happiness score grouped by season and city with a 95% confidence interval for the mean of each group.

# Question 5

## Question 5a

The needed continuous variables have been standardized because the data did not have the same scales. The scatterplot matrix showed a high correlation between health and age (r= - .53). The model was chosen by a stepwise algorithm. The final model that predicts dropping out includes two predictors: Age and Self-motivation. 

```{r q5a, include = FALSE}
couchto5k <- couchto5k %>%
mutate(is_completed = ifelse(couchto5k$week_stopped==9, 1, 0))
couchto5k=couchto5k[complete.cases(couchto5k),]
ggplot(couchto5k, aes(season)) +
		geom_bar() +
		theme(axis.text.x = element_text(angle = 90))
table(couchto5k$season)
ggplot(couchto5k, aes(city)) +
		geom_bar() +
		theme(axis.text.x = element_text(angle = 90))

?standardize
st6 <- standardize(is_completed~age + accountability+selfmot+health+happiness, data = couchto5k,family = "binomial")
resultst6 <- st6$data

couchto5k %>% 
  select(age, accountability, selfmot, health, happiness, season, city) %>%
  pairs.panels()

model6_1 <- glm(st6$formula, st6$data, family = "binomial")
summary(model6_1)

model6_1 <- step(model6_1)
summary(model6_1)
exp(0.709)
exp(coef(model6_1))

```

## Question 5b

Whether or not participants completed the fitness programme Couch to 5k  (binary 0 vs 1) is modeled using logistic regression, with Age (years) and Self-motivation (scored from 5 - 35). The analyses revealed that the Self-Motivation is a significant predictor of the programme completion (β = .71, *p* < .01). Adding 1 score of self-motivation increases the log-odds of programme completion by 0.71. If Self-motivation increases by 1, odds increases by 2. The odds for programme completion for someone scored 0 in self-motivation equals to 1.2. 

## Question 5c

```{r q5c, include = FALSE}
model6_2 <- glm(is_completed~selfmot, data = couchto5k, family = "binomial")
summary(model6_2)

selfmot22 <- tibble(selfmot = 0:30)
predict(model6_2, newdata = selfmot22, type = "response")

selfmot22 <- 
  selfmot22 %>%
  mutate(
    predprobs = predict(model6_2, newdata = selfmot22, type = "response")
  )
```

```{r q5c_1, include = TRUE}
ggplot(data = selfmot22, aes(x = selfmot, y = predprobs)) +
  geom_line()+
  labs(x = "Score in self-motivation", y="Predicted probability of quitting") 
```

Fig.2. The plot of predicted probabilities of quitting for each value of self-motivation.








