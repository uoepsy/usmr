---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
params:
  examnumber: B171824
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
library(sjPlot)
library(ggplot2)
library(knitr)
library(patchwork)
library(dplyr)
library(psych)
library(pander)


# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

In this report, I will be assessing data collected from 135 participants who participated in the NHS-sponsored fitness programme 'Couch To 5k'. All of the participants came from the cities of Edinburgh and Glasgow, and the programme lasted a total of 9 weeks. Participants were able to join at any point of the year, and were asked to complete a questionnaire at the commencement of the programme at week 0 which assessed the psychometric factors of accountability and self-motivation. Upon either completion or drop-out from the programme, participants were then asked to complete a questionnaire of their self-reported happiness and a physiological health measure.
The researchers had two primary interests; the psychological factors that make people continue with the programme, and the effects of taking the programme upon health and wellbeing.


# Question 0
<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->


```{r cleaning, include = FALSE}
# Neither output nor code from this chunk will be shown in the compiled document. 

summary(couchto5k)
plot(couchto5k[1:9])

couchto5k[couchto5k$week_stopped == "14",] #participant put in impossible finishing week, going to reassign to week_stopped = 9.
couchto5k[44,9] <- 9
couchto5k[44,]

#changing categoricals to factors
couchto5k$city <- as.factor(couchto5k$city)
couchto5k$season <- as.factor(couchto5k$season)

levels(couchto5k$season) #autumn and autunm. Correct all incorrect entries and replace with correct spelling.
levels(couchto5k$season) <- gsub("autunm", "autumn", levels(couchto5k$season)) #using gsub to change misspelled entries

#relevelling seasons 
couchto5k$season <- couchto5k$season %>% fct_relevel("spring", "summer", "autumn", "winter")


hist(as.numeric(couchto5k$selfmot)) 
hist(as.numeric(couchto5k$age))
#impossible values. Going to keep the rows and change the specific entries to NA since there is still valid observations in other variables.
couchto5k[couchto5k$selfmot == "-99",]
couchto5k[c(89,95),4] <- NA
couchto5k[couchto5k$age > 100,]
couchto5k[c(36,64),2] <- NA

#creating a table to discuss the impossible values
couchto5k$missing <- NA
couchto5k$missing[is.na(couchto5k$selfmot)] <- "Impossible Self-Motivation Scores"
couchto5k$missing[is.na(couchto5k$age)] <- "Impossible Age Data"

mtab <- table(couchto5k$missing)
allppts <- count(couchto5k)
```

Prior to starting our analyses, the data was cleaned to check for any impossible values or incorrect entries. A table summarising all of the impossible values changed to 'NA' within the dataset can be seen in Table 1. It was decided that these impossible values would not be removed from the dataset, as the other data that was provided was still relevant to our research question. Other modifications that were made include changing the misspelled entries of 'autunm' to 'autumn', and changing an entry in week stopped. This entry stated that the participant stopped the programme in week 14, which is not a value that can be used for this variable, which should have a maximum of 9 weeks. It was decided not to mark this as an 'NA' value, and was instead inferred to mean that the participant had completed the programme, and thus changed to a value of 9.

```{r table 1, results="asis"}
mtab %>% pander(caption="Table 1: Summary of missing values.")
```

```{r plot creation, include = FALSE} 
age_plot <- 
  ggplot(data = couchto5k, aes(x=age)) +
  geom_density(na.rm = TRUE) +
  geom_boxplot(width = 1/150) +
  theme_bw() +
  labs(x = "Age (years)", y = "Density", caption = "Figure 1")

age_plot # brief notes - age is bimodal :/ mean of 38.3, min of 18.0 and max of 60.0. SD = 12.6.
summary(couchto5k$age)
sd(couchto5k$age, na.rm = TRUE)

accountability_plot <-
  ggplot(data = couchto5k, aes(x=accountability)) +
  geom_density(na.rm = TRUE) +
  geom_boxplot(width = 1/150) +
  theme_bw() +
  labs(x = "Accountability (min = 5, max = 35)", y = "Density", caption = "Figure 2")

accountability_plot #unimodal, mean of 20.6, max of 34.0 and min of 6.0. SD = 5.44.
summary(couchto5k$accountability)
sd(couchto5k$accountability)

selfmot_plot <-
  ggplot(data = couchto5k, aes(x=selfmot)) +
  geom_density(na.rm = TRUE) +
  geom_boxplot(width = 1/150) +
  theme_bw() +
  labs(x = "Self-Motivation (min = 5, max = 35)", y = "Density", caption = "Figure 3")

selfmot_plot #unimodal, mean of 15.1, max of 22.0 and min of 5.0. SD = 3.01.
summary(couchto5k$selfmot)
sd(couchto5k$selfmot, na.rm = TRUE)

health_plot <-
  ggplot(data = couchto5k, aes(x=health)) +
  geom_density(na.rm = TRUE) +
  geom_boxplot(width = 1/150) +
  theme_bw() +
  labs(x = "Health Measure (0-100)", y = "Density", caption = "Figure 4")

health_plot #unimodal, mean of 57.0, max of 85.0 and min of 6.0. SD = 10.0.
summary(couchto5k$health)
sd(couchto5k$health)

happiness_plot <-
  ggplot(data = couchto5k, aes(x=happiness)) +
  geom_density(na.rm = TRUE) +
  geom_boxplot(width = 1/150) +
  theme_bw() +
  labs(x = "Happiness (0-100)", y = "Density", caption = "Figure 5")

happiness_plot #bimodal??, mean of 46.6, max of 100.0 and min of 0.0. SD = 30.6.
summary(couchto5k$happiness)
sd(couchto5k$happiness)

weekstop_plot <-
  ggplot(data = couchto5k, aes(x=week_stopped)) +
  geom_density(na.rm = TRUE) +
  geom_boxplot(width = 1/50) +
  theme_bw() +
  labs(x = "Week Stopped (minimum = 1, maximum = 9 (completed)", y = "Density", caption = "Figure 6")

weekstop_plot #negatively skewed?, mean of 6.19, max of 9.0 and min of 1.0. SD = 3.09.
summary(couchto5k$week_stopped)
sd(couchto5k$week_stopped)

season_plot <- 
  ggplot(data = couchto5k, aes(x = season, fill = season)) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Season", y = "Count", caption = "Figure 7")

season_plot
summary(couchto5k$season)

city_plot <- 
  ggplot(data = couchto5k, aes(x = city, fill=city)) +
  geom_bar() +
  theme_minimal() +
  scale_fill_brewer(palette = 1) +
  labs(x = "City", y = "Count", caption = "Figure 8") 

city_plot
summary(couchto5k$city)

tab_2 <- describe(couchto5k %>% select("Age"=age, "Accountability" = accountability, "Self-Motivation" = selfmot, "Health" = health, "Happiness" = happiness, "Week Stopped Programme" = week_stopped))[,c(2:4,8:11)] %>% round(2) %>%
  kable(., caption = "Table 2: Summary of Numeric Variables")
```

```{r descriptives accountability and selfmot, warning=FALSE, fig.align='center'}
age_plot
```

Above is a density and integrated boxplot of age. Participants were aged between 18 - 60, and as stated impossible age values were removed. We can see from the shape of the density plot that the curve is bimodal, such that our population was not normally distributed.

```{r age descriptive, fig.align='center', warning=FALSE}
accountability_plot / selfmot_plot
```
Above are graphs of self-motivation and accountability. Both of these psychometric variables were generated from a sum of 5 questions, scoring 1-7 on each. The higher the score, the more strongly participants felt self-motivated and accountable, respectively. The graphs are unimodal, inferring that they come from a normally distributed sample. Boxplots are included with the density plots to show the spread and averages for participants.

```{r health, happiness, week descriptives, fig.align='center'}
(health_plot + happiness_plot) / weekstop_plot
```

Above are density and integrated boxplots for self-rated health, happiness and week in which participants stopped the programme. The multi-test health questionnaire was rated between 0 and 100, from poor to good health, and happiness was rated 0 - 100 too, from low to high happiness. The week stopped ranged from week 1 to 9 (completion). While both health and happiness seem to be relatively normal, week stopped was bimodal. It appears that a large number of participants dropped out of the programme during its first weeks, with a dip in attrition during the middle weeks. A large number of people then went on to complete the programme.

A full summary of these continuous variables an be found below in Table 2.

```{r tab2, summary of continuous descriptives}
tab_2
```
Below is a barplot of our seasons. Altogether, 66 people participated in spring, 36 in summer, 14 in autumn, and 19 in winter.
```{r season descriptive, fig.align='center',results="asis"}
season_plot
```
Below is a barplot of our cities, Edinburgh and Glasgow, showing how many participants were allocated to each. Glasgow had a count of 40 participants, and Edinburgh had 95.
```{r city descriptive, fig.align = 'center'}
city_plot
```




# Question 1 

## Question 1a

```{r q1a, include=FALSE}
#divide into 3 different categories (stopped before week 5, after week 5 etc. using ifelse), then do a t-test

drophalfway <- ifelse(couchto5k$week_stopped < 5, 1, 0)
dropafterhalfway <- ifelse((couchto5k$week_stopped >=5)&(couchto5k$week_stopped <9), 1, 0)


#need a single sample t-test

#first check assumptions
shapiro.test(drophalfway)
shapiro.test(dropafterhalfway)

#both of our groups fail the normality test for Shapiro-Wilk, so we have to conclude that our groups do not come from a normally distributed population. We can compare this against the overall plot for weeks stopped:

weekstop_plot

#our density plot here shows a bimodal distribution, but since this is real-world data we cannot expect it to conform completely to normality. In this case, it shows that people typically stopped early in the programme, or finished it. 

dropstat1 <- t.test(drophalfway, mu = 0.45, alternative = "two.sided")
dropstat2 <- t.test(dropafterhalfway, mu = 0.1, alternative = "two.sided")
dropstat1
dropstat2
```
The data collected here can be directly compared to an earlier nationwide survey. In this survey, 45% of the participants dropped out of the programme before the halfway point in week 5, and a further 10% dropped out before the end of the programme. We wish to determine whether the data in our sample is in line with the data from the earlier survey. 
To test this, we conducted two t-tests - one on the sample of participants who abandoned the programme prior to the halfway point in week 5 and one on the sample who dropped out after the halfway point and prior to the end point at week 9.
The first one-sample t-test was run on the `r sum(drophalfway)` participants who abandoned the study before week 5. The result was insignificant against our fixed alpha level ($\alpha = .05$), and the t-test revealed that there was not a significant difference in dropout rate of the individuals in the nationwide study compared to our own: t(`r dropstat1$parameter`) = `r dropstat1$statistic %>% round (2)`, $p$ = `r dropstat1$p.value`.
The second one-sample t-test was run on the `r sum(dropafterhalfway)`participants who abandoned the study before week 5. The result was insignificant against our fixed alpha level ($\alpha = .05$), and the t-test revealed that there was not a significant difference in dropout rate of the individuals in the nationwide study compared to our own: t(`r dropstat2$parameter`) = `r dropstat2$statistic %>% round (2)`, $p$ = `r dropstat2$p.value`. Therefore, our sample is in line with the attrition rates of the earlier survey.
It should be noted that the t-tests performed here were checked against the assumption of normality by the Shapiro-Wilks test. Both p-values were significant, indicating that our data do not come from a normally distributed sample. This can be seen in our density plot (see Figure 6) of weekly drop-out, where the data takes a bimodal distribution, with a heavy negative skew, indicating that most of the sample completed the programme. 



## Question 1b

```{r q1b, include=FALSE}

#in order to assess attrition rates by city, we need to do a chi-squared test.  First, I need to divide the weeks into one variable, dividing them by halfway stopped, non-completed and completed.

couchto5k <- couchto5k %>%
  mutate(
    week_categories = ifelse(week_stopped < 5, 1, 0) + ifelse((week_stopped >=5)&(week_stopped<9), 2, 0) + ifelse(week_stopped == 9, 3, 0)
  )
summary(couchto5k)
couchto5k$week_categories <- as.factor(couchto5k$week_categories)

chi_week <- chisq.test(couchto5k$week_categories, couchto5k$city)

chi_week

#plot to show the differences in attrition rates per city. 

week_stopplot <- ggplot(data = couchto5k, aes(x = week_stopped, fill = city)) +
  geom_bar() +
  labs(x = "Week Stopped Programme", y = "Count", caption = "Figure 9") +
  theme_bw() +
  facet_wrap(~city)
```
In order to test whether the rates of attrition differed by city, a $\chi^2$ test of Independence was carried out.
The $\chi^2$ test of Independence was not significant, $\chi^2$ (`r chi_week$parameter`, N =`r nrow(couchto5k)`) = `r chi_week$statistic`, $p$ = `r chi_week$p.value`. Due to our non-significant p-value, we can accept the null hypothesis that the rates of attrition do not differ depending on which city the programme was taken in. To visualise these rates of attrition, see Figure 9.

```{r Figure q1b, fig.align='center'}
week_stopplot
```

## Question 1c

Next, we want to know whether the average ages of our participants differ by city. In Figure 10 is a boxplot to show the spread of scores across ages by city, with the average age denoted by a thick black line in the centre of the boxes. 
```{r q1c, include=FALSE}
#independent samples t-test to answer this:

#check assumptions first 

shapiro.test(couchto5k$age[couchto5k$city=="Edinburgh"])
shapiro.test(couchto5k$age[couchto5k$city=="Glasgow"])
#both of the Shapiro-Wilk tests note a significant departure from a normal distribution, but t-tests are relatively robust against deviations in normality.

#A plot to visually assess normality:
agecityplot <- ggplot(data = couchto5k, aes(x = age, y = city, fill = city)) +
  geom_boxplot(na.rm = TRUE) +
  scale_fill_brewer(palette="Dark2") +
  labs(x = "Age", y = "City", caption = "Figure 10")

#can see from the boxplot that the spread of ages across the two cities appears to be relatively normal.

tstat1 <- with(couchto5k, t.test(age ~ city, alternative = "two.sided"))
tstat1
```

```{r q1c plot, fig.align='center'}
agecityplot
```
An independent samples t-test was conducted in order to determine if a sample of `r nrow(couchto5k)` participants differed in age relative to the city they commenced the programme in, at a significance level of ($\alpha = .05$).

Participants who commenced the programme in Edinburgh were aged older on average(M = `r mean(couchto5k$age[couchto5k$city == "Edinburgh"], na.rm = TRUE) %>% round(2)`, SD = `r sd(couchto5k$age[couchto5k$city == "Edinburgh"], na.rm = TRUE)`), than participants who commenced the programme in Glasgow (M = `r mean(couchto5k$age[couchto5k$city == "Glasgow"], na.rm = TRUE) %>% round(2)`, SD = `r sd(couchto5k$age[couchto5k$city == "Glasgow"], na.rm = TRUE)`). This difference was not statistically significant (t(`r nrow(couchto5k) - 1`)= `r tstat1$statistic %>% round(2)`, $p$ = 0.10). This indicates that the city participants were in had no effect on their reported age.

# Question 2

## Question 2a

We want to find out whether happiness ratings are affected by the season in which participants were first interviewed. Below in Figure 11 boxplots representing the spread of ages across the seasons can be visualised. Initially, we can see that happiness ratings tend to be lower in the seasons of winter and autumn, but this needs to be tested first to draw any conclusions of significant differences in happiness between the seasons. 

```{r q2a fitting and fixing the model, include=FALSE}
modifiedcouchto5k <- couchto5k[-c(36, 64),] #to have the same size of dataset for both linear models.

seasonhappymodel <- lm(happiness ~ season, data = modifiedcouchto5k)
seasonhappymodel
summary(seasonhappymodel)
plot(seasonhappymodel)

plot(seasonhappymodel, which = 4)
#two outliers were identified using Cook's distance. These will now be removed, and a new model will be fit. 
modifiedcouchto5k <- modifiedcouchto5k[-c(51,103),]

count(modifiedcouchto5k) # the new count of participants is n = 131.

revisedseasonhappymodel <- lm(happiness ~ season, data = modifiedcouchto5k)
revisedseasonhappymodel
summary(revisedseasonhappymodel)
plot(revisedseasonhappymodel)
plot(revisedseasonhappymodel, which = 4)
```

```{r q2a table and plot creation, include=FALSE}
t1mod <- tab_model(revisedseasonhappymodel, title = "Table 3: Model predicting happiness by season")
t1plot <- ggplot(data = couchto5k, aes(x = happiness, y = season, fill = season)) +
  geom_boxplot() +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(x = "Happiness (0-100)", y = "Season", caption = "Figure 11")
```

```{r q2a plot, fig.align='center'}
t1plot
```
Below in Table 3 is a summary of our model.
```{r q2a table, fig.align='center'}
t1mod
```


```{r q2a describing the model, include=FALSE}
summary(revisedseasonhappymodel)
plot(revisedseasonhappymodel)
sigma(revisedseasonhappymodel)
confint(revisedseasonhappymodel, level = 0.95)
```
In order to investigate whether participants' happiness rating were affected by season, a simple linear regression model was constructed. Several values were removed for violating Cook's Distance, and a revised model was constructed using the new sample of `r nrow(modifiedcouchto5k)`. Tests of linearity were performed, and the residuals were checked for assumptions of normality, homogeneity of variance, and independence. No abnormalities were identified.
The estimated average happiness ratings for a participant who undertook the programme in spring while controlling for other seasons was `r revisedseasonhappymodel$intercept` 49.50, which acts as the model intercept. The estimated increase in average happiness for summer while controlling for other seasons was 7.15, however this was not a significant value ($p$ = 0.235). For autumn, the average happiness decreased by 30.75, and for winter the average happiness decreased by 21.39. These were both significant at $p$ < 0.05.
For any particular season, the happiness scores should be distributed above and below the regression line with standard deviation estimated to be $\sigma$ = 28.4. 
Our model did not explain a lot of the variance in our sample, with the adjusted $R^2$ = `r summary(revisedseasonhappymodel)[9]`, however, our model was tested for the overall significance of the interaction using an F-test, which was significant: F(`r summary(revisedseasonhappymodel)$fstatistic[2]`, `r summary(revisedseasonhappymodel)$fstatistic[3]`) = `r summary(revisedseasonhappymodel)$fstatistic[1]`), $p$ < 0.05.
In summary, our model does explain the variance of happiness in our sample to a significant level ($\alpha$ = .05), particularly in the seasons of spring and summer where average happiness scores are higher on average.


## Question 2b

Next, we want to investigate whether, accounting for the effects of season we found previously, happiness is affected by age. To address this question, a multiple linear regression model will be built including the predictor of age. 
```{r q2b building the second model, include=FALSE}
ageseasonhappymodel <- lm(happiness ~ season*age, data = modifiedcouchto5k)
ageseasonhappymodel
summary(ageseasonhappymodel)



count(modifiedcouchto5k)
plot(ageseasonhappymodel, which = 4) #removing this one outlier does not impact our model - everything is still insignificant. Age just is not a predictor.

```

```{r q2b plot and table creation, include=FALSE}
q2bplot <- ggplot(data = couchto5k, aes(x = age, y = happiness, color = season)) +
  geom_point(na.rm = TRUE) +
  geom_smooth(method = "lm", se=FALSE) +
  theme_minimal() +
  labs(x = "Age", y = "Happiness (0-100)", caption = "Figure 12")

t2mod <- tab_model(ageseasonhappymodel, title = "Table 4: Model predicting happiness by season and age")
```

```{r q2b plot, warning=FALSE, fig.align='center'}
q2bplot
```
Above in Figure 12, it would appear that summer and winter are slightly influential when accounting for age in our happiness model. However, in our model we can test this by looking at the interaction of age and season, and age as an additional explanatory variable for happiness. Below is Table 4, our model's summary.
```{r q2b table, fig.align='center'}
t2mod
```

Tests of linearity were performed, and the residuals were checked for assumptions of normality, homogeneity of variance, and independence. No abnormalities were identified. Our tested population was `r nrow(modifiedcouchto5k)`. Integrating age with our model did not proffer any significance, with the increase of average happiness with every year of age being 0.01, which was non-significant at $p$ = 0.978. Interacting age with season did not produce any significant values either, indicating that age does not have a significant effect on our model overall. 

Our new model did not explain a lot of the variance in our sample, with the adjusted $R^2$ = `r summary(ageseasonhappymodel)[9]`, however, our model was tested for the overall significance of the interaction using an F-test, which was significant: F(`r summary(ageseasonhappymodel)$fstatistic[2]`, `r summary(ageseasonhappymodel)$fstatistic[3]`) = `r summary(ageseasonhappymodel)$fstatistic[1]`), $p$ < 0.05. Overall, this model with the addition of age did not explain more of the variance in our sample over and above our original model with just season.


## Question 2c

```{r q2c evaluating models, include=FALSE}
null_mod <- lm(happiness ~ 1, data = modifiedcouchto5k)
summary(null_mod)
anova(null_mod, revisedseasonhappymodel) #both significant against the null models.
anova(null_mod, ageseasonhappymodel)
anova(revisedseasonhappymodel, ageseasonhappymodel) #model explaining age was not significant when compared against the season model.
#going to use my original season model
baseline <- revisedseasonhappymodel
```
We are going to be selecting one of our baseline models to carry forward for use in this report. A null model was compared against both of our models, and they both returned significant values (p<0.05), indicating that they both explain more of the variance in our sample over and above the null model.
Running an ANOVA to compare the experimental models against one another, no significance was discovered: F(4, 123) = 0.66, $p$ = 0.62. We can infer from this that the addition of age did not explain more of the variance in our sample than our original model using only season as a predictor. They were both significant over the null, but this was likely due to the model being significant already prior to the addition with age.
With this in mind, we will be using the original model using only season as a predictor for our baseline.



# Question 3

## Question 3a

Next, we wanted to assess whether happiness ratings were affected by whether the participants completed the programme or not. Below in Figure 13 you can see the spread of participants' happiness scores divided by those who completed the programme and those who did not against the variable of season.

```{r q3a, include=FALSE}
#applying to the full dataset once more with our established baseline model.
couchto5k <- couchto5k %>%
  mutate(dropoutmeasure = ifelse(week_stopped == 9, "Completed", "Incomplete")
  )

couchto5k$dropoutmeasure <- as.factor(couchto5k$dropoutmeasure)

baselinedropout <- lm(happiness ~ season + dropoutmeasure, data = couchto5k)
plot(baselinedropout)
plot(baselinedropout, which = 4) #extracting entries only increased the Cook's Distance of other entries, so none were extracted.
summary(baselinedropout)
```

```{r plot q3a plot creation, include=FALSE}
q3a_plot <- ggplot(data = couchto5k, aes(x = happiness, y = season, fill = season)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Accent") +
  theme(legend.position = "none") +
  facet_wrap(~dropoutmeasure) +
  labs(x = "Happiness (0-100)", y = "Season", caption = "Figure 13")
```

```{r plot q3a, fig.align='center'}
q3a_plot 
```
```{r q3a summary, include = FALSE}
summary(baselinedropout) #not dropping out (completing the programme) has a significant effect on happiness when participants partook in spring, autumn and winter. Let's look at the assumptions.
coefficients(baselinedropout)
plot(baselinedropout) #all look fairly good. Will assume normality here. Let's see how dropout predicts happiness without the factor of season:
t3atestmod <- lm(happiness ~ dropoutmeasure, data = couchto5k)
summary(t3atestmod)#still significant here, and just like our baseline-integrated model, there is no significant effect on happiness by dropping out of the programme. We can assert then perhaps that in our sample of participants, those who completed the programme had higher happiness scores on average, but those who did not complete the programme were not severely affected in average happiness by dropping out. A happy set of people? 
t3amod <- tab_model(baselinedropout, title = "Table 5: Model predicting happiness by season and programme dropout")
t3amod

#making a null model for my anova

null_mod2 <- lm(happiness ~ 1, data = couchto5k)
anova(null_mod2, baselinedropout)
```

Tests of linearity were performed, and the residuals were checked for assumptions of normality, homogeneity of variance, and independence. No abnormalities were identified. We applied this model to our sample of `r nrow(couchto5k)` participants. With our new model, our intercept is now predicting the average happiness of participants who took part in the programme in spring, and completed it without dropping out. The intercept itself was significant at $p$ < 0.05, with an estimate of 48.26 for average happiness. For participants who completed the programme in summer, the estimate for average happiness increased by 1.56, but this was not a significant increase, $p$ = 0.844. This would suggest that participants were not, on average, significantly happier when comparing against our intercept of participants who fully completed the programme in spring. For participants who completed the programme in autumn, there was a significant decrease in happiness by 30.16, $p$ <0.05. This would suggest that the average happiness of participants who completed the programme fully in autumn were significantly less happy on average than those who took part in spring or summer. For participants who completed the season in winter, average happiness decreased significantly by 26.39 points, $p$ < 0.05. Again, this would suggest that the average happiness of participants who completed the programme fully in winter were significantly less happy on average than those who took part in spring or summer. Controlling for all other seasons, participants who dropped out of the programme and participated in spring did not have a significant change in average happiness, increasing on average by 9.11 points, $p$ = 0.205.

Our new model only explained around 12% of the variance in our data, with the adjusted $R^2$ = `r summary(baselinedropout)[9]`, however, our model was tested for the overall significance of the interaction using an F-test, which was significant: F(`r summary(baselinedropout)$fstatistic[2]`, `r summary(baselinedropout)$fstatistic[3]`) = `r summary(baselinedropout)$fstatistic[1]`, $p$ < 0.05. The full output of our model can be found below in Table 5. In order to test whether our new model explains more over a null model, an ANOVA was performed. Our ANOVA returned a significant value for our season and dropout exploratory model, indicating that our model improves over the null and explains more of the variance in our sample, F(4,130) = 5.45, $p$ < 0.05.

```{r q3a tab, fig.align='center'}
t3amod
```

```{r q3a test, include=FALSE}
t3atestmod <- lm(happiness ~ dropoutmeasure, data = couchto5k)
summary(t3atestmod)
plot(t3atestmod) # just some normality tests here, everything looks fairly normal. 
anova(t3atestmod, baselinedropout) 
anova(null_mod2, t3atestmod)
```
To test whether dropout alone would predict happiness outcomes, a simple linear regression model was constructed that predicted happiness by dropout. An ANOVA was also run to compare our baseline model plus dropout against our new model predicting happiness just by dropout. 
Our intercept of participants who completed the programme had a significant average happiness of 46.04, $p$ < 0.05. For participants who dropped out of the programme, average happiness increased by 0.63 points, but was an insignificant change at $p$ = 0.91. Against a null model, a model incorporating both season and dropout significantly explained more of the variance in our sample above and beyond a null model, F(3,130) = 7.26, $p$ < 0.05. 

We can reasonably assume that programme completion significantly predicts average happiness outcomes, especially in the months of spring, autumn and winter. However, the difference in average happiness scores was not significant, indicating that our participants' average happiness was not affected by whether they completed the programme or not. This was confirmed by an ANOVA comprising a null model that we ran against a model only predicting dropout as a determinant for happiness outcomes: F(1,130) = 0.01, $p$ = 0.91. Because of this, I will not be carrying the dropout variable forward in my next model.


## Question 3b

Next, we want to investigate whether health will affect happiness by integrating it into our existing model. Below in Figure 14 is a scatterplot showing the relationship between happiness outcomes and health, where we can see a very small positive upward trend.
```{r q3b, include=FALSE}

baselinehealth <- lm(happiness ~ season:health, data = couchto5k)
summary(baselinehealth) #health metric does not influence happiness to a significant degree
plot(baselinehealth)
plot(baselinehealth, which = 4)
modifiedcouchto5k <- couchto5k[-c(52,105,117),] #some entries removed for Cook's Distance
baselinehealth <- lm(happiness ~ season:health, data = modifiedcouchto5k)
plot(baselinehealth) #plots looking a lot better now. 
summary(baselinehealth)

t3bmod <- tab_model(baselinehealth, title = "Table 6: Model predicting happiness by season and health metric")
```

```{r q3b plot, fig.align='center'}
ggplot(data = couchto5k, aes(x = happiness, y = health)) +
  geom_point(size = 3, color="#69b3a2") +
  geom_smooth(method = lm) +
  theme_minimal() +
  labs(x = "Happiness (0-100)", y = "Health (0-100)", caption = "Figure 14")
```
Our model, which is summarised in Table 6 below, integrates health into our existing happiness model. Three entries were removed due to a violation of Cook's Distance resulting in a total count of `r nrow(modifiedcouchto5k)` participants. We then we re-ran our tests of linearity, and the residuals were checked for assumptions of normality, homogeneity of variance, and independence. No abnormalities were identified.
We ran an interaction for this model instead of adding it as a singular predictor, `season:health`. This investigates the interaction of both season and the health metric in determining happiness outcomes. Altogether however, only one significant value was rendered from this interaction, meaning that average happiness was not significantly affected by the interaction of health and season, other than summer where happiness increased by 0.50, $p$ = 0.05. The model itself was significant, but this was likely due to the inclusion of our already significant season predictor, F(`r summary(baselinehealth)$fstatistic[2]`, `r summary(baselinehealth)$fstatistic[3]`) = `r summary(baselinehealth)$fstatistic[1]`, , $p$ < 0.05. Additionally, our model explained around 14% of the variance in our model, $R^2$ = `r summary(baselinehealth)[9]`. 

```{r q3b tab, fig.align='center'}
t3bmod
```

```{r q3b test, include=FALSE}
baselinehealthtest <- lm(happiness ~ 1 + health, data = modifiedcouchto5k)
summary(baselinehealthtest)
plot(baselinehealthtest, which = 4) #eliminating outliers only cropped up more, left it in since this is only a test.
null_mod3 <- lm(happiness ~ 1, data = modifiedcouchto5k)

#ANOVAS
anova(null_mod3, baselinehealth)
anova(null_mod3, baselinehealthtest)
```
We individually tested health in a separate linear model to test its utility outside of a model already incorporating season. As an individual predictor, health was not a significant predictor of average happiness, increasing the estimate by 0.52, $p$ = 0.053. We then evaluated our models against a null model using an ANOVA. The ANOVA of our interactive season and health model against the null was significant, F(4,127) = 6.91, $p$ < 0.05. Again, this was likely due to the fact that our model included the already significant predictor of season. Testing a model of only health as a predictor of happiness against the null rendered an insignificant result, F(1,130) = 3.81, $p$ = 0.053. Thus, we will not be including the health metric as a predictor of happiness going forward.

## Question 3c

We now want to investigate the hypothesis that the effects of good health are amplified by the feeling of acting healthily, such that the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier. We will investigate this by building onto our model. Below in Figure 15 is a scatterplot of happiness against the week that participants stopped the programme. It would appear that happiness was not severely implicated by the week that participants dropped out, but to test this against the health metric, we will make a multiple linear regression model. For this particular model, we investigated the interaction between health and week in which participants stopped the programme, `week_stopped:health`.
```{r q3c, include=FALSE}
summary(couchto5k$week_categories)
baselineweekstop <- lm(happiness ~ season + week_stopped:health, data = modifiedcouchto5k)
plot(baselineweekstop)
plot(baselineweekstop, which = 4)
summary(baselineweekstop)

t3cmod <- tab_model(baselineweekstop, title = "Table 7: Model predicting happiness by season, health metric and week stopped the programme")
```

```{r q3c plot, fig.align='center'}
ggplot(data = modifiedcouchto5k, aes(x = week_stopped, y = happiness)) +
  geom_point(size = 3, color="#E69F00") +
  geom_smooth(method = lm) +
  theme_minimal() +
  labs(x = "Week Stopped Programme", y = "Happiness (0-100)", caption = "Figure 15")
```
Our model tested a total of `r nrow(modifiedcouchto5k)` participants. Tests of linearity were performed, and the residuals were checked for assumptions of normality, homogeneity of variance, and independence. No abnormalities were identified. The interaction of the health metric and the week in which the programme was stopped did not have a significant effect on average happiness outcomes. The estimate for average happiness only increased by 0.03 points when accounting for health and week stopped, with a $p$ = 0.053. This indicates that for every week passed, and every point of health allocated to the health metric, average happiness did not increase significantly.
Overall, the model explained around 17% of the variance in our sample, $R^2$ = `r summary(baselineweekstop)[9]`. The model itself was significant, but as with our model in 3b, this may be due to the fact that our significant season predictor was included: F(`r summary(baselineweekstop)$fstatistic[2]`, `r summary(baselineweekstop)$fstatistic[3]`) = `r summary(baselineweekstop)$fstatistic[1]`), $p$ < 0.05.
A summary of this model can be found below in Table 7.

```{r q3c table, fig.align='center', }
t3cmod
```

```{r q3c test, include=FALSE}
baselineweekstoptest <- lm(happiness ~ season + week_stopped, data = modifiedcouchto5k)
summary(baselineweekstoptest)
plot(baselineweekstoptest)
#week as a single predictor
baselineweekstoptest1 <- lm(happiness ~ week_stopped, data = modifiedcouchto5k)
summary(baselineweekstoptest1)
plot(baselineweekstoptest1) #resids look fine for a test
#running anovas to test the model
anova(null_mod3, baselineweekstop)
anova(null_mod3, baselineweekstoptest)
```
Considering the health metric was not significant in our previous model (3b), we thought it may be pertinent to run a model with week stopped as a predictor in our baseline, to investigate its utility as a singular predictor. However, the week in which participants stopped was not a significant predictor, and for every week that a participant decided to drop out of the programme, average happiness only increased by 1.23 for participants in spring, with a $p$ = 0.32. This model again was significant, but was likely due to the significant season predictors, F(`r summary(baselineweekstoptest)$fstatistic[2]`, `r summary(baselineweekstoptest)$fstatistic[3]`) = `r summary(baselineweekstoptest)$fstatistic[1]`, $p$ < 0.05. Finally, week was investigated as a singular variable predicting happiness outcomes, but this was again insignificant, with every week passed before dropping out only reducing average happiness by 0.38 points, $p$ = 0.66. The overall model here was also insignificant, F(`r summary(baselineweekstoptest1)$fstatistic[2]`, `r summary(baselineweekstoptest1)$fstatistic[3]`) = `r summary(baselineweekstoptest1)$fstatistic[1]`, $p$ = 0.66.

Overall, we can conclude that the week in which participants dropped out, and the interaction of this with health, had no significant implications for happiness outcomes.


## Question 3d

So far, we have ran several models to test the causes of happiness in our model. Each of our models contained our baseline, which consisted only of season as a predictor. Thus, our baseline model is as follows: `lm(happiness ~ season)`. 
First, we wanted to investigate whether participant happiness was affected by whether they completed the programme or not. In other words, whether dropout affected our participants’ average happiness. We ran a model including dropout as a predictor, `lm(happiness ~ 1 + season + dropout)`. When factoring this in, the intercept now became participants who completed the programme fully in spring without dropping out. This on its own was significant, along with autumn and winter. These values can be viewed in Table 5. Additionally, there was no significant difference in participants who completed the programme in summer. This would suggest that the average happiness scores of participants who completed the programme were higher on average in both spring and summer, and significantly lower in autumn and winter. Our model overall was significant and explained around 12% of the variance in our sample. However, on its own, dropping out was not a significant predictor of happiness. As can be visualised in Figure 13, happiness scores appeared to be distributed relatively evenly across each season regardless of whether they dropped out of the programme or not. Comparing our models by running ANOVAS also revealed that dropout on its own was not a significant predictor of happiness above a null model, thus confirming that regardless of whether or not participants completed the programme, season explained more of the variance in average happiness above dropout. 
Next, we wanted to investigate whether the health metric that participants completed prior to the study had any effect on their average happiness scores. Again, we ran a model with our baseline of season, but left our dropout variable since it proved to be insignificant, `lm(happiness ~ season:health)`. We investigated health as an interaction first to observe the interaction of health and season combined upon average happiness. This yielded only one significant value in summer, which just qualified for our threshold of significance, $\alpha$ = 0.05. This would suggest that with every point of health allocated, the only significant change in happiness outcomes was in summer, with an increase of 0.17 in average happiness. Our model itself was again significant, and explained 14% of the variance in our sample which improved upon our last model incorporating dropout. However, we wanted to investigate whether the health metric alone in predicting happiness would have any significant effects, or whether the presence of season in our baseline was causing our significant values to arise. Thus, we created a model of `lm(happiness ~ health)`. As an individual predictor, health was not a significant predictor of happiness, and an ANOVA against our null model confirmed that having health as a predictor did not improve over the null. Because of this, we can conclude that health does not have a significant effect upon happiness outcomes. Again, it would appear that the season participants took part in was the only significant predictor of average happiness. 
Finally, we wanted to investigate the hypothesis that the effects of good health are amplified by the feeling of acting healthily, such that the happiness of participants who got further along in the programme may be more affected by the health metric than those who stopped earlier. We confirmed in our earlier investigation that the health metric was not a significant predictor of happiness, but decided to investigate the interaction of week and health to address this question properly. Thus, our model was as follows: `lm(happiness ~ season + week_stopped:health)`. It was discovered that for every week passed and every point allocated to the health metric, average happiness increased insignificantly by 0.03 points, indicating that it was not a significant predictor of overall happiness outcomes. Investigating how long participants got along in the programme also did not affect happiness scores to a significant degree when investigating the predictor individually, with every week passed only reducing happiness scores by 0.38, an insignificant reduction, $p$ = 0.66. ANOVAs were again run to test the efficaciousness of these models, and the significance arose once more due to the inclusion of seasonal predictors. We can therefor conclude that neither the health metric, week stopped, or interaction between these predictors had any significant overall effects on our sample’s average happiness.
To summarise, seasons were the only significant predictor of happiness, regardless of our health metric, weeks in the programme, and dropout rate. It is particularly interesting that participant dropout was not a significant predictor of overall happiness. The overarching predictor of season was the largest determinant, inferring that regardless of which season you dropped out of, your happiness did not vary substantially. Self-perceived health was also expected to have some sort of significant effect, especially its interaction with weeks into the programme, but participants were largely unaffected, even when investigating these variables individually. Our one unique finding in summer was interesting, indicating that there was some form of effect occurring here. But after investigating health as a singular predictor, it is likely that this significance arose because of the effect from season, rather than the health metric having any particularly significant effects. It was also expected that the week in which individuals stopped may at least have an effect on happiness, but this again proved not to be the case. Investigating this as an individual predictor also did not rear any significant results when factoring out season, inferring that average happiness was not implicated by the week at which participants decided to end the programme. Overall, season is our one primary predictor of participant happiness.


# Question 4

Next I will be creating a plot for the funders of this programme, including only the participants who completed the full 9-week programme.
```{r q4 plot creation, include=FALSE}
couchto5ksubset <- subset(couchto5k, dropoutmeasure == "Completed")

funderplot <- ggplot(data = couchto5ksubset, aes(x = happiness, y = season, fill = season)) +
  geom_boxplot() +
  theme_bw() +
  theme(legend.position = "none") +
  facet_wrap(~city) +
  labs(x = "Happiness (0-100)", y = "Season", caption = "Figure 16: Funder Presentation Plot")
```

Below is a plot of the average happiness of this subset of participants, with their average happiness, grouped by season and city. I believe that the funders will find this plot useful.

```{r q4 funder plot, fig.align='center'}
funderplot
```

# Question 5
## Predictors of dropout

## Question 5a
In order to predict the likelihood of dropping out (at all), we will construct a generalised linear model. First, we are going to be looking at the associations between our variables using a large correlational matrix that is displayed below.
```{r q5a}
pairs.panels(couchto5k[2:9]) #looking at the correlations, I want to organise my glm with the most highly correlated predictors to dropout 
```
Above, we can see that the most powerful predictors with `week:stopped` are season, self-motivation and age. Thus, we will first be constructing a glm to investigate these against our binary dropout variable.


```{r q5a contrusting the glm, include=FALSE}
contrasts(couchto5k$dropoutmeasure)
#I want to change the reference level to those who did not complete the programme, the "dropout group"
contrasts(couchto5k$dropoutmeasure) <- cbind(Incomplete=c(1,0))

couchto5k <- couchto5k %>%
  mutate(Dropout = ifelse(week_categories == 3, 0, 1)
  )

glmmod1 <- glm(dropoutmeasure ~ season + selfmot + age, data = couchto5k, family = "binomial")
summary(glmmod1)

glmmod2 <- glm(dropoutmeasure ~ selfmot + season, data = couchto5k, family = "binomial")
summary(glmmod2)
plot(glmmod2, which = 4) #outliers identified, need to extract from data 

couchto5k <- couchto5k[-c(6,75,3),]
glmmod2 <- glm(dropoutmeasure ~ selfmot + season, data = couchto5k, family = "binomial")
summary(glmmod2)
plot(glmmod2, which = 4) #outliers identified, however upon extracting these more popped up, so I will refrain from removing these. 
```
Upon running a model of `glm(Dropout ~ selfmot + season + age)`, age did not prove to be a significant predictor of dropout outcome, $p$ = 0.35. We then removed age, and included a model of only season and self-motivation as the predictors for dropout, `glm(Dropout ~ selfmot + season)`. Three entries were removed due to a violation of Cook's Distance resulting in a total count of `r nrow(couchto5k)` participants. We then we re-ran our tests of linearity, and the residuals were checked for assumptions of normality, homogeneity of variance, and independence. No abnormalities were identified. Season and self-motivation were both significant predictors for our generalised linear model. The only predictor this was not significant for was autumn, with a $p$ = 0.99.

## Question 5b

```{r anova on model, include=FALSE}
anovamod <- anova(glmmod2, test = "Chisq") #specifying a chi-squared test to evaluate model as it acts like a F ratio for the linear model.
anovamod
```
A $\chi^2$ goodness of fit test and ANOVA (analysis of deviance) was performed on the generalised linear model to evaluate our model. They revealed that the addition of season for our model has explained a greater deal of the deviance for dropout ($p$ < 0.05), with a deviance score of 116.5 and a residual deviance of 51. This high deviance and low residual deviance for season is good, as it informs us that we are able to explain a greater deal of the deviance over the null model to a significant degree with the inclusion of season. Self-motivation had a deviance of 12.6 and a residual deviance of 168. Although the deviance is much higher than the residual, the amount of deviance that self-motivation explains in our model is still significant ($p$ < 0.05), indicating that it explains more of the deviance over a null model.

Overall, season appears to be the most significant variable in predicting dropout, and accounts for a great deal of the deviance in our data. Self-motivation follows, and although it does not explain deviance to the same degree, it is nonetheless significant. We can conclude that the likelihood of dropout is determined by both season and self-motivation. The effect of self-motivation is explored more in 5c. A graph on the relationship between dropout, season and self-motivation can be seen in Figure 17 below.

```{r q5b graph, fig.align='center', warning=FALSE}
ggplot(data = couchto5k, aes(x = selfmot, y = season, fill = season)) +
  geom_boxplot() +
  theme_bw() +
  theme(legend.position = "none") +
  labs(x = "Self-Motivation (5-35)", y = "Season", caption = "Figure 17") +
  facet_wrap(~dropoutmeasure)
```

## Question 5c

```{r q5c, include=FALSE}
couchto5k <- couchto5k %>%
  mutate(Dropout = ifelse(week_categories == 3, 0, 1)
  )

dropoutselfmotplot <- ggplot(data = couchto5k, aes(x = selfmot, y = Dropout, color = Dropout)) +
  labs(x = "Self-Motivation (5-35)", y = "Probability of Dropout", caption = "Figure 18: Probability of dropout and self-motivation") +
  geom_jitter(size = 3, width = 0, height = .2, alpha = .2, na.rm = TRUE) +
  scale_y_discrete(breaks = seq(0, 1, by=.2)) +
  theme_bw()+
  geom_smooth(method = "glm", method.args = list(family = "binomial"))
```
Lastly, I will produce a graph representing the probability of quitting as a function of how self-motivated the participants were. Dropout has been coded as 1, with no dropout (programme completion) coded as 0. As we can see, as self-motivation increases, the probability of dropping out decreases. Thus, the self-motivated you are, the less likely you are to drop out of the 'Couch to 5k' programme. So, highly motivated individuals are less likely to drop out, whilst poorly-motivated individuals are more likely to drop out. The graph showcasing this probability can be found below, in Figure 17.

```{r funder plot, fig.align='center', warning=FALSE}
dropoutselfmotplot
```


