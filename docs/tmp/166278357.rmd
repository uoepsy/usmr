---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
params:
  examnumber: B199218
---

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# this line means all numeric output gets rounded to 3 d.p.
options(digits=3)
#I added the option to configure plots exactly how I like them :) 
knitr::opts_chunk$set(fig.align = "center")
# load any other packages that you require here:
library(tidyverse)
library(psych)
library(sjPlot)
library(patchwork)
library(stargazer)
library(kableExtra)


# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0

Before beginning data analysis or even cleaning, it is worth to visualise the data just to see if anything looks particularly unsual. This will be used to guide data cleaning procedures as well as later data analysis.

```{r descriptives, fig.width= 14}
# Code will not be shown from this chunk (because we set echo = FALSE in the very first chunk)
# the output from this code will be shown. 

#Visualisation - basic plots
couchto5k %>% 
  select(age, accountability, selfmot, health, happiness) %>% 
  plot()

```

Two unusual values in age (unlikely a 120 year old will be doing a CouchTo5k) 
two unusual values in self_mot (-90 where the rest are around 20) 

The descriptives for this dataset can be found in the table below. 

**Table 1** 
*Table to show the descriptives of the dataset* 

```{r}

describe(couchto5k) %>% 
  select(-trimmed, -mad, -skew, -kurtosis, -se) %>% 
   kable(col.names = c("Variables", "N", "Mean", "SD", "Median", "Min", "Max", "Range"), align = "c") %>% 
  kable_styling(full_width =T)
  
```


One participant also finished the program in week 13. 

There is no need to remove outliers blindly. Considering this, looking at the participants who are 100 years old, it can be seen that the rest of the data is normal for other values, and I am going to assume that the participants just mistakenly wrote a 1 in-front of their age (1 is close to 2 after all). These will be amended and included.

For the self_mot values, I do not understand why there are two values that are -99, and it is unclear whether this is meant to be NA or not.

Likewise, for the participant who finished the programme in week 13, I do not understand how this value has come to be.

Because I cannot ascertain a plausible reason for those scores outside of the allowed range, I have decided to take a conservative approach in data analysis and exclude these participants by filtering the data by possible scale outcomes.

Apart from this, some participants have misspelled "autumn" as "autunm", this will be amended for consistency.

```{r cleaning}
# Neither output nor code from this chunk will be shown in the compiled document. 

#filtering all invalid that are below the valid response range

couchto5k <- couchto5k %>% 
  filter(selfmot > 0 & selfmot  < 35) %>% #filtering impossible values for self_mot
  filter(week_stopped < 10) #fitered for impossible ending date values

#adjusting invalid age responses - explain in text

couchto5k$age[couchto5k$age > 100] <- couchto5k$age[couchto5k$age > 100] - 100

#Autumn misspelling

couchto5k <- couchto5k %>% 
  mutate(season = replace(season, season == "autunm", "autumn"))

#useful values for writing up and general

couchto5k <- couchto5k %>% 
  mutate(season = factor(season, levels = c("spring", "summer", "autumn", "winter" ))) # re-leveled the seasons, purely for aesthetic reasons 

couchto5k <- couchto5k %>% 
  mutate(week_stopped = as.factor(week_stopped)) %>% 
  mutate(prog_fin = as.factor(ifelse(week_stopped == 9, 1, 0)))

participant_total <- nrow(couchto5k)


```

This is how the descriptives look after data cleaning.

```{r descriptives plots ,fig.width = 14}
# Code will not be shown from this chunk (because we set echo = FALSE in the very first chunk)
# the output from this code will be shown. 

couchto5k %>% 
  select(age, accountability, selfmot, health, happiness) %>% 
  plot()

season_plot <- couchto5k %>% 
  ggplot(aes(season, fill = season)) + 
  geom_bar() + 
  labs(x = "City" , y = "Number of Participants") + 
  theme_classic() +
  scale_fill_brewer(palette = "GnBu")
  #two misspellings of autumn - will change

city_plot <- couchto5k %>% 
  ggplot(aes(city, fill = city)) + 
  geom_bar() +
  labs(x = "Season" , y = "Number of Participants") + 
  theme_classic()

city_plot + season_plot
```
------------------------------------------------------------------------

# Question 1

## Question 1a

In an earlier nationwide survey, researchers found that 45% of participants abandoned the programme before the halfway point in week 5, and a further 10% gave up before the end of the programme. Is the data in the sample you have been given in line with data from the earlier survey? Once you have created a suitable variable to map to the information in the question, you should be able to answer this using a simple statistical test.

``` {r q1a}
abandonment_data <- couchto5k %>% 
  group_by(week_stopped) %>% 
  summarise(number = n()) %>% #grouping number of participants by week of completion/drop-out
  mutate(percentage = (number/participant_total) * 100) #calculating percentage of drop out per week

#calculating and assinging the percentage of participants that drop out before and after the half way point, as well as who have finished 

before_half <- abandonment_data$percentage[1:4]

after_half <- abandonment_data$percentage[5:8]

finished <- abandonment_data$week_stopped[9]

```


In total,`r sum(before_half)`% of participants have abandoned the program before the halfway point in week five, and `r sum(after_half)`% of participants have abandoned the program after the half-way point which differs from the earlier nationwide survey data.

A t-test was conducted to examine whether the difference between the two samples was statistically significant. A Shapiro-Wilk test of normality was also conducted to check for normality. No violations of normality were detected. Regardless, equality of variance was assumed to be *FALSE*, due to tests using Leven's assumption having less power and will therefore fail to reject the null-hypothesis of variances being equal (even when they differ).

```{r, include = FALSE}

#shapiro.test(before_half) 
#shapiro.test(after_half)

beforeh_ttest <- t.test(before_half, mu = 45, var.equal = FALSE)
afterh_ttest <- t.test(after_half, mu = 10, var.equal = FALSE)

```

The results of the t-test suggest that there was a statistically significant difference in the percentage of participants who abandoned the program before the halfway point (*t* (`r beforeh_ttest$parameter`) = `r beforeh_ttest$statistic`, *p* < .001), as well as after the halfway point (*t* (`r afterh_ttest$parameter`) = `r afterh_ttest$statistic`, *p* < .001) of the current dataset, and the results of the previous nationwide survey. 

## Question 1b

Using the same three categories (stopped before week 5, stopped after week 5, completed), examine whether the patterns of attrition rates differ by city.

**Figure 1**

*Bar Chart to Show Differences in Attriton Rates by City*

```{r q1b, echo = FALSE, message = FALSE}

#creating data-frame with relevant numbers
city_drop <- couchto5k %>% 
  group_by(week_stopped, city) %>% 
  summarise(number = n())
  
edi_drop <- city_drop %>% 
  filter(city == "Edinburgh") # subsetting the df with participants only from Edinburgh

#calculating drop-outs for before and after halfway, as well as finished. Repeat for each city

edi_bhalf <- sum(edi_drop$number[1:4]) 
edi_ahalf <- sum(edi_drop$number[5:8])
edi_finished <- edi_drop$number[9]
edi_total <- sum(edi_drop$number[1:9])
  

glas_drop <- city_drop %>% 
  filter(city == "Glasgow")
  
glas_bhalf <- sum(glas_drop$number[1:4], na.rm = TRUE)
glas_ahalf <- sum(glas_drop$number[5:6], na.rm = TRUE)
glas_finished <- glas_drop$number[7]
glas_total <- sum(glas_drop$number[1:7], na.rm = TRUE)

  

```

```{r q1b graph, echo = FALSE, fig.align="center", ,fig.width = 14}

#visualising differences in attrition rates by city
city_drop %>% 
  ggplot(aes(week_stopped, number, fill = city)) + 
  geom_col() + 
  labs(x = "Week Stopped" , y = "Number of Participants", title = "Attrition Rates by City") + 
  facet_wrap(~city) + 
  theme_minimal()

```


Due to the differences in number of participants between the two cities (`r couchto5k$city[couchto5k$city == "Edinburgh"] %>% length()` participants from Edinburgh and `r couchto5k$city[couchto5k$city == "Glasgow"] %>% length()` from Glasgow), comparisons were conducted as proportions rather than sums. The data suggests that:

The proportion of participants from Edinburgh (`r edi_bhalf/edi_total* 100`%) who drop out before the half way mark is lower compared to participants from Glasgow (`r glas_bhalf/glas_total* 100`%). 

The proportion of participants from Edinburgh (`r edi_ahalf/edi_total* 100`%) who drop out after the half way mark is lower compared to participants from Glasgow (`r glas_ahalf/glas_total* 100`%).

A higher proportion of participants from Edinburgh (`r edi_finished/edi_total * 100`%) finished the program compared to participants from Glasgow (`r glas_finished/glas_total * 100`%).

## Question 1c

Do the average ages of participants who commenced the programme differ by city?

**Figure 2**

*Bar Chart Showing Differences in Age by City*

```{r q1c, echo = FALSE}

#visualising difference in age by city
couchto5k %>% 
  select(age, city) %>% 
  group_by(city) %>% 
  summarise(mean = mean(age)) %>% 
  ggplot(aes(city, mean, fill = city)) +
  geom_col(show.legend = FALSE) + 
  labs(x = "City", y = "Mean Age of Participants", title = "Mean Age of Participants by City") +
  theme_classic() 

age_ttest <- t.test(x = couchto5k$age[couchto5k$city=="Edinburgh"], y = couchto5k$age[couchto5k$city=="Glasgow"])

```

The mean age differs between the two cities, with participants in Edinburgh reporting an higher mean age (`r mean(couchto5k$age[couchto5k$city=="Edinburgh"]) `) compared to participants in Glasgow (`r mean(couchto5k$age[couchto5k$city=="Glasgow"]) `)

The results of a Welch Two Sample t-test suggest this difference is not statistically significant with *t* (`r age_ttest$parameter`) = `r age_ttest$statistic`, *p* = `r age_ttest$p.value`

------------------------------------------------------------------------

# Question 2

## Question 2a

Are participants' happiness ratings affected by the season they were interviewed in? Describe the way in which season influences happiness outcomes.

**Figure 3 & 4**

*Bar Chart and Violin Boxplot to Show Mean Differences in Happiness by Season*

```{r q2a graph , echo = FALSE, fig.align="center", ,fig.width = 14}

plot3 <- couchto5k %>% 
  group_by(season) %>% 
  summarise(mean_happiness = mean(happiness)) %>% 
  ggplot(aes(season, mean_happiness, fill = season)) + 
  geom_col(position = position_dodge(.9)) +
  labs(x = "Season", y = "Mean Happiness Score", title = "Mean Happiness Scores by Season") + # centre title
  theme_classic() +
  scale_fill_brewer(palette = "GnBu")

plot4 <- couchto5k %>% 
  select(happiness, season, health) %>% 
  ggplot(aes(x = season , y = happiness, colour = season)) + 
  geom_jitter(alpha = .3, show.legend =  FALSE) +
  geom_violin(trim = FALSE, show.legend = FALSE, alpha = .4) + #violin plots :) 
  geom_boxplot(width = .2, show.legend = FALSE, alpha = .7)+
  coord_cartesian(ylim = c(0, 100)) + 
  labs(x = "Season", y = "Happiness Scores", title = "Mean Happiness Scores") + 
  theme_classic() +
  scale_fill_brewer(palette = "GnBu")
  

plot3 + plot4
```

As can be seem from the graph, there are some differences between the mean scores reported on happiness depending on the season, particularly with summer reporting the highest mean score of happiness (`r mean(couchto5k$happiness[couchto5k$season == "summer"])`) and winter reporting the lowest (`r mean(couchto5k$happiness[couchto5k$season == "winter"])`).

To test whether the season in which a participant was interviewed affected their happiness score, a categorical linear regression analysis was conducted. 

The results suggest that the seasons significantly predict change in happiness scores. The results can be seen in Table 1.

**Table 1**

*Results of Categorical Linear Regression Analysis of the Effects of Season on Happiness*

```{r q2a linear regression, echo = FALSE, message = FALSE, error = FALSE}
lm1 <- lm(happiness ~ season, data = couchto5k)

#plot_model(lm1, type = "pred")

tab_model(lm1)

```



Participants in spring reported a mean score of `r mean(couchto5k$happiness)` on the happiness scale. 

From here, being interviewed in the Summer predicted an increase of 4.06 units on the happiness scale, however, this was not statistically significant (*p* = .508)

Being interviewed in the Autumn predicted a decrease of 19.89 units on the happiness scale, however, this was not statistically significant (*p* = .057). 

Being interviewed in the Winter predicted a decreas of 23.13 units on the happiness scale. This was statistically significant (*p* = .009). 

The season in which a participant was interviewed explained 8.8% (R^2 = 0.088) of the variance in happiness scores. 

The F-statistic (F(3,128) = 4.11, p = .008) suggests that the model fits the data weakly, but significantly better than the null mean model.  

## Question 2b

Accounting for any effects you discovered in (2a), is happiness affected by age?

A multiple regression analysis was used to assess the ability of seasons with addition to age to predict happiness test scores. The results suggest that seasons, but not age significantly predict changes in happiness scores. The results can be seen in table 2. 

**Table 2**

*Results of Multiple Linear Regression Analysis of the Effects of Season and Age on Happiness*


```{r q2b, message = FALSE, warning = FALSE}
lm2 <- lm(happiness ~ season + age, data = couchto5k)

#plot_model(lm2, type = "pred")

tab_model(lm2)

```



The effects of season on happiness remained largely unchanged by the addition of age to the model. 

Age was an insignificant predictor of happiness (*p* = .776), with a predicted increase of 0.06 units on the happiness scale per year.

A model including the season in which a participant was interviewed alongside age as predictors explained 8.9% (R^2 = 0.089) of the variance in happiness scores. This is 0.1% more than the previous model with just season. 

The F-statistic (F(4,127) = 3.08, p = .0184) suggests that the model fits the data weakly, but significantly better than the null mean model.  

## Question 2c

The models you have built above explore 'baseline' effects; that is, effects that are not of primary interest to the researchers but which might affect the outcome variable of happiness. For use in question 3, pick a specific baseline model and justify why you are using this.

```{r q2c}

lm1 <- lm(happiness ~ season, data = couchto5k)

```

Age was an insignificant predictor of happiness which explained an additional 0.1% of variance. Because of this, I am hesitant to include it in our baseline model, and have decided to use the following linear model only using season. 

To ensure this model was fit to be used as a baseline, regression diagnostics were conducted to check for assumptions. No violation of assumption was found. 


```{r q2c assumption check, include = FALSE}

plot(lm1)

``` 

Because of the above, I am going to be using *lm(happiness ~ season, data = couchto5k)* as my baseline model for the following questions. 

------------------------------------------------------------------------

# Question 3

## Question 3a

Building on your baseline model, are participants' happiness ratings affected by whether or not they completed the programme? Describe the way in which programme completion influences happiness outcomes.

For the purpose of analysing whether participants' happiness ratings were by whether or not they completed the programme, participants were  grouped on whether they completed (week_stopped ==9) or did not complete (week_stopped != 9) the programme. 

**Table 3**

*Results of Multiple Linear Regression Analysis of the Effects of Season and Week Stopped on Happiness Scores*

```{r q3a, warning = FALSE}

couchto5k <- couchto5k %>% 
  mutate(week_stopped = as.numeric(week_stopped))

lm3 <- lm(happiness ~ season + prog_fin, data = couchto5k)

#plot_model(lm3, type = "pred")

tab_model(lm3) 

#lot(lm3) for assumption checks

```



The baseline model with the addition of whether or not the participant finished the program was not a significant predictor  of happiness scores. 

The model with season and program completion suggests that finishing this program increases scores in happiness by 13.46 units compared to the intercept of average happiness of a participant interviewed in spring. However, this was not statistically significant (*p* = .079) 

Furthermore, this model explained 11% (R^2 = .11) of the variance in the data, which is 3% more than in the baseline model 

The F-statistic (F(3.92) = 3.08, p = .005) suggests that the model fits the data weakly, but significantly better than the null mean model.  

## Question 3b

Building on the analysis in (3a), is happiness additionally affected by the "health metric"?

**Table 4**

*Results of Multiple Linear Regression Analysis of the Effects of Season, Week Stopped, and Health on Happiness Scores*


```{r q3b}

lm4 <- lm(happiness ~ season + prog_fin + health, data = couchto5k)

#plot_model(lm4, type = "pred")

tab_model(lm4)

```



The baseline model with the addition health metric is not a strong additional predictor of happiness increase. 

The model predicts that for a increase of 1 point on the health metric reduces the happiness score by .19. However, this was statistically insignificant, suggesting that this model was not better at predicting the outcome compared to the null model. 

This model explained 11% (R^2 = 0.114) of the variance in the happiness metric, which is the same as the model without the health metric, suggesting that the health variable does not help explain more variance compared to the previous model.

The F-statistic (F(5,126) = 3.23, p < .001) suggests that the model fits the data weakly, but significantly better than the null mean model.  

## Question 3c

It's been hypothesised that the effects of good health are amplified by the feeling of acting healthily, such that the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier. Building on the model in (3b), can you test this hypothesis?

To investigate the hypothesis of whether the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier, a multiple regression analysis was conducted including season of interview, week stopped and health as predictors. To test the hypothesis, an interaction between week stopped and the health metric was specified. 


**Table 5** 

*Results of Multiple Linear Regression Analysis of the Effects of Season, and the Interaction Between Week Stopped and Health on Happiness Scores*

```{r q3c, echo = FALSE, message = FALSE}

lm5 <- lm(happiness ~ season + week_stopped * health, data = couchto5k) #fitting model

tab_model(lm5) #creating an APA table of results for regression analysis 


```



The season in which a participant was interviewed was still a strong predictor of happiness scores. 

The week stopped and health were also significant predictors.

(see above)

In particular, the further along the programme participants got, the higher the happiness scores reported. 

Health was a weak but significant predictor of happiness, suggesting that increases with the health metric predicted a slow decrease in happiness ratings. 

There was a significant interaction between health and week stopped,  suggesting that the longer the participants lasted in the Couchto5k programme, the more pronounced the effect of health is on happiness. While being statistically significant, this interaction predicted small increases in the happiness metric. 

However, the estimates and significance values provide an unclear picture so in order to explore this interaction further, an interaction plot was made to visualise the model. 

```{r q3c plot, echo = FALSE, fig.align="center", ,fig.width = 14}

#lm5 <- lm(happiness ~ season + week_stopped * health, data = couchto5k)
couchto5k <- couchto5k %>% 
  mutate(week_stopped = as.numeric(week_stopped))


couchto5k %>% 
  select(happiness, season, prog_fin, health, week_stopped) %>%
  group_by(season) %>% 
  ggplot(aes(x = health , y = happiness, colour = week_stopped)) + 
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm", se = FALSE) 
```


This suggests to me that, the interaction would be better interpreted as groups of participants who have not finished and participants who have finished the program. I explored this, along with additional analytical approaches in the section below (*optional*)

------------------------------------------------------------------------

## Q3C - Optional Exploratory Analysis 

When the week stopped variable is classed as a categorical variable, the above graph results in something the following. 

```{r optional analysis q3c, fig.width = 14}

couchto5k <- couchto5k %>% 
  mutate(week_stopped = as.factor(week_stopped))

lm6 <- lm(happiness ~ season + week_stopped * health, data = couchto5k) #fitting model

#plot_model(lm5, type = "pred") #plotting the model

#tab_model(lm6) #creating an APA table of results for regression analysis

couchto5k %>% 
  select(happiness, season, week_stopped, health, prog_fin) %>% 
  ggplot(aes(x = health , y = happiness, colour = week_stopped)) + 
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm", se = FALSE) 

```
What was expected is that participants who quit in week one would display a negative correlation between happiness and health, and with each progressive week in which participants remain in the programme, this correlation would slide towards being positive all the way until the week of completion. 

This is not the case, with participants from week 1 to week 6 displaying strong negative correlations between happiness and health. It is only in week 9, which exhibits a clear positive correlation, which must exert a strong influence on the model. 

Furthermore, when conducting this analysis with the week stopped as a categorical factor,  this model suggests that there is only an interaction between finishing the programme (week_stopped == 9) and health metrics. This can suggest that only finishing the programme and the interaction between finishing the programme and health scores are significant predictor of happiness scores. 

This is very striking, especially when illustrated visually. 

```{r plot q3copt, echo = FALSE}

couchto5k %>% 
  select(happiness, season, week_stopped, health, prog_fin) %>% 
  ggplot(aes(x = health , y = happiness, colour = prog_fin)) + 
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm", se = FALSE) + 
  labs(x = "Health", y = "Happiness") + 
  facet_wrap(~prog_fin)

```

From the plot above, it is very evident that completing the programme significantly changes the relationship between health and happiness. By visually examining this graph, we can see that participants who did not finish the programme show a strong negative correlation between health and happiness, and conversely, participants who completed the programme displayed a strong positive correlation between health and happiness. 

One potential line of analysis is to separate the dataset into participants who have completed the programme and those who have not and investigating separately whether there are differences between predictors. 

```{r q3copt_regression}

week9_only <- couchto5k %>% 
  filter(week_stopped == 9)

lm_opt <- lm(happiness ~ season + health, data = week9_only)

tab_model(lm_opt)
  

```

In this model - which is identical to the one specified in Q3c, with the only difference of only including participants who finished the programme - health was a statistically significant predictor of health, with a single increase on the health metric corresponding to an increase of 1.28 points of happiness (*p* < .001).

```{r q3copt_regression_not_finished}

not_week9 <- couchto5k %>% 
  filter(week_stopped != 9)

lm_optb <- lm(happiness ~ season + health, data = not_week9)

tab_model(lm_optb)
  

```

Oppositely, in participants who did not finish the programme, health was a statistically significant predictor of health, with a single increase on the health metric corresponding to an decrease of 1.92 points of happiness (*p* < .001)


## Question 3d

What can we conclude about the various causes of happiness in our data? Write a brief description of the effects in the model, such as you might find in an academic paper.

To investigate the hypothesis of whether the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier, a multiple regression analysis was conducted including season of interview, week stopped and health metric as predictors. To test the hypothesis, an interaction between week stopped and the health metric was specified. 

The season in which a participant was interviewed was still a strong predictor of happiness scores. Being interviewed in autumn and winter significantly predicted a drop in happiness scores (-30.67, *p* < .001, and -34.96, *p* < .001 respectively) compared to being mean happiness scores in spring. 

The week stopped (-29.38, *p* < .001) and health (-3.72, *p* < .001) were also significant predictors of happiness scores, however, this relationship is not clearly illustrated by the linear regression analysis. 

There was a significant interaction between health and week stopped, which suggests that the longer the participants last in the Couchto5k programme, the more pronounced the effect of health is on happiness. While being statistically significant, this interaction predicted small increases in the happiness metric. 

This can be explained by the differing effects of health on happiness scores between participants who finished and did not finish the programme. The interaction for participants who did finish the program, with happiness of participants who finished were positively affected by the health metric compared to that of those who stopped earlier, who were affected inversely by this effect. Details of this can be found in the optional section of Q3C.

This model explained 41% (R^2 = 0.410) of the variance in the happiness metric, which is more than the previous model,  suggesting that the interaction between the health and week stopped variable does help explain more variance compared to the previous model. The F-statistic (F(6,125) = 14.5, p < .001) suggests that the model fits the data well, and significantly better than the null mean model.

------------------------------------------------------------------------

# Question 4

Create a subset of the data, including only those participants who completed the programme. Create a plot of the average happiness ratings grouped by season and city, that can be used in a presentation to the funders of the project.

**Figure 5**

**Bar Chart to show Mean Happiness Scores by Season and City**

```{r q4, echo = FALSE, message = FALSE, fig.align="center", ,fig.width = 14}
q4 <- couchto5k %>% 
  filter(week_stopped == 9) %>% #filtering for participants who finished the program
  group_by(season, city) %>% #grouping by season and city
  summarise(mean_happinness = mean(happiness)) #summarising the mean happiness scores

q4 %>% 
  ggplot(aes(city,mean_happinness, fill = season)) + 
  geom_col(position = position_dodge(.9)) +
  labs(x = "City", y = "Mean Happiness Score", title = "Mean Happiness Scores by Season and City") + #figure out how to make the title fit on one page
  theme_classic() +
  scale_fill_brewer(palette = "GnBu")

```
------------------------------------------------------------------------

# Question 5

## Question 5a

Build a model that predicts the likelihood of dropping out (at all).

To examine the likelihood of dropping out, whether a participant completed the program, or dropped out, was quantified, where dropping out = 1, and finishing = 0.

Following this, a generalised linear regression analysis was done to examine whether there is a predictor for dropping out. City, accountability, happiness and heath were non-significant predictors for the likelihood of dropping out. Because of this, they were not included in the final model for the write-up. 


**Table 6**

*Table to Show the Results of a Generalised Linear Regression*


```{r q5a}
#usful function 
l2p <- function(logits) {
  odds = exp(logits)
  prob = odds/(1+odds)
  return(prob)
  }

#Data Prep

couchto5k <- couchto5k %>% 
  mutate(drop_out = ifelse(week_stopped != 9, 1, 0)) #changed the value of week_stopped back to numeric from as it is now used as an outcome variable
#1 = completion, 0 = drop-out

#Mod
lm6 <- glm(drop_out ~ selfmot + season, family = binomial, data = couchto5k)

#Mel Building odel Diagnostics
glm_coef <- coef(lm6)


#summary(lm6)

tab_model(lm6)



```


```{r q5 logit coef calc, include = FALSE}
intercept <- glm_coef[1]
glm_selfmot <- glm_coef[2]

logits_dropout <- intercept + 14.2 * glm_selfmot

l2p(logits_dropout)

```

--- 

**Table 7**

*Table to Show the Results of a Analysis of Deviance*

```{r q5a1}
as.tibble(anova(lm6, test = "Chisq")) %>% 
   kable(col.names = c("DF", "Deviance", "Residual DF", "Residual Deviance", "Pr ( > Chi)"), align = "c") %>% 
  kable_styling(full_width =T)
```


```{r q5a2_accuracy, include = FALSE}
#Accuracy 

guess <- predict(lm6)
guess <-  ifelse(guess>0, 1, 0)

hits <- sum(guess == couchto5k$drop_out)
hits/length(couchto5k$drop_out)
```


## Question 5b

Briefly describe the effects in your model as you would in an academic paper.

A generalised linear regression analysis was conducted to examine whether there is a predictor for dropping out. 

Self motivation was a statistically significant predictor of dropping out, with lower scores on self motivation predicting a higher likelihood of dropping out (-4.3, *z* = 4.57, *p* < .001). 

Adding self motivation to the model drops the residual deviance by 5.7 (*p*(X^2 > 5.7) = .017), suggesting that the model explains a small but significantly amount of deviance compared to the null model.

For the mean score of self motivation (`r mean(couchto5k$selfmot)`) the probability of dropping out is `r l2p(9.13 +- 0.470*(14.2))`.


Similarly, season was a predictor for the likelihood of dropping out, with summer (-4.976, *z* = -5.88, *p* < .001), autumn (-4.692, *z* = -4.03, *p* < .001) and winter (-6.135, *z* = -4.55, *p* < .001) significantly predicting lower likelihoods of dropping out, compared to the baseline of spring. 

Adding season to the model drops the residual deviance by 93.7 (*p*(X^2 > 93.7) <.001), suggesting that the model explains a significantly larger amount of deviance compared to the null model.

The accuracy of this model was `r hits/length(couchto5k$drop_out)` suggesting the model explained `r hits/length(couchto5k$drop_out)`% of the deviance in the data correctly. 

## Question 5c

Draw a graph representing the probability of quitting as a function of how self motivated participants are.

**Figure 6** 

*Plot To Show the Probability of Quitting as a Function of Self Motivation*

```{r q5c, message= FALSE, echo = FALSE, fig.align="center", ,fig.width = 14}

couchto5k %>% ggplot(aes(x = selfmot, y = drop_out)) + 
  geom_jitter(size = 4, height = .1, width = .5, alpha = .3) + 
  geom_smooth(method = "glm", method.args = list(family = binomial), se = TRUE) + 
  labs(x = "Self Motivation", y = "Probability of Dropping Out", title = "Probability of Quitting as a Function of How Self Motivated a Participant" )

```

