---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
params:
  examnumber: B192523
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# when document is compiled/knitted, code will not show, but the output will
knitr::opts_chunk$set(echo = FALSE)
# all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
library(pander)
library(psych)
library(sjPlot)

library(broom)

# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0 - Cleaning & Describing

## Overview of the data

```{r q0 - variable overview}
vartable1 <- data.frame(
  name=c('pptID', 'age', 'accountability', 'selfmot', 'health', 'happiness', 'season', 'city', 'week_stopped'),
  type=c('nominal categorical', 'continuous numerical', 'continuous numerical', 'continuous numerical', 'continuous numerical', 'continuous numerical', 'nominal categorical', 'binary categorical', 'discrete numerical'),
  description=c('identifying alphanumeric combination', 'integer measured in years', 'integer calculated by summing answers (1-7) to 5 questions', 'integer calculated by summing answers (1-7) to 5 questions', 'integer score measured on range of 1-100', 'integer score measured on range of 1-100', 'winter, spring, summer, or autumn', 'edinburgh or glasgow', 'integer in range of 1-9'))

```
Table 1 gives an overview of the variables used in this project.
```{r table1, results="asis"}
vartable1 %>% pander(caption="Table 1: Couchto5k variable descriptions.")
```


```{r cleaning, include = FALSE}
# removing data
couchto5k$remove <- NA
couchto5k$remove[couchto5k$age>100] <- "unrealistic age"
couchto5k$remove[couchto5k$selfmot<5] <- "below 5-35 range"
couchto5k$remove[couchto5k$happiness<1] <- "below 1-100 range"
couchto5k$remove[couchto5k$week_stopped>9] <- "above 1-9 range"

# as.factor for categorical variables
couchto5k$city <- as.factor(couchto5k$city)

# create table of removed data
removetable <- table(couchto5k$remove)

# delete the observations deemed for removal 
couchto5k <- 
  couchto5k %>% 
  filter(is.na(remove))
  
# count number of removed observations
totalobs <- count(couchto5k)
```

## Cleaning the data

The data were inspected and there were no missing values. 
Unlikely values were removed, resulting in `r totalobs` observations for analysis, as opposed to the original 131. The unlikely values included ages over 100, happiness scores below 1-100 range, self-motivation below 5-35 range, and week stopped values above 1-9 range.

Table 2 gives a summary of removed data, categorized by reason for removal.

```{r table2, results="asis"}
removetable %>% pander(caption="Table 2: Summary of removed values.")
```
```{r season}
# correcting spelling mistakes in data
misspell <- sum(couchto5k$season=="autunm")
couchto5k$season[couchto5k$season=="autunm"] <- "autumn"
couchto5k$season <- as.factor(couchto5k$season)
```
There existed `r misspell` misspellings in the season column of "autumn" as "autunm". Instead of omitting these anomalies, the typos were simply corrected in place and recorded as "autumn".


# Question 1 - General Checks

## Question 1a
Q: "In an earlier nationwide survey, researchers found that 45% of participants abandoned the programme before the halfway point in week 5, and a further 10% gave up before the end of the programme. Is the data in the sample you have been given in line with data from the earlier survey? Once you have created a suitable variable to map to the information in the question, you should be able to answer this using a simple statistical test."

```{r q1a}
# couchto5k %>% summary()

# create df for participants who quit before week 5
under5 <- 
  couchto5k %>%
  filter(couchto5k$week_stopped < 5)
count_under5 <- count(under5)

# create df for participants who quit on or after week 5, but before week 9
above5 <- 
  couchto5k %>%
  filter(couchto5k$week_stopped >= 5, couchto5k$week_stopped != 9)
count_above5 <- count(above5)

# create df for participants who completed the programme
completed <- 
  couchto5k %>%
  filter(couchto5k$week_stopped==9)
count_completed <- count(completed)

# add attrition column to original df
couchto5k$attrition <- NA
couchto5k$attrition[couchto5k$week_stopped<5] <- "under 5"
couchto5k$attrition[couchto5k$week_stopped>=5 & couchto5k$week_stopped!=9] <- "above 5"
couchto5k$attrition[couchto5k$week_stopped==9] <- "completed"
# couchto5k$attrition <- as.factor(couchto5k$attrition)
```
In this sample, `r count_under5` participants abandoned the program before the 
start of week 5 (`r (count_under5/totalobs)*100`% of participants) which is less than the 
previous study (45% of participants). 
However, another `r count_above5` participants abandoned the program before the 
last week (`r (count_above5/totalobs)*100`% of participants) which is almost double the previous
study (10% of participants).
So, in the end we observed a `r (count_completed/totalobs)*100`% completion rate,
comparable to 45% in the previous study. 
Although participants dropped at different times (i.e., weeks) in this sample, 
we observe a similar overall trend to drop out versus compeletion rates.

Table 3 gives a summary of the chi-squared simple statistical test.
```{r table3 - chisquared, results="asis"}
tidy(chisq.test(table(couchto5k$attrition), p = c(.1, .45, .45))) %>% 
  pander(caption="Table 3: Chi-squared test for rates of attrition.")
```

We use the Chi-squared test for given probabilities to see if the two variables (i.e., comparing previous survey to rates of attrition in this sample) are independent. Since the p-value of the Chi-squared test is statistically significant, we reject that the variables are independent. Hence, the data from this sample is in-line with that of the previous survey.

## Question 1b
Q: "Using the same three categories (stopped before week 5, stopped after week 5, completed), examine whether the patterns of attrition rates differ by city."

Figure 1 is a barplot that displays the city categorization behind each attrition group.
```{r q1b}
# barplot(table(couchto5k$attrition, couchto5k$city))

ggplot(couchto5k, aes(x = attrition, fill = city)) +
  geom_bar(color = "black") +  
  labs(x = "Attrition Groups", y = "Number of Participants", 
       title = "Figure 1: Attrition pattern by city") +
  scale_x_discrete(limits=c("under 5", "above 5", "completed")) + 
  guides(fill = guide_legend(title = "City")) +
  scale_fill_brewer(palette="Blues") +
  theme_minimal()

```
We see in Figure 1 that the two cities have slightly different patters of attrition. 

In Glasgow, approximately the same amount of participants drop out of the programme before and after the halfway point. There is a slight increase in the number of participants who actually completed the programme.

In Edinburgh, out of the total participants who drop out of the programme at some point, more do so
before the halfway point. There is a much more significant increase, compared to Glasgow, in the number of 
participants who finish the programme. 

## Question 1c
Q: "Do the average ages of participants who commenced the programme differ by city?" 

```{r q1c - calculate mean}
edi_completed <- 
  couchto5k %>%
  filter(city=="Edinburgh")
edi_mean <- mean(edi_completed$age)

gla_completed <-
  couchto5k %>%
  filter(city=="Glasgow")
gla_mean <- mean(gla_completed$age)
```

The average age of participants in Edinburgh is `r edi_mean` years, and `r gla_mean` years in Glasgow. Therefore, the average age is higher for participants in Edinburgh by three years.

To further investigate the statistical dispertion of ages in either city, it can be helpful to plot the  interquartile range(IQR). This will allow us to observe where the 25th and 75th percentiles (and median) of the data exist in comparison to one another. 


Figure 2 is a boxplot that visualizes the IQR of participant ages in Glasgow and Edinburgh separately. 

```{r figure 2}
# plot the IQR using boxplot
ggplot(data = completed, aes(x = age, y = city)) +
  geom_boxplot() +
  labs(x = "Age of Participants (in years)", y = "City", 
       title = "Figure 2: Comparing distribution of commenced participant ages by city")

```

# Question 2 - Happiness

## Question 2a
Q: "Are participants’ happiness ratings affected by the season they were interviewed in? Describe the way in which season influences happiness outcomes."

First, we will observe the distribution of happiness ratings across seasons in the figure below. 

Figure 3 investigates how happiness changes when varying season of participation. Hence, happiness is the dependent variable (on the y-axis), and season is the independent variable (on the x-axis) in the figure.

```{r q2a - figure3: happiness ratings grouped by season}
# plot the distribution
ggplot(data = couchto5k, aes(x = season, y = happiness)) +
  geom_point(alpha = 0.5) +
  labs(x = "Season", y = "Happiness (in range of 1-100)",
       title = "Figure 3: Happiness ratings grouped by season")
```

We model the relationship between happiness and season using a Linear Regression Model (LM). 

```{r q2a - lm}
# remove influential observation (48)
couchto5k <- couchto5k[-c(48),]
# create linear model
lmmod1 <- lm(happiness ~ season, data = couchto5k)
# summary(lmmod1)
# plot(lmmod1, which=1:4)
# anova(lmmod1)
# contrasts(couchto5k$season)

# as.factor for categorical variables?
couchto5k$week_stopped <- as.factor(couchto5k$week_stopped)

# model p-value
pval_lmmod1 <- glance(lmmod1)$p.value
```
With initial model diagnostics using a linear model for parameters season and happiness, we see that observation 48 was highly influential and skewing the results. Removing this observation however showed no improvement of the model. 

The LM yields a p-value of `r pval_lmmod1` showing that the variable is statistically significant to happiness and is unlikely to be due to chance. The seasons "autumn" and "winter' have high statistical significance, compared to "summer" and "spring", with p-values less than .001.

We can evaluate the coefficients of the model (autumn, spring, summer, winter) to see how season influences happiness. 

See examples:

- Changing participation from "autumn" to "spring" decreases the happiness score from 71.44 to 54.07.

- Changing participation from "autumn" to "summer" decreases the happiness score by 18.62.

- Changing participation from "autumn" to "winter" decreases the happiness score by 45.02.

Table 4 gives a summary of the linear model's coefficients.
```{r table4: table of lm of happiness and season, results="asis"}
pander(tidy(lmmod1)) %>%
  pander(caption="Table 4: LM for happiness and season.")
```


## Question 2b
Q: "Accounting for any effects you discovered in (2a), is happiness affected by age?"

There were no influential observations to remove from the data. Once again, we will model the relationship between happiness and age (while maintaining the season parameter) using an LM. 
```{r q2b}
# create lm
lmmod2 <- lm(happiness ~ season + age, data=couchto5k)
# summary(lmmod2)
# plot(lmmod2, which=1:4)
# anova(lmmod2)
# contrasts(couchto5k$age)

pval_lmmod2 <- glance(lmmod2)$p.value
# pval_age <- tidy(lmmod2)$p.value[5]

# table
# pander(tidy(lmmod2))
```
The LM has a p-value of `r pval_lmmod2` which is not statistically significant. This indicates that the variable age does not have a strong effect on the happiness ratings. 

## Question 2c
Q: "The models you have built above explore ‘baseline’ effects; that is, effects that are not of primary interest to the researchers but which might affect the outcome variable of happiness. For use in question 3, pick a specific baseline model and justify why you are using this."

Out of the two models created in this section, only the LM in Question 2A proved to have statistical significance (p-value < 0.05) for the happiness variable.

Moreover, ANOVA testing was used to compare the two models. We can see that the more complex model (i.e., with the additional variable "age") has a not sufficiently low p-value (p-value > 0.05). This indicates we should favor the simpler model.

Table 5 gives a summary of the ANOVA test output for comparing the LMs.
```{r r table5: ANOVA test output, results="asis"}
pander(tidy(anova(lmmod1, lmmod2))) %>%
  pander(caption="Table 5: ANOVA test for LM comparison.")
```

Therefore, we choose the LM used in Question 2A to be our baseline model to use in Question 3. 

# Question 3 - Happiness and Health

## Question 3a
Q: "Building on your baseline model, are participants’ happiness ratings affected by whether or not they completed the programme? Describe the way in which programme completion influences happiness outcomes."

After looking over the data, no observations were removed from the data. To observe the effect of programme completion, we are assuming that "completion" implies the participant stopped at week 9. This variable will be modeled by creating a new variable, called "isCompleted".

```{r q3a}
# make binary variable to indicate completion status
data3a <-
  couchto5k %>%
  mutate(
    isCompleted = ifelse(week_stopped == 9, "Yes", "No")
  )

lmmod3 <- lm(happiness ~ season + isCompleted, data = data3a)
# summary(lmmod3)
# pander(tidy(lmmod3))

pval_lmmod3 <- glance(lmmod3)$p.value
pval_isCompleted <- tidy(lmmod3)$p.value[5]

# couchto5k$city <- as.factor(couchto5k$city)
# couchto5k$week_stopped <- as.factor(couchto5k$week_stopped)
```
The LM yields a p-value of `r pval_lmmod3` showing that the explanatory variables, season and isCompleted, are statistically significant to the response variable, happiness. Moreover, the isCompleted coefficient is significant with a p-value of `r pval_isCompleted`. Therefore, we may conclude that happiness ratings are affected by completion of the programme.

We can interpret the isCompleted coefficient of the model to see how completing the programme influences happiness in the following way: 

Changing participation from season "autumn" to completing the programme increases the happiness score from 58.59 to 73.05.

## Question 3b
Q: "Building on the analysis in (3a), is happiness additionally affected by the “health metric”?"

```{r q3b}
lmmod4 <- lm(happiness ~ season + isCompleted + health, data = data3a)
# summary(lmmod4)
# pander(tidy(lmmod3))

pval_health <- tidy(lmmod4)$p.value[6]
```
Contrary to the isCompleted coefficient in Question 3A, the health coefficient does not have statistical significance on the happiness rating in this model. This was determined by the health coefficient's high p-value of `r pval_health`.


## Question 3c
Q: "It’s been hypothesised that the effects of good health are amplified by the feeling of acting healthily, such that the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier. Building on the model in (3b), can you test this hypothesis?"

```{r q3c - initial exploration of interactions}
# plot a scatter plot matrix of interaction related variables
# data3a %>% select(happiness, health, isCompleted) %>% pairs.panels()

# overview of numerical characteristics
# data3a %>% select(happiness, health, isCompleted) %>% describe()
```
Figure 4 observes the relationship between happiness and health, with separate facets for people who have completed the programme or not.

```{r q3c - figure4: relationship between happiness and health, with separate facets for people who have completed the programme or not.}

ggplot(data = data3a, aes(x = happiness, y = health)) + 
  geom_point(size=1) + 
  geom_smooth(method="lm") +
  facet_wrap(~isCompleted) +
  labs(title = "Figure 4: Relationship between happiness and health, by completion status", 
       x = "Happiness rating (in range of 1-100)", 
       y = "Health rating (in range of 1-100)")
```

```{r}
lmmod5 <- lm(happiness ~ 1 + health * isCompleted, data = data3a)
# summary(lmmod5)
```
We now observe the coefficients health and isCompleted in the presence of an interaction health:isCompleted. A significant interaction would indicate that the effect of health on happiness depends on/is conditional upon the value of isCompleted. However, after viewing the distribution in Figure 4 and the high p-value of the coefficient health:isCompleted (p-value > .05) we can conclude that there is not a conditional effect of a higher health score and programme completion (or vice-versa) regarding the happiness score. 

## Question 3d
Q: "What can we conclude about the various causes of happiness in our data? Write a brief description of the effects in the model, such as you might find in an academic paper."

The happiness rating is affected by the season of which a participant partakes in the programme. In particular, the seasons "autumn" and "winter" coefficients have a stronger influence as seen in the LMs. Comparatively, the seasons "summer" and "spring" demonstrate more distributed happiness ratings and consequently have less influence.

On the other hand, we concluded that age and health does not appear to be a cause of happiness in the data as these variables showed no statistical significance. 


# Question 4 - Happiness Ratings
Q: "Create a subset of the data, including only those participants who completed the programme. Create a plot of the average happiness ratings grouped by season and city, that can be used in a presentation to the funders of the project."

A subset was created for participants who completed the program, which are assumed to be those we stopped at week 9. Then, the average happiness scores were grouped by season (i.e., autumn, spring, summer, winter) and city (i.e., Edinburgh, Glasgow).

Figure 5 presents the average happiness ratings grouped by season and city. 
```{r q4 - figure 5: mean happiness grouped by season and city}
# create subset for participants who completed, keeping key variables
q4data <- couchto5k %>% 
  filter(week_stopped == 9)  %>% 
  select(happiness, season, city)

# create table of grouped average happiness ratings by season and city
grouped <- q4data %>%
  group_by(season, city) %>%
  summarise_at(vars(happiness),
               list(name = mean))    

# create stacked bar plot
ggplot(grouped, aes(x = season, y=name, fill = city)) +
  geom_bar(stat = "identity", color = "black", position=position_dodge()) +  
  labs(x = "Season",  y = "Happiness (average of scores)",
       title = "Figure 5: Happiness grouped by season and city") +
  guides(fill = guide_legend(title = "City")) +
  scale_fill_brewer(palette="Blues") +
  theme_minimal()
```


# Question 5 - Predictors of Drop-out

## Question 5a
Q: "Build a model that predicts the likelihood of dropping out (at all)."

For this model, we will predict the likelihood of a participant dropping out (at all). Any participant who did not make it to week 9 will be categorized as "dropping out" and represented with 1, while those who completed the programme with 0.

Initially, I created a Generalised Linear Model (glm) with all predictors including: age, accountability, selfmot, health, happiness, season, and city. After reviewing the p-values of the coefficients, the model was recreated only using coefficients that were statistically significant (i.e., p-value < 0.05).

The glm predicts the likelihood of dropping out using the following predictors: age, selfmot, health, and season. 

```{r q5a}
# make binary variable of dropping out
data5a <-
  couchto5k %>%
  mutate(isDroppingOut = ifelse(week_stopped != 9, 1, 0))

# create glm
dropout_model <- glm(isDroppingOut ~ age + selfmot + health + season, 
                     data = data5a, 
                     family = "binomial")
# summary(dropout_model)
```

```{r q5a - figure 6: glm model}
plot_model(dropout_model)
```


## Question 5b
Q: "Briefly describe the effects in your model as you would in an academic paper."

```{r q5b}

```

## Question 5c
Q: "Draw a graph representing the probability of quitting as a function of how self motivated participants were."

```{r q5c}

```










