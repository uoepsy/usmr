---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
  pdf_document: default
params:
  examnumber: 'B175159'
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
library(GGally) 
library(pastecs)
library(pander)
library(tidyr)
library(broom)
library(ggplot2)
library(psych)
library(sjPlot)
# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
getwd()


```

# Question 0

<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->
download.file('https://uoepsy.github.io/data/usmr_2122_data.csv', 'C:\\Users\\muham\\Downloads\\usmr_2122_data.csv', mode="wb")
d <- "https://uoepsy.github.io/data/usmr_2122_data.R"
View(d)

setupdata <- read.csv("https://uoepsy.github.io/data/usmr_2122_data.R", col_names = TRUE)
demo <- read.table(path = 'C:\\Users\\muham\\Downloads\\usmr_2122_assignment_template.R')

```{r cleaning, include = FALSE}
# Neither output nor code from this chunk will be shown in the compiled document. 

#changing categorical variables to factors 
couchto5k$season <- as.factor(couchto5k$season)
couchto5k$city <- as.factor(couchto5k$city)

#searching for outliers and removing impossible values

couchto5k <-
  couchto5k %>%
  mutate(
    age = ifelse(age > 105, NA, age),
    selfmot = ifelse(selfmot < 0, NA, selfmot),
    week_stopped = ifelse(week_stopped > 9, NA, week_stopped))

couchto5k$missing <- NA
couchto5k$missing[is.na(couchto5k$age>100)] <- "age too high"
couchto5k$missing[is.na(couchto5k$selfmot<0)] <- "selfmot less than 0"
couchto5k$missing[is.na(couchto5k$week_stopped>9)] <- "week_stopped after 9"

missingtable <- table(couchto5k$missing)

#remove missing values and check dataset changes
couchto5k <- couchto5k %>% filter(is.na(missing))
total <- nrow(couchto5k)

#visual observation of general data

summary(couchto5k)

glimpse(couchto5k)

ggpairs(couchto5k[, -1])

summary_df <- stat.desc(couchto5k) 

#visual observation of unique values 
unique(couchto5k$age)
unique(couchto5k$health)
unique(couchto5k$selfmot)
unique(couchto5k$accountability)
unique(couchto5k$happiness)
unique(couchto5k$season)
unique(couchto5k$city)
unique(couchto5k$week_stopped)

#correcting misspelled wordings 
levels(couchto5k$season) <- gsub("autunm", "autumn", levels(couchto5k$season))

                      
```

```{r table, results='asis'}

missingtable %>% pander(caption = "Table 1: Summary of Improbable Values.")

```

```{r descriptives}
# Code will not be shown from this chunk (because we set echo = FALSE in the very first chunk)
# the output from this code will be shown. 

sapply(couchto5k, class)

happyplot <- ggplot(data = couchto5k) +
geom_dotplot(aes(x = happiness, fill = "happiness")) +
  labs(x = "Happiness", y = "Count")

ageplot <- ggplot(data = couchto5k, aes(x = age)) +
geom_density() +
theme_bw() +
labs(x = "Age", y = "Density")

healthplot <- ggplot(data = couchto5k, aes(x = health)) +
geom_density() +
theme_bw() +
labs(x = "Health", y = "Density")

selfmotplot <- ggplot(data = couchto5k, aes(x = selfmot)) +
geom_density() +
theme_bw() +
labs(x = "Self-Motivation", y = "Density")

mean(couchto5k$happiness)
mean(couchto5k$health)

median(couchto5k$happiness)
median(couchto5k$health)

mode(couchto5k$happiness)
mode(couchto5k$health)

sd(couchto5k$happiness)

View(couchto5k)
```

##Question 0:

The following data “couchto5k” was acquired from “USMR_2021_data”. A total of 122 participants were observed and measured in the areas of health, happiness, age, self-motivation, and accountability. Measures of self-motivation and accountability were derived from five questions each (rated from 1 to 7), while both happiness and health factors were scored from 0-100. Additionally, the data specified the participant’s age, city (Edinburgh and Glasgow), and season during which the participant engaged in the activity (Spring, Summer, Autumn, Winter). The data also collected information on which participants completed the event, and which participants dropped out earlier (with dropout week specified). A series of steps were taken to clean and organize the data. After visually observing the data set, impossible and unlikely values were removed. The inclusion of participants with ages of 110 (participant no. 52) and 138 (participant no. 38) in the program would be highly unlikely, thus these age ranges were assigned as NA (Not Available) values. Only the Self-motivation and Health variables showed to be normally distributed during data organizing. A value from the Self-motivation variable was removed as it posed to be an impossible value of -99. It is considered an impossible value because ratings for each question was from 1-7. Including this value would negatively affect our data set’s mean and standard deviation. Despite the fact that some participants scored zero on happiness, the decision was made not to remove this as it remains possible for individuals to complete a measure which would result in a score of zero. Considering the program was 9 weeks in length, we found another impossible value of “12” in the “week_stopped” variable. In addition, the incorrect spelling of autumn (initially spelt as “autunm” for participant no. 51, 58, 64, 89, 99) was corrected. Lastly, both city and season variables were specified as character variables. In order to conduct statistical tests, these variables were converted to factors so that they were represented in levels. Listed below are some descriptive statistics which include values listed as NA (Table 1), participant distribution by city (Figure 1), and season (Figure 2), and length of time participants were in the program (Figure 3).


```{r q0}
ggplot(data = couchto5k) +
geom_bar(aes(x = season, fill = "season")) +
  labs(title = "Figure 1: Season Averages", x = "Season", y = "Count")

ggplot(data = couchto5k) +
geom_bar(aes(x = city, fill = "city")) +
  labs(title = "Firgure 2: Ratings by City", x = "City", y = "Count")

ggplot(data = couchto5k) +
geom_dotplot(aes(x = week_stopped, fill = "week_stopped")) +
  labs(title = "Figure 3: Participants dropping out by week)", x = "Week Stopped", y = "Count")
```

## Question 1a

First and foremost, 3 new vectors were generated. These included participants who left the program prior to week 5, those who left after week 5, and those who finished the program. In order to compare our current data to the previous survey, a t-test was conducted to confirm the exact numbers. Results shown in Table 2 reveal a significant difference when participants left the program before week 5. In particular, fewer participants in the current dataset dropped out before week 5 in comparison to the earlier survey. However, no significance is shown for participants leaving after week 5 (shown in Table 3). Furthermore, a Shapiro-Wilk test of normality showed non-significant results, thereby no violations of normality (the data therefore remains normally distributed as shown in Table 4 and 5).


```{r q1a}
#participants leaving program 
couchto5k_leaving <- couchto5k %>% 
  group_by(week_stopped) %>%
  summarise(number = n()) %>%
  mutate(percentage = (number/total)*100)

#when participants left - 3 categories 
beforehalf <- couchto5k_leaving$percentage[1:4]
beforeend <- couchto5k_leaving$percentage[5:8]
completed <- couchto5k_leaving$percentage[9]

#comparing data with earlier survey by conducting t test 
test1 <- t.test(beforehalf, mu = 0.45, na.action=na.omit)
test2 <- t.test(beforeend, mu = 0.10, na.action=na.omit)

test1 %>% pander(caption = "Table 2: T-test for Participants Who Dropped Out Before Week 5.")
test2 %>% pander(caption = "Table 3: T-test for Participants Who Dropped Out Before Week 9.")

#normality test

shap_before <- shapiro.test(beforehalf)
shap_after <- shapiro.test(beforeend)
shap_before %>% pander(caption = "Table 4: Shapiro-Wilk Test for Participants Who Dropped Out Before Week 5.")
shap_after %>% pander(caption = "Table 5: Shapiro-Wilk Test for Participants Who Dropped Out Before Week 9.")

```

## Question 1b

To test attrition rates, we first added a new category to the dataset. In the previous question, the data tested three different possibilities (participants dropping out before week 5, after week 5, and completing the program). These 3 groups were categorized in numbers (1, 2, 3) and added as a new column as factors to better read and understand. In addition, tables were generated for both cities, creating subsets of the original dataset. This was done to view the remaining data again but separately based on each city. Upon visualizing the bar plot in Figure 4, attrition rates appear to be different, although these differences are not statistically significant according to the Chi-square test results shown in Table 8 (X2(4) = 6, p = 0.19)). The test therefore made a comparison of the goodness of fit between the two sets of attrition rates.

```{r q1b}

#mutate data to measure dropouts before week 5 and dropouts right before completion. Data will now show column with values 1,2,3)
couchto5k <- couchto5k %>%
  mutate(
    category = 
      ifelse(week_stopped<5, 1, 0)+ 
      ifelse((week_stopped>=5)&(week_stopped<9), 2, 0)+ 
      ifelse(week_stopped==9, 3, 0)
  )

couchto5k$category <- factor(couchto5k$category)

gla = couchto5k[which(couchto5k["city"]=="Glasgow"),]
edi = couchto5k[which(couchto5k["city"]=="Edinburgh"),]

# creating a table with a number of participants per category 
                    
glatable <- table(gla$category)
editable <- table(edi$category)

print(glatable) %>% pander(caption = "Table 6: Attrition rates - Participants from Glasgow.")
print(editable) %>% pander(caption = "Table 7: Attrition rates - Participants from Edinburgh.")

chisquaretable <- chisq.test(glatable, editable)

chisquaretable %>% pander(caption = "Table 8: Pearson's Chi-squared Values")

couchto5k %>%
  drop_na(category) %>%
  ggplot(aes(x = city, fill = category)) +
  geom_bar(position = "dodge2", width = 0.9) +
  labs(title = "Figure 4: Differences in Attrition Rates 
               by City", x = "", y = "Participants", fill = "Week Stopped")+
  scale_fill_manual(values = c("blue", "purple", "orange"), labels=c("Before week 5", "Week 5 to 8", "Completed"))
```

## Question 1c

A boxplot analysis in Figure 5 shows the difference between average age of participants amongst Edinburgh and Glasgow. Both average ages show to be lower than 40 years old. Upon visualizing the graph, it is evident that the average age of participants in Glasgow shows to be lower than participants in Edinburgh. The differences however show to be just a couple of years apart when looking at the graph. A two-tailed t-test was therefore conducted to test the numeric difference between these independent groups. Results revealed no significant differences between the two groups, as shown in Table 9. Therefore, one can conclude that while a difference may seem visually significant, it may not necessarily be statistically significant.

```{r q1c}

#Comparison of averages between cities
mean(couchto5k$city == "Edinburgh")
mean(couchto5k$city == "Glasgow")

# removing NA age
summary(couchto5k$age)
couchto5k <-
  couchto5k %>% filter(!is.na(age))

#visualizing age influence on differences in cities
ggplot(couchto5k, aes(x = city, y = age, fill = city)) +
  geom_boxplot() +
  theme_bw() +
  scale_fill_manual(values = c("purple", "orange"))+
     labs(title = "Figure 5: Average Age Across Cities", x = "City", y = "Participants Age")

#Comparing the two groups
test3 <- t.test(couchto5k$age[couchto5k$city== "Edinburgh"], couchto5k$age [couchto5k$city == "Glasgow"]) 

test3 %>% pander(caption = "Table 9: T-test Comparing Average Age Based on Diffeerent Cities.")


```

# Question 2

## Question 2a

Figure 6 displays a bar plot representing average happiness ratings across seasons. Visually, it is clear that happiness ratings in Spring time are highest, whereas lowest during the Winter season. Based on our analysis, we then tested whether our Independent Variable, season, is a good predictor of our Dependent Variable, happiness. A categorical linear regression analysis was performed, season being the predictor and happiness acting as the dependent variable. As observed by the graph, Spring season revealed to have the highest coefficient value (13.7) while Winter season was the lowest (6.8). However, season as a predictor did not show to have a statistically significant effect on happiness outcomes (p>0.05) as shown in Table 10. A Shapiro-Wilk test of normality displayed in Table 11 also finds a non-normal distribution of data due to the significant P value. 
After examining each season’s impact on happiness separately, it is also revealed that no single season has a significant effect on happiness. Based on values observed from Cook’s distance in Figure 7, one outlier was removed (99) from the data. This however did not change the results in any significant manner. In addition, the value of R^2 shows that only 23% of the variation in happiness is explained by seasons. 
 

```{r q2a}

#Checking happiness levels by season
ggplot(data = couchto5k, aes(x = season, fill=season))+
  geom_density(size = 3, alpha = 4)+
  geom_bar() +
  labs(title = "Figure 6: Average Happiness Across Seasons", x = "Season", y = "Happiness")  

#Using a linear model to analyze relationship between happiness and season
happyseasonmodel <- lm(happiness ~ season, data = couchto5k, na.action = na.omit)

happyseasonmodel %>% pander(caption = "Table 10: Linear Model To Test Season As a Predictor For Happiness")

#normality test
shap_season <- shapiro.test(residuals(happyseasonmodel))

shap_season %>% pander(caption="Table 11: Shapiro-Wilk Test for Season")

#cooks
plot(happyseasonmodel, which = 4) #figure7
couchto5k <- couchto5k[-c(99),]

#overall info
tab_model(happyseasonmodel)
summary(happyseasonmodel)


```


## Question 2b

The information on happiness and season showed differences when visualizing the graph, although this was not the case with age and happiness. Upon creating a graph with points to plot values of happiness in regard to age (Figure 8), there is no meaningful relationship observed. Based on the scatter plot, there appears to be little, if any, relationship between the data points. A multiple regression analysis was carried forward to confirm whether this is the case. This analysis followed the previous regression analysis, with age being added as another predictor to the equation. Results in Table 12 reveal that for every year’s increase in age, happiness rises by 0.08, however this is not statistically significant (p>0.05). Accordingly, this confirms that while happiness ratings vary with age slightly, they are not significantly affected in any way and the addition of age does not improve our model. The value of R^2 (level of variance explained by the model) is likely to increase but this does not give us accurate information on the effect age has on happiness, thereby we look towards the adjusted R^2 value. It is evident that after adding age as a predictor, the relationship is not any stronger on the influence of happiness outcomes (based on very low adjusted R^2 value below 0). This further indicates that age is not a good predictor for happiness ratings. In addition, a Shapiro-Wilk test of normality was performed (as shown in table 13), revealing a significant outcome. This indicates that the data is deviated from a normal distribution. 

```{r q2b}

# generate plot to visualize age influence
ggplot(couchto5k, aes(x= age, y = happiness, fill=happiness))+ 
labs(title = "Figure 8: Influence of Age on Happiness", x = "Age", y = "Happiness Level")+
  geom_point(alpha=3)+
  geom_smooth(method = "lm") +
  theme_bw()+
  theme(aspect.ratio=1)

#Using a linear model to analyze relationship between hapiness and age
happyagemodel <- lm(happiness ~ season + age, data = couchto5k, na.action = na.exclude)

happyagemodel %>% pander(caption = "Table 12: Linear Model To Test Age As a Predictor For Happiness")

#checking assumptions 
plot(happyagemodel, which =4) #figure 9 

#normality test
shap_age <- shapiro.test(residuals(happyagemodel))

shap_age %>% pander(caption="Table 13: Shapiro-Wilk Test For Age")

#overall info
tab_model(happyagemodel)
summary(happyagemodel)



```

## Question 2c

Due to the fact that season nor age has a significant effect on the dependent variable (happiness), using either as a baseline effect for future linear models is implausible. Neither of the predictors help explain the variation in happiness outcomes, thereby it is advised to avoid using them. For further questions that require more than one independent variable, we will use multiple regression models. This will help explain and predict the value of our single dependent variable.

```{r q2c}
# Information provided in Report
```
     
## Question 3a

In order to test the differences between participants in regard to program completion, a new column was created in the dataset entitled “comleteprogram.” The variable was converted into a factor to specify levels. The two levels outlined which participants managed to get through all 9 weeks of the program by highlighting the column with “complete.” Participants who dropped out earlier were marked as “incomplete.” As we did not want season or age to be included in the model, we used a linear model to determine if program completion has an influence on happiness outcomes. 
Figure 10 displays the normality of scores on a QQ plot for visually understanding some of the data. The data points have been standardized here. Results from the linear model confirm little influence by program completion by revealing that completing the program did not significantly affect overall ratings in happiness, as shown in table 14. Cook’s distance did not show any outliers, so no values were removed for re-analysis. Figure 12 displays a boxplot also showing that program completion seems to have little impact on happiness outcomes, based on visual observation of the data.  



```{r q3a}
#adding new variables to highlight who did or did not complete the program
couchto5k <- couchto5k %>% mutate(
  completeprogram = ifelse(week_stopped == 9, "completed", "incompleted")
)

couchto5k$completeprogram <- as.factor(couchto5k$completeprogram)

#Observing if program completion further influences happiness - by visualizing
ggplot(couchto5k, aes(x = happiness, y = completeprogram, fill = completeprogram)) +
   labs(x = "Happiness", y="Program Completion", title = "Figure 10: Happiness Based on 
                 Program Completion")+
  geom_boxplot() +
  scale_fill_manual(values = c("purple", "orange"))

#applying lm function to statistically test the influence
happyweekmodel <- lm(happiness ~ completeprogram, data = couchto5k)

happyweekmodel %>% pander(caption = "Table 14: Linear Model To Test Program Completion As a Predictor For Happiness")

#Observing and removing outliers 
plot(happyweekmodel, which = 4) #figure 11
plot(happyweekmodel)

couchto5k <- couchto5k %>% filter(is.na(missing))

summary(happyweekmodel)
#tidy(happyweek) - use this function to look at codes in a cleaner way for reference

#graph for visualization 
couchto5k %>% 
  ggplot(aes(x = completeprogram, y = happiness, fill = completeprogram, na.rm = TRUE)) +
  geom_boxplot() +
labs(title = "Figure 12: Influence of Program Completion 
                on Happiness", x = "Completed Program", y = "Happiness") +
  scale_fill_manual(values = c("blue", "purple", "darkgreen", "orange"))
```

## Question 3b

A scatterplot in figure 13 shows how health ratings affect happiness among participants who completed the program or dropped out. This visualization is however, difficult to interpret by only visual observation. Therefore, it is advised to look directly at the results of the linear model. To test whether the health metric influences happiness, we build our model by adding health as an additional predictor in our model equation. Upon looking at the results, it is evident that the addition of health does not significantly influence happiness ratings, as shown by the P values in table 15. Cook’s distance does not show any outliers that need to be removed for re-analysis. Furthermore, the R^2 points out that the regression line is very close to the actual points. The adjusted R^2 with a value below 0 indicates extremely low explanation towards our response variable. 

```{r q3b}
#visualize data 
ggplot(couchto5k, aes(x = health, y = happiness, color = completeprogram)) +
  geom_point() +
  theme_bw() +
     labs(title = "Figure 13: Healths Influence on Age", x = "Health", y = "Happiness") 

happyhealth <- lm(happiness ~ completeprogram + health, data = couchto5k)

happyhealth %>% pander(caption = "Table 15: Linear Model To Test Program Complete and Health As a Predictor For Happiness")

#Observing and removing outliers 
plot(happyhealth, which = 4) #figure 14

summary(happyhealth)


```

## Question 3c

To test the current hypothesis at stake, we first direct our attention to the bar plot shown in Figure 15. The graph shows higher happiness levels towards the end of the program. It is interesting to note that happiness ratings were rather high in the first couple of weeks but drastically decreased during the middle weeks of the program. The ratings increased rapidly towards the end of the program, possibly indicating the sense of achievement participants felt upon completing the program. However, to monitor whether health ratings are amplified by the feeling of acting healthily, we require further statistical tests. This was done by carrying out a linear model to measure health and week progress on happiness, along with checking for an interaction between the two variables. Results reveal a significant interaction between the two predictors (p<0.05), as shown in Table 16. The interaction can also be seen in Figure 16 by visual observation. This indicates that participants who reported higher happiness scores as the weeks went by also reported higher health scores. The opposite was shown for participants leaving the program, as both happiness and health ratings dropped. Participants reporting high health ratings still showed to have lower happiness if they did not complete the program, and vice versa. No outliers were spotted in Cook’s distance (Figure 17) and the data showed normality after conducting a Shapiro-Wilk test (Table 17). It must be highlighted that the model explains only 15.6% of variability (based on adjusted R^2 value). This may seem a little low, however when compared to the previous model (in which we don’t select the “week_stopped” predictor), there is evidently a large change in results. 

```{r q3c}

#visualize data 
ggplot(couchto5k, aes(x= week_stopped, y = happiness)) +
  geom_count(stat='identity', color="orange")+
  labs(x= "Week", y = "Happinesss", title = "Figure 15: Happiness Outcomes By Week Stopped")+
  theme_bw()

couchto5k %>% ggplot(
  aes(x=happiness,y=health, colour=completeprogram)) +
  labs(x = "Happiness", y = "Health", title = "Figure 16: Happiness Influence On Health Based 
                On Program Completion")+
  geom_point() +
  geom_smooth(method="lm")

#testing whether leaving program later influences health metric 
happyweekmodel <- lm(happiness ~ completeprogram + health*week_stopped, data = couchto5k)

happyweekmodel %>% pander(caption = "Table 16: Linear Model To Test Program Progress with Health Metric as a Predictor for Happiness")

shap_happyweekmodel <- shapiro.test(residuals(happyweekmodel))

shap_happyweekmodel %>% pander(caption="Table 17: Shapiro Test to Observe Normality of Linear Model")

#tidy(happyweek) - can also this code for further reference
summary(happyweekmodel)

#Observing and removing outliers 
plot(happyweekmodel, which = 4) #figure 17

```

## Question 3d

After performing various tests, it is evident that the predictors such as season, age and health do not independently affect the results of happiness, as shown in previous tables. Indeed, these predictors showed non-significant results when measured (p> 0.05). Further analysis of Seasons (looking at each season individually) did not reveal any significant results either. It is thereby plausible to state that none of the three variables help predict how happiness outcomes will be affected.

Even so, a difference in happiness outcomes is evident when considering health in relation to the progress week. The model explained 14.7% of the variance (R^2 = 0.147, F(4, 111) = 4.77, p-value = 0.001). Even though health as a predictor alone cannot affect happiness significantly overall, observing it with the “week_stopped” variable shows significant results (p<0.05). This means that participants continuing the program for longer showed both higher health metrics and happiness outcomes, and vice versa. In addition, it should be highlighted that happiness outcomes were higher at both the start and end of the program, and lowest during the middle period of the program.



# Question 4

A subset of the “couchto5k” dataset was generated. This dataset included information of participants who completed the program i.e., till week 9. All predictor variables remained the same in this subset of data. Figure 18 shows a graph which may be used to present to funders of the project when visualizing observable differences in the sub- data. It is evident that although happiness levels amongst participants completing the program are a lot more spread across autumn in Edinburgh, the average ratings still match nearly with the average happiness ratings in Glasgow.

Figure 19 on the other hand shows average happiness by season and city ratings for the entire dataset, revealing that average happiness ratings were slightly lower in Glasgow when taking all participants into consideration. For Spring, we observe how happiness levels in Glasgow are a lot lower than those in Edinburgh in both the datasets. The season of Summer reveals average happiness ratings to be higher in Edinburgh as opposed to Glasgow. However, the differences in happiness between cities during Winter show a larger difference between each other if participants completed the program.


Overall, average happiness amongst both cities seems to be highest during the Winter season based on a visual observation. Even though Edinburgh shows high levels of average happiness during Springtime, ratings from Glasgow instead show to be a lot lower. 

```{r q4}

#creating subset of data for those who completed the program
newdata <- couchto5k[ which(couchto5k$week_stopped== 9), ]

summary(newdata)

#visual observation of the data subset
ggplot(newdata, aes(x = season, y = happiness, fill=city)) +
    labs(x= "Season", y="Happiness", title = "Figure 18: Average Happiness by Season and 
                City For Participants Completing 
                Program") +
  geom_boxplot(alpha=3) +
  theme(legend.position = "right") +
   scale_fill_manual(values = c("orange", "purple"))

ggplot(couchto5k, aes(x = season, y = happiness, fill=city)) +
    labs(x= "Season", y="Happiness", title = "Figure 19: Average Happiness by Season
                 and City For All Participants") +
  geom_boxplot(alpha=3) +
  theme(legend.position = "right") +
   scale_fill_manual(values = c("orange", "purple"))
```


# Question 5

In order to build a model which predicts the likelihood of dropping out (at all), a General Linier Model (GLM) was generated. The rate of dropping out served as the dependent variable, while self-motivation and accountability served as predictors to test the likelihood of participants dropping out. All predictors were individually tested for significance, and only the ones showing significance were included. With the help of a categorical variable, a new column was produced. The new variable was entitled “dropout,” for which participants completing the program fell under the number “0” and participants who dropped out fell under the number “1.” In other words, dropout was measured as a binary “yes” or “no” and then converted to a numeric variable. Results from the GLM revealed that Self-motivation showed to significantly affect the likelihood of dropping out of the program, whereas Accountability showed no significant effect, as shown in Table 18. Accountability shows to be closer to the mean as opposed to Self-motivation due to differences in Z scores.

Furthermore, the variance is tested in more detail with the help of ANOVA (Analysis Of Variance) and Chi-Square tests. As seen in Table 19, Self-motivation remains to have a significant effect, thereby, we conclude that it shares an association with dropping out, whereas accountability does not. In addition, we calculated the average predicted value of dropping out of the program, based on the model we created. This value resulted to be nearly 50%.


```{r q5a summary, results='asis'}

#Building model to test likeliness of dropping out
couchto5k <- couchto5k %>% mutate(dropout = ifelse(week_stopped < 9, "dropout", "completed")
)

couchto5k <- couchto5k %>% mutate(dropout = ifelse(couchto5k$week_stopped < 9, 1, 0))
  
couchdropout <- as.factor(couchto5k$dropout)
levels(couchdropout)

dropglm <- glm(couchdropout ~ 1 + selfmot + accountability, data = couchto5k, family = "binomial")

dropglm %>% pander(caption = "Table 18: General Linear Model For Likelihood of Dropout")

#tidy(dropglm)
summary(dropglm)

anova(dropglm, test = "Chisq") %>% pander(caption = "Table 19: Analysis of Deviance Table for General Linear Model")

predictdropout <- predict(dropglm, couchto5k, type= "response")

meanpredict <- mean(predictdropout)

meanpredict %>% pander(caption = "Table 20: Probability of Dropping Out")
```

```{r q5a, include = FALSE}

seasontest <- lm(dropout ~ season, data = couchto5k, na.action = na.exclude)
tab_model(seasontest)

agetest <- lm(dropout ~ age, data = couchto5k, na.action = na.exclude)
tab_model(agetest)

selfmottest <- lm(dropout ~ selfmot, data = couchto5k, na.action = na.exclude)
tab_model(selfmottest)

happinesstest <- lm(dropout ~ happiness, data = couchto5k, na.action = na.exclude)
tab_model(happinesstest)

accounttest <- lm(dropout ~ accountability, data = couchto5k, na.action = na.exclude)
tab_model(accounttest)

healthtest <- lm(dropout ~ health, data = couchto5k, na.action = na.exclude)
tab_model(healthtest)

citytest <- lm(dropout ~ city, data = couchto5k, na.action = na.exclude)
tab_model(citytest)

```

## Question 5b

After producing a General Linear Model to test the likelihood of dropping out (Dependent Variable) of the program, two key results were found. Firstly, as shown in Table 18, Self-motivation is a statistically significant predictor (p<0.05) thereby having an impact on the Dependent Variable. Secondly, Accountability is not a statistically significant predictor (p>0.05), thereby it does not influence the Dependent Variable. Our model, therefore, partially predicts the likelihood of dropping out. The residual deviance (147.58) shows to be lower than the null deviance (160.67). This indicates that the likelihood of dropping out can be better predicted by our model with variables, as opposed to just the intercept. The AIC value of 153.6 will come in hand if any further models are devised, as the score can help compare which model fits the data better. The ANOVA and Chi-Square test reveal Self-motivation to be statistically significant, whereas Accountability was statistically non-significant when testing the independence of groups (further results shown in Table 19). Hence, the data suggests an association between Self-motivation and the likelihood dropping out. Lastly, the average likelihood of dropping out based on the discussed model is 48.28% by using the “predict” function in RStudio.

## Question 5c

Based on ratings of Self-motivation, a scatter plot was generated to test the probability of quitting the program (Figure 20) This required us to include the “dropout” variable we added previously in our dataset. A GLM method was used to generate a line across the graph, in order to visually observe an effect. Upon looking at the graph, it is evident that as Self-motivation increases, the probability of quitting the program decreases, and vice versa. This visual data indicates that Self-motivation does indeed predict whether participants may quit during a particular time period.

```{r q5c}

#adding dropout variable 
couchto5k <- couchto5k %>% mutate(dropout = ifelse(week_stopped < 9, 1, 0))

#graph showing probability of quitting
ggplot(data = couchto5k, aes(x = selfmot, y = dropout)) +
  geom_jitter() +
  geom_smooth(method = "glm", method.args = list(family = binomial), se = TRUE)+
  labs(y="Probability of Dropping Out", x = "Self Motivation", title = "Figure 20: Probability of Dropping Out 
               As a Function of Participant's 
               Self-motivation Ratings.")+
  scale_x_discrete(breaks = seq(0,5,by=.5))+
  theme_bw()

```










