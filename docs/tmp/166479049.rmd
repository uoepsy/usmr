---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
  html_document: default
params:
  examnumber: 'B203234'
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
library(pander)
library(ggplot2)
library(psych)
library(patchwork)
library(sjPlot)
library(jtools)
library(huxtable)
# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
total_before <- count(couchto5k)
```

# Question 0
<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->


```{r cleaning, include = FALSE}
# Neither output nor code from this chunk will be shown in the compiled document. 
summary(couchto5k)
couchto5k$missing <- NA
#ther are people with ages over 100
couchto5k$missing[couchto5k$age>100] <- "crazy age"
#there are self motivation scores below 1 which is impossible as this measure is a sum of 5 question with scores 1-7 per question
couchto5k$missing[couchto5k$selfmot<1] <- "impossible selfmot"
#there are weeks over week 9 which is the max week
couchto5k$missing[couchto5k$week_stopped>9] <- "impossible end of programme"
mtab <- table(couchto5k$missing)

#removing the rows that need to be removed
couchto5k <- couchto5k %>% filter(is.na(missing))
total <- count(couchto5k)
summary(couchto5k)

```

The data was obtained from https://uoepsy.github.io/data/usmr_2122_data.R: a dataset containing information on `r total_before` participants, taking part in the Couch to 5k program over the course of a year in the cities of Edinburgh and Glasgow. The dataset contains information on the age of the participants and the week at which the participant stopped the program with week 9 being the final week of the program. It also contains a measure of accountability measured on 5 questions with scores from 1 to 7 each, a measure of self motivation assessed on 5 questions with scores from 1 to 7each, a measure of health from 0 to 100, a happiness measure from 0 to 100, and the season of the year in which the participants were interviewed in. 


The data was checked for missing values and impossible values. No missing values were found but the age, self-motivation and week_stopped columns had some impossible values that could not be interpreted thus were removed from the data set resulting in `r total` observations for analysis. Table 1 gives a summary of removed data.
```{r table, results="asis"}

mtab %>% pander(caption="Table 1: Summary of missing values.")

```

```{r season, include = FALSE}
#season data
as.factor(couchto5k$season)
miscoded <- sum(couchto5k$season=='autunm')
couchto5k$season[couchto5k$season=='autunm'] <- 'autumn'
couchto5k$season <- as.factor(couchto5k$season)

summary(couchto5k)
```

`r miscoded` season entries were initially misentered as 'autunm'. These were recoded as 'autumn' as they looked like typos and could be easily understood that they were meant to indicate the autumn season. 

The descriptive values for the numerical variables including the number of samples, mean, standard deviation, min and max can be seen in Table 2.  

```{r descriptives}
# Code will not be shown from this chunk (because we set echo = FALSE in the very first chunk)
# the output from this code will be shown. 
descriptive_info <- describe(couchto5k[-c(7,8,10)])
descriptive_info <- descriptive_info[-c(1,5,6,7, 10:13)]
descriptive_info %>% pander(caption="Table 2: Summary of the numerical values.")

```

The figure below shows the plot of the numerical variables, all variables except for week_stopped appear to be normally distributes based on the histograms and their means in table 2. Bivariate correlation shows a strong negative correlation (r = -0.69) between age and health which is expected, a moderate positive correlation (r= 0.30) between self motivation and happiness, a weak positive correlation between accountability and age (r = 0.12), a weak positive correlation between week_stopped and self motivation (r = 0.15) and week_stopped and accountability (r=0.14), and a moderate positive correlation (r = 0.24) between week_stopped and health.   

figure lable: Figure 1: Bivariate scatter plots (below diagonal), histograms (diagonal), and Pearson correlation coefficient (above diagonal), of all numerical variables.

```{r}
plot_data <- couchto5k[-c(1,7,8,10)]
pairs.panels(plot_data)

```


# Question 1 

## Question 1a

```{r q1a}
couchto5k$stopped <- NA
couchto5k$stopped[couchto5k$week_stopped<5] <- "stopped before 5"
couchto5k$stopped[couchto5k$week_stopped > 4 & couchto5k$week_stopped < 9] <- "stopped after 5"
couchto5k$stopped[couchto5k$week_stopped == 9] <- "completed"

#testing whether they are in line with the survey data
table(couchto5k$stopped)
test <- chisq.test(table(couchto5k$stopped), p = c(.45,.1,.45))
test
```
A chi-squared test of independence (with statistical significance set at $\alpha$= 0.05) was conducted on a table with the week_stopped variable which is a categorical variable divided by time of end of programme (before week 5, after week 5 and completed) to investigate whether the data given is in line with the data from the survey. It was found that the difference between the given sample and the proportions in the survey sample was not significant p>0.05 (p-value = `r test$p.value` and x-squared = `r test$statistic`) indicating that the data in the given sample is in line with the data from the survey. Just like in the survey, in our sample around 45% of participants abandoned the programme before week 5, 10% after week 5 and the remaining 45% completed the program.

## Question 1b

```{r q1b}
t <- couchto5k %>%
  select(city,stopped) %>% table()
#t
# expected values
e <- rowSums(t) %o% colSums(t) / sum(t)
#e

#residuals = t - e
#plot(density(residuals))
plot(table(couchto5k$stopped, couchto5k$city), main= 'Week stopped by city')


chisq.test(t)
p <- chisq.test(t)$p.value
#p
```
A chi square test of independence (with statistical significance set at $\alpha$= 0.05) was conducted to examine whether the patterns of attrition rates differ by city (Edinburgh and Glasgow). It was found that the pattern of attrition rates differ between the two cities, p-value=`r p` which is smaller than the set alpha 0.05 indicating that the null hypothesis that the two distributions are the same needs to be rejected.

## Question 1c

```{r q1c}


t_age <- couchto5k %>%
  select(city, age) %>% table()
#t_age
# expected values
e_age <- rowSums(t_age) %o% colSums(t_age) / sum(t_age)
#e_age



residuals_age = t_age - e_age
#residuals_age

#norm_res <- shapiro.test(residuals_age)

#norm_res$p.value

  


```

```{r}
#res_plot <- plot(density(residuals_age))
par(mfrow=c(1, 2))
plot(density(residuals_age[1,])) #edinburgh
plot(density(residuals_age[2,])) #glasgow
shapiro.test(residuals_age[1,])
shapiro.test(residuals_age[2,])

#plot showing the difference in means between the two cities
ggplot(data = couchto5k, aes(x = age, y = city)) +
  geom_boxplot()
```

```{r}
t_test <- with(couchto5k, t.test(age ~ city, alternative = "two.sided"))
#t_test
```


To compare whether the average ages of participants differ by city a two sided independent sample t-test was conducted (with statistical significance set at $\alpha$= 0.05) after checking for assumptions of normality (figure x, figure y). The residuals of the age distributions per city are both normally distributed as can be seen from their density plots and the results of the Shapiro-Wilk test for normality indicated no evidence against the null hypothesis for both cities (W=1, p=0.2, W=1, p=0.2). The t-test indicated that there is a significant difference in the average ages of participants in the two different cities (p-value=`r t_test$p.value`, t=`r t_test$statistic`) as the p-value < 0.05. Figure X shows a boxplot of the two means by city.


# Question 2

## Question 2a

```{r q2a, results='asis'}

#rstudent(model)
couchto5k <- couchto5k[-c(115),]
model1 <- lm(happiness ~ 1 + season, data = couchto5k)
summary(model1)
anova(model1)
export_summs(model1, error_format = "[{conf.low}, {conf.high}]")
#knitr(tab_model(model1))

#check assumptions:
#linearity of relationship, categorical predictor so this doesn't work
#plot(model1, which=1)
layout(matrix(c(1,2,3,3), 2,2, byrow = TRUE))
#for the residuals:
#normality
plot(density(resid(model1)))
#Q-Q
plot(model1, which=2)
#rstudent(model)

#homogeneity of variance
#categorical variables so no
#independence
library(car)
dwt(model1)
#no 'bad' (overly influential) observations
#cook's distance
plot(model1, which=4)


```
To investigate whether season influences happiness outcomes happiness was modeled using linear regression. Season was included as a predictor and is a categorical variable with four levels. Effects will be considered statistically significant at Î±=0.05.
One observation was excluded from the final analysis as it was judged to be a regression outlier (studentised residual > |2|). The final model was fitted to the remaining 121 observations, and took the form: $$happiness = \hat{\beta_{0}} + \hat{\beta_{1}}SP + \hat{\beta_{2}}SU + \hat{\beta_{3}}WI +Ïµ $$ 

Where: SP = seasonspring 
SU = seasonsummer
WI = season winter
The model is close to normal though there are some data points on the Q-Q plot still diverging from the normal line. The density plot of the residuals also shows this. The Cook's distance plot shows that there are no influential outliers. The assumption of independence of errors was not fully met as the p-vaue is below 2 (Durbin-Watson test for autocorrelation of residuals: DW=1.70, p=0.09). This means there might still be systematic structure in the residuals. The plot to check for homogeneity and the plot of residuals vs fitted values were not valid tests as our predictor is a categorical variable so the points cluster around the four categories. Overall more predictors seem to be needed to explain the variance in the data.

Full regression results and 95% confidence intervals can be seen in Table X. The F-test for model utility was significant (F(3,117)=4.99, p=0.003) indicating that this model improves the ability to explain the data over the null model, and the model explained approximately 11% of the variability in the happiness scores. There was a significant effect of season on happiness as can be seen from the anova of the model (p = 0.0027, F=4.99), in particular the effect of summer ($\beta$ = `r model1$coefficients[3]`, SE = 11.60 , p = 0.024), spring ($\beta$ = `r model1$coefficients[2]` , SE = 10.59 , p <0.001) and autumn ($\beta$ = `r model1$coefficients[1]`, SE = 9.91, p = 0.018) was statistically significant. This suggests that for those who participated in the programme in autumn the average value of happiness is 23.80, for those who participated during spring there was an increase of 38.34 over the happiness rating in autumn and for those who participated during summer there was an increase of 20.51 over the rating in autumn. Winter instead is not reliably statistically different from autumn ($\beta$ = `r model1$coefficients[4]`, SE =  13.21, p = 0.12). Happiness ratings are thus highest during spring, and lowest during autumn indicating that season does have an effect on happiness. The mean happiness ratings per season can be seen in the boxplot (Figure X). 


```{r}
gd <- couchto5k %>% group_by(season) %>%
  summarise(mean_se(happiness))
gd %>% ggplot(aes(x=season,y=y,
                  ymin=ymin,ymax=ymax)) +
  geom_bar(stat="identity") +
  geom_errorbar(width=.2) +
  ylab("happiness")
```

## Question 2b

```{r q2b, results = 'asis'}
model2 <- lm(happiness ~ 1 + season + I(age-18), data = couchto5k)
summary(model2)
anova(model2)
export_summs(model2, error_format = "[{conf.low}, {conf.high}]")
#tab_model(model2)
```
To investigate whether age influences happiness outcomes happiness was modeled using linear regression. Season and age were included as predictors, age being a numeric predictor. Age was rescaled to being a participant of age 18 at the intercept as that is the minimum age in the dataset and a participant with 0 years of age would not be able to take part in the programme. Effects will be considered statistically significant at Î±=0.05.
The model took the form: $$happiness = \hat{\beta_{0}} + \hat{\beta_{1}}SP + \hat{\beta_{2}}SU + \hat{\beta_{3}}WI + \hat{\beta_{4}}A +Ïµ$$ 

Where: SP = seasonspring 
SU = seasonsummer
WI = season winter
A = age


```{r, include = FALSE}
cor <- couchto5k %>%
 select(age, happiness) %>%
 cor()
```


Full regression results and 95% confidence intervals can be seen in Table X. 
The model's anova (F-value =0.80, p = 0.37) indicated that the effect of age was not significant, indicating that this model does not significantly improve the ability to explain the data over the null model. The model explained 12% of the variance in the data, only a 1% increase compared to the model with just season as a predictor. The intercept shows the average value of happiness in autumn when age is 18 ($\beta$ = `r model2$coefficients[1]`, SE = 13.6 , p = 0.26) though this is not statistically significant as seen from the p-value. For every additional year of age there is an increase in happiness of `r model2$coefficients[5]` (SE =  0.222 , p = 0.37265) which is also not statistically significant. The potential effect of age on happiness was further investigated by calculating their correlation, however their correlation coefficient (r=`r cor[2]`) indicated no correlation between happiness and age. Overall age does not seem to have an effect on happiness. 




## Question 2c

The baseline model for further analysis will be the model with only season as a predictor. This is justified by the fact that age does not have a statistically significant effect on happiness and does not further improve the model with only season. This was seen in the anova results of the model as well as the fact that there is no correlation between age and happiness. Keeping a predictor within the model that does not further contribute to explaining the variance in the data can cause noise in the model when adding further predictors. Thus the baseline model will take the form of the model with only season as a predictor of happiness. 

# Question 3

## Question 3a

```{r q3a, results='asis'}
couchto5k$completed <- NA
couchto5k$completed[couchto5k$week_stopped<9] <- "not completed"
couchto5k$completed[couchto5k$week_stopped == 9] <- "completed"
couchto5k$completed <- as.factor(couchto5k$completed)

couchto5k$completed <- relevel(couchto5k$completed, ref = "not completed")
model3 <- lm(happiness ~ 1 + season + completed, data = couchto5k)
summary(model3)
anova(model3)
export_summs(model3, error_format = "[{conf.low}, {conf.high}]")
#tab_model(model3)
```

To investigate whether completion of the programme influences happiness outcomes happiness was modeled using linear regression. Season and completion or not of the programme were included as predictors. Completion of the programme was modeled as a two level categorical variable with not completed as the reference level. Effects will be considered statistically significant at Î±=0.05.
The model took the form: $$happiness = \hat{\beta_{0}} + \hat{\beta_{1}}SP + \hat{\beta_{2}}SU + \hat{\beta_{3}}WI + \hat{\beta_{4}}C +Ïµ$$ 

Where: SP = seasonspring 
SU = seasonsummer
WI = season winter
C = completion


Full regression results and 95% confidence intervals can be seen in Table X. The model's anova (F-value =2.24, p = 0.14) indicated that the effect of completion was not significant, indicating that this model does not significantly improve the ability to explain the data over the null model. The model explained 13% of the variability in the happiness rating, only a 2% increase over the baseline model with just season as a predictor. The intercept is the value for happiness in autumn and in the condition in which participants have not completed the program ($\beta$ = `r model3$coefficients[1]`, SE =  11.35, p = 0.18). When participants complete the programme there is a `r model3$coefficients[5]` increase in the mean happiness rating however this increase is not statistically significant ($\beta$ = `r model3$coefficients[1]`, SE =  1.50, p = 0.14). Completion of the programme does not seem to influence happiness ratings in a statistically significant way, more predictors are needed to explain the variance in the data. The 'completed' predictor will be removed from the model for happiness.



## Question 3b

```{r q3b, results='asis'}
model4 <- lm(happiness ~ 1 + season + health, data = couchto5k)
summary(model4)
anova(model4)
export_summs(model4, error_format = "[{conf.low}, {conf.high}]")
#tab_model(model4)
cor3 <- couchto5k %>%
  select(health, happiness) %>%
  cor()
cor3
#ggplot(data = couchto5k, aes(x = health, y = happiness)) +
 # geom_point(alpha = 0.5) +
  #labs(x = "health", 
    #   y = "Happiness")

```
To investigate whether happiness outcomes are additionally affected by the health metric happiness was modeled using linear regression. Season and health were included as predictors with health being a numeric variable. Effects will be considered statistically significant at Î±=0.05.
The model took the form: $$happiness = \hat{\beta_{0}} + \hat{\beta_{1}}SP + \hat{\beta_{2}}SU + \hat{\beta_{3}}WI + \hat{\beta_{4}}H +Ïµ$$ 

Where: SP = seasonspring 
SU = seasonsummer
WI = season winter
H = health

Full regression results and 95% confidence intervals can be seen in Table X. The F-test for model utility was not significant (F(4,116)=3.72, p< 0.007) indicating that this model does not improve the ability to explain the data over the null model. The model explained approximately 11% of the variability in the happiness scores (R-squared = 0.114). The intercept shows the value of happiness during autumn, and with health score of zero ($\beta$ = `r model4$coefficients[1]`, SE = 19.0, p=0.27). For a one unit increase in health there is a `r model4$coefficients[5]` increase in mean happiness rating however this is not statistically significant ($\beta$ = `r model4$coefficients[5]`, SE = 0.29, p=0.88) meaning that the effect of healthy is not reliably different from the mean value of happiness without health (at the intercept). The F-value (0.02) and p-value (0.8767) for health in the model anova further supports the fact that the effect of health is not statistically significant. There is also no correlation between health and happiness (r=`r cor3[2]`) So happiness does not seem to be additionally affected by the 'health metric', further predictors are needed in the model such as interactions between predictors. 

## Question 3c

```{r q3c, results='asis'}

couchto5k$further_along <- NA
couchto5k$further_along[couchto5k$week_stopped<5] <- "stopped soon"
couchto5k$further_along[couchto5k$week_stopped > 4] <- "stopped later"
couchto5k$further_along <- as.factor(couchto5k$further_along)
couchto5k$further_along <- relevel(couchto5k$further_along, ref = "stopped soon")
#modely <- lm(happiness ~ 1 + season + further_along + health, data = couchto5k)
#modelz <- lm(happiness ~ 1 + season + further_along, data = couchto5k)
#summary(modely)
#summary(modelz)
#anova(modelz)

#anova(modely)

model5 <- lm(happiness ~ 1 + season + further_along + health + health:further_along, data = couchto5k)
summary(model5)
anova(model5)
export_summs(model5, error_format = "[{conf.low}, {conf.high}]")
#tab_model(model5)

par(mfrow=c(2,2))

plot(model5, which = 1)
plot(model5, which = 2)
plot(model5, which = 3)
plot(model5, which = 4)


```
To answer the question of whether the effect of good health is amplified by the feeling of acting healthily, with the happiness of participants who got further along the programme being more affected by the health metric happiness was modeled using linear regression. Season, health, further_along and the interaction between health and getting further along were included as predictors with further_along being a categorical predictor with two levels (left the programme before 5 weeks, or continued the programme after five weeks includng the participants who completed it). Effects will be considered statistically significant at Î±=0.05.
The model took the form: $$happiness = \hat{\beta_{0}} + \hat{\beta_{1}}SP + \hat{\beta_{2}}SU + \hat{\beta_{3}}WI + \hat{\beta_{4}}F + \hat{\beta_{5}}H + \hat{\beta_{6}}F+ \hat{\beta_{7}}H Â· F + Ïµ$$ 

Where: SP = seasonspring 
SU = seasonsummer
WI = season winter
F = further into the programme or not
H = health

To address the research question of whether taking the programme affects health and wellbeing we will consider the hypothesis test that the interaction coefficient between getting further along he programme and the health metric is equal to zero, where:

H0:Î²7=0. The interaction between health and further_along is equal to zero.
H1:Î²7â 0. The interaction between health and further_along is not equal to zero.

The assumption of linearity of relationship and the assumptions of normality. homogeneity and independence of residuals were checked again for this model and was found that all assumption were met as can be seen from the Q-Q plot, the scale-location plot for homogeneity of variance and the residuals vs fitted plot for linearity. There are no particularly influential values as can be seen on the Cook's distance plot.

Table X shows full regression results including 95% confidence intervals. The interaction between health and getting further along in the programme in predicting happiness can be seen visually in Figure X. The F-test for model utility was significant (F(6,114)=10.3, p<.001), and the model explained approximately 35.2% of the variability in happiness ratings which is much higher than in any previous models meaning that this model with the interaction between health and getting further along the programme can explain more of the variance in the happiness ratings than any of the previous models.

```{r}
couchto5k %>% ggplot(
  aes(x=health,y=happiness,colour=further_along)) +
  xlab("health") +
  ylab("happiness") +
  geom_point(size=3) +
  geom_smooth(method="lm")
```
Results showed that the interaction between completion of the program and health is significant ($\beta$ = `r model5$coefficients[7]`, SE = 0.53, p<.001) which means that the effect of health is not the same for the participants that have gone further along the programme (after week 5) and the ones that have not (stopped before week 5). This also indicates that we can reject the null hypothesis that Î²7=0. The model shows that health affects participants differently depending on whether they continued the programme after week 5. For participants who went further along the program the higher the health score the higher the happiness score while for participants who stopped before week 5 the health score does not have an effect on happiness or might even lead to a decrease in happiness. For the participants who stopped earlier a one unit increase in health results in happiness increasing by the value of the coefficient of health which is `r model5$coefficients[6]`(SE = 0.427, p<.001), this is a negative value which results in a decrease in the mean happiness ratings for the participants who stopped earlier. Instead to obtain the value of happiness when stopping later we need to add the coefficient of the interaction between health and going further along and the coefficient of health which gives us: `r model5$coefficients[6] + model5$coefficients[7]`. This indicates that when the programme was stopped later the average increase in health is positive. A one unit increase in health will lead to a decrease in mean happiness ratings for the participants who stopped the programme before week 5 and viceversa a one unit increase in health will lead to an increase in the mean happiness ratings for the participants who stopped later. So the happiness of participants who got further along the programme is more positively affected by the health metric than the happiness of those who stopped earlier, happiness is arguably affected negatively by health in the participants who stopped earlier. However, average happiness ratings decrease more for the participants who stopped earlier than they increase for the participants who went further. 


## Question 3d

The results presented in this report indicate that the various causes of happiness in our data are the season in which the participants took the programme, with lower mean ratings during autumn and higher ones during spring and summer, and the interaction between health and getting further along in the programme. In fact, the association between happiness ratings and health ratings depends on whether participants got further along in the programme or not, with participants who got further along having higher mean happiness ratings with a one unit increase in health than the participants who stopped earlier (before 5 weeks). If the participants stopped the programme before 5 weeks then health seems to have a negative effect on the mean happiness ratings. So to address the research question of whether taking the programme affect s health and wellbeing, getting further along in the programme seems to have a more positive effect of participants' perceived health and happiness than stopping earlier in the programme. 

# Question 4

```{r q4}
couchto5k_sub <- subset(couchto5k, completed == 'completed')
gd <- couchto5k_sub %>% group_by(season, city) %>%
 summarise(mean_se(happiness))
#gd
gd %>% ggplot(aes(x=season,y=y,
                ymin=ymin,ymax=ymax)) +
  geom_bar(stat="identity") +
  geom_errorbar(width=.2) +
  ylab("happiness") +
  facet_wrap(~city)

```
Plot of the average happiness ratings grouped by season and city.

# Question 5

## Question 5a

```{r q5a, results='asis'}
couchto5k$quitting <- NA
couchto5k$quitting[couchto5k$completed == 'completed'] <- 0
couchto5k$quitting[couchto5k$completed == 'not completed'] <- 1
couchto5k$quitting <- as.numeric(couchto5k$quitting)
mod.q <- glm(quitting ~ 1,
             family = binomial, 
             data=couchto5k)

logLik(mod.q)
summary(mod.q) #coefficients are in log odds
export_summs(mod.q, error_format = "[{conf.low}, {conf.high}]")
#tab_model(mod.q)

#converting the log odds back to odds:
odds <- exp(coef(mod.q))
odds


```

## Question 5b

```{r q5b, include = FALSE}
l2p <- function(logits) {
  odds = exp(logits)
  prob = odds/(1+odds)
  return(prob)
}

probability <- l2p(mod.q$coefficients[1])
probability
```
The likelihood of at all quitting the programme is modeled using logistic regression with not completing the program as the reference level. The intercept value in log-odds is `r mod.q$coefficients[1]`. The odds of quitting the programme at all is 1:1, or equal odds. Converting this into probability gives us an overall probability of quitting of `r probability` which means there is approximately a 50% or equal chance of quitting or not quitting the programme overall. 

## Question 5c

```{r q5c}
couchto5k %>% ggplot(aes(x=selfmot,y=quitting)) +
  ylab("p(quitting)") +
  geom_jitter(size=3,width=0,height=.1, alpha=.1) +
  geom_smooth(method="glm",method.args=list(family=binomial)) +
  scale_y_continuous(breaks=seq(0,1,by=.2))

```
Graph representing the probability of quitting as a function of how self motivated participants are. The higher the self motivation score the less likely a participant is to quit the programme. Quitting is represented by the value 1 on the y axis, not quitting by the value 0.









