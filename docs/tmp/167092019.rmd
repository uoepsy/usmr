---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
  html_document: default
params:
  examnumber: "B197312"
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0
<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->

```{r cleaning, include = FALSE}

glimpse(couchto5k)
#install.packages("ggstatsplot")


# Visualise

outlier_acc <- boxplot(couchto5k$accountability,
  ylab = "accountability",
  main = "Boxplot of accountability"
)
mtext(paste("Outliers: ", paste(outlier_acc, collapse=", ")), cex=0.6)

outlier_hap <- boxplot(couchto5k$happiness,
  ylab = "happiness",
  main = "Boxplot of happiness"
)
mtext(paste("Outliers: ", paste(outlier_hap, collapse=", ")), cex=0.6)

outlier_health <- boxplot(couchto5k$health,
  ylab = "health",
  main = "Boxplot of health"
)
mtext(paste("Outliers: ", paste(outlier_health, collapse=", ")), cex=0.6)

outlier_age <- boxplot(couchto5k$age,
  ylab = "age",
  main = "Boxplot of age"
)
mtext(paste("Outliers: ", paste(outlier_age, collapse=", ")), cex=0.6)



```

# # Data Cleaning 
Before analyses were conducted on our variables of interest, the data set was cleaned by scanning for outliers and NA values. Impossible values were identified after running boxplots on each independent variable. These were changed to NA values since such an extreme value such as -99 which lay outside the actual scales can significantly alter SD, correlation coefficients and bring down the mean in our analyses. Given that the rest of the participants’ data points for the other variables were within a reasonable range of responses, the participants themselves were not removed for data analysis.
Although one outlier was identified for the health metric at health=86, it was included for analysis as it was considered only a mild-outlier on the inner fence of the data. I reasoned that this could be a result of natural variance of the data spread. Since it does not deviate in an extreme to warrant us excluding it from the analysis just to increase the statistical significance and power of our models.



# # Removing Outliers

```{r}
boxplot.stats(couchto5k$selfmot) 
# -99, -99
boxplot.stats(couchto5k$age) 
# 134, 140
boxplot.stats(couchto5k$accountability) 
# 0
boxplot.stats(couchto5k$health)
# 86
boxplot.stats(couchto5k$happiness)
# 0
boxplot.stats(couchto5k$week_stopped) 
# 0


# Remove values by switching to NA 


newcouchto5k <- couchto5k %>% 
  mutate(
    selfmot = as.numeric(selfmot),
    selfmot = ifelse(selfmot<7, NA, selfmot),
    week_stopped = ifelse(week_stopped>9, NA, week_stopped),
    age = ifelse(as.numeric(age)>60, NA, as.numeric(age)))

```

# Descriptives 
After cleaning the data set and identifying any impossible values and extreme outliers worth excluding, histograms were conducted on the variables of interest in our data set to determine whether the participant data was normally distributed. According to the results of our data, self-motivation, health and accountability were the only variables that were relatively normally distributed among our sample participants of N=128. 



# # Checking for Normalcy with histograms and Q-Q plots

Remove the NAs before doing the calculation 
`r na.rm=TRUE`
or remove rows with NA:
`r newcouchto5k <- na.omit(couchto5k)`

```{r descriptives1}
# Mean, SD, Median for numerical continuous variables

# Happiness
sd(newcouchto5k$happiness)
mean(newcouchto5k$happiness)
median(newcouchto5k$happiness)
# Accountability
sd(newcouchto5k$accountability)
mean(newcouchto5k$accountability)
median(newcouchto5k$accountability)
# Health
sd(newcouchto5k$health)
mean(newcouchto5k$health)
median(newcouchto5k$health) 
# Self-motivation
mean(newcouchto5k$selfmot)
median(newcouchto5k$selfmot)
# Age
mean(newcouchto5k$age)
median(newcouchto5k$age)
# Week Stopped
mean(newcouchto5k$week_stopped)
median(newcouchto5k$week_stopped)
```
```{r}
na.omit(newcouchto5k)

newcouchto5k$happiness_sc = scale(newcouchto5k$happiness)
newcouchto5k$health_sc = scale(newcouchto5k$health)
newcouchto5k$accountability_sc = scale(newcouchto5k$accountability)
newcouchto5k$health_sc = scale(newcouchto5k$health)
newcouchto5k$age_sc = scale(newcouchto5k$age)
newcouchto5k$selfmot_sc = scale(newcouchto5k$selfmot)
select(newcouchto5k, one_of(c("happiness_sc", "health_sc", "accountability_sc", "health_sc", "age_sc", "selfmot_sc"))) %>% cor()

corvar <- cor(newcouchto5k[c("happiness", "health", "accountability")])
corvar

```
```{r}
library(pander)
corvar %>% pander(caption = "Correlatin Matrix of continuous variables of interest")
```

# # Interpretation
A correlation test was run on predictor and outcome variables of interest to determine if there are any correlations between any two given variables. Where a moderate correlation lies between 0.3 and 0.7 (positive and negative), it appeared that no significant correlations exist between any of the given variables. However, health and accountability did show a small positive correlation coefficient of 0.1.  

```{r descriptives2}
splot <- newcouchto5k %>% ggplot(df, mapping = aes(x=selfmot)) + 
  geom_histogram(binwidth = 1.0, color  = "white")
splot + ggtitle("Self Motivation Distribution") + xlab("Self Motivation") + ylab("Frequency")
splot

hplot <- newcouchto5k %>% ggplot(df, mapping = aes(x=health)) + 
  geom_histogram(binwidth = 1.0, color  = "white")
hplot + ggtitle("Health Distribution") + xlab("Health") + ylab("Frequency")

hpplot <- newcouchto5k %>% ggplot(df, mapping = aes(x=happiness)) + 
  geom_histogram(binwidth = 1.0, color  = "white")
hpplot + ggtitle("Happiness Distribution") + xlab("Happiness") + ylab("Frequency") 
hpplot

ageplot <- newcouchto5k %>% ggplot(df, mapping = aes(x=age)) + 
  geom_histogram(binwidth = 1.0, color  = "white")
ageplot + ggtitle("Age Distribution") + xlab("Age") + ylab("Frequency")
ageplot

acplot <- newcouchto5k %>% ggplot(df, mapping = aes(x=accountability)) + geom_histogram(binwidth = 1.0, color  = "white")
acplot + ggtitle("Accountability Distribution") + 
  xlab("Accountability") + ylab("Frequency")
acplot
wkplot <- newcouchto5k %>% ggplot(df, mapping = aes(x=week_stopped)) + geom_histogram(binwidth = 1.0, color  = "white")
wkplot + ggtitle("Week Stopped Distribution") + 
  xlab("Week Stopped") + ylab("Frequency")
wkplot
```

```{r}
summary(newcouchto5k)
```

# Study Aim

# # The researchers’ interests are two-fold: They are interested in the psychological factors that make people continue on the programme, and in the effects of taking the programme on health and wellbeing.
At Week 0, all participants completed a questionnaire measuring the psychometric factors of accountability and self-motivation.
Upon either completing the programme (Week 9) or dropping out (< Week 9), participants completed a questionnaire which included a measure of their self-reported happiness, and a “health” measure derived from a number of physiological tests.

# Question 1 

## Question 1a
In an earlier nationwide survey, researchers found that 45% of participants abandoned the programme before the halfway point in week 5, and a further 10% gave up before the end of the programme. Is the data in the sample you have been given in line with data from the earlier survey? Once you have created a suitable variable to map to the information in the question, you should be able to answer this using a simple statistical test.



```{r q1yh}



newcouchto5k <-
  newcouchto5k %>%
  mutate(group1 = ifelse(week_stopped <5, 1, 0), group3 = ifelse(week_stopped > 8, 3, 0), group2 = ifelse(week_stopped >4 & week_stopped <9, 2, 0))

newcouchto5k <-
  newcouchto5k %>%
  mutate(categ = ifelse(week_stopped <5, 1, ifelse(week_stopped > 8, 3, 2)))

summary(newcouchto5k)

```

```{r q1yolo}
#create histogram of progress

hist(newcouchto5k$categ,
     main="Frequency of program progress",
     xlab="Before, midway, completed",
     xlim=c(0,4),
     col="lightblue",
     freq=FALSE)
```

```{r q1b}
# Find proportions

hist(newcouchto5k$week_stopped)
table(newcouchto5k$week_stopped)
prop.table(table(newcouchto5k$categ))*100

table(newcouchto5k$categ)
print(table(newcouchto5k$categ))

chisqt <- chisq.test(table(newcouchto5k$categ), p = c(0.45,0.10,0.45))
print(chisqt)
```
# # Interpretation:
According to our sample data, differences in proportions of individuals that stopped before week 5, finished only part way and completed do not differ significantly from those in the previous sample. After conducting a histogram to visualise the spread of the data, it appeared that the data in our sample was skewed in a highly similar way. To confirm the exact frequencies, a Chi Square goodness of fit test was conducted to determine if this sample was representative of the previous one. We can accept the null hypothesis that the two samples do not differ significantly, X^2(2, N=127)=0.04, p=1. What is interesting to note is that there was a mere perfect correlation of p=1. Not only are the two samples not significantly different, but they are almost exactly the same in terms of the proportions of progress for the three stages of the program.

# Question 1b
Using the same three categories (stopped before week 5, stopped after week 5, completed), examine whether the patterns of attrition rates differ by city.


```{r}
glasgow = newcouchto5k[which(newcouchto5k['city']=="Glasgow"),]
edinburgh = newcouchto5k[which(newcouchto5k['city']=="Edinburgh"),]
glastab <- table(glasgow$categ)
edtab <- table(edinburgh$categ)
print(glastab)
print(edtab)
chisq.test(glastab, edtab)

```

# # Interpretation

A Chi square test was conducted to determine whether the attrition rates of the program differ significantly by city. After creating a new dataset for each city, I generated a table for each city and filtered by the variable which partitions the data sets by category of completion (i.e. dropped out before week 5, stopped midway and completed). The Chi square test ran the two sets of attrition rate and compared the goodness of fit between the two, revealing that they did not differ significantly, X^2=(4)=6, p=0.2.


## Question 1c
Do the average ages of participants who commenced the programme differ by city?

Hypotheses (H0= Null hypothesis and H1= Alternative hypothesis)
H0: The average age does not differ by city for individuals that commenced the program. H1: The average age between participants that commenced the program in Edinburgh differ significantly from that of participants in Glasgow.


```{r q1c}
table(newcouchto5k$season)
newcouchto5k$season = recode_factor(newcouchto5k$season, autumn = "autumn", autunm = "autumn", spring = "spring", summer = "summer", winter = "winter")
season <- newcouchto5k$season


# assumptions

categ3 = newcouchto5k[which(newcouchto5k['categ']=="3"),]

# t-test group by category 3: compare means of age for Edinburgh and Glasgow (group by categ 3)
# numerical: age and categorical: city 

boxplot(newcouchto5k$age ~ newcouchto5k$city)

acbp <- ggplot(newcouchto5k, aes(x=city, y=age)) + geom_boxplot() 
acbp + ggtitle("Age and City") + xlab("City") + ylab("Age") + ylim(20, 60)




```


```{r}
# t-test
t.test(newcouchto5k$age ~ newcouchto5k$city, mu=0, alt="two.sided", conf=0.95, var.eq=F, paired=F)
```
# # Interpretation

To determine whether the average ages for the two cities in the study differ significantly, a two-tailed t-test was run. Given that it is used to assess meaningful differences between independent groups, it was determined to be an appropriate method of analysis. Upon analysing the output, we fail to reject the null hypothesis (H0) that the mean age of the two cities does not differ significantly for individuals that commenced the program. We cannot accept the alternative hypothesis (H1) that a significant difference in average age between Edinburgh, (M= 38.9, SD=-1.34) and Glasgow, (M=35.6, SD=7.85) is present in the results for a 95% confidence interval, t(79)=1, p=0.2. 
# Question 2

## Question 2a
Are participants’ happiness ratings affected by the season they were interviewed in? Describe the way in which season influences happiness outcomes.

```{r}
# box plots group by season for happiness ratings for t-tests


hapabp <- ggplot(newcouchto5k, aes(x=season, y=happiness)) + geom_boxplot() 
hapabp + ggtitle("Season and Happiness") + xlab("Season") + ylab("Happiness")


```
# # Visualizing The Data

Hypotheses: 
H0: Happiness ratings do not significantly differ across season of program participation
H1: Happiness ratings are significantly different between seasons of program participation


```{r q2a}
# does season have a sig effect on happiness? 

lm_hap_szn <- lm(happiness ~ 1 + newcouchto5k$season, data = newcouchto5k, na.action=na.exclude)
summary(lm_hap_szn)


# Note that we used the na.action=na.exclude function to account for NA values which were found in season. We did not want to ommit the entire rows as not to disrupt the regression model too much. We use na.exclude to perform casewise deletion, thus, we can retain all of the data for each row with the exception of the individual case of missing data.

```
```{r}
plot_szn_happ <- ggplot(data=newcouchto5k, aes(x=season, y=happiness)) + geom_point(stat='identity') 

plot_szn_happ
```

```{r}
library(pander)
summary(lm_hap_szn) %>% pander(caption = "Season and Happiness") 
```

# # Interpretation

After running a linear model of happiness as a dependent variable and season as an independent variable, we fail to reject the null hypothesis that season has a significant effect on happiness ratings in our sample (H0) for a 95% confidence interval (p<0.05). We cannot accept the alternative hypothesis that there is a significant relationship between season of program enrollment and happiness. Upon analysing the spread of our data as seen in the figure above, the range of values for each season in terms of happiness appears relatively similar. There were no identifiable trends, although according to our linear model output, happiness was slightly higher for winter, however the p value was too large to indicate any significant difference. Furthermore, our R squared value indicates season accounted for a minuscule amount of the variation in happiness ratings with R=0.0025. 


## Question 2b
Accounting for any effects you discovered in (2a), is happiness affected by age?

Hypotheses:
H0: There is no significant relationship between age and happiness outcomes.
H1: There is a significant relationship between age and happiness outcomes. 

```{r q2b}

# Does age improve the model? 

na_dropped <- newcouchto5k %>% 
  drop_na(happiness, age, season)
glimpse(na_dropped)
  
lm_hap_age <- lm(happiness ~ 1 + age, data = na_dropped)
summary(lm_hap_age)

lm_hap_int <- lm(happiness ~ 1 + age + season:age, data = na_dropped)
summary(lm_hap_int)

lm_hap_age <- lm(happiness ~ 1 + age + season, data = na_dropped)
summary(lm_hap_age)

plot(lm_hap_age, which=4)

```

```{r q2c}

# Revised Model accounting for high leverage outliers: Three high leverage outliers identified to be removed for analysis, however, it does not surpass 1 thus we will not remove it as that might be considered data mining


lm_hap_age <- lm(happiness ~ 1 + age, data = na_dropped)
summary(lm_hap_age)

summary(lm_hap_age) %>% pander(caption = "Age and Happiness") 
```

```{r}
# Plots 

# Model with happiness, season and age 

plot_happageszn <- ggplot(data=newcouchto5k,
mapping=aes(x=age, y=happiness, color=season)) +
  geom_point() + 
  ggtitle("Assessing Age as a Baseline Effect") +
  xlab("Age") +
  ylab("Happiness") + xlim(0,60)
plot_happageszn
```

# # Interpretation

The results indicate that participant age has no significant relationship to happiness outcomes, thus, we fail to reject the null hypothesis. Furthermore, season does not have any significant effect as seen from the null results in the previous analysis of season on happiness. Adding age did not improve the model as there are no independent or interaction effects. Upon visualizing the data, it becomes even more evident that there is no correlation or pattern between predictor variables and the outcome of happiness as seen in the scattered distribution of the data.


## Question 2c

Baseline Justification

Given that null effects were observed for both the effect of season and age on happiness as our outcome variable, no relevant baseline effects are to be included in our subsequent linear models for determining relevant predictors of happiness for participants. We can therefore exclude age and season as accounting for a statistically significant amount of variation in our model for happiness outcomes.
 

# Question 3

## Question 3a
Building on your baseline model, are participants’ happiness ratings affected by whether or not they completed the programme? Describe the way in which programme completion influences happiness outcomes.

Hypotheses:
H0: There is no significant relationship between program completion and happiness outcomes.
H1: There is a significant relationship between program completion and happiness outcomes. 
```{r q3a}

# A linear model was run to assess program completion (represented as a binary predictor variable, i.e. yes or no) on happiness ratings (DV). 

newcouchto5k$completed <- ifelse(newcouchto5k$categ == "3", "yes", "no")
newcouchto5k$comp_nu <- ifelse(newcouchto5k$completed == "yes", 1, 0)
comp_nu <- newcouchto5k$comp_nu

lm_hap_comp <- lm(happiness ~ 1 + comp_nu, data =newcouchto5k, na.action=na.exclude)

# Plots

plot(lm_hap_comp, which=4)

# No high leverage outliers were identified to be removed

# Running the Model

summary(lm_hap_comp)

```
```{r}
summary(lm_hap_comp) %>% pander(caption = "Program Completion and Happiness")
```

# # Interpretation

To determine whether participant happiness ratings were affected by whether or not they completed the program, a linear model was run which operationalized completion (a yes or no binary categorical variable) as the predictor and happiness as our outcome. Cook’s Distance was performed to identify any high leverage outliers which may skew the data and change our regression coefficients. None were identified and a summary of the model was made, in other words, no data points above 1.0 on the y-axis were present and worth excluding. Although it is useful to visualize high leverage outliers, for the purposes of avoiding the potential to data mine, anything below 1.0 was included in the data set after running the linear regression.  According to the results, we fail to reject the null hypothesis that completion did not have a significant effect on happiness ratings at a 95% confidence interval.


## Question 3b
Building on the analysis in (3a), is happiness additionally affected by the “health metric”?
Hypotheses:
H0: There is no significant relationship between health metric scores and happiness outcomes.
H1: There is a significant relationship between health metric scores and happiness outcomes. 

```{r q3b}
# lm with happiness, categ, health metric and no baseline 

lm_comp_h <- lm(happiness ~ 1 + completed + health, data =newcouchto5k, na.action=na.exclude)

plot(lm_comp_h, which=4)


```


```{r q3b2}

# One high leverage outlier identified to be removed for analysis, however, it does not surpass 1 thus we will not remove it as that might be considered data mining


lm_comph <- lm(happiness ~ 1 + completed + health, data =newcouchto5k, na.action=na.exclude)

# Visualize 

plot_happhealthcomp <- ggplot(data=newcouchto5k,
mapping=aes(x=health, y=happiness, color=completed)) +
  geom_point() + 
  ggtitle("Health and Completion on Happiness") +
  xlab("Health") +
  ylab("Happiness")
plot_happhealthcomp

summary(lm_comph)
```
```{r}
summary(lm_comph) %>% pander(caption = "Program Completion and Health on Happiness")
```

# # Interpretation:

We fail to reject the null hypothesis that health scores are related to happiness outcomes for participants with a 95% confidence interval (p<0.05). No high leverage outliers above 1.0 were present and thus, no participants warrented being removed from the analyses. The linear model was re-run to assess a relationship between health and happiness. Health was not independently related to happiness outcomes and thus, did not improve the model. Although both completion and health appear to have a negative impact on happiness according to our beta coefficients, b=-0.9 and b=-0.25 respectively, neither variables were significantly related. Combined, this accounted for less than 1% of the variance, according to our R2=0.007. 


## Question 3c
It’s been hypothesised that the effects of good health are amplified by the feeling of acting healthily, such that the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier. Building on the model in (3b), can you test this hypothesis?

```{r q3c}
# no baseline effects to account for 
lm_hap_int <- lm(happiness ~ 1  + completed + health + health:completed, data =newcouchto5k, na.action=na.exclude)
summary(lm_hap_int)

anova(lm_hap_int)

# Cook's Distance 

plot (lm_hap_int, which=4)

# Accounting for Cook's D: One high leverage outlier identified to be removed for analysis, however, it does not surpass 1 thus we will not remove it as that might be considered data mining

lm_hap_int <- lm(happiness ~ 1  + completed + health + health:completed, data =newcouchto5k, na.action=na.exclude)

summary(lm_hap_int)
summary(lm_hap_int) %>% pander(caption = "Interaction Effect of Health and Completion on Happiness")
```


```{r}
# Visualizing our interaction effect of program completion and health on happiness

# Plotting the interaction

qplot <- qplot(x = health, y = happiness, data = newcouchto5k, color = completed) + geom_smooth(method = "lm")

qplot + ggtitle("Health on Happiness by Program Progress") + 
  xlab("Health") + ylab("Happiness")

```


## Question 3d
What can we conclude about the various causes of happiness in our data? Write a brief description of the effects in the model, such as you might find in an academic paper.

# # Interpretations: 

1.	According to our results for health and completion on happiness outcomes as reported above, completion and health were not independently significant predictors of happiness ratings for program participants. No high leverage residuals were above 1.0 and warrented being removed from the data after analyses. Null effects are reported for each, adding health to the model did not improve the fit or account for greater variance, with an extremely small R2 of less than 1% in happiness outcomes according to our linear model output.

2.	To determine whether the effects of good health are amplified by the feeling of acting healthily, a linear model was created to measure both the independent effects of health and program progress as well as an interaction effect between the two predictors on happiness. According to our analysis, adding the interaction of health and completion improved the model significantly, p<0.05. Furthermore, upon visualizing the linear model, the interaction plot confirms this positive moderating trend whereby individuals in the completion group who were higher in health ratings had significantly greater reported happiness than those that did not complete the program but were also high on health metric scores. However, it is also important to note that these effects still only accounted for 6% of the variance in the model, R2=0.06, F(3,122)=2.88, p<0.05.


# Question 4
Create a subset of the data, including only those participants who completed the programme. Create a plot of the average happiness ratings grouped by season and city, that can be used in a presentation to the funders of the project.
```{r q4}


# Mean happiness ratings for categ3 filter by city

avrghap <-
newcouchto5k %>% 
filter(categ == 3) %>% 
  group_by(city, season) %>%
  summarise(Mean = mean(happiness))
print(avrghap)



plot_hapbp <- ggplot(data=avrghap, aes_(x=avrghap$city, y=avrghap$Mean, fill=avrghap$season)) + geom_bar(position="dodge", stat='identity') 

plot_hapbp + ggtitle("Average Happiness by City and Season") + theme(legend.title = element_blank()) + 
  xlab("City") + ylab("Happiness")

# mean happiness by season and city

```
```{r}
# lm for completion and happiness
lm_comp_hp <- lm(Mean ~ 1 + city + season, data=avrghap, na.action=na.exclude)
summary(lm_comp_hp)
```
A subset of the data was created which included scores on predictor variables for only the participants that completed the program (i.e. category 3 according to my data set of variables). A linear model was created from the subset of data created for completion and mean happiness and the new dataset was plotted according to city and season. Although there were statistically null effects of season and city for mean happiness, F(4, 3)=0.152, p=0.95, among program completers, there was an observable difference in happiness among Edinburgh participants according to our data visualization in Figure 11.  Whereby, average happiness was highest in the winter and summer and lowest in autumn with spring being the second lowest average ratings. 

# Question 5

## Question 5a
 Build a model that predicts the likelihood of dropping out (at all).
 
```{r q5a}
# glm for completed 


# order of predictors matter (left most predictor to right least) anova(mod.mm)


# lm for completed and self-motivation
lm_comp_selfmot <- lm(comp_nu ~ 1 + selfmot, data =newcouchto5k, na.action=na.exclude)
summary(lm_comp_selfmot)


# lm for acc and selfmot
lm_comp_selfmot <- lm(comp_nu ~ 1 + accountability + selfmot:accountability, data =newcouchto5k, na.action=na.exclude)
summary(lm_comp_selfmot)

# Our glm 

mod.mm <- glm(comp_nu ~ 1 + selfmot + happiness + selfmot:season, data =newcouchto5k, na.action=na.exclude)
summary(mod.mm)
anova(mod.mm, test="Chisq")
```


Visualizing the Data
```{r}
summary(mod.mm) %>% pander(caption = "Determinants of Dropping out of the Program")
```

## Question 5b

# # Interpretation 

Briefly describe the effects in your model as you would in an academic paper.
Before running our analyses of our IVs on our DV of interest (whether participants completed the program), our outcome variable was coded as a binary ('yes' or 'no') and transformed into a numeric variable, missing or transformed NA values were removed and potential high leverage outliers were excluded based on previous models using the Cook's Distance test. 
After removing extraneous non significant IVs, the model improved revealing significant main effect and interaction effect of self motivation and self motivation on season respectively. All other factor IVs such as accountability and health metric did not reveal significant relationships independently or interacting on completion rate, furthermore, potential covariates such as age and city were also excluded as non significant variables. Happiness was included in the model as well though did not have a significant relationship to program completion. After these variables were removed from our overall model, significant effects were revealed for self-motivation which exerted a positive independent effect on program completion, p<0.01. For every unit increase in self motivation, there was a b=0.07 increase in completion rate.
There was also a significant interaction between self-motivation and season, p<0.01. For every unit increase of self motivation for spring time participants, there was a decrease in completion of b=-0.04. 



## Question 5c
Draw a graph representing the probability of quitting as a function of how self motivated participants were.
```{r q5c}
lm_comp_selfmot <- lm(comp_nu ~ 1 + selfmot, data =newcouchto5k, na.action=na.exclude)
summary(lm_comp_selfmot)

```

```{r}
# Check for outlier leverage using Cook's Distance
lm_comp_selfmot <- lm(comp_nu ~ 1 + selfmot, data =newcouchto5k, na.action=na.exclude)
summary(lm_comp_selfmot)

# Checking for outlier leverage using Cook's D

plot(lm_comp_selfmot, which=4)
```
According to the Cook's Distance which tests for the degree of leverage an outlier exerts on the model, we removed participant 13 given that the Cook's D exceeds 0.5. 

```{r}
# Revised Model Accounting for our high leverage outlier: One high leverage outlier identified to be removed for analysis, however, it does not surpass 1 thus we will not remove it as that might be considered data mining


lm_comp_selfmot <- lm(comp_nu ~ 1 + selfmot, data =newcouchto5k, na.action=na.exclude)

# rerun model and ggplot

summary(lm_comp_selfmot)

```
```{r}
summary(lm_comp_selfmot) %>% pander(caption = "Self Motivation and Completion")
```


```{r}
plot_sc <-
ggplot(newcouchto5k, aes(selfmot, comp_nu), na.rm=TRUE) +
  geom_point() +
  geom_smooth(method = "lm")
plot_sc + xlim(5, 23) + ylim(-0.1, 1.0) + ggtitle("Effect of Self Motivation on Program Completion") + xlab("Self-Motivation") + ylab("Completion (0=no, 1=yes") 


```

# # Interpretation:

After running a linear model for the influence of self motivation (predictor) on program completion (outcome), there was a positive significant effect according to our analysis table, yielding a F ratio of F(1,125)=10.7, p<0.01. According to our model results and the linear regression plot, greater self-motivation was slightly higher for participants that completed the program. We cannot determine that self-motivation directly leads to greater progress. However, we can say that self-motivation is a statistically significant predictor of program completion as our outcome variable. However, it is important to note that according to the R2 value, this only accounts for 8% of the variance (R2=0.08).





