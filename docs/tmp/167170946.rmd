---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
  word_document: default
params:
  examnumber: "B1701971"
---

```{r setup, include=FALSE}

#Chunk settings
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

rm(list = ls()) #clears the environment of variables

# my data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")

# loading packages:
library(tidyverse)
library(pander)
library(broom)
library(Rmisc) #also contains the summarise() and mutate() functions, therefore I will be specifying dplyr throughout the document 
library(RColorBrewer)
library(car)

# all numeric output gets rounded to 3 digits
options(digits=3)

```

# Question 0

```{r cleaning, include = FALSE}
summary(couchto5k)
head(couchto5k)

#identifying impossible data
couchto5k$missing <- NA
couchto5k$missing[couchto5k$selfmot<5] <- "Impossible self-motivation score"
couchto5k$missing[couchto5k$age>=100] <- "Very high age" 
couchto5k$missing[couchto5k$week_stopped>9] <- "Impossible week number"

#table of removed values
mtab <- table(couchto5k$missing)


#only include rows where missing is NA
couchto5k <- couchto5k %>% filter(is.na(missing))
total <- nrow(couchto5k) #no. of observations should decrease

#fixing spelling mistakes
miscoded <- sum(couchto5k$season=="autunm")
couchto5k$season[couchto5k$season=="autunm"] <- "autumn"

```

#### Cleaning the data
Any rows with unlikely or impossible observations were removed, leaving `r total` observations (detailed in Table 1). There were also spelling mistakes in `r miscoded` observations, with "autumn" being recorded as "autunm". These were recoded with the correct spelling.

```{r table showing removed observations}

mtab %>% pander(caption= "Table 1: Summary of removed data.")

```
<br>

#### Descriptives
In Figure 1, the self-motivation, accountability, and health ratings all look roughly normally distributed. Accountability shows a slight negative skew, while self-motivation and health show a positive skew. The ages of participants look a bit bimodal, while happiness ratings are fairly uniformly distributed. The data contained more participants from Edinburgh than from Glasgow. More participants stopped in week 9 than any other week. Spring was the most common season for participants to have done the running programme in, while Autumn was the lowest.
```{r descriptives}

a <- ggplot(couchto5k) + aes(x = age)
a <- a + geom_histogram(aes(y=..density..), colour="black", fill="white", bins=20) 
a <- a + geom_density(alpha=.2, fill="#FF6666") 
a <- a + geom_vline(xintercept=mean(couchto5k$age), linetype="dashed", color="black", size=.5)
a <- a + labs(x = "Age (in years)", title = "Age of participants") 
a <- a + theme_bw()

b <- ggplot(couchto5k, aes(x=accountability)) 
b <- b + geom_histogram(aes(y=..density..), colour="black", fill="white", bins=20) 
b <- b + geom_density(alpha=.2, fill="#FF6666") 
b <- b + geom_vline(xintercept=mean(couchto5k$accountability), linetype="dashed", color="black", size=.5) 
b <- b + labs(x = "Accountability", title = "Accountability") 
b <- b + theme_bw()

c <- ggplot(couchto5k) + aes(x = selfmot)
c <- c + geom_histogram(aes(y=..density..), colour="black", fill="white", bins=20) 
c <- c + geom_density(alpha=.2, fill="#FF6666") 
c <- c + geom_vline(xintercept=mean(couchto5k$selfmot), linetype="dashed", color="black", size=.5) 
c <- c + labs(x = "Self-motivation rating", title = "Self-motivation")
c <- c + theme_bw()

d <- ggplot(couchto5k) + aes(x = health)
d <- d + geom_histogram(aes(y=..density..), colour="black", fill="white", bins=20)
d <- d + geom_density(alpha=.2, fill="#FF6666") 
d <- d + geom_vline(xintercept=mean(couchto5k$health), linetype="dashed", color="black", size=.5) 
d <- d + labs(x = "Health", title = "Health") 
d <- d + theme_bw()

e <- ggplot(couchto5k) + aes(x = happiness) 
e <- e + geom_histogram(aes(y=..density..), colour="black", fill="white", bins=20) 
e <- e + geom_density(alpha=.2, fill="#FF6666") 
e <- e + geom_vline(xintercept=mean(couchto5k$happiness), linetype="dashed", color="black", size=.5) 
e <- e + labs(x = "Happiness", title = "Happiness") 
e <- e + theme_bw()

f <- ggplot(couchto5k) + aes(x = season) 
f <- f + geom_bar(fill="#2A90AA", alpha=.6, color= "black") 
f <- f + labs(x = "Season", title = "Season") 
f <- f + theme_bw()

g <- ggplot(couchto5k) + aes(x = city) 
g <- g + geom_bar(fill="#2A90AA", alpha=.6, color= "black") 
g <- g + labs(x = "City", title = "City") 
g <- g + theme_bw()

h <- ggplot(couchto5k, aes(x=week_stopped))
h <- h + geom_bar(fill="#2A90AA", alpha=.6, color= "black") 
h <- h + scale_x_continuous(breaks = c(1:9))
h <- h + labs(x = "Week Stopped", title = "Week Stopped") 
h <- h + theme_bw()

```


```{r fig1, fig.asp=.6, fig.cap="Figure 1: Overview of the data "}
multiplot(a,b,c,d,e,f,g,h, cols = 3)
```


# Question 1 

**1a. In an earlier nationwide survey, researchers found that 45% of participants abandoned the programme before the halfway point in week 5, and a further 10% gave up before the end of the programme. Is the data in the sample you have been given in line with data from the earlier survey?**

```{r q1a}

couchto5k <- 
  couchto5k %>%
  dplyr::mutate(
    attrition_time = ifelse(week_stopped<5, "before halfway", NA),
    attrition_time = ifelse(week_stopped==9, "completed", attrition_time),
    attrition_time = ifelse(week_stopped>=5 & week_stopped<9, "after halfway", attrition_time)
  ) 

```

```{r fig2, fig.asp=.6, fig.cap="Figure 2: Attrition time", include=FALSE}
i <-  ggplot(couchto5k, aes(x=attrition_time, fill=attrition_time))
i <- i + geom_bar() 
i <- i + labs(title= "Participant attrition rates", x= "Attrition", y= "Frequency")
i <- i + theme_bw()
i <- i + scale_fill_brewer(palette= "Paired")
i
```

```{r Chi-squared test}
chi_1 <- chisq.test(table(couchto5k$attrition_time), p=c(.1, .45, .45))
tidy_chi_1 <- tidy(chi_1)
```


The proportions of completion rates in the current sample *are* in line with results from the earlier survey, with no significant difference between the expected and observed proportions ($X^2$ (`r tidy_chi_1$parameter[1]`, N = `r total`) = `r tidy_chi_1$statistic[1]`, p<1).

<br>

**1b. Using the same three categories (stopped before week 5, stopped after week 5, completed), examine whether the patterns of attrition rates differ by city.**


```{r preparation for figure 3}

attrition_tab <- as.data.frame.matrix(table(couchto5k$city, couchto5k$attrition_time))

attrition_tab <- 
  attrition_tab %>%
  dplyr::mutate(
    prop_after_halfway= 100*(`after halfway`)/(`after halfway` + `before halfway` + `completed`),
    prop_before_halfway= 100*(`before halfway`)/(`after halfway` + `before halfway` + `completed`),
    prop_completed= 100*(`completed`)/(`after halfway` + `before halfway` + `completed`)
  )

attrition_tab_2 <- 
  attrition_tab %>%
  dplyr::select(c(prop_before_halfway, prop_after_halfway, prop_completed))


attrition_tab_3 <- 
  attrition_tab_2 %>%
  pivot_longer(
    everything()
    ) %>%
  dplyr::mutate(
    attrition_time = c("before", "after", "completed","before", "after", "completed"),
    city = c("Edinburgh", "Glasgow", "Edinburgh", "Glasgow", "Edinburgh", "Glasgow")
  )


```

```{r figure3, fig.asp=.6, fig.cap="Figure 2: Bar plot showing attrition rates proportional to the size of each city."}

j <- ggplot(attrition_tab_3, aes(x=attrition_time, y= value, fill=city)) 
j <- j + geom_bar(stat = "identity", position = "dodge") 
j <- j + labs (title= "Proportional attrition rates across Edinburgh and Glasgow", y= "Proportion (by city)", x= "Attrition Time") 
j <- j + theme_bw()
j <- j + scale_fill_brewer(palette= "Paired", name="City")
j

```




```{r q1b}
attrition_table <- table(couchto5k$attrition_time, couchto5k$city)
chi_2 <- chisq.test(attrition_table)
tidy_chi_2 <- tidy(chi_2)

```
The patterns of attrition rates do not appear to differ by city ($X^2$ (`r tidy_chi_1$parameter[1]`, N = `r total`) = `r tidy_chi_1$statistic[1]`, p<1). However, it should be noted that observed and expected values were very low for some categories, with particularly few participants from Glasgow stopping after  halfway (n=3).

<br>

**1c. Do the average ages of participants who commenced the programme differ by city?**

Initial visualisation of the ages of participants grouped by city (Figure 3) suggests that participants in Edinburgh may be older than those in Glasgow.
```{r figure 4, fig.asp=.6, fig.cap="Figure 3: Box plot investigating the ages of participants in Edinburgh and Glasgow" }

k <- ggplot(couchto5k, aes(x=city, y=age, fill=city))
k <- k + geom_boxplot()
k <- k + theme_bw()
k <- k + scale_fill_brewer(palette= "Paired", name="City")
k <- k + labs(title= "Age of participants by city", x= "City", y="Age (in years)")
k

```

```{r q1c}

#subset by city
city_edinburgh <- 
  couchto5k %>%
  filter(
    city== "Edinburgh"
    )

city_glasgow <- 
  couchto5k %>%
  filter(
    city== "Glasgow"
    )

#test normality
shap_test <- shapiro.test(city_edinburgh$age) #not normal
shap_test2 <- shapiro.test(city_glasgow$age)

```
A Shapiro-Wilk test revealed that the ages of participants from Edinburgh are not normally distributed (W=0.9, p=0.002). This is illustrated in Figure 4, which shows a bimodal distribution.



```{r figure 5, fig.asp=.6, fig.cap="Figure 4: Density plot showing the ages of participants from Edinburgh" }

l <- ggplot(city_edinburgh, aes(x=age))
l <- l + geom_density()
l <- l + labs(title= "Ages of Edinburgh participants", x="Age (in years)", y="Density")
l <- l + theme_bw()
l

```



```{r 1c continued}
#testing homogeneity of variance
var_test <- var.test(age~city, couchto5k)
#passes this assumption BUT could delete as we know we need a non-parametric test anyway

#t test (two sample, unpaired)
wilcox_1 <- wilcox.test(age~city, data=couchto5k)
tidy_wilcox_1 <- tidy(wilcox_1)
```

A Wilcoxon Test was used as a non-parametric alternative to the two-sample t-test, as the assumption of normality had not been met. The test showed that the ages of participants do differ by city (V = `r tidy_wilcox_1$statistic[1]`, p = `r tidy_wilcox_1$p.value[1]`).



# Question 2

**2a. Are participants’ happiness ratings affected by the season they were interviewed in? Describe the way in which season influences happiness outcomes.**

Comparing the happiness ratings of participants grouped by season (Figure 5)  suggests that there may be differences between the happiness ratings of some seasons, but not others. For example, Spring shows a much higher happiness rating than Autumn, but the happiness ratings in Autumn and Winter are very similar. 

```{r figure 6, fig.asp=.6, fig.cap="Figure 5: Box plot showing the effect of season on happiness ratings." }

m <- ggplot(couchto5k, aes(x=season, y=happiness, fill=season)) 
m <- m + geom_boxplot()
m <- m + theme_bw()
m <- m + scale_fill_brewer(palette= "Paired", name="Season")
m <- m + labs(title= "Happiness ratings by season", x="Season", y="Happiness rating (0-100)")
m
```
I will be investigating a model which takes season as the sole predictor of happiness.

Model 1: $Happiness$ $rating=b_0+b_1(Season)+ϵ$

```{r q2a}

mod1 <- lm(happiness~ 1 + season, data=couchto5k)

```


```{r figure 7, fig.asp=.6, fig.cap="Figure 6: Diagnostic plots for Model 1"}
par(mfrow=c(2,2))
plot(mod1)

```
The diagnostic plots (Figure 6) suggest that the assumptions of normality and homogeneity of variance of residuals have likely been met. 

1. The residuals vs. fitted plot shows a straight line, which indicates that the mean of the residuals is close to zero across the fitted values.

2. In the Q-Q plot, the residuals form a relatively straight line, with only a small amount of coiling at the ends. This suggests that the assumption of normality of residuals has been met. 

3. The Scale-Location plots shows a straight line with only a very small incline, therefore we can assume that the residuals show mostly homogeneous variance. The 

4. Residuals vs. Leverage plot highlights relatively few residuals beyond Cook's distance, and therefore potential outliers. 




```{r q2a continued, include=FALSE}
s1 <- summary(mod1)$coefficients
a1 <- anova(mod1)
tidy_a1 <- tidy(a1)

```
Evaluating Model 1 shows that season *is* a predictor of happiness ratings (F(1,`r tidy_a1$df[2]`)=`r tidy_a1$statistic[1]`, `r tidy_a1$p.value[1]`), and that, as predicted by Figure 5, the happiness ratings recorded in Spring are significantly greater than those recorded in Autumn. The average happiness rating in Autumn is 29.0, with a 26.9 average increase in happiness rating expected when recorded in Spring rather than Autumn.

<br>

**2b. Accounting for any effects you discovered in (2a), is happiness affected by age?**
```{r q2b}

#adding age to regression equation
#2a: autumn + spring are different 
mod2 <- lm(happiness~season + age, data=couchto5k)
a2 <- anova(mod2)
tidy_a2 <- tidy(a2)

```
Model 2: $Happiness$ $rating=b_0+b_1(Season)+ b_2(Age) + ϵ$


The diagnostic plots do not indicate that any assumptions have been violated. Evaluating the model shows that once the influence of season has been taken into account, age does *not* appear to have a significant effect on happiness (F(1,`r tidy_a2$df[3]`)=`r tidy_a2$statistic[2]`, p<1]). This is illustrated in Figure 7.




```{r figure 8, fig.asp=.6, fig.cap="Figure 8: Diagnostic plots for mod2", include=FALSE}

#checking residuals
par(mfrow=c(2,2))
plot(mod2)
```

```{r figure 9, fig.asp=.6, fig.cap="Figure 7: Scatter plots showing the effect of age on happiness, grouped by season"}

#visualising
n <- ggplot(data = couchto5k, aes(x = age, y = happiness, colour=season)) 
n <- n + geom_point()
n <- n + facet_wrap(~season) 
n <- n + theme_bw()
n <- n + labs(title="Age, season, and happiness", x="Age (in years)", y="Happiness rating (0-100)")
n <- n + scale_colour_discrete(name="Season")
n

```



**2c. Pick a specific baseline model and justify why you are using this.**
```{r q2c}
#baseline model
#season has an effect

#anova comparing mod1 (season) + mod2 (season + age)
mod_comparison <- anova(mod1, mod2)
tidy_mod_comparison <- tidy(mod_comparison)

```

Comparing Model 1 and Model 2 revealed no significant difference between the two models (F(1,`r tidy_mod_comparison$df[2]`)=`r tidy_mod_comparison$statistic[2]`, p<1). This justifies using only season as a predictor, as age does not significantly explain the variance in happiness ratings over and above what is achieved by season.

Baseline Model: $Happiness$ $rating=b_0+b_1(Season)+ϵ$

<br>

# Question 3

**3a. Building on your baseline model, are participants’ happiness ratings affected by whether or not they completed the programme? Describe the way in which programme completion influences happiness outcomes.**

Initial visualisation of the data (Figure 8) illustrates the expected difference of happiness rating by season, but is not indicative of a strong interaction between season and completion rates. Only Autumn appears to have significantly different happiness ratings across participants who did and did not complete the programme.

```{r figure 11, fig.asp=.6, fig.cap="Figure 8: Box plot comparing happiness ratings of participants who did and did not complete the course, grouped by season"}

#new column for completed/not completed
couchto5k <- 
  couchto5k %>%
  mutate(
    is_completed = ifelse(week_stopped==9, "yes", "no")
  )

o <- ggplot(data = couchto5k, aes(x = is_completed, y = happiness, fill=is_completed)) 
o <- o + geom_boxplot() 
o <- o + facet_wrap(~season) 
o <- o + theme_bw()
o <- o + scale_fill_brewer(palette= "Paired", name= "Completion (Yes/No)")
o <- o + labs(title="Completion rates, season, and happiness", x="Completion (Yes/No)", y= "Happiness rating (0-100)")
o

```


```{r q3a: building mod3}
#building on your baseline model (i.e. taking season into account)



#does completion influence happiness?
mod3 <- lm(happiness~season + is_completed, data=couchto5k)

```

Model 3 investigates the effect of season and completion rates on happiness:

$Happiness$ $rating=b_0 + b_1(Season) + b_2(Completion$ $rate) + ϵ$.

```{r figure 10, fig.asp=.6, fig.cap="Figure X: Diagnostic plots for mod2", include=FALSE}
par(mfrow=c(2,2))
plot(mod3)
```

Diagnostic plots suggest that the residuals are mostly normal and homogeneous, although there may there may be some outliers.



```{r q3a continued: evaluating mod3, include=FALSE}
summary(mod3)
a3 <- anova(mod3)
tidy_a3 <- tidy(a3)


#looking into autumn
no_autumn <- nrow(couchto5k[couchto5k$is_completed=="no" & couchto5k$season=="autumn", ])
```


Completion does appear to influence happiness (F(1,`r tidy_a3$df[2]`)=`r tidy_a3$statistic[2]`,`r tidy_a3$p.value[2]`]). In Autumn, the average happiness rating for participants who did not complete the programme is 14.8. This is associated with an increase of 17.4 when looking at participants who completed the programme. However, it should be noted that there are only `r no_autumn` observations in the data which were both recorded in Autumn and from participants who did not complete the programme.

<br>

**3b. Building on the analysis in (3a), is happiness additionally affected by the “health metric”?**

```{r figure 12, fig.asp=.6, fig.cap="Figure X: Effect of health on happiness, grouped by season", include=FALSE}

p <- ggplot(couchto5k, aes(x=health, y=happiness, colour=season)) 
p <- p + geom_point() 
p <- p + facet_wrap(~season) 
p <- p + theme_bw()
p <- p + labs(title="Effect of happiness and completion on health", x="Happiness Rating (0-100)", y="Health (0-100)")
p <- p + scale_colour_discrete(name="Completion (Yes/No)")
p

```


```{r figure 13, fig.asp=.6, fig.cap="Figure X: Effect of health on happiness, grouped by completion rates.", include=FALSE}

q <- ggplot(couchto5k, aes(x=health, y=happiness, colour=is_completed)) 
q <- q + geom_point() 
q <- q + facet_wrap(~is_completed) 
q <- q + theme_bw()
q

```


```{r q3b, include=FALSE}

mod4 <- lm(happiness~ season + is_completed + health, data=couchto5k)
a4 <- anova(mod4)
tidy_a4 <- tidy(a4)


par(mfrow=c(2,2))
plot(mod4)
summary(mod4)


anova_comp <- anova(mod3, mod4) #not significant (no effect of health)

```
Model 4 builds onto previous models through the addition of health as a predictor: $Happiness$ $rating=b_0+b_1(Season) + b_2(Completion$ $rate) + b_3 (Health) + ϵ$.

Evaluating the model shows that health does *not* influence happiness ratings (F(1,`r tidy_a4$df[3]`)=`r tidy_a3$statistic[3]`, p<1).

<br>

**3c/d.It’s been hypothesised that the effects of good health are amplified by the feeling of acting healthily, such that the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier. Building on the model in (3b), can you test this hypothesis?**
```{r q3c}

#reason for using is_completed rather than week_stopped
stopped_week6 <- nrow(couchto5k[couchto5k$week_stopped=="6",])


#new model:
mod5 <- lm(happiness~ season + is_completed*health, data=couchto5k)
a5 <- anova(mod5)
tidy_a5 <- tidy(a5)
           
```

The question states "people who got further along the programme", for which the week stopped variable would be the closest measure. However, there is not much data in weeks 1-8 compared to week 9 (e.g. only `r stopped_week6` people stopped in week 6.) I am therefore separating participants into those who completed and those who did not complete the programme.  

We hypothesized that there is an interaction between completing the programme and health scores (see Figure 9 for a visualisation). This does seem to be the case (F(1),`r tidy_a5$df[4]`)=`r tidy_a5$statistic[4]`, `r tidy_a5$p.value[4]`).

Model 5: $Happiness$ $rating=b_0+b_1(Season) + b_2(Completion$ $rate*Health) + ϵ$



```{r figure 14, fig.asp=.6, fig.cap="Figure 9: Effect of health on happiness, grouped by completion rates. With smoothing line/linear model. Shows an interaction."}

r <- ggplot(couchto5k, aes(x=health,y=happiness, colour=is_completed))
r <- r + geom_point(size=1)
r <- r + geom_smooth(method="lm")
r <- r + ylim(0, 100)
r <- r + labs(title="Effect of happiness and completion on health", x="Happiness rating (0-100)", y= "Health (0-100)")
r <- r + theme_bw()
r <- r + scale_color_discrete(name="Completion (Yes/No)")
r


```



```{r}
vif_test <- vif(mod5)

```

When investigated individually, completion rates significantly influence happiness, whereas health scores do not. However, a completion rate-health interaction added to the model was shown to be significant, which is suggestive of multicollinearity.

In a test of multicollinearity, VIF values were greater than 5 for completion rate (`r vif_test[2,3]`) and for the completion rate-health interaction (`r vif_test[4,3]`) indicating that multicollinearity may be affecting model estimates.



# Question 4
**Create a subset of the data, including only those participants who completed the programme. Create a plot of the average happiness ratings grouped by season and city, that can be used in a presentation to the funders of the project.**
```{r q4}
#subset
completed <- 
  couchto5k %>%
  filter(week_stopped==9)

#average happiness ratings for Edinburgh, grouped by season
g3 <- 
  completed %>%
  filter(city=="Edinburgh") %>%
  group_by(season) %>%
  dplyr::summarise(mean_se(happiness))


#average happiness ratings for Glasgow, grouped by season
g4 <- 
  completed %>%
  filter(city=="Glasgow") %>%
  group_by(season) %>%
  dplyr::summarise(mean_se(happiness))


table_E <- g3 %>%
  mutate (city_name = "Edinburgh")


table_G <- g4 %>%
  mutate(city_name = "Glasgow")


merged_table <- full_join(x=table_E, y=table_G)
```


```{r figure 15, fig.asp=.6, fig.cap="Figure 10: Average happiness ratings grouped by season and city. There were insufficient participants in both the Season and Glasgow categories, resulting in no error bar."}

s <- ggplot(merged_table, aes(x=season, y=y, ymin=ymin, ymax=ymax, fill=city_name))
s <- s + geom_bar(stat = "identity", position= "dodge") 
s <- s + geom_errorbar(width=.2, position= position_dodge(.9)) 
s <- s + labs(title="Season, city, and happiness", y="Average happiness rating (0-100)", x="Season")
s <- s + theme_bw() 
s <- s + scale_fill_brewer(palette= "Paired", name="City")
s

```



# Question 5

**5a. Build a model that predicts the likelihood of dropping out (at all).**
```{r q5a}

#baseline model
model1 <- lm(week_stopped ~ season, data=couchto5k)
aov1 <- anova(model1)

#health
model2 <- update(model1, .~. + health) #not significant
aov2 <- anova(model2)

#accountability
model3 <- update(model1, .~. + accountability) #not significant
aov3 <- anova(model3)

#selfmot
model4 <- update(model1, .~. + selfmot) #significant
aov4 <- anova(model4)
tidy_aov4 <- tidy(aov4)

#happiness
model5 <- update(model4, .~. + happiness) #not significant
aov5 <- anova(model5)

#city
model6 <- update(model4, .~. + city) #not significant
aov6 <- anova(model6)

#age
model7 <- update(model4, .~. + age) #not significant
aov7 <- anova(model7)

#the model so far: season and selfmot

```

Variables were added to the model one at a time, using season as a predictor in the baseline model. If a variable had a significant effect on week stopped, then it was included as a predictor in future models.

Taking the effect of season into account, self-motivation was shown to be a significant predictor of week stopped. The relationship between self-motivation, season, and week stopped is visualised in Figure 11. 

```{r figure 16, fig.asp=.6, fig.cap="Figure 11: Relationship between self motivation and week stopped, grouped by season"}

#visualising
t <- ggplot(couchto5k, aes(x=selfmot, y=week_stopped, colour=season))
t <- t + geom_smooth(method="lm") 
t <- t + scale_x_continuous(breaks=seq(8,22,2)) 
t <- t + scale_y_continuous(limits = c(1,9), breaks=seq(1,9,1)) 
t <- t + labs(x="Self-motivation", y="Week stopped", title="Week stopped and Self-motivation")
t <- t + theme_bw()
t <- t + geom_point()
t


```



```{r q5a continued: testing for an interaction}
model8 <- update(model4, .~. + season:selfmot)
aov8 <- anova(model8)
tidy_aov8 <- tidy(aov8)
```

<br>

**5b. Briefly describe the effects in your model as you would in an academic paper.**

There was a known effect of season on week stopped, so this was included as a predictor in the baseline model. 

Baseline model: $Week$ $stopped=b_0+b_1(Season) + ϵ$


From there, I investigated a range of variables in the data and their influence on the week when a participant stopped. Only self-motivation was found to have a significant effect beyond that explained by season. (F(1),`r tidy_aov4$df[2]`)=`r tidy_aov4$statistic[2]`, `r tidy_aov4$p.value[2]`).

Visualisation of the data suggested an interaction between self-motivation and week stopped. Adding an interaction to the model showed that there was indeed a significant season:self-motivation interaction (F(1),`r tidy_aov8$df[3]`)=`r tidy_aov8$statistic[3]`, `r tidy_aov8$p.value[3]`).

The final model:
$Week$ $stopped=b_0+b_1(Season*Self$ $motivation) + ϵ$

<br>

**5c. Draw a graph representing the probability of quitting as a function of how self motivated participants were.**
```{r q5c preparing the data}

grouped_data <- 
  couchto5k %>%
  group_by(selfmot) %>%
  dplyr::summarise(is_completed)

grouped_data <- 
  grouped_data %>%
  mutate(
    if_quit= ifelse(is_completed == "yes", 0, 1)
    ) #quit=1,completed=0


#building the model
model9 <- glm(if_quit ~ selfmot, data = grouped_data, family="binomial")


#selfmot values
selfmot_5_35 <- tibble(selfmot= 5:35)

predicted_values <- predict(model9, newdata= selfmot_5_35, type="response")

#predicting probability of quitting for self mot values
selfmot_5_35 <- 
  selfmot_5_35 %>%
  mutate(
    predprobs = predicted_values
  )

```


```{r figure 17, fig.asp=.6, fig.cap="Figure 12: Predicted probabilies of quitting, based on self-motivation scores."}

u <- ggplot(data = selfmot_5_35, aes(x = selfmot, y = predprobs))
u <- u + geom_line()
u <- u + xlim(5, 35) 
u <- u + ylim(0,1) 
u <- u + labs(title="Probability of quitting as a function of self-motivation", y="Predicted probability of quitting", x="Self-motivation score (5-35)") 
u <- u + theme_bw()
u

```
As the outcome measure is probability, which is not linear, a generalised linear model was used to calculate the predicted probabilities of quitting.


It should be noted that there were very few data points at some levels of self-motivation. This may be an issue as maximum likelihood fitting relies on large sample sizes. 