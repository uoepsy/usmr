---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
params:
  examnumber: s1865631
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(digits=3)
library(tidyverse)
library(sjPlot)
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0

This report describes the effects of various factors on participants of the "Couch to 5k" 9-week program run by the NHS. The data consists of `r nrow(couchto5k)` participants and includes age, self-reported happiness, accountability and self-motivation, a health measure, what week they ended the program, and information about the time of year and location the participant entered the information.

Several boxplots were generated of the various variables to remove outliers or impossible values. As can be seen in the figure below, outliers exist within the age, self motivation, and week_stopped variables. These values are replaced with NA values so the rest of the data points can still be used.

```{r charts}
par(mfrow=c(1,3), oma=c(0,0,2,0))
boxplot(couchto5k$age, ylab = 'age')
boxplot(couchto5k$selfmot, ylab = 'self motivation (7-35)')
boxplot(couchto5k$week_stopped, ylab = 'week stopped (1-9)')

mtext("Outliers in the data", line=0, side=3, outer=TRUE, cex=1)
```

The data also included some misspellings. Where the season was written as "autunm" this was replaced with "autumn". As both accountability and self-motivation were ranked on a scale of 5-35, instances where they were recorded as below 5 but above 0 were replaced with an entry of 5.

```{r cleaning, include = FALSE}
# Nothing from this chunk is included in output document
cleandata = couchto5k
cleandata[which(cleandata$age>100),]$age <- NA
cleandata[which(cleandata$selfmot<0),]$selfmot <- NA
cleandata[which(cleandata$selfmot<5),]$selfmot <- 5
cleandata[which(cleandata$accountability<5),]$accountability <- 5
cleandata[which(cleandata$week_stopped>9),]$week_stopped <- NA
cleandata[which(cleandata$season=='autunm'),]$season <- 'autumn'
```

# Question 1 

## Question 1a

A new variable was added to the dataframe to determine what the distribution of these different categories was in this data. The counts are shown below:

```{r q1a}
#adding new category data
stopped = gsub(TRUE, 2, cleandata$week_stopped<9)
stopped = replace(stopped, cleandata$week_stopped<5, 1)
stopped = replace(stopped, cleandata$week_stopped==9, 3)
cleandata$category = stopped

#adding completed data
cleandata$completed = 1*(cleandata$week_stopped==9)

test = data.frame(observed=c(0,0,0), expected=c(0,0,0))

test$observed = c(nrow(cleandata[which(cleandata$category==1),]),
  nrow(cleandata[which(cleandata$category==2),]),
  nrow(cleandata[which(cleandata$category==3),]))
test$expected = c(0.45, 0.10, 0.45)

results = chisq.test(test$observed, p = test$expected)

barplot(test$observed, 
        name = c("before half", "after half", "completed"), 
        col = c(2,4,3))
title('Counts of participants stopping times')
```

The question asks whether this data is in line with earlier findings where the three categories had a distribution of `r test$expected` respectively. To test whether the findings significantly differ from this distribution, a chi-square goodness of fit test is used.

The results of this test result in a p-value of `r results$p.value`, which is larger than 0.05 and therefore does not show that there is a statistically significant at the 95% confidence interval. The null hypothesis is accepted: the distribution of categories in our dataset is in line with the earlier findings.

## Question 1b

To approach this question, the dataset needs to be split into two parts for Edinburgh and Glasgow, the only two cities in the dataset. The counts for each category are then calculated and shown below. The scale is set seperately for the two sets to show the difference in distribution.

```{r q1b}
ed_data = cleandata[which(cleandata['city']=="Edinburgh"),]
gl_data = cleandata[which(cleandata['city']=="Glasgow"),]

test$edinburgh <- c(nrow(ed_data[which(ed_data$category==1),]),
  nrow(ed_data[which(ed_data$category==2),]),
  nrow(ed_data[which(ed_data$category==3),]))

test$glasgow <- c(nrow(gl_data[which(gl_data$category==1),]),
  nrow(gl_data[which(gl_data$category==2),]),
  nrow(gl_data[which(gl_data$category==3),]))

par(mfrow=c(1,2), mar=c(4,2,4,2))
barplot(test$edinburgh, 
        name = c("before", "after", "completed"), 
        col = c(2,4,3))
title("Edinburgh")

barplot(test$glasgow, 
        name = c("before", "after", "completed"), 
        col = c(2,4,3))
title("Glasgow")

options(warn=-1)
results = chisq.test(test$edinburgh, test$glasgow)
#p-value is 0.2, so the rates are not different
```

Performing a chi-square test between these two distribution yields a p-value of `r results$p.value`, which is again larger than 0.05 meaning there is no significant difference between the two distributions. The patterns of attrition therefore do not significantly differ between the two cities.

## Question 1c

```{r q1c}
ttest = t.test(ed_data$age, gl_data$age)
#p value = 0.1, so the means are not different.
```

To test for averages, a t-test is most appropriate. A t-test over these two average ages shows a p-value of `r ttest$p.value`, which again shows there is no statistically significant difference over the 95% confidence interval in the average ages between the two cities.

# Question 2

## Question 2a

To model the effect of one variable on another within a set of data points, we can construct a linear model to show the variation of the one variable plotted against the other. As such, a linear model is constructed that captures the relationship between the average happiness ratings and the season the participant filled out the survey in. The model was then used to generate predicted happiness values for each season which is shown below:

```{r echo=FALSE,results='hide',fig.keep='all'}
#shows the figures but suppresses useless console outputs.
seas_hap_model = lm(happiness ~ season, data=cleandata)

plot_model(seas_hap_model, type="pred")
```

The figure above shows a different range of possible values for each seasons. Examining the coefficients of the model show that the different seasons each have a significant effect as the p-values for the non-intercept variables are all smaller than 0.05. The "autumn" class is selected as the intercept as it is the most different from the three other seasons. The estimates show that autumn has the lowest estimate, followed by winter, summer and then spring.

```{r}
print(summary(seas_hap_model)$coef)
```

## Question 2b

As season is shown to have a significant effect on the happiness values, this is included in the next model to control for it. To test whether age affects happiness, the model is expanded to include it. As shown in the table below, the p-value for age is far larger than 0.05, meaning age has almost no discernable effect on the happiness of participants.

```{r q2b}
age_hap_model = (lm(scale(happiness) ~ age + season, data=cleandata))

print(summary(age_hap_model)$coef)
```

## Question 2c

As age has been shown to not significantly impact model performance for predicting happiness, this can be left out of the baseline model. Season however does impact the happiness value, and thefore is left in the model. In subsequent models season will be included as a predictor value to normalize for the effect it has on the happiness outcome value.

# Question 3

## Question 3a

To analyze the difference in happiness between participants who completed the program and participants who dropped out, an additional feature was added that was "0" when a participant dropped out and "1" if a participant completed the program in week 9. The happiness for each of these categories is plotted below:

```{r q3a}
boxplot(happiness ~ completed, data = cleandata, col = c(10,3))
```

The boxplots seem very similar, and when constructing a model that accounts for the effect of season on this data we find the following coefficients:

```{r}
hap_com_model = lm(happiness ~ completed + season, data=cleandata)

print(summary(hap_com_model)$coef)
```

This table shows that the completed variable has no significant effect on the predicted happiness variable with a p-value of 0.76.

## Question 3b

Identical to above, the health metric is used as an additional predictor in the baseline model designed in 2c. As the completed variable was not statistically significant, this can be removed from the baseline model. The resulting coefficients are:

```{r q3b}
hap_health_model1 = lm(scale(happiness) ~ health + season, data=cleandata)

print(summary(hap_health_model1)$coef)
```

Again, seasons are statistically significant, but the health variable has a p-value of 0.71, far removed from the necessary <0.05 confidence interval. This means happiness is not signficantly affected by the health variable in this dataset.

## Question 3c

As the hypothesis states happiness might be affected more by the health metric for people who got further through the program, we test this by creating a new linear model that tests for an association between the health and the week_stopped variable. The coefficients for the generated model are shown below:

```{r q3c}
hap_health_model2 = (lm(happiness ~ season + (health * week_stopped), 
                        data = cleandata))

print(summary(hap_health_model2)$coef)
```

In the new model, both week_stopped and health are significant variables, and the association between them is also strongly significant with a p-value of 2.5e-5. The model is plotted below, showing the combined effects of health and week_stopped. The two most extreme examples are plotted: the happiness of participants who quit in week 1 are strongly negatively affected by the health metric, while those who completed the program in week 9 are positively affected by the health metric.

```{r}
plot_model(hap_health_model2, 
           type="int", 
           mdrt.values = c("minmax"))
```

```{r outliers}
cooksd <- cooks.distance(hap_health_model2)
barplot(cooksd)
title("Cook's distance of data points")
```

As a number of statistically significant influences have been discovered on the model, we now test for any outliers. Taking a maximum Cook's distance of 0.5, we find that the highest Cook's distance for a data point in this model is `r max(cooksd)`. This is considerably lower than the threshold and therefore is not an influential outlier - we do not need to remove any values from the dataset.

## Question 3d

We find that there are a number of effects on the model that influence the happiness predictor. The table of coefficients for the final model, repeated below for convenience, shows that there are a number of effects. Taking autumn as the intercept term, the high positive estimate for the three other seasons show that when the participant filled in the form in any other season their happiness was positively affected.

In general, both health and week_stopped have a negative impact on the happiness of a participant. However, the week_stopped parameter also influences the effect of the health variable by a factor of 0.367, which means that when the week_stopped parameter is higher, it is multiplied by the health parameter to produce an overall positive effect on the happiness variable.

```{r}
print(summary(hap_health_model2)$coef)
```

# Question 4

```{r q4}
completed = cleandata[which(cleandata['week_stopped']==9),]

ggplot(data = completed, aes(x=season, y=happiness, fill=city)) + 
        geom_boxplot(width=0.8,lwd=0.5) +
        labs(title="Happiness of participants that completed the program")
```

# Question 5

## Question 5a

To calculate the probability of dropping out, the "completed" variable which was added to the dataset above is used. The probability to drop out is the inverse of the probability to complete the program (1-P(completion)), so we calculate the probability of completing the program first. The GLM described below shows how the various factors in the model modify the probability of completing the course:

```{r q5a}
pred_model = glm(completed ~ age + accountability + selfmot + health + happiness + season + city, data=cleandata, family = "binomial")
print(exp(coef(pred_model)))
```

To calculate the probability of completing the program from this model, the value shown in intercept is used as an initial probability. This probability is then modified by each of the variables in the chart by multiplication. This means that, for example, if the participant has filled out the questionnaire in the summer, the probability that they have completed the program is multiplied by `r exp(coef(pred_model))['seasonsummer']`. On the other hand, the probability of their success is multiplied by `r exp(coef(pred_model))['happiness']` to the power of their happiness value.

## Question 5b

To see which of these variables significantly affects the probability of dropping out, we look at the p-values for each of these variables. The chart below shows that age, self-motivation and health all significantly (p < 0.05) positively impact the probability of completing the program. Season is also a significant effect: spring and autumn negatively impacts the chances of completion, while summer and winter both signify more likely completion.

```{r q5b}
print(summary(pred_model)$coef)
```

## Question 5c

The probability of dropping out is shown in the chart below as a function of self motivation. 

```{r echo=FALSE, message=FALSE, results='hide'}
#shows the figures but suppresses useless console outputs.

ggplot(data = cleandata, aes(x = selfmot, y = 1 - completed)) +
  geom_smooth(method="glm", method.args = list(family = binomial)) +
  labs(y="predicted probability of dropping out of the program") +
  labs(x="calculated self-motivation from survey") +
  ggtitle("Probability of dropping out versus recorded self-motivation")
```
