---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
  pdf_document: default
params:
  examnumber: B200513
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0
<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->

Using summary() to see the data and roughly(the minimum number and the maximum number) find some impossible data. Then according to the content of data dictionary, making sure the age is reasonable(under 100); accountability and selfmot are between 5 and 35; health and happiness are between 0 and 100; season only including "spring", "summer", "autumn" and "winter"; city only including "Edinburgh" and "Glasgow"; week_stopped is digit number between 1 and 9. For example, change "autunm" (some typos) to "autumn", delete impossible data like negative number or aging 156.

```{r cleaning, include = FALSE}
# Neither output nor code from this chunk will be shown in the compiled document. summary(couchto5k)
couchto5k <-
  couchto5k %>%
  filter(age<=100) %>%
  filter(selfmot <=35) %>%
  filter(selfmot >=5) %>%
  filter(week_stopped <= 9)
couchto5k$season[couchto5k$season == "autunm"] <- "autumn"
```

To describe the data, firstly, using summary to see the rough description like the minimum, the mean, the median, and the maximum. Then, based on each column, using ggplot, bar plots, histograms and 5 density plots are drawn to illustrate the data separately. Density plots are used to see if is is the normal distribution roughly(for following check).

```{r descriptives}
# Code will not be shown from this chunk (because we set echo = FALSE in the very first chunk)
# the output from this code will be shown. 
summary(couchto5k)
ggplot(data = couchto5k, aes(x = age)) +
  geom_histogram()
ggplot(data = couchto5k, aes(x = age)) +
  geom_density()
ggplot(data = couchto5k, aes(x = accountability)) +
  geom_histogram()
ggplot(data = couchto5k, aes(x = accountability)) +
  geom_density()
ggplot(data = couchto5k, aes(x = selfmot)) +
  geom_bar()
ggplot(data = couchto5k, aes(x = selfmot)) +
  geom_density()
ggplot(data = couchto5k, aes(x = health)) +
  geom_histogram()
ggplot(data = couchto5k, aes(x = health)) +
  geom_density()
ggplot(data = couchto5k, aes(x = happiness)) +
  geom_histogram() 
ggplot(data = couchto5k, aes(x = happiness)) +
  geom_density()
ggplot(data = couchto5k, aes(x = season)) +
  geom_bar()
ggplot(data = couchto5k, aes(x = city)) +
  geom_bar()
ggplot(data = couchto5k, aes(x = week_stopped)) +
  geom_bar() + scale_x_continuous(breaks = 1:9)
```

# Question 1 

Firstly, we do some general checks to see: if the data in the sample is in line with earlier survey on attrition rates; whether the pattern of attrition rates differ by city(Edinburgh and Glasgow); if the average ages of participants differ by city.

## Question 1a

To check if the data in the sample is in line with earlier survey on attrition rates, which means, alternatively, if it is from the same database.  
Test we use: because it is related to "goodness of fit", we use chi-square test.
H0:there are no difference in observed data and expected data
H1:there are difference in observed data and expected data

```{r q1a}
# number of total observations
totaln <- nrow(couchto5k)
# percentage of subjects dropping halfway
Halfway <-
  couchto5k %>%
  filter(week_stopped <= 5)
nhalf <- nrow(Halfway)
phalf <- nhalf / totaln
# percentage of subjects dropping before end
BeforeEnd <-
  couchto5k %>%
  filter(week_stopped > 5) %>%
  filter(week_stopped < 9)
nbfend <- nrow(BeforeEnd)
pbfend <- nbfend / totaln
# percentage of subjects dropping before end
End <-
  couchto5k %>%
  filter(week_stopped == 9)
pend = 100 - phalf - pbfend
# chi-square test
pearlier = c(0.45, 0.1, 0.45)
pnow = c(phalf, pbfend, pend)
chisq.test(pnow, p=pearlier)

```

The p-value of the chi-square test is 2e-16, which is much less than the significance level alpha, 0.05. So we can reject H0. Therefore, we can conclude that the data in the sample is not line with data from the earlier survey.

## Question 1b
To see whether the pattern of attrition rates differ by city(Edinburgh and Glasgow), which means if the pattern of attrition rates is independent on city(discrete data). 
Test we use: because we are interested in the test of independence, so we use chi-square test.
H0:no relationship exists on the categorical variables in the population; they are independent.
H1:there are relationship on the categorical variables in the population
```{r q1b}
# categorize week_stopped
filtered = couchto5k %>%
  mutate(drop_type = case_when(week_stopped <5 ~ 0,
                              week_stopped %in% (5:8) ~ 1,
                              week_stopped == 9 ~2))
# make a table of city vs. drop_type
t = table(filtered$city, filtered$drop_type)
# make a mosaic plot
mosaicplot(t, main = "Mosaic plot", color = TRUE)
# do chi-square test
chisq.test(t)
```

The p-value of the test is 0.6, which is far greater than the significance level alpha, 0.05. So we can accept Ho. Therefore, we can conclude that the patterns of attrition rates don not differ by city.

## Question 1c

To see if the average ages of participants differ by city, which means to compare the means of two independent samples. 
Test we use: unpaired two-samples t-test
H0:true difference in means between group Edinburgh and group Glasgow is equal to 0
H1:true difference in means between group Edinburgh and group Glasgow is not equal to 0

```{r q1c}
# filter data by city
Edin <- 
  couchto5k %>%
  filter(city == "Edinburgh")
Glas <- 
  couchto5k %>%
  filter(city == "Glasgow")
# check if they are normal-distributed
shapiro.test(Edin$age)
shapiro.test(Glas$age)
# check the variance
var.test(Edin$age, Glas$age)
# do the t-test
with(couchto5k, t.test(age ~ city, alternative = "two.sided", var.equal = FALSE))
```

After shapiro test, age in Edin is not normal distribution, considering the small sample size, we choose to ignore this and still do t test. 
Through variance test, we found that two samples are not different significantly then we can do t-test.
From the result, p-value = 0.3, which is greater than the significance level alpha, 0.05, we can accept H0, so we can conclude that the average ages of participants who commenced the program don't differ by city.

# Question 2

In this section we are interested in what effects happiness ratings: Whether it is affected by the season they were interviewed in, and based on season, whether it is affected by age. And what about other effects?

## Question 2a

To check if happiness is affected by the season(discrete data and having more than two categorical variables), which means there are multiple independent groups.
Test we use: AOV
H0:true difference in means between Group spring, Group summer, Group autumn, Group winter is equal to 0
H1:true difference in means between Group spring, Group summer, Group autumn, Group winter is not equal to 0

```{r q2a}
# do AOV
summary(aov(couchto5k$happiness ~ couchto5k$season))
# draw plots 
ggplot(couchto5k, aes(x = season, y = happiness)) + 
  geom_boxplot()
ggplot(couchto5k, aes(x = season, y = happiness)) + 
  geom_jitter(height=0, width=.05)
```

From the output, we find that 0.013 is smaller than the significance level alpha, 0.05, so we can reject the null hypothesis. Then we can conclude that participants' happiness ratings are affected by the season they were interviewed in. And through the boxplot, we can find that participants interviewed in autumn are significantly having lower degree of happiness, which supports the results.

## Question 2b

Based on the results from 2a that season effects happiness, to see whether it is also affected by age(continuous variable), so we use linear model to test. There are two ways to choose, The first one is, adding age and season to the model. The second one is holding the season then test on the filtered data. 
H0: age has no significant influence on happiness
H1: age has significant influence on happiness

```{r q2b}

# add season to the linear model
model1 <- lm(happiness ~ age + factor(season), data = couchto5k)
summary(model1)
# hold the season, choose "spring" having the most data
spring <-
  couchto5k %>%
  filter(season == "spring")
model2 <- lm(happiness ~ age , data = spring)
summary(model2)
# hold the season, choose "summer" having the second most data
summer <-
  couchto5k %>%
  filter(season == "summer")
model3 <- lm(happiness ~ age , data = summer)
summary(model3)
# draw a point plot
ggplot(spring, aes(x = age, y = happiness)) + 
  geom_point()
```

From the output, we find that if we use two variables of linear model, from the significance code(*** or ** or * or . or nothing) we can tell that age has no significant influence on happiness, and "spring" and "summer" have, "spring" has larger influence. 
If we control "spring" or "summer", in "spring", we find that the influence of age appears, but in "summer", age still has no influence, which might because the influence of "spring" is so strong that it depresses the influence of age.
Then we can conclude that happiness are not effected by age except that we do the assumption in the data of "spring". So to control the model, we coose to hold in data of spring.

## Question 2c

Then besides age and season, what about other effects?
From question3 we know that we are going to explore the effect of health and week_stopped to happiness, so except for these two, we are adding other predictors including accountability, selfmot and city to see if they effect the outcome variable of happiness. Firstly, based on 2b, we know that season and age all have an effect, so besides season and age, we add other three predictors(accountability, selfmot, city).

```{r q2c_1}
baseline1 <- lm(happiness ~ age + accountability + selfmot + factor(city), data = spring)
summary(baseline1)
```

From the first try, we find that  Pr values of "selfmot" and "age" are significant (having *** or **), so these two predictors are significant, so we delete city and accountability,then have a second try. 

```{r q2c_2}
baseline2 <- lm(happiness ~ age + selfmot, data = spring)
summary(baseline2)
```

This time, we got our baseline model which containing predictors of selfmot and age.

# Question 3

Based on the baseline we bulit in 2c, in this section, we are interested in whether "if they complete the program" and health metric affect happiness ratings.

## Question 3a

To see if participants' happiness ratings are effected by whether or not they completed the program, we firstly categorize it to two variables, then add this predictor to the baseline.

```{r q3a}
# divide week_stopped into "drop" and "complete"
end_detail <-
  spring %>%
  mutate(droptype = case_when(week_stopped < 9 ~ 0,
                               week_stopped == 9 ~ 1))
# add predictors to the model
model4 <- lm(happiness ~ age + selfmot + factor(droptype), data = end_detail)
summary(model4)
```
From the output, we find that Pr of droptype is not significant, so we can conclude that happiness outcome are not effected by whether or not they completed the program.

## Question 3b

To see if participants' happiness ratings are effected by health, we add the predictor of health on the baseline.

```{r q3b_1}
model5 <- lm(happiness ~ age + selfmot + health, data = spring)
summary(model5)
```

From the result we find that the effects of age and health disappear, and checking the question of 3c, we find that the effect of health is neccessary, so we try different circumstances(do not hold the season which means using season as a predictor, and do not add season as a predictor although it do has effect) and find that it still cannot appear "health", so we finally try to hold "summer", and do a whole new procedure from 2c, then get the ideal model.  

```{r q3b_2}
model6 <- lm(happiness ~ selfmot + health, data = summer)
summary(model6)
```

## Question 3c

To explore how dropping type effects relation between happiness and health, we need to find the interaction between health and weeks. So what we are examining is how the effect of health on happiness depends on the dropping type, which means we need to estimate a parameter b such that the outcome is predicted by b(health x dropping type).
Our model needs to be like:
happiness = b0 + b1(selfmot) + b2(health) + b3(dropping type) + b4(health x dropping type) + ε

```{r q3c}
model7 <- lm(happiness ~ 1 + selfmot + health + week_stopped + health*week_stopped, data = spring)
summary(model7)
#draw the plot
library(sjPlot)
plot_model(model7, type="int")
```

From the output we find that they all have significant effect on happiness.  
From the graph, in which red represents staying for just one week and blue represents completing the whole program. It is indicated that the happiness of participants who complete is positively affected by the health metric, while one week is negatively effected. So the regression model does not align with the hypothesis that "the effects of good health are amplified by the feeling of acting healthily, such that the happiness of participants who got further along the program might be more affected by the health metric than that of those who stopped earlier".

## Question 3d

To figure out what effects happiness, we conducted some experiments. 
Firstly we do find season has an effect, however, it is not an ideal model for following experiments, so after trying a lot of combination, we decided to use data of summer. Then for the following exploring, we find that age, accountability and week_stopped do not have a significant effect while selfmot and health do have. 
However, for health, if we base on the whole data or on spring data, it do not have a significant effect. 
Furthermore, we also find that drpping week do not effect the relation between health and happiness.

# Question 4

First, we get the subset of participants who complete the program using filter(). Then, because 0 data cannot appear on the plot, so change it to 1 for convenience. Then, get the means grouped by seasons and cities using aggregate(), finally, plot the results that can be used in a presentation to the funders of the project

```{r q4}
#get the subset of participants who complete the program
enddata <- couchto5k %>% filter(week_stopped == 9)

#because 0 data cannot appear on the plot, so change it to 1 for convenience
enddata2 <- enddata[enddata$happiness == 0, "happiness"] <- 1

#get the means grouped by seasons and cities  
agg <- aggregate(x = enddata$happiness,
                by = list(enddata$city, enddata$season),
                FUN=mean )
#plot the results that can be used in a presentation to the funders of the project
ggplot(agg,
       aes(x = Group.1,
           y = x,
           fill = Group.2))+
  geom_bar(stat = "identity", position = "dodge")+
  labs(y="happiness",x="cities")+
  ggtitle(label="mean of happiness based on season & city")
```


# Question 5

In this section, we mainly experiment the predictors of drop-out

## Question 5a

To predict the likelihood of dropping out given some variables, we need a generalized linear model. First, we need to make the dropping type to a binary variable (marking 0 and 1), then we get all possible variables for gml and then see which ones are significant.

```{r q5a_1}
# binary variable drop(1), complete(0)
Dropout <- 
  couchto5k %>%
  mutate(dropout = case_when(week_stopped <9 ~1,
                             week_stopped == 9 ~0))
# get gml
model8 <- glm(dropout ~ age + accountability + selfmot + health + happiness + factor(city) + factor(season), data = Dropout, family = "binomial")
summary(model8)
# use anova
anova(model8, test = "Chisq")
```

The result shows that the model has Null deviance of 188.065, Residual deviance of 94.858. After calculating, model has an explainable deviance of 93.207, in which . To evaluate the model, we use ANOVA, and find that season contains 85.2 deviance to the total model and the p-value  is far less than 0.05, which means it is a significant variable. And other predictors are proved to be insignificant.

Then we renew the model with only reserved variable, season.

```{r q5a_2}
model9 <- glm(dropout ~ factor(season), data = Dropout, family = "binomial")
summary(model9)
```

## Question 5b
```{r q5b}
model9 <- glm(dropout ~ factor(season), data = Dropout, family = "binomial")
summary(model9)
```

From the result, we see that participants attend in spring has a higher probability of drop-out.

## Question 5c

```{r q5c}
dropout_data = Dropout[,c("dropout", "selfmot")]
ggplot(data = dropout_data, aes(x = selfmot, y = dropout)) + 
  ylab("P(dropout)") +
  geom_jitter(size = 3, width = 0, height = 0.2, alpha = 0.2 ) + geom_smooth(method = "glm", method.args = list(family = binomial), formula = y~x) + scale_y_continuous(breaks = seq(0, 1, by = 0.2))
```










