---
title: "USMR 2021-2022 Coursework"
author: "`r params$examnumber`"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
  pdf_document: default
params:
  examnumber: "B198873"
---

<!-- We have provided a template below with headings/sub-headings for each question/sub-question. This is just a template. Feel free to add or delete code-chunks if desired.  -->
<!-- Beneath here is some code which will set everything up for you.  Anything that is needed to run your code should be explicitly set up below -->

```{r setup, include=FALSE}
# this line will mean that when you compile/knit your document, 
# the code will not show, but the output (e.g., plots) will!
knitr::opts_chunk$set(echo = FALSE)
# this line means all numeric output gets rounded to 3 dp
options(digits=3)
# load any other packages that you require here:
library(tidyverse)
library(ggplot2)
library(pander)
library(psych)
library(sjPlot)
library(car)
# This will read in your own personal data:
source("https://uoepsy.github.io/data/usmr_2122_data.R")
```

# Question 0
Have a look at the data. Check for impossible values and deal with these in an appropriate manner. Describe the data, either in words or using suitable graphs (or a combination). Remember to detail the decisions you have made.
<!-- If you have run the R code above this point (you can do this now by pressing Ctrl-Shift-Alt-P, or running the chunk above) then your data will be in a dataframe called `couchto5k`. -->


```{r cleaning, include = FALSE}
# Neither output nor code from this chunk will be shown in the compiled document. 
summary(couchto5k)
count <- count(couchto5k)

couchto5k$missing <- NA
couchto5k$missing[couchto5k$age>100] <- "crazy age"
couchto5k$missing[couchto5k$selfmot<5] <- "impossible selfmot"
couchto5k$missing[couchto5k$week_stopped>9] <- "impossible week_stopped"
table1 <- table(couchto5k$missing)
couchto5k_2 <- couchto5k %>% filter(is.na(missing))
couchto5k_2 <- couchto5k_2[,-10]
total <- count(couchto5k_2)

as.factor(couchto5k_2$season)
as.factor(couchto5k_2$city)

miscoded <- sum(couchto5k_2$season=='autunm')
couchto5k_2$season[couchto5k_2$season =="autunm"] <- 'autumn'
couchto5k_2$season <- as.factor(couchto5k_2$season)
couchto5k_2$city <- as.factor(couchto5k_2$city)

summary(couchto5k_2)

ggplot(data = couchto5k_2, aes(x = age)) +
  geom_density() +
  geom_boxplot(width = 1/300) +
  labs(title="Figure3:Marginal distribution of age",
       x = "age", 
       y = "Probability density")
ggplot(data = couchto5k_2, aes(x=health)) + 
  geom_density() + 
  geom_boxplot(width = 1/50) +
  labs(title="Figure4:Marginal distribution of health", 
       x = "health", y = "Probability density")
ggplot(data = couchto5k_2, aes(x = accountability)) +
  geom_density() +
  geom_boxplot(width = 1/300) +
  labs(title="Figure5:Marginal distribution of accountability",
       x = "accountability", 
       y = "Probability density")
ggplot(data = couchto5k_2, aes(x = selfmot)) +
  geom_density() +
  geom_boxplot(width = 1/300) +
  labs(title="Figure6:Marginal distribution of selfmot",
       x = "selfmot", 
       y = "Probability density")
ggplot(data = couchto5k_2, aes(x = happiness)) +
  geom_density() +
  geom_boxplot(width = 1/300) +
  labs(title="Figure7:Marginal distribution of happiness",
       x = "happiness", 
       y = "Probability density")
ggplot(data = couchto5k_2, aes(x = week_stopped)) +
  geom_density() +
  geom_boxplot(width = 1/300) +
  labs(title="Figure8:Marginal distribution of week_stopped",
       x = "week_stopped", 
       y = "Probability density")

```

Data was obtained from https://uoepsy.github.io/data/usmr_2122_data.R: a dataset containing information on  `r count` participants, including 9 variables(pptID, age, accountability(a 7-point scale,sum of 5 questions, score:5-35), selfmot(a 7-point scale,sum of 5 questions, score:5-35), health(0-100), happiness(0-100),season,city(2 levels),week_stopped(1-9,9= completed).

After checking the variables, we found some odds values. For example, the max age was over 100; the min selfmot was `r min(couchto5k$selfmot)`, and the max week_stopped was  `r max(couchto5k$week_stopped)`. Therefore, we removed them, resulting in  `r total` observations for analysis. Table 1 summarizes the removed data. Additionally,  `r miscoded` seasons were miscoded as "autunm". Then we recoded them as "autumn". Table 2 shows the frequency of categorical variables. And table 3 describes the numerical variables.

```{r table, results="asis"}
table1 %>% pander(caption="Table 1: Summary of removed data.")
```

```{r descriptives,table, results="asis"}
# Code will not be shown from this chunk (because we set echo = FALSE in the very first chunk)
# the output from this code will be shown. 
table(couchto5k_2$season)%>% pander(caption="Table 2:Frequency.")
table(couchto5k_2$city)%>% pander(caption="Table 2:Frequency.")
describe(couchto5k_2)%>% pander(caption="Table 3: Summary of analysis data.")
```


# Question 1 

## Question 1a   
In an earlier nationwide survey, researchers found that 45% of participants abandoned the programme before the halfway point in week 5, and a further 10% gave up before the end of the programme. Is the data in the sample you have been given in line with data from the earlier survey? Once you have created a suitable variable to map to the information in the question, you should be able to answer this using a simple statistical test.

```{r q1a}
couchto5k_2$week_group <- NA
couchto5k_2$week_group[couchto5k_2$week_stopped<5] <- "stopped before week 5"
couchto5k_2$week_group[couchto5k_2$week_stopped>=5&couchto5k_2$week_stopped<9] <- "stopped after week 5"
couchto5k_2$week_group[couchto5k_2$week_stopped>=9] <- "completed"
table(couchto5k_2$week_group)
q1a <- chisq.test(table(couchto5k_2$week_group), p = c(0.45, 0.1, 0.45))
q1a
```
We divided the variable week_stopped into 3 categories. To evaluate whether our sample fitted the distribution of the previous study, a χ2 goodness of fit test was conducted. Effects will be considered statistically significant at α=0.05. The null hypothesis is the current data fits with the previous one. The alternative hypothesis is the current data does not fit with the previous one. The results show that X-squared= `r q1a$statistic %>% round(0)`, df=`r q1a$parameter`, p>0.05, which means we accept the null hypothesis. Namely, the data in the current study is consistent with data in the earlier survey.

## Question 1b
Using the same three categories (stopped before week 5, stopped after week 5, completed), examine whether the patterns of attrition rates differ by city.

```{r q1b}
table(couchto5k_2$week_group, couchto5k_2$city) %>% pander(caption="Table 4: Table of city and week_group.")
plot(table(couchto5k_2$week_group, couchto5k_2$city))
q1b<-chisq.test(table(couchto5k_2$week_group, couchto5k_2$city))
q1b
```

To examine whether the patterns of attrition rates differ by city, a χ2 goodness of fit test  was conducted. The null hypothesis is Edinburgh and Glasgow have the same patterns of attrition rates. The alternative hypothesis is the patterns of attrition rates vary from Edinburgh to Glasgow. The result is that X-squared= `r q1b$statistic %>% round(1)`, df=`r q1b$parameter`, p>0.05, which means that we accept the null hypothesis. Namely, the patterns of attrition rates are identical in Edinburgh and Glasgow. Table 4 shows the data of city and week_group.

## Question 1c
Do the average ages of participants who commenced the programme differ by city?

```{r q1c}
par(mfrow=c(1,2))
plot(density(couchto5k_2$age))
qqnorm(couchto5k_2$age)

shapiro.test(couchto5k_2$age[couchto5k_2$city=="Edinburgh"])
shapiro.test(couchto5k_2$age[couchto5k_2$city=="Glasgow"])


with(couchto5k_2, var.test(age ~ city))
q1c<-t.test(couchto5k_2$age ~ couchto5k_2$city, alternative = "two.sided")
q1c

```

To assess whether the average ages of participants who commenced the programme differ by city, a two-tailed two-sample t-test was conducted. The null hypothesis is that Edinburgh and Glasgow have the same average ages. Our alternative hypothesis is that participants in different cities have different mean ages. The t-test showed that t(35)=`r q1c$statistic %>% round(2)`, p>0.05, two-tailed, which means the average ages of participants who start the program do not vary from Edinburgh and Glasgow.

And we tested the assumption that the data were normally distributed. Though shapiro.test showed the p<0.05, but the plot of them was roughly normally distributed. Therefore, we still conducted a t-test.

# Question 2

## Question 2a
Are participants’ happiness ratings affected by the season they were interviewed in? Describe the way in which season influences happiness outcomes.

```{r q2a}

ggplot(couchto5k_2, aes(x=season, y = happiness))+
  geom_boxplot()
  
contrasts(couchto5k_2$season)
model2a <- lm(happiness ~ season, data=couchto5k_2)
summary(model2a)
anova(model2a)
par(mfrow=c(2,3))
plot(model2a)
plot(model2a,which=4)
tab_model(model2a)

```
The categorical variable season has four levels; therefore, a linear model was set up to know whether participants happiness ratings are affected by the season. The assumed model took the form:Happiness=b0+b1*(spring)+b2*(summer)+b3*(winter)+ ϵ. b0  = the estimated mean score on the happiness for autumn is 35.14, which is meaningful(SE=8.15, t=4.13, p<0.05). But the p-value of other seasons is not significant(p>0.05), which means that there is no difference among seasons. Besides. R-squared = `r summary(model2a)$adj.r.sq  %>% round(2)`, F (3,112) =3.14,p<0.05. It indicated that the variance of autumn is different from other seasons. Besides, the model met assumptions of homoscedasticity, independence of errors, and normality of error terms.
In brief, the average happiness rating for autumn is 35.14, but other seasons are not significantly different from autumn for happiness outcomes(p>0.05).

## Question 2b
Accounting for any effects you discovered in (2a), is happiness affected by age?

```{r q2b}

ggplot(data = couchto5k_2, aes(x = age, y=happiness)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method="lm")+
  facet_wrap(~season)+
  labs(x = "age", 
       y = "happiness")

couchto5k_2 %>% select(age,happiness) %>% cor()

model2b <- lm(happiness ~ 1 + season + age, data = couchto5k_2)
summary(model2b)

par(mfrow=c(2,3))
plot(model2b)
plot(model2b,which=4)

tab_model(model2b)
```

To explore whether happiness is affected  by age, based on seasons. We need to set up a multiple linear regression model using season and age as predictors.  The assumed model took the form: Happiness=b0+b1*(spring)+b2*(summer)+b3*(winter)+b4*(age)+ ϵ.  The result showed that age did not affect happiness, because the statistic of age is not significantly different(p>0.05). Furthermore, adjusted R-squared = `r summary(model2b)$adj.r.sq %>% round(2)`, F(4,111)=2.33, p>0.05.Besides, the assumptions were tested. The plots show the linearity of the relationship. And the residuals plots look good which means residuals are normal, independent, and homogeneous.
In brief, happiness is not affected by age.

## Question 2c  
The models you have built above explore ‘baseline’ effects; that is, effects that are not of primary interest to the researchers but which might affect the outcome variable of happiness. For use in question 3, pick a specific baseline model and justify why you are using this.

```{r q2c}
anova(model2a,model2b)
par(mfrow=c(2,3))
plot(model2a)
plot(model2a,which=4)
```
An ANOVA was conducted to compare the models we have set up, the results showed that the F=0, p>0.05. I will choose the model in 2a: Happiness= b0+b1*(spring)+b2*(summer)+b3*(winter)+ ϵ. The reason is that adding age as a predictor does not make the model fit better. And the model of 2a met assumptions of linearity (see the plot of model residuals vs fitted values), homoscedasticity, independence of errors. All the assumptions were checked, there were no violations.

# Question 3

## Question 3a  
Building on your baseline model, are participants’ happiness ratings affected by whether or not they completed the programme? Describe the way in which programme completion influences happiness outcomes.

```{r q3a}
couchto5k_2 <- couchto5k_2 %>% mutate(completed=ifelse(week_stopped=="9","1","0"))
model3a <- lm(happiness~1+ season + completed,data=couchto5k_2)
summary(model3a)
anova(model2a,model3a)
par(mfrow=c(2,3))
plot(model3a)
plot(model3a,which=4)
tab_model(model3a)
```

To test whether participants’ happiness ratings were affected by whether they completed the programme. We need to set up a binominal variable: completed. We modelled a multiple linear regression. The predictors are season and completed.  The assumed model took the form: Happiness=b0+b1*(spring)+b2*(summer)+b3*(winter)+b4*(completed)+ ϵ. And the results showed that the intercept was 30.02 with high significance(SE=10.71, t=2.80, p<0.05), and spring is significantly different from intercept(autumn)(SE=10.69, t=2, p<0.05), others are not significantly different(p>0.05). Also, the coefficient for completed is 5.98, but it does not significant from the intercept(SE=7.56, t=0.79, p>0.5). Furthermore, adjusted R-squared = `r summary(model3a)$adj.r.sq %>% round(2)`, F(4,11) = 2.5,p<0.05. Besides, the model met assumptions of linearity, homoscedasticity, independence of errors.

In brief, programme completion does not influence happiness outcomes.

## Question 3b
Building on the analysis in (3a), is happiness additionally affected by the “health metric”?

```{r q3b}

ggplot(data=couchto5k_2,aes(x=health,y=happiness))+
  geom_point()+
  geom_smooth(method="lm")+
  facet_wrap(~completed)

model3b <- lm(happiness~season+completed+health,data=couchto5k_2)
summary(model3b)

par(mfrow=c(2,3))
plot(model3b)
plot(model3b,which=4)

tab_model(model3b)

```

To investigate whether happiness is additionally affected by the “health metric” based on 3a, scores of happiness were modelled using multiple linear regression using season, completed and health as predictors. The assumed model took the form: Happiness=b0+b1*(spring)+b2*(summer)+b3*(winter)+b4*(completed)+b5*(health)+ϵ.The result showed that health did not influence happiness significantly(b=-0.17, SE=0.30, t=-0.55, p>0.05). Furthermore, adjusted R-squared = `r summary(model3b)$adj.r.sq  %>% round(2)`. F(5,110)=2.05, p>0.05. And the assumptions were met. 
Therefore, building on the analysis in (3a), happiness was not additionally affected by the “health metric”.

## Question 3c  
It’s been hypothesised that the effects of good health are amplified by the feeling of acting healthily, such that the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier. Building on the model in (3b), can you test this hypothesis?

```{r q3c}

ggplot(data = couchto5k_2, aes(x = health, y = happiness)) + 
  geom_point() + 
  geom_smooth(method=lm)+
  facet_wrap(~completed)

model3c <- lm(happiness~season+completed*health,data=couchto5k_2)
summary(model3c)
anova(model3b,model3c)

par(mfrow=c(2,3))
plot(model3c)
plot(model3c,which=4)
plot_model(model3c,type = "pred", terms = c("health","completed"), show.data = TRUE, title = "Figure 2: the interaction of completed and health")
ncvTest(model3c)
tab_model(model3c)
```
To test the hypothesis that the happiness of participants who got further along the programme might be more affected by the health metric than that of those who stopped earlier, we conducted a multiple linear regression model using season, completed, health and the interaction between completed and health as predictors, the outcome was happiness.  The assumed model took the form: Happiness=b0+b1*(spring)+b2*(summer)+b3*(winter)+b4*(completed)+b5*(health)+b6(completed:health)+ϵ.The results show that the completed, health and the interaction between them are all significant(p<0.05).Furthermore, adjusted R-squared = `r summary(model3c)$adj.r.sq  %>% round(2)`. And we conducted an ANOVA, F(6,109)=8.01, p<0.05. It indicated that the health metric has a greater influence on the participants’ happiness score for those who process the program longer than those who drop out earlier.We also conducted a Non-constant Variance Score Test to test multicollinearity, the result shows Chisquare =0.13, df = 1, p>0.05, which indicates that we do not have evidence that the assumption has been violated. All assumptions were checked, and no violations were found.
In brief, the happiness of participants who got further along the programme is affected by the health metric than that of those who stopped earlier.

## Question 3d  
What can we conclude about the various causes of happiness in our data? Write a brief description of the effects in the model, such as you might find in an academic paper.

The association between health and happiness was found to be dependent upon the level of completion. For those choosing autumn and not completed, the estimated happiness Score is 124.13(SE=22.33, t=5.56, p<0.05). For those who were not complete and chose autumn, an increase of 1 health is associated with a change of -1.74 (SE = 0.38, t=-4.65, p<0.05) in happiness Scores. For those choosing autumn, the happiness score of the completed person is `r 124.132-167.674`, (SE = 30.34, t=-5.53, p<0.05). For those who completed the program, for the increase of 1 score in health, the change in happiness is adjusted by 3.09(SE =0.52, t=5.89, p<0.05). Besides, for the person who did not complete, the happiness score for spring is different from autumn. The average happiness is `r 124.132+24.453` for the not completed person who choose spring.
The results presented here indicate that the happiness associated with health may depend upon ‘completed’. Namely, for these individuals –  higher health on completed leads to a greater increment in happiness.


# Question 4
Create a subset of the data, including only those participants who completed the programme. Create a plot of the average happiness ratings grouped by season and city, that can be used in a presentation to the funders of the project.

```{r q4}
subset_data <- couchto5k_2 %>% filter(week_group=="completed")

average_happiness <- subset_data %>% group_by(season,city) %>% summarise(mean_se(happiness))

ggplot(average_happiness, aes(x=season,y=y,ymin=ymin, ymax=ymax))+
  geom_bar(stat = "identity")+
  geom_errorbar(width=.2)+
  ylab("average happiness ratings")+
  facet_wrap(~city)+ 
  labs(title = "Figure 3:  the average happiness ratings grouped by season and city")
  
```


# Question 5

## Question 5a
Build a model that predicts the likelihood of dropping out (at all).

```{r q5a}
couchto5k_2$completed <- as.numeric(couchto5k_2$completed)
couchto5k_2 <- couchto5k_2 %>%mutate(dropping_out=1-completed)
model5a <- glm(dropping_out ~ accountability+selfmot, data=couchto5k_2, family = "binomial" )
```

To predict the likelihood of dropping out at all predictors, we conducted a generalised linear regression model using accountability and selfmot as predictors, the outcome is whether dropping out because they are what researchers were interested in.
The model is ln(P(Dropping_out)/(1- P(Dropping_out))=β0+β1*accountability+β2*selfmot.

## Question 5b
Briefly describe the effects in your model as you would in an academic paper.

```{r q5b}
summary(model5a)
exp(coef(model5a))

par(mfrow=c(2,3))
ggplot(couchto5k_2,aes(x=accountability,y=dropping_out))+
  geom_smooth(method="glm")
ggplot(couchto5k_2,aes(x=selfmot,y=dropping_out))+
  geom_smooth(method="glm")
plot(model5a)
plot(model5a,which=4)
tab_model(model5a)
```
We can find that compared to accountability, selfmot was the predictor that influenced the likelihood of dropping out significantly (β = -0.19, SE = 0.07, p <.01), suggesting being 1 selfmot score bigger  decreases the log-odds of dropping_out by 0.19.”. Furthermore, the odds of dropping out for someone who scores selfmot 0 is 53:1, for every selfmot larger someone is, the odds of dropping out decrease by 0.83. While accountability did not influence the probability of dropping out significantly(p>0.05)

## Question 5c
Draw a graph representing the probability of quitting as a function of how self motivated participants were.

```{r q5c}
ggplot(data = couchto5k_2, aes(x = selfmot, y = dropping_out)) +
  geom_jitter(size=3,width=0.3,height=0.1,alpha=.1)+
  geom_smooth(method="glm",method.args=list(family=binomial))+
  scale_y_continuous(breaks=seq(0,1,by=.2))+
  labs(title = "Figure 4:  the probability of quitting",
       y="predicted probability of quitting")
```










