---
title: "Test of learnr + webassemby"
link-citations: true
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---

```{r setup, include=FALSE}
source('assets/setup.R')
library(xaringanExtra)
xaringanExtra::use_panelset()
library(webexercises)
```

{{< include ./_extensions/r-wasm/live/_knitr.qmd >}} 
{{< include ./_extensions/r-wasm/live/_gradethis.qmd >}}

## Introduction


we have content.    

read this. 
```{webr}
#| include: false
x = rnorm(100)
y = rnorm(100, 1*x, 1)
df1 <- data.frame(x,y)

webr::eval_js('
  async function submitForm(data) {
    const formData = new FormData();
    formData.append("entry.839205657", data.field1);
    
    try {
      const response = await fetch("https://docs.google.com/forms/d/e/1FAIpQLSekV6BBmR3EWhTERZOK-boMsW-lC1HeKN76gWG95q7FeTE3vA/formResponse", {
        method: "POST",
        body: formData,
        mode: "no-cors"
      });
      return "Form submitted successfully";
    } catch (error) {
      return "Error: " + error.message;
    }
  }
')
submit <- function(response=0){
  webr::eval_js(paste0('submitForm({
  field1: "', response, '"})'))
  cat("Thank you for your feedback!")
}
```


above here is a webr chunk with include: false. Because the webr stuff is basically just evaluated in a single env for the page, it might be worth having an initial chunk to pre-populate the page with loading the relevant libraries & data etc.  


here is something you can play with:  
can you guess what the coefficient will be? 
```{webr}
#| caption: Simple regression
x <- rnorm(100)
y <- rnorm(100, 1*x, 1)
df <- data.frame(x,y)

lm(y ~ x, data = df) |>
  summary()
```

What about this one? where is df1 from? the author has made it for you already! 
```{webr}
#| caption: Simple regression
lm(y ~ x, data = df1) |> coef()
```



blah blah.   

here's a question.. what is 3+4?  
```{webr}
#| exercise: initq
#| setup: true

```

```{webr}
#| caption: Exercise
#| exercise: initq

```

::: {.hint exercise="initq"}
::: {.callout-note collapse="false"}
#### Hint 1

<!-- hint text here -->

```{r}
#| eval: false
3+?
```
:::
:::

::: {.solution exercise="initq"}
::: {.callout-tip collapse="false"}
#### Solution

<!-- Solution text here -->

```{webr}
#| exercise: initq
#| solution: true
3+4
```
:::
::::

```{webr}
#| exercise: initq
#| check: true
#| class: wait
gradethis::grade_this_code()
```


# part 2

hello you made it to part 2 because you correctly calculated 3+4.  

if we wanted to link people directly to pages that avoid this incremental reveal, then we just use:  

- *with* incremental reveal: https://uoepsy.github.io/lm/00activetest.html
- *without* incremental reveal: https://uoepsy.github.io/lm/00activetest.html?displayall
 
here are some more types of question:  

```{r}
#| echo: false
#| results: 'asis'
# library(webexercises)
qm1 <- c(
  3, 
  4,
  1,
  answer = 7
  )
```

| Question | &nbsp; |
| -------- | ------ |
| what was 3+4? | `{r} I(mcq(qm1))` |
| 3 + 4 = 5 | `{r} I(torf(FALSE))` |

- [ ] Continue to the next section

# part 3

and here we are.  




# part 4

i now want to check if i can make an mcq thing work with incremental reveal

### Checkpoint question!

Q:  What do you think is worst?  

A. this one  
B. the first one  
C. something other than this or the ones either side  
D. none of them. not even this one

```{webr}
#| setup: true
#| exercise: qtest
## can provide specific feedback if we like?
A <- "just because it said this one?"
B <- "surely you should have chosen A?"
C <- "this excludes B,C or D?"
D <- "this one is a paradox! this is the worst! whoop!"
```
```{webr}
#| caption: Exercise
#| exercise: qtest
answer <- ""
get(answer)
```

::: {.hint exercise="qtest"}
::: {.callout-note collapse="false"}
#### Hint 1

<!-- hint text here -->

```{r}
#| eval: false
# just write either A, B, C or D
answer <- "A"
answer <- "B"
answer <- "C"
answer <- "D"
```
:::
:::

::: {.solution exercise="qtest"}
::: {.callout-tip collapse="false"}
#### Solution

<!-- Solution text here -->

```{webr}
#| exercise: qtest
#| solution: true
answer <- "D"
get(answer)
```
:::
::::

```{webr}
#| exercise: qtest
#| check: true
#| class: wait
gradethis::grade_this_code(incorrect = "Not Quite. {random_encouragement()}")
```



# feedback? 

How did you find this reading/resource?  

1 - "I got to the end! Woohoo!"  
2 - "This was boring. i knew it all already"  
3 - "This helped. i think i understand things a little better now"  
4 - "This just made things more confusing"  

Use the numbers above to submit quick feedback (i.e., replace the 1 in `submit(1)` with the number of your choice, or leave a custom message for us `submit("Hello my friends!")`)!    

```{webr}
submit(1)
```


