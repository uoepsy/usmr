
# Adding Age into the Equation

.pull-left[
- so far, have focused on effects of practice

- but presumably older children read better?

```{r}
#| label: tab3
#| echo: false
reading %>% slice(c(1:3,48:50)) %>% gt() %>%
  data_color(columns=c("age","R_AGE"),colors="#d0d9ff",alpha=.8)
```
]
.pull-right[
```{r}
#| label: try3d
#| echo: false
#| fig.width: 7.0
library(rgl)
par(mar=c(0,0,0,0))
plot3d(x=reading$hrs_wk,y=reading$age,z=reading$R_AGE,
       type='s',
       radius=.1,
       xlab="practise",ylab="age",zlab="READING AGE")
rglwidget()
```
]

???
- **rotate cube leftward to show R_AGE~age**
---
# Another Model

.center[
```{r}
#| label: anmod
#| fig-asp: 0.6
#| echo: false
reading %>% ggplot(aes(x=age,y=R_AGE)) +
  xlab("age") + ylab("reading age") +
  geom_point(size=3) +
  geom_smooth(method="lm")
```

]

---
# Another Model

```{r}
#| label: mod2
#| highlight.output: !expr c(7, 11, 12, 17, 18)
mod2 <- lm(R_AGE ~ age, data=reading)
summary(mod2)
```

???
- point out that intercept is quite meaningless (reading age for age zero)

---
.center[
```{r}
#| label: diag2
#| echo: false
#| fig-asp: 0.7
#| fig.width: 9.0
par(mfrow=c(2,2))
plot(mod2,which=1:4)

```
]

---
# Two Models, No Answers

.pull-left[
- we now have two models that don't map well to assumptions

- each suggests an effect

  + one of `age`

  + one of `hrs_wk`
]
.pull-right[
- if we run them independently, the chances of a type 1 error are

  + $\frac{1}{20}$ (`mod`, including `hrs_wk`)

  + $\frac{1}{20}$ (`mod2`, including `age`)

- or ** $\frac{1}{10}$ ** overall
]

--
.pt1[
&nbsp;
]

.br3.pa2.bg-gray.white.tc[
we need to test multiple predictors in _one_ linear model
]
---
# Model Equations Again

$$\color{red}{\textrm{outcome}_i}=\color{blue}{(\textrm{model})_i}+\textrm{error}_i$$

$$\color{red}{y_i}=\color{blue}{b_0\cdot{}1+b_1\cdot{}x_i}+\epsilon_i$$
--

### linear model with two predictors

$$\color{red}{y_i}=\color{blue}{b_0\cdot{}1+b_1\cdot{}x_{1i}+b_2\cdot{}x_{2i}}+\epsilon_i$$
$$\color{red}{\hat{y}_i}=\color{blue}{b_0\cdot{}1+b_1\cdot{}x_{1i}+b_2\cdot{}x_{2i}}$$

--
.center[
`y ~ 1 + x1 + x2`

`R_AGE ~ 1 + hrs_wk + age` &nbsp;&nbsp; or &nbsp;&nbsp; `R_AGE ~ hrs_wk + age`<sup>1</sup>
]


.footnote[
<sup>1</sup> we'll come back to why order can matter in a bit
]
---
# Running A Multiple Regression

```{r}
#| label: multi
#| highlight.output: !expr '11:13'
mod.m <- lm(R_AGE ~ age + hrs_wk, data=reading)
summary(mod.m)
```

---
# Running a Multiple Regression

```{r}
#| label: multi2
#| echo: false
ca <- coef(mod.m)[2]
ch <- coef(mod.m)[3]
.pp(summary(mod.m),l = list(0,11:13,0))
```

- there are _independent_ effects of age and practice

  + reading age improves by `r ca` for each year of age

  + reading age improves by `r ch` for each weekly hour of practice

- note that the _intercept_ (0 years old, 0 hours/week) is meaningless here

--

- important question:  is this model _better_ than a model based just on age?

---
# Model Fit

```{r}
#| label: multi3
#| echo: false
.pp(summary(mod.m),l=list(0,17:19))

```

- in multiple regression, $R^2$ measures the fit of the entire model
  + sum of individual $R^2$s _if predictors not correlated_

- $R^2=`r summary(mod.m)$r.squared`$ looks better than the $R^2$ for `mod2` (`age` as a predictor) of $`r summary(mod2)$r.squared`$

- but _any_ predictor will improve $R^2$ (chance associations guarantee this)

```{r}
#| label: multi4
#| eval: false
mod.r <- update(mod2, ~ . + runif(50)) #<<
summary(mod.r)
```
```{r}
#| label: multi4b
#| echo: false
mod.r <- update(mod2, ~ . + runif(50))
.pp(summary(mod.r),l=list(0,18,0))
```
???

- Adjusted $R^2$ accounts for multiple predictors

- for `mod2`, it's `r summary(mod2)$adj.r.squared`

- for `mod.r`, it's `r summary(mod.r)$adj.r.squared`

---
#
## Slide

## Order Matters!

- `age` then `hrs_wk`
```{r}
#| label: multic3
#| echo: false
<<multic2>>
```
- `hrs_wk` then `age`
```{r}
#| label: multic4o
#| echo: false
anova(lm(R_AGE~hrs_wk+age,data=reading))
```

---
# Type 1 vs. Type 3 SS

- order matters because R, by default, uses **Type 1** sums of squares
  + calculate each predictor's improvement to the model _in turn_
- compare to **Type 3** sums of squares
  + calculate each predictor's improvement to the model _taking all other predictors into account_

- huge debate about which is "better" (nobody likes Type 2)

- if using Type 1, _predictors should be entered into the model in a theoretically-motivated order_
---
# Type 1 vs. Type 3 SS
.pull-left[
### type 1
.center[
![:scale 70%](lecture_7_files/t13/type0-0.svg)
]]
.pull-right[
### type 3
.center[
![:scale 70%](lecture_7_files/t13/type0-0.svg)
]]
---

```{r}
#| label: t1
#| echo: false
#| results: asis
img <- dir("lecture_7_files/t13/",pattern="type1.+svg$",full.names=TRUE)
slides_txt <- glue::glue("
count: false
# Type 1 vs. Type 3 SS
.pull-left[
### type 1
.center[
![:scale 70%]({img})
]]
.pull-right[
### type 3
.center[
![:scale 70%](lecture_7_files/t13/type0-0.svg)
]]

---

")
cat(slides_txt, sep="")
```

```{r}
#| label: t3
#| echo: false
#| results: asis
img <- dir("lecture_7_files/t13/",pattern="type3.+svg$",full.names=TRUE)
slides_txt <- glue::glue("
count: false
# Type 1 vs. Type 3 SS
.pull-left[
### type 1
.center[
![:scale 70%](lecture_7_files/t13/type1-3.svg)
]]
.pull-right[
### type 3
.center[
![:scale 70%]({img})
]]

---

")
cat(slides_txt, sep="")
```

# The Two-Predictor Model

```{r}
#| label: multiti
#| highlight.output: !expr '11:13'
<<multi>>
```
---

# The Two-Predictor Model

.flex.items-center[
.w-25[
&nbsp;
]
.w-50[
```{r}
#| label: 3d
#| echo: false
plot3d(x=reading$hrs_wk,y=reading$age,z=reading$R_AGE,
       type='s',
       radius=.1,
       xlab="practise",ylab="age",zlab="READING AGE")
coefs <- coef(mod.m)
a <- coefs["hrs_wk"]
b <- coefs["age"]
c <- -1
d <- coefs["(Intercept)"]
planes3d(a,b,c,d, alpha=0.5)
rglwidget()
```
]
.w-25[
&nbsp;
]]
