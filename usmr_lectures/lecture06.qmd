---
title: "The Linear Model"
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
source('_theme/theme_quarto.R')
```

# Model Comparison

## Where we Were {auto-animate=true}

:::: {.columns}

::: {.column width="60%"}

:::: r-stack

::: {.fragment .fade-out fragment-index=1}

```{r}
#| echo: false
set.seed(29)
dat <- faux::rnorm_multi(n=50,
                   mu=c(0.1,650),
                   sd=c(.009,60),
                   r=.4,
                   varnames=c('BloodAlc','RT')) |>
  mutate(BloodAlc=BloodAlc*100)
dat %>% ggplot(aes(x=BloodAlc,y=RT)) +
  xlab("Blood Alcohol 100 * %/vol") + ylab("RT (ms)") +
  geom_point(size=3) -> dp
dp
```

:::

::: {.fragment fragment-index=1 data-id="grph"}

```{r}
#| echo: false
#| label: dp

dp + geom_smooth(method="lm",linewidth=2)
```

:::

::::

:::

::: {.column width="40%"}
![](img/playmo_traffic.jpg)
:::

::::

::: {.fragment fragment-index=1}
```{r}
#| label: mod
#| echo: false
mod <- lm(RT~BloodAlc,data=dat)
.pp(summary(mod),l=list(0,11:12,0))

```


:::

## Intercept and Slope {auto-animate=true}

::: {data-id="grph"}

```{r}
#| echo: false
#| fig-asp: .35
#| fig-width: 15
#| fig-align: center

mf <- function(x) {
  coef(mod)[1]+coef(mod)[2]*x
}

dp2 <- dp + xlim(-.5,12) + ylim(250,785) +
  geom_abline(intercept=coef(mod)[1],slope=coef(mod)[2],colour="blue",linewidth=2) +
  annotate("segment",x=0,xend=0,y=250,yend=coef(mod)[1],arrow=arrow(length=unit(.03,"native")),colour="orange",linewidth=1.5) +
  annotate("segment",x=6,xend=6,y=mf(5),yend=mf(6),arrow=arrow(length = unit(.03,"native")),colour="orange",linewidth=1.5) +
  annotate("segment",x=3,xend=3,y=mf(2),yend=mf(3),arrow=arrow(length = unit(.03,"native")),colour="orange",linewidth=1.5) +
  annotate("text",x=.8,y=mf(.8)-85,label=.rround(coef(mod)[1],2),size=8,colour="orange") +
  annotate("text",x=6.8,y=mf(6.8)-55,label=.rround(coef(mod)[2],2),size=8,colour="orange") +
  annotate("text",x=3.8,y=mf(3.8)-55,label=.rround(coef(mod)[2],2),size=8,colour="orange") +
  annotate("segment",x=5,xend=6,y=mf(5)-25,yend=mf(5)-25,colour="red",arrow=arrow(length=unit(.03,"native"),ends="both")) +
  annotate("segment",x=2,xend=3,y=mf(2)-25,yend=mf(2)-25,colour="red",arrow=arrow(length=unit(.03,"native"),ends="both")) +
  geom_label(aes(x=5.5,y=mf(5)-25,label="1"),size=7,fill="white",label.size=NA) +
  geom_label(aes(x=2.5,y=mf(2)-25,label="1"),size=7,fill="white",label.size=NA) +
  annotate("point",x=5,y=mf(5),colour="orange") +
  annotate("point",x=2,y=mf(2),colour="orange")  

xLabVals <- as.numeric(ggplot_build(dp2)$layout$panel_params[[1]]$x$get_labels())
xLabs <- ifelse(xLabVals==0,"red","black")

dp2 + theme(axis.text.x=element_text(colour=xLabs))

```

:::

```{r}
#| echo: false
<<mod>>
```


## What If We Know Nothing

:::: {.columns}

::: {.column width="40%"}
![](img/playmo_frazzled.jpg)
:::

::: {.column width="60%"}

:::: myblock
there is no relationship between our **independent** and **dependent** variables
::::

<!-- div to ensure bullet points are aligned -->
::: {#id1}

- equivalent to "not knowing" the independent variable

:::

::: {.fragment}

- if we've measured a bunch of RTs but nothing else, our best estimate of a new RT is [_the mean RT_]{.fragment}

:::


:::

::::

::: {.fragment .center-x}

`y ~ 1` or `RT ~ 1`

:::


::: notes

"the mean RT" appears late, ask the audience

:::


## The Null Model

```{r}
#| echo: false
#| fig-asp: .6
#| fig-align: center

dp + geom_abline(intercept=mean(dat$RT),slope=0,colour="blue",linewidth=2)

```
- how much _better_ is `RT ~ BloodAlc` than `RT ~ 1`?

## Simplify the Data

:::: {.columns}

::: {.column width="50%"}
- to make the next few graphs less busy

::: {.fragment fragment-index=1}


```{r}
#| include: false

set.seed(29)
```


```{r}
#| tidy.opts: { width.cutoff: 24 }
ourDat <- dat |> slice_sample(n=20)
```

:::

:::

::: {.column width="50%"}

:::: r-stack

::: {.fragment .fade-out fragment-index=1}
```{r}
#| echo: false
#| fig-asp: .6
#| fig-align: center
dp
```

:::

::: {.fragment fragment-index=1}

```{r}
#| echo: false
#| fig-align: center
#| fig-asp: .6

xl <- range(dat$BloodAlc)
yl <- range(dat$RT)

ourDat %>% ggplot(aes(x=BloodAlc,y=RT)) +
  xlab("Blood Alcohol 100 * %/vol") + ylab("RT (ms)") +
  geom_point(size=3) -> nd
nd + xlim(xl) + ylim(yl)
```


:::

::::

:::

::::

## Total Sum of Squares

$$ \textrm{total SS}=\sum{(y - \bar{y})^2} $$

:::: {.columns}

::: {.column width="50%"}

- sum of squared differences between observed $y$ and mean $\bar{y}$

- = total amount of variance in the data

- = total _unexplained_ variance from the **null model**

:::

::: {.column width="50%"}

```{r}
#| label: totss
#| echo: false
#| fig.asp: 0.6
m1 <- lm(RT ~ BloodAlc,data=ourDat)
ourDat <- ourDat %>% mutate(pred=predict(m1),mRT=mean(RT))
p1 <- ourDat %>% ggplot(aes(x=BloodAlc,y=RT,yend=pred))

pTot <- p1 + geom_abline(intercept=mean(ourDat$RT),slope=0,linewidth=1.5,colour="blue") +
  geom_segment(aes(yend=mean(mRT),xend=BloodAlc),linetype="31",colour="orange",linewidth=1.5) +
  geom_point(size=3)
pTot
```

:::

::::


## Residual Sum of Squares

$$\textrm{residual SS} = \sum{(y - \hat{y})^2}$$

:::: {.columns}

::: {.column width="50%"}
- sum of squared differences between observed $y$ and predicted $\hat{y}$

- = total _unexplained_ variance from a _given_ model in the data

:::

::: {.column width="50%"}
```{r}
#| label: residp
#| echo: false
#| fig.asp: 0.6
pRes<- p1 + geom_segment(aes(xend=BloodAlc),linetype="31",colour="orange",linewidth=1.5) +
  geom_smooth(method="lm",se=FALSE,linewidth=1.5) +
  geom_point(size=3)
pRes
```
:::

::::

::: aside
this is the summed square errors, or $\sum{\epsilon^2}$
:::

::: notes
- so for the null model, total SS is the same as residual SS
:::

## Model Sum of Squares

$$ \textrm{model SS} = \sum{(\hat{y} - \bar{y})^2} $$

:::: {.columns}

::: {.column width="50%"}
- sum of squared differences between predicted $\hat{y}$ and observed $\bar{y}$

- total variance _explained_ by a given model
:::

::: {.column width="50%"}
```{r}
#| label: modp
#| echo: false
#| fig.asp: 0.6
pMod <- p1 + geom_segment(aes(y=mRT,xend=BloodAlc),colour="orange",linetype="31",linewidth=1.5) +
  geom_hline(yintercept = mean(ourDat$RT),linewidth=1.5,colour="blue") +
  geom_smooth(method="lm",se=FALSE,linewidth=1.5) +
  geom_point(size=3)
pMod
```
:::

::::

## Testing the Model: _R^2^_

:::: {.columns}

::: {.column width="58%"}

$$ R^2 = \frac{\textrm{model SS}}{\textrm{total SS}} = \frac{\sum{(\hat{y}-\bar{y})^2}}{\sum{(y-\bar{y})^2}} $$

::: myblock
how much the model improves over the null
:::

- $0 \le R^2 \le 1$

- we want $R^2$ to be large
:::

::: aside
for a single predictor, $\sqrt{R^2}=|r|$
:::


::: {.column width="2%"}
&nbsp;
:::

::: {.column width="40%"}
```{r}
#| echo: false
#| layout-nrow: 2
pMod
pTot
```

:::

::::

## Testing the Model: _F_

:::: {.columns}

::: {.column width="68%"}
$F$ ratio depends on **mean squares**

$$(\textrm{MS}_x=\textrm{SS}_x/\textrm{df}_x)$$

$$F=\frac{\textrm{model MS}}{\textrm{residual MS}}=\frac{\sum{(\hat{y}-\bar{y})^2}/\textrm{df}_m}{\sum{(y-\hat{y})^2}/\textrm{df}_r}$$

::: myblock
how much the model 'explains'
:::

- $0<F$

- we want $F$ to be large

:::

::: {.column width="2%"}
&nbsp;
:::

::: {.column width="30%"}
```{r}
#| echo: false
#| layout-nrow: 2
pMod
pRes
```
:::

::::

::: notes
- significance of $F$ does not always equate to a large (or theoretically sensible) effect
:::

## Two Types of Significance

```{r}
#| label: model
#| output-line-numbers: "11,12"
mod <- lm(RT ~ BloodAlc, data=dat)
summary(mod)
```

## Two Types of Significance {visibility="uncounted"}

```{r}
#| output-line-numbers: "11,12,17,18"
<<model>>
```

## Two Types of Significance

```r
summary(mod)
```
```{r}
#| echo: false
.pp(summary(mod),l=list(0,c(17,18)))
```
. . .

- $F$-statistic comes from _comparison_ of model with null model

```{r}
mod0 <- lm(RT~1, data=dat)
anova(mod0,mod)
```

```{r}
#| include: false
t <- broom::glance(mod)
ssr <- t$deviance
f <- t$statistic
dfr <- t$df.residual
df <- t$df
ss <- .rround(f*(ssr/dfr),0)
ssr <- .rround(ssr,0)
f <- .rround(f,1)
```

## Two Types of Significance

- in fact, because comparison is implicit:

```r
anova(mod0,mod)
```
```{r}
#| echo: false
.pp(anova(mod0,mod),l=list(1:7))
```

::: {#empty}
 
:::

```r
anova(mod)
```
```{r}
#| echo: false
.pp(anova(mod),l=list(1:6))
```

## Summarising...


Adding a predictor of blood alcohol improved the amount of variance explained over the null model [(_R^2^_=`r .rround(t$r.squared,2)`]{.nobrk}, [_F_(`r t$df`,`r t$df.residual`)=`r .rround(t$statistic,1)`]{.nobrk}, [_p_=`r .rround(t$p.value,4,drop.zero=T)`).]{.nobrk}

- we also have the $t$-statistic describing the effect...

## Hold On {transition="convex"}


:::: {.columns}

::: {.column width="50%"}
![](img/playmo_clown.jpg){.center-img}
:::

::: {.column width="50%"}
- we've made a lot of assumptions

:::

::::

# Assumptions

## The Most Important Rule

```{r}
#| include: false

generate_heart_data <- function(n_points, intercept, slope) {
  # Create a sequence of theta values
  theta <- seq(-pi, pi, length.out = n_points)
  
  # Generate x and y coordinates for a heart shape
  x_heart <- 16 * sin(theta)^3
  y_heart <- 13 * cos(theta) - 5 * cos(2 * theta) - 2 * cos(3 * theta) - cos(4 * theta)
  
  # Standardize x and y to zero mean
  x_heart <- x_heart - mean(x_heart)
  y_heart <- y_heart - mean(y_heart)
  
  # Rescale x to have a standard deviation of 1
  x_heart <- x_heart / sd(x_heart)
  
  # Generate y values for the best-fit line
  y_line <- intercept + slope * x_heart
  
  # Create y values for the heart shape that also fit the given best-fit line
  y_new <- y_heart + y_line
  
  # Create a dataframe
  return(data.frame(x = x_heart, y = y_new))
}

generate_random_data <- function(n_points, intercept, slope, x_range, y_range) {
  # Generate random x values within the given range
  x_random <- runif(n_points, min = x_range[1], max = x_range[2])
  
  # Center x values to have zero mean
  x_random <- x_random - mean(x_random)
  
  # Generate y values for the best-fit line
  y_line <- intercept + slope * x_random
  
  # Orthogonalize random noise to x
  noise <- rnorm(n_points, mean = 0, sd = 7.5)
  noise <- noise - mean(noise)  # make sure noise has zero mean
  noise <- noise - lm(noise ~ x_random)$fitted.values  # make noise orthogonal to x
  
  # Add orthogonal noise to y
  y_random <- y_line + noise
  
  # Create a dataframe
  return(data.frame(x = x_random, y = y_random))
  
  
}

dfH <- generate_heart_data(30,3,1)
dfR <- generate_random_data(30,3,1,range(dfH$x),range(dfH$y))

```

::: {layout-ncol=2}

```{r}
#| echo: false
#| fig-asp: .8

xl=range(c(dfR$x,dfH$x)+c(-1,1))
yl=range(c(dfR$y,dfH$y))

dfR |> ggplot(aes(x=x,y=y)) +
  xlim(xl) + ylim(yl) +
# geom_point(colour="black",size=5) +
  geom_abline(intercept=3,slope=1,colour="blue",linewidth=2) +
  ggtitle(expression(paste(hat(y)," = ",3 + 1 %.% x ))) -> ng1
ng1
```

```{r}
#| echo: false
#| fig-asp: .8

dfH |> ggplot(aes(x=x,y=y)) +
  xlim(xl) + ylim(yl) +
#  geom_point(colour="black",size=5) +
  geom_abline(intercept=3,slope=1,colour="blue",linewidth=2) +
  ggtitle(expression(paste(hat(y)," = ",3 + 1 %.% x ))) -> ng2
ng2
```
:::

## The Most Important Rule {visibility="uncounted"}

::: {layout-ncol=2}

```{r}
#| echo: false
#| fig-asp: .8
ng1 + geom_point(colour="black",size=5)
```

```{r}
#| echo: false
#| fig-asp: .8
ng2 + geom_point(colour="black",size=5)
```

:::

- look at your data, not just the statistics

## Anscombe's Quartet

```{r}
#| echo: false
#| layout: [[1,1],[1,1]]
anscombe |> ggplot(aes(x=x1,y=y1)) +
  xlim(0,20) + ylim(0,13) +
  geom_point(size=3) +
  geom_abline(intercept=3,slope=.5,colour="blue",linewidth=1.5) +
  xlab("x") + ylab("y")

anscombe |> ggplot(aes(x=x2,y=y2)) +
  xlim(0,20) + ylim(0,13) +
  geom_point(size=3) +
  geom_abline(intercept=3,slope=.5,colour="blue",linewidth=1.5) +
  xlab("x") + ylab("y")

anscombe |> ggplot(aes(x=x3,y=y3)) +
  xlim(0,20) + ylim(0,13) +
  geom_point(size=3) +
  geom_abline(intercept=3,slope=.5,colour="blue",linewidth=1.5) +
  xlab("x") + ylab("y")

anscombe |> ggplot(aes(x=x4,y=y4)) +
  xlim(0,20) + ylim(0,13) +
  geom_point(size=3) +
  geom_abline(intercept=3,slope=.5,colour="blue",linewidth=1.5) +
  xlab("x") + ylab("y")


```

::: attribution
Anscombe (1973)
:::

::: notes
- best-fit lines are $\hat{y}_i=3+0.5\cdot{}x_i$
:::




## Assumptions of Linear Models

:::: {.columns}

::: {.column width="45%"}
### required
:::: myyellowblock

- **linearity** of relationship(!)

- for the _residuals_:
  + **normality**
  + **homogeneity of variance**
  + **independence**

::::
:::

::: {.column width="10%"}
<!-- spacer -->
:::

::: {.column width="45%"}
### desirable

::: myyellowblock
- no 'bad' (overly influential) observations
:::
:::

::::

## Residuals

:::: {.columns}

::: {.column width="50%"}
$$y_i=b_0+b_1\cdot{}x_i+\epsilon_i$$

$$\color{red}{\epsilon\sim{}N(0,\sigma)~\text{independently}}$$

- normally distributed (mean should be $\simeq{}$ zero)

:::

::: {.column width="50%"}

![](`r knitr::fig_chunk('residp','svg')`)
:::

::::
- homogeneous (differences from $\hat{y}$ shouldn't be systematically smaller or larger for different $x$)

- independent (residuals shouldn't influence other residuals)

## At A Glance
```{r}
#| label: modresid
#| output-line-numbers: "7"
summary(mod)
```

## In More Detail

```{r}
#| label: margins
#| include: false
par(mar=c(0,0,0,0))
```



:::: {.columns}

::: {.column width="50%"}
### linearity

```{r}
#| label: resid1
#| fig-asp: 0.8
#| fig-show: hide
plot(mod,which=1)
```
- plots residuals $\epsilon_i$ against fitted values $\hat{y}_i$

- the 'average residual' is roughly zero across $\hat{y}$, so relationship is likely to be linear
:::

::: {.column width="50%"}
![](`r knitr::fig_chunk('resid1','svg')`)
:::

::::

## In More Detail

:::: {.columns}

::: {.column width="50%"}
### normality

```{r}
#| label: resid2
#| fig-asp: 0.8
#| fig.show: hide
hist(resid(mod))
```

:::

::: {.column width="50%"}
![](`r knitr::fig_chunk('resid2','svg')`)

:::

::::

## In More Detail {visibility="uncounted"}

:::: {.columns}

::: {.column width="50%"}
### normality

```{r}
#| label: resid3
#| fig-asp: 0.8
#| fig.show: hide
plot(density(resid(mod)))
```

- check that residuals $\epsilon$ are approximately normally distributed

- in fact there's a better way of doing this...
:::

::: {.column width="50%"}
![](`r knitr::fig_chunk('resid3','svg')`)
:::

::::

## In More Detail

:::: {.columns}

::: {.column width="50%"}
### normality

```{r}
#| label: resid4
#| fig-asp: 0.8
#| fig.show: hide
plot(mod,which=2)
```
- **Q-Q plot** compares the residuals $\epsilon$ against a known distribution (here, normal)

- observations close to the straight line mean residuals are approximately normal


:::

::: {.column width="50%"}
![](`r knitr::fig_chunk('resid4','svg')`)
:::

::::

## Q-Q Plots

:::: {.columns}

::: {.column width="46%"}

```{r}
#| echo: false
#| fig-asp: .7
#| fig-align: center

p <- ggplot(data=data.frame(x=c(-3.5,3.5)),aes(x=x)) +
  stat_function(fun = dnorm, n =151,size=2) + ylab("") +
  xlab("standard deviations (z)") +
  ylab("density")
d <- layer_data(p) |> filter(x <=qnorm(.1))
d2 <- layer_data(p) |> filter(x <= qnorm(.05))
p + geom_area(data=d, aes(x=x,y=y),fill="orange") +
  geom_area(data=d2,aes(x=x,y=y),fill="red") +
  stat_function(fun = dnorm, n =151,size=2)
```

:::

::: {.column width="8%"}
<!-- spacer -->
:::

::: {.column width="46%"}

#### y axis

- for a normal distribution, what values _should_ (say) [5%]{.red}, or [10%]{.orange} of the observations lie below?

- expressed in "standard deviations from the mean"

```{r}
#| label: qn1
qnorm(c(.05,.10))
```

:::

::::

## Q-Q Plots {visibility="uncounted"}


:::: {.columns}

::: {.column width="46%"}
#### x axis

- from our residuals, what values _are_ (say) [5%]{.red}, or [10%]{.orange}, of observations found to be less than?

- convert to "standard deviations from the mean"

```{r}
#| label: qn2
quantile(scale(resid(mod)),c(.05,.10))
```

:::

::: {.column width="8%"}
<!-- spacer -->
:::

::: {.column width="46%"}

```{r}
#| echo: false
#| fig-asp: .7
#| fig-align: center
p <- ggplot(data=data.frame(x=scale(resid(mod))),aes(x=x)) +
  geom_density(linewidth=2)
d <- layer_data(p) |> filter(x <= quantile(scale(resid(mod)),.1))
d2 <- layer_data(p) |> filter(x <= quantile(scale(resid(mod)),.05))
p + geom_area(data=d, aes(x=x,y=y),fill="orange") +
  geom_area(data=d2,aes(x=x,y=y),fill="red") +
  geom_density(linewidth=2) +
  xlab("standardized residuals") +
  ylab("density")
```


:::

::::

::: {.fragment}
- **Q-Q Plot** shows these values plotted against each other
:::

## In More Detail

:::: {.columns}

::: {.column width="50%"}
### normality

```r
plot(mod,which=2)
```
- **Q-Q plot** compares the residuals $\epsilon$ against a known distribution (here, normal)

- observations close to the straight line mean residuals are approximately normal


:::

::: {.column width="50%"}
![](`r knitr::fig_chunk('resid4','svg')`)
:::

::::

- numbered points refer to _row numbers_ in the original data


## In More Detail

:::: {.columns}

::: {.column width="50%"}
### [homogeneity of variance]{.r-fit-text}


```{r}
#| label: resid5
#| fig-asp: 0.8
#| fig-show: hide
plot(mod,which=3)
```

- graph shows $\sqrt{|\textrm{standardized residuals|}}$

- the _size_ of the residuals is approximately the same across values of $\hat{y}$


:::

::: {.column width="50%"}
![](`r knitr::fig_chunk('resid5','svg')`)
:::

::::

## What about Independence?

- no easy way to check independence of residuals

- in part, because it depends on the _source_ of the observations


- one determinant might be a single person being observed multiple times

- e.g., my reaction times might tend to be slower than yours<br/>
  $\rightarrow$ multivariate statistics

## Independence 

- another determinant might be _time_

- observations in a sequence might be **autocorrelated**

- can be checked using the Durbin-Watson Test from the `car` package

```{r}
library(car)
dwt(mod)
```


## Visual vs Other Methods

- more statistical ways of checking assumptions will be introduced in labs

- they tend to have limitations (for example, they're susceptible to sample size)

- nothing beats looking at plots like these (and `plot(<model>)` makes it easy)


## Assumption Checking

- there are no criteria for deciding exactly when assumptions are sufficiently met

  + it's a matter of experience and judgement

- we need to talk about **influence**

# Influence

##  Influence
```{r}
#| label: baddata1
#| echo: false
#| fig-asp: 0.6
#| fig-align: center

## NB., fix for new slide order
d20 <- ourDat

ba <- mean(d20$BloodAlc)
b20 <- d20 %>% select(RT,BloodAlc) %>% add_row(BloodAlc=ba,RT=1000)
p <- d20 %>% ggplot(aes(x=BloodAlc,y=RT)) +
  geom_point(size=3) +
  geom_smooth(method="lm",se=FALSE,linewidth=1.5)
m <- lm(RT~BloodAlc,data=b20)
p + geom_abline(intercept=coef(m)[1],slope=coef(m)[2],size=1.5,colour="red") +
  geom_point(aes(x=ba,y=1000),size=4,colour="red")
```

- even substantial **outliers** may only have small effects on the model

- here, only the intercept is affected


## Influence

```{r}
#| label: baddata2
#| echo: false
#| fig-asp: 0.6
#| fig-align: center

m1 <- lm(RT~BloodAlc,data=d20)
rt=coef(m1)[1]+14*coef(m1)[2]+rnorm(1,sd=10)
b20 <- d20 %>% select(RT,BloodAlc) %>% add_row(BloodAlc=14,RT=rt)
m <- lm(RT~BloodAlc,data=b20)
p + geom_abline(intercept=coef(m)[1],slope=coef(m)[2],size=1.5,colour="red") +
  geom_point(aes(x=14,y=rt),size=4,colour="red")
```

- observations with high **leverage** are inconsistent with other data, but may not be distorting the model

## Influence

```{r}
#| label: baddata3
#| echo: false
#| fig-asp: 0.6
#| fig-align: center

m1 <- lm(RT~BloodAlc,data=d20)
rt=coef(m1)[1]+13*coef(m1)[2]+rnorm(1,sd=10)-250
b20 <- d20 %>% select(RT,BloodAlc) %>% add_row(BloodAlc=13,RT=rt)
m <- lm(RT~BloodAlc,data=b20)
p + geom_abline(intercept=coef(m)[1],slope=coef(m)[2],colour="red",linewidth=1.5) +
  geom_point(aes(x=13,y=rt),size=4,colour="red")
```

- we care about observations with high **influence** (outliers with high leverage)

## Cook's Distance


```{r}
#| label: cook
#| fig-asp: 0.6
#| fig-align: center
#| echo: false
tb <- d20 |> mutate(y1=predict(m1),y2=predict(m)[-21])
d20 |> ggplot(aes(x=BloodAlc,y=RT)) +
  geom_point(size=3) + geom_point(aes(x=13,y=rt),size=4,colour="red") +
  geom_abline(intercept=coef(m1)[1],slope=coef(m1)[2],colour="blue",linewidth=1.5) +
  geom_abline(intercept=coef(m)[1],slope=coef(m)[2],colour="red",linewidth=1.5) +
  geom_segment(data=tb,aes(x=BloodAlc,xend=BloodAlc,y=y1,yend=y2),linetype="31",colour="orange",linewidth=1)
```

- a standardised measure of "how much the model differs without observation $i$"

## ![](img/css/what.jpg){width=70px style="transform: translateY(50%);"} Cook's Distance

:::: {.columns}

::: {.column width="67%"}

$$D_i=\frac{\sum_{j=1}^{n}{(\hat{y}_j-\hat{y}_{j(i)})^2}}{(p+1)\hat{\sigma}^2}$$

- $\hat{y}_j$ is the $j$th fitted value
- $\hat{y}_{j(i)}$ is the $j$th value from a fit which doesn't include observation $i$
- $p$ is the number of regression coefficients
- $\hat{\sigma}^2$ is the estimated variance from the fit, i.e., mean squared error

:::

::: {.column width="33%"}
![](img/playmo_wizard.jpg)
:::

::::

## Cook's Distance


```{r}
#| label: scramble
#| include: false
b20 <- b20 |> slice_sample(n=21)
bad <- lm(RT~BloodAlc,data=b20)
```

:::: {.columns}

::: {.column width="50%"}

```{r}
#| label: cook2
#| fig-asp: 0.8
#| fig-show: hide
plot(bad,which=4)
```


- observations labelled by row

- various rules of thumb, but start looking when Cook's Distance > 0.5
:::

::: {.column width="50%"}


![](`r knitr::fig_chunk('cook2','svg')`)
:::

::::

::: notes
- I've deliberately added an influential observation to the data here
:::

## Cook's Distance {visibility="uncounted"}

:::: {.columns}

::: {.column width="50%"}

```{r}
#| label: ncook
#| fig-asp: 0.8
#| fig-show: hide
plot(mod,which=4)
```


- observations labelled by row

- various rules of thumb, but start looking when Cook's Distance > 0.5
:::

::: {.column width="50%"}


![](`r knitr::fig_chunk('ncook','svg')`)
:::

::::


## So Now We Know... {.smaller}

:::: {.columns}

::: {.column width="55%"}
::: {#id0}
- the relationship is approximately linear
:::
::: {.fragment fragment-index=1}
- the residuals are approximately normal
:::
::: {.fragment fragment-index=2}
- the variance is approximately homogeneous
:::
::: {.fragment fragment-index=3}
- we _believe_ the observations are independent
:::
::: {.fragment fragment-index=4}
- there are no overly-influential observations
:::

:::

::: {.column width="45%"}
:::: r-stack
[![](`r knitr::fig_chunk('resid1','svg')`)]{.fragment fragment-index=1 .fade-out}

[![](`r knitr::fig_chunk('resid4','svg')`)]{.fragment fragment-index=1 .fade-in-then-out}

[![](`r knitr::fig_chunk('resid5','svg')`)]{.fragment fragment-index=2 .fade-in-then-out}

[![](img/playmo_dice.jpg){width="50%" .center-img}]{.fragment fragment-index=3 .fade-in-then-out}

[![](`r knitr::fig_chunk('ncook','svg')`)]{.fragment fragment-index=4 .fade-in-then-out}

::: {.fragment fragment-index=5}
```{r}
#| echo: false
#| output-line-numbers: "12,17,18"
summary(mod)
```


:::
::::
:::

::::

::: {.myyellowblock .space-above .fragment fragment-index=5}
- we are ready to report our observations
:::

<!-- ABOVE HERE -->

## What We Know

:::: {.columns}

::: {.column width="40%"}
::: myblock
Adding a predictor of blood alcohol improved the amount of variance explained over the null model [(_R^2^_=`r .rround(t$r.squared,2)`]{.nobrk}, [_F_(`r t$df`,`r t$df.residual`)=`r .rround(t$statistic,1)`]{.nobrk}, [_p_=`r .rround(t$p.value,4,drop.zero=T)`).]{.nobrk}
Reaction time slowed by `r .rround(coef(mod)[2],1)` ms for every additional 0.01% blood alcohol by volume [(_t_(`r summary(mod)$df[2]`)=`r .rround(coef(summary(mod))[2, "t value"],2)`]{.nobrk}, [_p_=`r .rround(coef(summary(mod))[2, "Pr(>|t|)"],4,drop.zero=T)`).]{.nobrk}
:::
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| fig-align: center
#| fig-asp: .95

<<dp>>
```

:::

::::

# Learning to Read

## Learning to Read

```{r}
#| label: makedat
#| include: false
# library(broom)
# doit <- TRUE
# 
# while (doit) {
#   reading <- tibble(
#     age=runif(50,5,11),
#     hrs_wk=rnorm(50,5,1),
#     method=gl(2,25,labels=c("phonics","word"))
#   )
# 
#   reading <- reading %>% mutate(
#     R_AGE=age + hrs_wk/2 - ifelse(method=="word",2,0)
#   )
# 
#   reading <- reading %>% mutate(
#     R_AGE=R_AGE+hrs_wk*ifelse(method=="word",0,.6)
#   )
# 
#   reading <- reading %>% mutate(
#     R_AGE=R_AGE-.03*age*hrs_wk
#   )
# 
#   reading <- reading %>% mutate(
#     R_AGE=R_AGE+rnorm(50,sd=.5)
#   )
# 
#   m <- lm(R_AGE ~ method,data=reading) %>% tidy() %>% mutate(sig=(p.value<.05))
#   if (!m$sig[2]) {
#     next
#   }
# 
#   m <- lm(R_AGE~age+hrs_wk,data=reading) %>% tidy() %>% mutate(sig=(p.value<.05))
# 
#   if (sum(m$sig[2:3])!=2) {
#     next
#   }
# 
#   m <- lm(R_AGE ~ hrs_wk*method,data=reading) %>% tidy() %>% mutate(sig=(p.value<.05))
#   if (!m$sig[4]) {
#     next
#   }
# 
#   m <- lm(R_AGE ~ age*hrs_wk,data=reading) %>% tidy() %>% mutate(sig=(p.value<.05))
#   if (!m$sig[4]) {
#     next
#   }
# 
#   doit <- FALSE
# 
# }
# 
# save(reading,file = "R/reading.Rdata")

load("R/reading.Rdata")
```

:::: {.columns}

::: {.column width="50%"}
![](img/playmo_teach.jpg)
:::

::: {.column width="50%"}
- the Playmo School has been evaluating its reading programmes, using 50 students

- ages of students

- hours per week students spend reading of their own volition

- whether they are taught using phonics or whole-word methods

- **outcome: "reading age"**

:::

::::

## Learning to Read {visibility="uncounted"}

:::: {.columns}

::: {.column width="50%"}
![](img/playmo_teach.jpg)
:::

::: {.column width="50%"}
```{r}
#| label: showdat
#| echo: false
library(gt)
reading |> slice(c(1:5,46:50)) |> gt() |>
  tab_options(table.font.size=pct(70)) |>
  fmt_number(decimals=1)
```
:::

::::

::: notes

- this is just some of the data in the dataframe

- on the right you can see the outcome variable, `R_AGE` for reading age.

- note that I tend to put my dependent variables in all caps, just so that I can recognise at a glance that they're what we measured.

:::


## Learning to Read {visibility="uncounted"}


:::: {.columns}

::: {.column width="50%"}
![](img/playmo_teach.jpg)
:::

::: {.column width="50%"}
```{r}
#| echo: false
reading |> slice(c(1:5,46:50)) |> gt() |>
  data_color(columns=c("hrs_wk","R_AGE"),colors="#d0d9ff",alpha=.8) |> tab_options(table.font.size=pct(70)) |>
  fmt_number(decimals=1)
```
:::

::::

## Does Practice Affect Reading Age?

```{r}
#| output-location: column
#| tidy.opts: { width.cutoff: 20 }
#| fig-asp: .6
p <- reading |>
  ggplot(aes(x=hrs_wk,
             y=R_AGE)) +
  geom_point(size=3) +
  ylab("reading age") +
  xlab("hours reading/week")
p

```

- hours per week is correlated with reading age: [_r_=`r cor(reading$hrs_wk,reading$R_AGE)`,]{.nobrk}
[_p_=`r cor.test(reading$hrs_wk,reading$R_AGE)$p.value`]{.nobrk}

- we can use a linear model to say something about the effect size

## Does Practice Affect Reading Age?

```{r}
#| output-location: column
#| tidy.opts: { width.cutoff: 20 }
#| fig-asp: 0.6
p + geom_smooth(method="lm")
```

```{r}
#| include: false
mod <- lm(R_AGE~hrs_wk,data=reading)
```

. . .

- each extra hour spent reading a week adds `r .rround(coef(mod)[2])` years to reading age

## A Linear Model

```{r}
#| label: lm1
#| output-line-numbers: "7,11,12,17,18"


summary(mod)
```

---

[but...]{.r-fit-text}

---

```{r}
#| label: diagp2
#| echo: false
#| fig-asp: 0.7
#| fig-align: center
par(mfrow=c(2,2))
plot(mod,which=1:4)
```

## Assumptions Not Met!

:::: {.columns}

::: {.column width="50%"}
- it seems that the assumptions aren't met for this model

- (another demonstration on the right)

- one reason for this can be because there's still systematic structure in the residuals

- i.e., _more than one thing_ which can explain the variance
:::

::: {.column width="50%"}

```{r}
#| echo: false
#| fig-align: center

ggplot(data=data.frame(x=resid(mod)),aes(x=x)) +
  geom_density(linewidth=2) +
  xlab("model residuals") +
  ylab("density")
```

:::

::::

## Adding Age into the Equation

:::: {.columns}

::: {.column width="50%"}

- so far, have focused on effects of practice

- but presumably older children read better?

```{r}
#| label: tab3
#| echo: false

library(gt)

reading |> slice(c(1:3,48:50)) %>% gt() |>
  data_color(columns=c("age","R_AGE"),colors="#d0d9ff",alpha=.8) |>
  tab_options(table.font.size=pct(70))
```
:::

::: {.column width="50%"}
```{r}
#| label: try3d
#| echo: false
library(rgl)
par(mar=c(0,0,0,0))
plot3d(x=reading$hrs_wk,y=reading$age,z=reading$R_AGE,
       type='s',
       radius=.1,
       xlab="practise",ylab="age",zlab="READING AGE")
rglwidget()
```
:::
::::

## Another Model

```{r}
#| label: anmod
#| fig-asp: 0.6
#| echo: false
reading %>% ggplot(aes(x=age,y=R_AGE)) +
  xlab("age") + ylab("reading age") +
  geom_point(size=3) +
  geom_smooth(method="lm")
```

## Another Model

:::: {.columns}

::: {.column width="80%"}

```{r}
#| label: mod2
#| output-line-numbers: "7,11,12,17,18"
mod2 <- lm(R_AGE ~ age, data=reading)
summary(mod2)
```

:::

::: {.column width="20%"}


```{r}
#| include: false
mr2 <- summary(mod2)$r.squared |> .rround(2)
```


![](img/playmo_profr2.svg)


- _R_^2^=`r mr2`

:::

::::
::: notes
- this is just to remind you to remember that _R_^2^ for a couple of slides
:::

---

```{r}
#| label: diag2
#| echo: false
#| fig-asp: 0.7
#| fig-align: center
par(mfrow=c(2,2))
plot(mod2,which=1:4)

```

## Two Models, No Answers

:::: {.columns}

::: {.column width="50%"}

- we now have two models that don't map well to assumptions

- each suggests an effect

  + one of `age`

  + one of `hrs_wk`

:::

::: {.column width="50%"}

- if we run them independently, the chances of a type 1 error are

  + $\frac{1}{20}$ (`mod`, including `hrs_wk`)

  + $\frac{1}{20}$ (`mod2`, including `age`)

- or **$\frac{1}{10}$** overall

:::
::::

. . .

::: myyellowblock
- we need to test multiple predictors in _one_ linear mod
:::

## Model Equations Again

$$\color{red}{\textrm{outcome}_i}=\color{blue}{(\textrm{model})_i}+\textrm{error}_i$$

$$\color{red}{y_i}=\color{blue}{b_0}\cdot{}\color{orange}{1}+\color{blue}{b_1}\cdot{}\color{orange}{x_i}+\epsilon_i$$

. . .

### linear model with two predictors

$$\color{red}{y_i}=\color{blue}{b_0}\cdot{}\color{orange}{1}+\color{blue}{b_1}\cdot{}\color{orange}{x_{1i}}+\color{blue}{b_2}\cdot{}\color{orange}{x_{2i}}+\epsilon_i$$

$$\color{red}{\hat{y}_i}=\color{blue}{b_0}\cdot{}\color{orange}{1}+\color{blue}{b_1}\cdot{}\color{orange}{x_{1i}}+\color{blue}{b_2}\cdot{}\color{orange}{x_{2i}}$$


## Two Predictors

$$\color{red}{y_i}=\color{blue}{b_0}\cdot{}\color{orange}{1}+\color{blue}{b_1}\cdot{}\color{orange}{x_{1i}}+\color{blue}{b_2}\cdot{}\color{orange}{x_{2i}}+\epsilon_i$$

$$\color{red}{\hat{y}_i}=\color{blue}{b_0}\cdot{}\color{orange}{1}+\color{blue}{b_1}\cdot{}\color{orange}{x_{1i}}+\color{blue}{b_2}\cdot{}\color{orange}{x_{2i}}$$

::: {layout=[1,1,1]}
 

![](img/formula_2x.svg){.nostretch .center-img}

 
:::

. . .

```r
mod.m <- lm(R_AGE ~ 1 + hrs_wk + age, data = reading)
```

_or_


```r
mod.m <- lm(R_AGE ~ 1 + age + hrs_wk, data = reading)
```

::: aside
we'll talk about why order matters in a moment
:::

## Running A Multiple Regression

```{r}
#| label: multi
#| output-line-numbers: "11,12,13"
mod.m <- lm(R_AGE ~ age + hrs_wk, data=reading)
summary(mod.m)
```

## Running a Multiple Regression

```{r}
#| label: multi2
#| echo: false
ca <- coef(mod.m)[2] |> .rround(2)
ch <- coef(mod.m)[3] |> .rround(2)
.pp(summary(mod.m),l = list(0,11:13,0))
```

- there are _independent_ effects of age and practice

  + reading age improves by `r ca` years for each year of age

  + reading age improves by `r ch` years for each hour of practice

- the _intercept_ (0 years old, 0 hours/week) is meaningless!

. . .

- important question:  is this model _better_ than a model based just on age?

## Model Fit

```{r}
#| label: multi3
#| echo: false
mmr2 <- summary(mod.m)$r.squared |> .rround(2)
.pp(summary(mod.m),l=list(0,18,0))

```

- in multiple regression, _R_^2^ measures the fit of the entire model
  + sum of individual _R_^2^s _if predictors not correlated_

- [_R_^2^=`r mmr2`]{.nobrk} looks better than the _R_^2^ for `mod2` (`age` as a predictor) of `r mr2`

- but _any_ predictor will improve _R_^2^ (chance associations guarantee this)

```{r}
#| label: multi4
#| eval: false
mod.r <- update(mod2, ~ . + runif(50))
summary(mod.r)
```
```{r}
#| label: multi4b
#| echo: false
set.seed(31)
mod.r <- update(mod2, ~ . + runif(50))
.pp(summary(mod.r),l=list(0,18,0))
```

## Comparing Models

```{r}
#| label: multic
#| echo: false
#| output-line-numbers: "3"
.pp(summary(mod.m),l=list(0,18:19))
```

- _F_ ratio compares model to the null model

- but we can also compare models in succession

```{r}
#| label: multic2
mod.n <- lm(R_AGE~1, data=reading)
anova(mod.n, mod2, mod.m)
```

## Comparing Models

:::: {.columns}

::: {.column width="46%"}
### explicit way
```r
anova(mod.n, mod2, mod.m)
```
```{r}
#| echo: false

print(anova(mod.n, mod2, mod.m),signif.stars = FALSE)
```



:::

::: {.column width="2%"}
<!-- filler -->
:::

::: {.column width="52%"}
### lazy way
```r
anova(mod.m)
```
```{r}
#| echo: false

print(anova(mod.m),signif.stars=FALSE)
```

:::

::::

## Order Matters! 

:::: {.columns}

::: {.column width="50%"}
### `age` then `hrs_wk`
```r
mod <- lm(R_AGE ~ age + hrs_wk, data=reading)
anova(mod)
```

```{r}
#| label: multic3
#| echo: false
print(anova(lm(R_AGE~age+hrs_wk,data=reading)),signif.stars=FALSE)
```
:::

::: {.column width="50%"}
### `hrs_wk` then `age`
```r
mod <- lm(R_AGE ~ hrs_wk + age, data=reading)
anova(mod)
```

```{r}
#| label: multic4o
#| echo: false
print(anova(lm(R_AGE~hrs_wk+age,data=reading)),signif.stars=FALSE)
```

:::

::::

## Order Matters!

- order affects _F_ ratios because R, by default, uses **Type 1** sums of squares
  + calculate each predictor's improvement to the model _in turn_
- compare to **Type 3** sums of squares
  + calculate each predictor's improvement to the model _taking all other predictors into account_

- in R, _predictors should be entered into the model in a theoretically-motivated order_

::: aside
more on orders of predictors, and sums of squares, in the course readings
:::

## The Two-Predictor Model

```{r}
#| label: 3d
#| echo: false
#| fig-align: center

plot3d(x=reading$hrs_wk,y=reading$age,z=reading$R_AGE,
       type='s',
       radius=.1,
       xlab="practise",ylab="age",zlab="READING AGE")
coefs <- coef(mod.m)
a <- coefs["hrs_wk"]
b <- coefs["age"]
c <- -1
d <- coefs["(Intercept)"]
planes3d(a,b,c,d, alpha=0.5)
rglwidget()
```

::: {.content-visible when-profile="local"}

## {background-color="black" background-image="img/playmo_spooky.jpg"}

:::

# End
