---
title: "Measurement and Distributions"
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
source('_theme/theme_quarto.R')
```

# Measurement


## The problem with measurement

- when we measure something, we want to identify its **true measurement** (the **ground truth**)

:::: {.columns}

::: {.column width="50%"}
- we don't have any way of measuring accurately enough

- our measurements are likely to be _close to_ the truth

- they might vary, if we measure more than once
:::

::: {.column width="50%"}
![](img/playmo2.jpg)
:::

::::


## Measurement
- we might _expect_ values close to the "true" measurement to be more frequent

:::: {.columns}

::: {.column width="40%"}
![](img/playmo_proft.svg){width=60% .center-img}
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| fig-width: 4
#| fig-asp: .7

set.seed(8423398)
pm <- data.frame(x=rnorm(70,7.5,.05))
pm %>% ggplot(aes(x=x)) +
  geom_density() + scale_y_continuous(breaks=NULL) +
  geom_vline(xintercept=7.5,colour="red") +
  annotate(geom="text",colour="red",x=7.5,y=3,label="TRUE MEASURE",size=3) +
  xlab('height (cm)') + ylab("")
```

:::

::::

::: notes
- so let's do a thought experiment and imagine what things
would look like if lots and lots of people tried to measure
the "true" distance of the notch from the end of the stick.

- most of them would be quite competent, and we would expect
the majority of the measurements to be close to the "true" value.

- every now and again, someone would overshoot or undershoot by rather
more.

- _theoretically_ they might be completely off-beam, although the chances of being way off get vanishingly small quite quickly.
:::

## Something quite familiar


```{r}
#| fig-asp: .55
#| echo: false
#| label: normnorm

t <- data.frame(x=c(7.35,7.65))
t %>% ggplot(aes(x)) +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.05),size=2) +
  ylab("") +
  geom_vline(xintercept = 7.5,colour="red",size=2) +
  scale_y_continuous(breaks=NULL) +
  xlab("height (cm)")
```


::: notes
- if we think a bit more about our thought experiment, we've actually described
something quite familiar:  A bell curve

- but what is a "bell curve"?

- to answer that question, let's start back where we were last week, with dice.
:::

## Dice again


```{r dice, echo=FALSE,fig.asp=.6}
set.seed(13)
dice <- function(num=1) {
  sum(sample(1:6,num,replace = T))
}
t <- data.frame(x=replicate(1000,dice(2)))
t %>% ggplot(aes(x)) + geom_bar() +
  scale_x_continuous(breaks=2:12,name = 'sum of dice',limits = c(1,13)) +
  ggtitle('1000 throws of 2 dice')

```


- the heights of the bars represent the numbers of times we obtain each value

- but why are the bars not touching each other?


## Dice throws aren't really numbers


:::: {.columns}

::: {.column width="50%"}
- **A** = ![](img/A1.svg){width=20%}

- **B** = ![](img/B1.svg){width=20%} or ![](img/B2.svg){width=20%}

- **C** = ![](img/C1.svg){width=20%} or ![](img/C2.svg){width=20%} or ![](img/C3.svg){width=20%}
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-asp: .5
t %>% ggplot(aes(x)) + geom_bar() +
  scale_x_continuous(breaks=2:12,labels = c('A','B','C','D','E','F','G','H','I','J','K'),
  name = 'outcome type',limits = c(1,13)) +
  ggtitle('1000 throws of 2 dice')
```
:::

::::

- bar plot ("bar chart") always has gaps between bars
- represents frequencies of _discrete categories_ (`factors`)

::: notes
- I could just label the possible outcomes of throwing two dice arbitrarily

- if you think about it, there are only 11 possible values that the sum
  of two dice can take.

- and if the dice didn't have actual numbers on their faces, you could still
  enumerate the outcomes

- so the outcomes are _discrete_ (you can never throw a value between 3 and 4, or between "B and C")
- and the bars on a bar plot have gaps between them to show this.
:::

## Back to playmobil

:::: {.columns}

::: {.column width="40%"}
![](img/playmo2.jpg)
:::

::: {.column width="60%"}
- **height** is a Ratio variable
- there will be limits to our precision, coventionally indicated by number of digits

::: fragment

| written | ⊢ min | ⊢ max |
|----|---|---|
| 7.5 | ≥ 7.450 | < 7.550 |
| 7.50 | ≥ 7.495 | < 7.505 |

: **height of figure (cm)**
:::

:::
::::

## Histograms    

:::: {.columns}

::: {.column width="40%"}
- we can represent all the measurements with a **histogram**

- the bars are touching because this represents _continuous_ data

:::

::: {.column width="60%"}

```{r}
#| echo: false
#| fig-asp: .6

minx <- round(min(pm$x - .02),2)
maxx <- round(max(pm$x + .02),2)
p <- pm %>% ggplot(aes(x=x)) + geom_histogram(binwidth=0.01) +
  scale_x_continuous(limits=c(minx,maxx)) + xlab('height (cm)')
layD <- layer_data(p) %>% filter(x>=7.495 & x<=7.505)
barHt <- layD$y
p
```

:::
::::

## Histograms {visibility="uncounted"}

:::: {.columns}

::: {.column width="40%"}
- we can represent all the measurements with a **histogram**

- the bars are touching because this represents _continuous_ data

:::

::: {.column width="60%"}

```{r}
#| echo: false
#| fig-asp: .6

p + geom_rect(xmin=layD$xmin,xmax=layD$xmax,ymin=0,ymax=barHt,fill="red")
```

:::

::::

- we know that there were `r barHt` measurements of about `r .rround(layD$x,2)` cm
  + strictly, ≥ `r .rround(layD$xmin,3)` and < `r .rround(layD$xmax,3)` cm

## Histograms (2)

:::: {.columns}

::: {.column width="40%"}
- note that the _bin width_ of the histogram matters

- these histograms all show the same data
:::

::: {.column width="60%"}

:::: r-stack

::: {#1}
```{r}
#| echo: false
#| fig-asp: .6
p
```
:::

::: {.fragment}

```{r}
#| echo: false
#| fig-asp: .6
pm %>% ggplot(aes(x=x)) + geom_histogram(binwidth=0.025) +
  scale_x_continuous(limits=c(minx,maxx)) + xlab('height (cm)')
```
:::

::: {.fragment}
```{r}
#| echo: false
#| fig-asp: .6
pm |> ggplot(aes(x=x)) + geom_histogram(binwidth=0.05) +
  scale_x_continuous(limits=c(minx,maxx)) + xlab('height (cm)')
```
:::

::::

:::

::::

## Histograms in R
```{r}
#| include: false

heights <- pm$x
```

:::: {.columns}

::: {.column width="30%"}
```{r}
head(heights)
```

```{r}
#| label: histy
#| output: false
#| fig-asp: .6

hist(heights)
```

:::

::: {.column width="70%"}

![](`r knitr::fig_chunk('histy','svg')`)

:::

::::




::: aside
you can make prettier graphs using `ggplot()`, but `hist()` is useful for exploring data
:::


## Histograms

:::: {.columns}

::: {.column width="50%"}
**the good**

- way to examine the _distribution_ of data

- easy to interpret ( $y$ axis = counts )

- [sometimes helpful in spotting weird data]{.fragment .highlight-red}
:::

::: {.column width="50%"}
**the bad**

- changing bin width can completely change graph

- only gives info about distribution and mode

  - not, e.g., mean or median

:::

::::

## Histograms

:::: {.columns}

::: {.column width="40%"}
```{r}
#| echo: false

pm2 <- rbind(pm,data.frame(x=c(4.196,4.199)))
sample(pm2$x)
```
:::

::: {.column width="60%" .fragment}
```{r}
#| echo: false
#| fig-asp: .6

p <- pm2 |> ggplot(aes(x)) + geom_histogram(binwidth=0.05) +
  scale_x_continuous() + xlab('height (cm)')
layD <- layer_data(p) |> filter(x<=4.201)
p + geom_rect(xmin=layD$xmin,xmax=layD$xmax,ymin=0,ymax=layD$y,fill="red")
```
:::
::::

## Density Plots

:::: {.columns}

::: {.column width="60%"}
:::: r-stack

::: {#1}
```{r}
#| echo: false
#| fig-asp: .6
p <- pm |> ggplot(aes(x=x)) + geom_density(size=2) +
  xlab("height (cm)") + ylim(0,10)
p
```
:::

::: {.fragment fragment-index=1}
```{r}
#| label: dg
#| echo: false
#| fig-asp: .6
p + geom_rug()
```
:::

::: {.fragment fragment-index=2}
```{r}
#| echo: false
#| fig-asp: .6

pm |> ggplot(aes(x=x)) +
  geom_density(bw=.006,size=2) +
  geom_rug() +
  xlab("height (cm)") +
  ylim(0,10)
```


:::
::::

:::

::: {.column width="40%" .fragment fragment-index=1}

- density plots depend on a _smoothing function_

- essentially, they're making guesses where there is no data

:::

::::


## Density Plots

:::: {.columns}

::: {.column width="60%"}
```{r}
#| echo: false
#| fig-asp: .6

<<dg>>
```

:::
::: {.column width="40%"}

- $y$ axis is no longer a count
- _total area_ under curve = "all possibilities" = **1**
:::
::::

## Density Plots

:::: {.columns}

::: {.column width="60%"}
```{r}
#| echo: false
#| fig-asp: .6

gp <- layer_data(p)
gp <- gp |> filter( x>=7.5 &  x<7.525)
p + geom_area(data=gp, aes(x=x,y=y), fill="red") +
  geom_density(size=2) + ylab("density")

dens <- density(pm$x)
prop <- sum(dens$y[dens$x>=7.5 & dens$x<7.525]) / sum(dens$y)
```

:::

::: {.column width="40%"}
- partial area under the curve gives _proportion_ of cases (here, `r prop` ≥ 7.500 and < 7.525)
:::

::::

::: {.myblock .fragment}
this is equivalent to saying that if I pick an observation $x_i$ from this sample at random, there is a probability of `r prop` that $7.500 \le x_i < 7.525$
:::

# The Normal Distribution

## A Famous Density Plot

:::: {.columns}

::: {.column width="40%"}
- when we started thinking about measurement,
  we thought things might look a bit like this

- the so-called **normal curve**
:::

::: {.column width="60%"}
![](`r knitr::fig_chunk('normnorm','svg')`)
:::

::::
::: {.myblock .fragment}
the normal curve is a _hypothetical_, asymptotic, density plot, with an area under the curve of **1**
:::

::: notes
- in part 3, we'll look at where the normal curve comes from

- for now, let's look at some of its features
:::

## Normal Curves: Mean

:::: {.columns}

::: {.column width="40%"}
- normal curves can be defined in terms of _two parameters_

- one is the centre or **mean** of the distribution ($\bar{x}$, or sometimes $\mu$)

:::

::: {.column width="60%"}
```{r}
#| echo: false
#| label: norms
#| fig-asp: .6

t <- data.frame(x=c(6,9))
p <- t %>% ggplot(aes(x)) +
  stat_function(fun = dnorm, n =151, args=list(mean=6.9,sd=.25),size=2) +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.25),size=2) +
  stat_function(fun = dnorm, n =151, args=list(mean=8.1,sd=.25),size=2) +
  ylab("") +
#  scale_y_continuous(breaks=NULL) +
  xlab("height (cm)")
p + geom_vline(xintercept = 7.5,colour="red",size=1.5) +
  geom_vline(xintercept = 6.9,colour="red",size=1.5) +
  geom_vline(xintercept = 8.1,colour="red",size=1.5)
```

:::
::::

::: notes
- the y value here is just what is needed to ensure that the area under the is 1
:::

## Standard Deviation

:::: {.columns}

::: {.column width="40%"}


- the other is the **standard deviation** (sd, or sometimes $\sigma$)

$$\textrm{sd}=\sqrt{\frac{\sum{(x-\bar{x})^2}}{n-1}}$$

:::

::: {.column width="60%"}
```{r annotated, echo=FALSE, fig.asp=.6}
p <- t %>% ggplot(aes(x)) +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.1),size=2) +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.25),size=2) +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.5),size=2) +
  ylab("") +
#  scale_y_continuous(breaks=NULL) +
  xlab("height (cm)")
p +
  geom_vline(xintercept = 7.5, col=alpha("red",.5)) +
  geom_segment(aes(x=7.5, xend=7.5+.1, y=dnorm(7.5+.1,7.5,.1),yend=dnorm(7.5+.1,7.5,.1)), col="red", size=2) +
  geom_segment(aes(x=7.5, xend=7.5+.25, y=dnorm(7.5+.25,7.5,.25),yend=dnorm(7.5+.25,7.5,.25)), col="red", size=2) +
  geom_segment(aes(x=7.5, xend=7.5+.5, y=dnorm(7.5+.5,7.5,.5),yend=dnorm(7.5+.5,7.5,.5)), col="red", size=2) 
```
:::

::::


- standard deviation is the "average distance of observations from the mean"


## Why Does the Height Vary?

::: {layout="[1,1]"}
```{r}
#| echo: false
#| fig-asp: .5

p <- t |> ggplot(aes(x)) +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.1),size=0) +
  ylab("") +
#  scale_y_continuous(breaks=NULL) +
  xlab("height (cm)")
layD <- layer_data(p) |> filter(x>=7.4 & x<=7.6)
p + geom_area(data=layD,aes(x=x,y=y),fill="red") +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.1),size=2) +
  ylim(0,4)
```

```{r}
#| echo: false
#| fig-asp: .5

p <- t |> ggplot(aes(x)) +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.5),size=0) +
  ylab("") +
#  scale_y_continuous(breaks=NULL) +
  xlab("height (cm)")
layD <- layer_data(p) |> filter(x>=7.0 & x<=8.0)
p + geom_area(data=layD,aes(x=x,y=y),fill="red") +
  stat_function(fun = dnorm, n =151, args=list(mean=7.5,sd=.5),size=2) +
  ylim(0,4)
```
:::

- area under the curve is always the same by sd

- for ± 1 sd it's `r 1-2*pnorm(1,lower.tail=F)`

. . .

::: myblock
there is a 68% chance of obtaining data within 1 sd of the mean
:::

::: notes
- remember though that we're in _hypothetical_ world!
:::


## The Standard Normal Curve

:::: {.columns}
::: {.column width="50%"}
- we can **standardize** any value on any normal curve by

- subtracting the mean
  + the effective mean is now **zero**

- dividing by the standard deviation
  + the effective standard deviation is now **one**
:::

::: {.column width="50%"}

```{r}
#| echo: false
#| fig-asp: .6

p <- ggplot(data=data.frame(x=c(-3.5,3.5)),aes(x=x)) +
  stat_function(fun = dnorm, n =151,size=2) + ylab("") +
  xlab("standard deviations (z)")
p
```

:::: {.fragment}

$$ z_i = \frac{x_i - \bar{x}}{\sigma} $$
::::
:::
::::

## The Standard Normal Curve

:::: {.columns}
::: {.column width="50%"}
- the area between 1 standard deviation below the mean and 1 standard deviation above the mean is, as we know, [`r pnorm(1)-pnorm(-1)`]{.fragment fragment-index=1}
:::

::: {.column width="50%"}

:::: r-stack

```{r}
#| echo: false
#| fig-asp: .6

d <- layer_data(p) |> filter(x >=-1 & x <=1)
p + geom_area(data=d, aes(x=x,y=y),fill="red") +
  stat_function(fun = dnorm, n =151,size=2)
```

::: {.fragment fragment-index=2}
```{r}
#| echo: false
#| fig-asp: .6
d <- layer_data(p) |> filter(x >=qnorm(.025) & x <=qnorm(.975))
p + geom_area(data=d, aes(x=x,y=y),fill="red") +
  stat_function(fun = dnorm, n =151,size=2)
```
:::
::::
:::
::::

:::: {.fragment fragment-index=2}
- we can ask the question the other way around:  _an area of .95_ lies between `r qnorm(.025)` and `r qnorm(.975)` standard deviations from the mean

::: myblock
95% of the hypothetical observations (95% confidence interval)
:::

::::

# Sampling from a Population

## {background-image="img/playmo_pop.jpg"}
