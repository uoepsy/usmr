---
title: "Nominal Data"
bibliography: assets/refs.bib
csl: _theme/apa7.csl
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
source('_theme/theme_quarto.R')
```



# Binomial Test

## Last Week

- the $t$-test and $z$-test deal with _interval_ (at least) data

- they can compare continuous data to a distribution with
  - known $\mu$ and $\sigma$ ($z$-test)
  - known $\mu$ and unknown $\sigma$ (**one-sample** $t$-test)

. . .
  
- they can compare continuous data from two samples
  - independent groups (**independent-samples** $t$-test)
  - related groups (**paired-samples** $t$-test)

::: notes
- these are formalisations of what we talked about last week

- the one-sample and related-samples $t$-tests use essentially the same maths
:::

## Not Everything is Numbers

:::: {.columns}

::: {.column width="60%"}
- sometimes the things we are interested in aren't numeric

- fashionable or not?

- heads or tails?

- USMR student or not?
:::

::: {.column width="40%"}

![](img/playmo_fash.jpg)
:::

::::

## Binomial Distribution

:::: {.columns}

::: {.column width="50%"}
![](img/50p_ht.jpg){width=60%}

- two possible outcomes with fixed probabilities $p$ and $1-p$

- with enough trials, proportion of outcomes will be $p$ and $1-p$
:::

::: {.column width="10%"}

:::

::: {.column width="40%" .fragment}
- the number of trials ($n$) is fixed
- each observation is independent
- each observation has one of two outcomes
- the probability of each outcome is consistent
:::

::::

## Binomial?

- [a fair coin is tossed 20 times]{.fragment .highlight-red fragment-index=1}
  - [$x$ = # of heads]{.fragment .highlight-red fragment-index=1}

- [draw 3 cards at random without replacement]{.fragment .semi-fade-out fragment-index=1}
  - [$x$ = # of diamonds]{.fragment .semi-fade-out fragment-index=1}

- [draw 3 cards at random with replacement]{.fragment .highlight-red fragment-index=1}
  - [$x$ = # of diamonds]{.fragment .highlight-red fragment-index=1}

- the probability of having blood type B is .1; choose 4 people at random.
  - $x$ = # with type B

## Binomial Distribution

:::: {.columns}

::: {.column width="40%"}
![](img/50p_ht.jpg){width=60%}

- toss a coin 100 times
- how many "successes" (=heads, say) are you likely to get?
:::

::: {.column width="60%"}

```{r}
#| echo: false
#| fig-width: 7
#| fig-asp: .6
set.seed(2210)
n <-  100
p <-  0.5
nSuccess = 1:n

dat <- data.frame(nSuccess = nSuccess, prob = dbinom(nSuccess, size=n, prob=p))

ggplot(dat, aes(nSuccess, prob)) + geom_col(width = 0.5) + 
  labs(x = 'Number of Successes', y = 'Probability') + 
  scale_x_continuous(breaks = seq(20, 80, 10), limits = c(20, 80)) +
  ggtitle(label = paste0('Binomial Distribution (n = ', n, ', p = ', p, ')')) +
  theme(axis.text = element_text(size = 14), axis.title = element_text(size = 16, face = 'bold'),
        title = element_text(size = 16, face = 'bold')) 
```

:::
::::


<!-- this isn't perfect but it moves the column up -->
<style>
.col-slide .columns {
        position: relative;
    }


.col-slide .columns > div:nth-child(2) {
      position: absolute;
      top: -100px; /* Adjust this value as needed */
    }

</style>


::: aside
actually coin tosses aren't 50/50 [@bartos2024]
:::

## Binomial Test {.col-slide}

:::: {.columns}

::: {.column width="50%"}
+ if you toss a coin 4 times, what's the probability of it landing on heads at least 3 times?

+ $2^4 = 16$ possible sequences of outcomes
  
+ Of those 16, 5 outcomes include $\ge$ 3 heads 

+ $p = 5/16 = .3125$
:::

<!-- to move column up {.my-slide} above the width needs to be 100% for some reason -->
::: {.column width="100%"}
```{r}
#| echo: false

coins <- expand.grid(rep(list(c('H','T')),4))
names(coins) <- c('Toss1','Toss2','Toss3', 'Toss4')
coins$HEADS <- apply(coins[1:4],1, function(x) length(which(x=='H')))
coins |> gt::gt() |>
  gtExtras::gt_highlight_rows(rows=which(coins$HEADS>=3),fill="#ffc587")
```

:::

::::

## Binomial Test

```{r}
#| echo: true
#| output-line-numbers: "5"
print(binom.test(3, 4, p = 0.5, alternative = 'greater'), digits = 7)
```

- don't be fooled by the `probability of success` which is just 3/4


## Binomial Test (2)

::: myblock
approximately 9% of the world's population have blue eyes; is the USMR class of 2024--25 a representative sample?
:::

![](img/playmo_pop_eyes.jpeg){.center-img}


## Eye Colours for USMR

```{r}
#| include: false

statsClasses <- read.csv("https://uoepsy.github.io/data/surveydata_historical.csv") |> select(course,year,eyecolour,in_uk)
newClasses <- read.csv("https://uoepsy.github.io/data/usmr2024.csv") |> select(course,year,eyecolour) |> mutate(in_uk=NA)
statsClasses <- statsClasses |> bind_rows(newClasses)
rm(newClasses)

usmrEyes <- statsClasses |> filter(course=="usmr", year==2024) |> pull(eyecolour) |> discard(is.na)
```

```{r}
#| echo: true
(eyes <- table(usmrEyes))
```

```{r}
#| echo: false
#| fig-asp: .5
#| fig-align: center
#| label: ecfig

ggplot(as.data.frame(eyes), aes(usmrEyes, Freq, fill = usmrEyes)) +
  geom_bar(stat='identity') +
  labs(x='Eye Colour', y = 'Count') +
  scale_fill_manual(values = c('#218BB2', '#593520', '#7CA69A',
                               #'#8C8C8C', no grey in 2024
                               '#5C643D', '#071726')) +
  theme(legend.position = 'none', axis.text = element_text(size=14), 
        axis.title=element_text(size=16, face = 'bold'))
```

::: aside
putting `(eyes <- ...)` in parentheses assigns and prints at the same time
:::

## Binomial Test

- approximately 9% of the world's population have blue eyes

```{r}
#| echo: true
#| output-line-numbers: "5"

binom.test(eyes['blue'],
           sum(eyes),
           0.09,
           alternative = "two.sided"
          )
```

# THe $\chi^2$ Distribution

## Goodness-of-Fit Test

:::: {.columns}

::: {.column width="80%"}

- so what happens when we are interested in _more than two_ outcomes?

- we have already talked about dice "numbers" being categories

- we know that, in a fair die, the probability of getting each number is $\frac{1}{6}$ (**H~0~**)

- can we assess the probability of getting a known set of throws if H~0~ is true?

- if the _probability is low enough_ ($p<.05$) we can assert that the die is biased

:::

::: {.column width="20%"}

![](img/playmo_dice.jpg)

:::


::::

## Calculating $\chi^2$

```{r}
#| label: settings
#| include: false
throws=600
```

- let's assume we throw the die `r throws` times

- if everything worked out _perfectly_ for an unbiased die, our **expected values** would be:

```{r}
(expected <- 600 * c(1/6,1/6,1/6,1/6,1/6,1/6))
```

- and we can calculate a $\chi^2$ statistic using the formula

$$\chi^2 = \sum{\frac{(O_i-E_i)^2}{E_i}}$$ 
where $O_i$ is the $i\textrm{th}$ _observed_ and $E_i$ is the $i\textrm{th}$ _expected_ value



## Calculating $\chi^2$

- we don't have to do this calculation by hand

- we can do it piece-by-piece, starting with 600 throws I've 'recorded'

```{r}
#| label: t1
#| include: false
repeat {
  throws<-sample(1:6,prob = c(1,1.2,1,1,.8,1), 600, replace=TRUE)
  xx <- chisq.test(table(throws))$statistic
  if (xx> qchisq(.95,5) & xx < 15) {
    break
  }
}
```
```r
throws
```

```{r}
#| echo: false
cat(paste(c(head(throws,80),'...'),collapse=' '))
```

```{r}
table(throws)
```


## Calculating $\chi^2$ {auto-animate=true}
```{r}
#| label: expected
chiTab <- data.frame(
  expected=expected, # from earlier calculation
  observed=table(throws) |> as.integer()
)
chiTab
```

::: aside
`as_integer()` chucks out irrelevant information from the table of `throws`, leaving the counts
:::



$$\chi^2 = \sum{\frac{(O_i-E_i)^2}{E_i}}$$





## Calculating $\chi^2$ {auto-animate=true}

:::: {.columns}

::: {.column width="70%"}

```{r}
#| eval: false
#| tidy.opts: { width.cutoff: 40 }
chiTab <- chiTab |> mutate(
  sq_diff=(observed-expected)^2)
```

:::

::: {.column width="30%"}
$$\chi^2 = \sum{\frac{\color{red}{(O_i-E_i)^2}}{E_i}}$$ 
:::
::: aside
using the `tidyverse` way of doing things, where `mutate()` creates columns
:::

::::


## Calculating $\chi^2$ {auto-animate=true visibility="uncounted"}

:::: {.columns}

::: {.column width="70%"}

```{r}
#| eval: false
#| tidy.opts: { width.cutoff: 40 }
chiTab <- chiTab |> mutate(
  sq_diff=(observed-expected)^2,
  std_sq_diff=(sq_diff/expected)
  )
```

:::

::: {.column width="30%"}
$$\chi^2 = \sum{\color{red}{\frac{(O_i-E_i)^2}{E_i}}}$$ 
:::
::: aside
using the `tidyverse` way of doing things, where `mutate()` creates columns
:::

::::

## Calculating $\chi^2$ {auto-animate=true visibility="uncounted"}

:::: {.columns}

::: {.column width="70%"}

```{r}
#| eval: false
#| tidy.opts: { width.cutoff: 40 }
chiTab <- chiTab |> mutate(
  sq_diff=(observed-expected)^2,
  std_sq_diff=(sq_diff/expected)
  )
chiTab
```

:::

::: {.column width="30%"}
$$\chi^2 = \sum{\color{red}{\frac{(O_i-E_i)^2}{E_i}}}$$ 
:::
::: aside
using the `tidyverse` way of doing things, where `mutate()` creates columns
:::

::::

## Calculating $\chi^2$ {auto-animate=true visibility="uncounted"}

:::: {.columns}

::: {.column width="70%"}

```{r}
#| tidy.opts: { width.cutoff: 40 }
chiTab <- chiTab |> mutate(
  sq_diff=(observed-expected)^2,
  std_sq_diff=(sq_diff/expected)
  )
chiTab
```

::: {.fragment fragment-index=1}

```{r}
sum(chiTab$std_sq_diff)
```

:::

::: {.fragment fragment-index=2}

- **df** = $\textrm{number of groups}-1 = 5$

:::
:::

::: {.column width="30%"}
:::: {.r-stack}

::: {.fragment .fade-out fragment-index=1}
$$\chi^2 = \sum{\color{red}{\frac{(O_i-E_i)^2}{E_i}}}$$ 
:::

::: {.fragment fragment-index=1}
$$\chi^2 = \color{red}{\sum{\frac{(O_i-E_i)^2}{E_i}}}$$ 
:::

:::
::::


::: aside
using the `tidyverse` way of doing things, where `mutate()` creates columns
:::

::::

## Evaluating $\chi^2$

- so for the particular random throws we did, $\chi^2=`r (xx=sum(chiTab$std_sq_diff))`$

- what we want to know is how probable that value is in a world where chance governs dice throws

. . .

- we already know two important things

  1. we're going to have to work out the distribution of $\chi^2$ and work out the probability of getting that value _or more_
  
  1. the reason we're calling the value we've calculated **$\chi^2$** is because we're going to compare it to the $\chi^2$ distribution
  
<!--   + the calculation is actually "Pearson's goodness-of-fit calculation"
  
- in R, there are `pchisq(), dchisq(), rchisq(), qchisq()` -->

## Why do Things the Easy Way?

- calculate and plot 10,000 random 600-fair-dice-throw $\chi^2$s


```{r}
#| output-location: column
#| tidy.opts: { width.cutoff: 24 }
#| fig-asp: .65
diceChi <- function(n) {
  dice <- sample(1:6, n, replace=TRUE)
  chisq.test(table(dice))$statistic
}

chiDist <- replicate(10000,diceChi(600))

plot(density(chiDist),
     main="chisq(5)",lwd=2)
```

::: aside
for more on `chisq.test(...)$statistic`, start with `str(chisq.test(...))`
:::

## The $\chi^2$ Distribution

```{r chiSqDist}
#| echo: false
#| fig-asp: .6
#| fig-width: 8

ggplot(data.frame(x = c(0, 20)), aes(x = x)) +
  stat_function(fun = dchisq, args = list(df = 2), colour = '#002060', size = 1) +
  stat_function(fun = dchisq, args = list(df = 4), colour = '#9E3E50', size = 1) +
  stat_function(fun = dchisq, args = list(df = 6), colour = '#BE6751', size = 1) +
  stat_function(fun = dchisq, args = list(df = 10), colour = '#F2C36B', size = 1) +
  labs(x = expression(chi^{2}), y = 'density') +
  annotate(geom = 'rect', xmin=14, xmax=16, ymin = .27, ymax =.48, fill = 'white') +
  annotate(geom = 'text', x = 15, y = 0.45, label = 'df = 2', colour = '#002060', size = 8) +
  annotate(geom = 'text', x = 15, y = 0.40, label = 'df = 4', colour = '#9E3E50', size = 8) +
  annotate(geom = 'text', x = 15, y = 0.35, label = 'df = 6', colour = '#BE6751', size = 8) +
  annotate(geom = 'text', x = 15, y = 0.30, label = 'df = 8', colour = '#F2C36B', size = 8)
```

::: aside
the "squared" in $\chi^2$ is because $\chi^2$ is derived from squared normal distributions
:::

## $\chi^2$ Probability

:::: {.columns}

::: {.column width="50%"}
- for our random 600 dice throws a couple of slides back

  + $\chi^2=`r xx`$, $\textrm{df} = 5$

- we can use `pchisq()`


```{r}
#| results: asis
#| echo: false
cat("```r\n")
cat(paste0("pchisq(",xx,", 5, lower.tail=FALSE)"),"\n")
cat("```\n")
```

```{r}
#| label: pchisq
#| echo: false
pchisq(xx, 5, lower.tail=FALSE)
```

:::

::: {.column width="50%"}
```{r}
#| label: chisqf2
#| echo: false
#| fig.asp: 0.6
df <- tibble(x=c(0,20))
p <- df %>% ggplot(aes(x=x)) +
  xlab(expression(paste(chi^2, "(5)"))) + ylab("density") +
  stat_function(fun=dchisq,n=151,args=list(df=5),linewidth=2)
ld <- layer_data(p) %>% filter(x>=xx)
p + geom_area(data=ld, aes(x=x,y=y),fill="red") +
  stat_function(fun=dchisq,n=151,args=list(df=5),linewidth=2)
```
:::

::::

- looks like we can conclude that our die is `r ifelse(pchisq(xx, 5, lower.tail=FALSE)<.05,"_unlikely_","likely")` to be fair

# Two-Dimensional $\chi^2$

## Types of $\chi^2$ Test

- what we've just seen is a **goodness of fit** calculation

  - do the data come from a specific distribution?


  
. . .

:::: {.columns}

::: {.column width="50%"}
- **test of homogeneity**

  - do groups have same distribution of a variable of interest?

- **test of independence**

  - are categorical variables associated with each other?
:::

::: {.column width="50%"}
```{r}
#| echo: false
statsClasses  |> group_by(course,in_uk) |> summarise(students=n())|>
  pivot_wider(names_from=in_uk,values_from = students) |> select(-`NA`) -> tData
tData |> ungroup() |> gt::gt() |> gt::tab_options(table.font.size=gt::pct(70))
```


:::

::::

## Teaching in 2020 {background-image="img/playmo_world.jpg" background-opacity=.3}

- 2020 data from all of the stats modules in Psychology

:::: {.columns}

::: {.column width="50%"}
```{r}
#| tidy.opts: { width.cutoff: 24 }
statsClasses |> filter(year==2020) |> select(course,in_uk) |> table()

```

:::

::: {.column width="50%" .fragment fragment-index=1}
```{r}
#| tidy.opts: { width.cutoff: 24 }
statsClasses |> filter(year==2020) |> select(course,in_uk) |> table() |> addmargins()

```
:::

::::

- contingency tables

::: notes
in the second version, I've added the `addmargins()` function to give useful summary statistics.  I can also use functions like `rowSums()` which I'll show you in the next slide
:::

## Under the Null Hypothesis


```{r}
#| label: readData
#| include: false
sc <- statsClasses |> filter(year==2020) |> select(course,in_uk)
```

:::: {.columns}

::: {.column width="60%"}
- students on each module would be _equally likely_ to be in the UK

- in other words, of the `r rowSums(table(sc))[1]` students on dapr1, $\frac{`r colSums(table(sc))[2]`}{`r sum(table(sc))`}\times{}`r rowSums(table(sc))[1]`$, or approx `r round(rowSums(table(sc))[1]*colSums(table(sc))[2]/sum(table(sc)),2)` students, should be in the UK under H~0~
:::

::: {.column width="40%"}
```{r}
#| echo: false

sc |> table() |> addmargins()
```

:::

::::

. . .

- we can repeat this calculation for each cell of the table, to give "expected values"

  + like the probability-based values for dice
  
## Expected Values

- repeating the calculation is easy using the "outer product ($\otimes$)" operator `%o%` in R (this takes two vectors and multiplies them out into a matrix)


$$
(a,b) \otimes (y, z) =
\begin{bmatrix}
a \times y & b \times y \\
a \times z & b \times z \\
\end{bmatrix}
$$

## Expected Values

- repeating the calculation is easy using the "outer product ($\otimes$)" operator `%o%` in R (this takes two vectors and multiplies them out into a matrix)

:::: {.columns}

::: {.column width="50%"}
```{r}
#| label: tab5
t <- sc |>
  select(course,in_uk) |> table()
t
```
:::

::: {.column width="50%"}
```{r}
#| label: tab6
# expected values
e <- rowSums(t) %o% colSums(t) / sum(t)
e
```
:::

::::

## Restating the Null Hypothesis

:::: {.columns}

::: {.column width="60%"}
- under H~0~:

  + knowing which class people are in gives no additional information about where they come from

  + knowing where they're from gives no additional information about which class they're in

<!--$$\chi^2 = \sum{\frac{(O_i-E_i)^2}{E_i}}$$-->
:::

::: {.column width="40%"}

observed

```{r}
#| label: tab7a
#| echo: false
as.matrix(t)
```

expected

```{r}
#| label: tab7
#| echo: false
e
```

:::

::::

## Using `plot()`



:::: {.columns}

::: {.column width="50%"}
```{r}
#| label: p1
#| fig.asp: 0.7
plot(t)
```
:::

::: {.column width="50%"}
```{r}
#| label: p2
#| fig.asp: 0.7
plot(as.table(e))
```
:::

::::

::: aside
`e` was created as a `matrix` (using `%o%`) so here we tell R to treat it as a table
:::

## Are The Courses Different?

:::: {.columns}

::: {.column width="50%"}

```{r}
#| label: uk1
chisq.test(t)
```

- might need to look more closely

```{r}
#| label: uk3
chisq.test(t)$p.value
```

:::

::: {.column width="50%"}
```{r}
#| label: uk2
#| fig.asp: 0.6
#| echo: false
x <- tibble(x=c(0,20))
p <- x %>% ggplot(aes(x=x)) +
  stat_function(fun=dchisq,n=151,args=list(df=3)) +
  xlab(expression(paste(chi^2, "(3)"))) + ylab("density")
ld <- layer_data(p) %>% filter(x >= chisq.test(t)$statistic)
p + geom_area(data=ld,aes(x=x,y=y),fill="red") +
  stat_function(fun=dchisq,n=151,args=list(df=3),size=2)

```
:::

::::

## Bonus: Eye Colours: All Years

```{r}
#| echo: false

ec <- statsClasses |> select(course,eyecolour) |>
  filter(!is.na(eyecolour)) |> mutate(course=ifelse(course=='rms2','dapr3',course))
uc <- ec |> filter(course=='usmr') |> pull(eyecolour)

ggec <- ec |> filter(course=='usmr') |> table() |> as.data.frame()

ggec |> ggplot(aes(eyecolour, Freq, fill = eyecolour)) +
  geom_bar(stat='identity') +
  labs(x='Eye Colour', y = 'Count') +
  scale_fill_manual(values = c('#8A4B08',
    '#218BB2', '#593520', '#7CA69A',
                               '#8C8C8C', 
                               '#5C643D', '#071726')) +
  theme(legend.position = 'none', axis.text = element_text(size=14), 
        axis.title=element_text(size=16, face = 'bold'))
```




<!-- ![](`r knitr::fig_chunk('ecfig','svg')`) -->



- are USMR eyes different from estimated world proportions?

```{r}
#| warning: false
chisq.test(table(uc),p=c(.05,.09,.70,.02,.03,.05,.06))
```


## Bonus: Eye Colours

```{r}
#| echo: false
library(ggmosaic)
ec |> ggplot() +
  geom_mosaic(aes(x=product(eyecolour,course),fill=eyecolour)) +
  scale_fill_manual(values=c("blue"='#218BB2',
                    "brown"='#593520',
                    "green"='#7CA69A',
                    "grey"= '#8C8C8C',
                    "hazel"='#5C643D',
                    "other"='#071726',
                    "amber"='#b36800')) +
  theme(legend.position = "none")
                      
```
- are eye colours different between stats classes?

```{r}
chisq.test(table(ec))
```

## References {.smaller .appendix}

::: {#refs}
:::


