---
title: "08A: Multiple Linear Regression"
link-citations: yes
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---


```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(xaringanExtra)
library(tidyverse)
library(patchwork)
xaringanExtra::use_panelset()
```

In this reading, we move from the simple linear regression model (one outcome variable, one explanatory variable) to the _multiple regression model_ (one outcome variable, multiple explanatory variables).  
Everything we learned about simple linear regression in [Reading 7A](07a_slr.html){target="_blank"} can be extended (with minor modification) to the multiple regression model. The key conceptual difference is that for simple linear regression we think of the distribution of errors at some fixed value of the explanatory variable, and for multiple linear regression, we think about the distribution of errors at fixed set of values for all our explanatory variables. 

# Multiple Linear Regression

**Model formula**

For multiple linear regression, the model formula is an extension of the one predictor ("simple") regression model, to include any number of predictors:  
$$
\begin{align}
& y = b_0 \ + \ b_1 x_1 \ + \ b_2 x_2 \ + \ ... \ + b_k x_k \ + \ \epsilon \\ 
& \quad \\ 
& \text{where} \\
& \epsilon \sim N(0, \sigma) \text{ independently}
\end{align}
$$

In the model specified above,

- $\mu_{y|x_1, x_2, ..., x_k} = b_0 + b_1 x + b_2 x_2 + ... b_k x_k$ represents the systematic part of the model giving the mean of $y$ at each combination of values of variables $x_1$-$x_k$;
- $\epsilon$ represents the error (deviation) from that mean, and the errors are independent from one another.    
  
__Visual__

Note that for simple linear regression we talked about our model as a _line_ in 2 dimensions: the systematic part $b_0 + b_1 x$ defined a line for $\mu_y$ across the possible values of $x$, with $\epsilon$ as the random deviations from that line. But in multiple regression we have more than two variables making up our model. 

In this particular case of three variables (one outcome + two explanatory), we can think of our model as a _regression surface_ (See @fig-regsurf). The systematic part of our model defines the surface across a range of possible values of both $x_1$ *and* $x_2$. Deviations from the surface are determined by the random error component, $\hat \epsilon$.  

```{r}
#| label: fig-regsurf
#| echo: false
#| fig-cap: "Regression surface for y~x1+x2, from two different angles"
#| message: false
#| warning: false


mwdata = read_csv(file = "https://uoepsy.github.io/data/wellbeing.csv")
mwdata %>% rename(y=wellbeing,x1=outdoor_time,x2=social_int) -> mwdata
fit<-lm(y~x1+x2, data=mwdata)
steps=50
x1 <- with(mwdata, seq(min(x1),max(x1),length=steps))
x2 <- with(mwdata, seq(min(x2),max(x2),length=steps))
newdat <- expand.grid(x1=x1, x2=x2)
y <- matrix(predict(fit, newdat), steps, steps)


par(mfrow=c(1,2))
p <- persp(x1,x2,y, theta = 35,phi=10, col = NA)
obs <- with(mwdata, trans3d(x1,x2, y, p))
pred <- with(mwdata, trans3d(x1, x2, fitted(fit), p))
points(obs, col = "red", pch = 16)
#points(pred, col = "blue", pch = 16)
segments(obs$x, obs$y, pred$x, pred$y)

p <- persp(x1,x2,y, theta = -35,phi=10, col = NA)
obs <- with(mwdata, trans3d(x1,x2, y, p))
pred <- with(mwdata, trans3d(x1, x2, fitted(fit), p))
points(obs, col = "red", pch = 16)
#points(pred, col = "blue", pch = 16)
segments(obs$x, obs$y, pred$x, pred$y)

par(mfrow=c(1,1))
```

Don't worry about trying to figure out how to visualise it if we had any more explanatory variables! We can only concieve of 3 spatial dimensions. One could imagine this surface changing over time, which would bring in a 4th dimension, but beyond that, it's not worth trying!.


## Research Question

The data for this walkthrough is from an hypothetical study in which some reseachers are interested in the relationship between psychological wellbeing and time spent outdoors. They know that other aspects of peoples' lifestyles such as how much social interaction they have can influence their mental well-being.  

> **Research Question**   
> Is there a relationship between well-being and time spent outdoors *after* taking into account the relationship between well-being and social interactions?.  

:::frame
__Data: Wellbeing__  

Researchers interviewed 32 participants, selected at random from the population of residents of Edinburgh & Lothians. They used the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.  
The researchers also asked participants to estimate the average number of hours they spend outdoors each week, the average number of social interactions they have each week (whether on-line or in-person), and whether they believe that they stick to a routine throughout the week (Yes/No).  

The dataset is available at [https://uoepsy.github.io/data/wellbeing.csv](https://uoepsy.github.io/data/wellbeing.csv){target="_blank"} and contains five attributes: 

- `wellbeing`: Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.  
- `outdoor_time`: Self report estimated number of hours per week spent outdoors  
- `social_int`: Self report estimated number of social interactions per week (both online and in-person)
- `routine`: Binary Yes/No response to the question "Do you follow a daily routine throughout the week?"
- `location`: Location of primary residence (City, Suburb, Rural)

:::

## Model Specification 

To address the research question we are going to fit the following model:  

$$
Wellbeing = b_0 \ + \ b_1 \cdot Social Interactions \ + \ b_2 \cdot Outdoor Time \ + \ \epsilon
$$
## Exploring the Data

First we need to import the wellbeing data into R. We'll give them the name `mwdata`.    
  
```{r}
library(tidyverse)
# Read in data
mwdata = read_csv("https://uoepsy.github.io/data/wellbeing.csv")
```

Now, as before, we explore and describe the relevant variables and relationships.  
We will want to:  

- Produce plots of the _marginal distributions_ (the distributions of each variable in the analysis without reference to the other variables) of the `wellbeing`, `outdoor_time`, and `social_int` variables. 
- Produce plots of the _marginal relationships_ between the outcome variable (`wellbeing`) and each of the explanatory variables.  
- Produce a correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the relationships. 


:::sticky
__Correlation matrix__  

A table showing the correlation coefficients - $r_{(x,y)}=\frac{\mathrm{cov}(x,y)}{s_xs_y}$ - between variables. Each cell in the table shows the relationship between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).  

__In R:__
We can create a correlation matrix easily by giving the `cor()` function a dataframe. If we only want to give it a certain set of columns, we can combine this with `select()`, or giving the column numbers inside `[]`. 

:::

```{r}
#| label: fig-marg
#| fig-cap: "Marginal distribution plots of wellbeing sores, weekly hours spent outdoors, and social interactions"


library(patchwork) #used to arrange plots
wellbeing_plot <- 
  ggplot(data = mwdata, aes(x = wellbeing)) +
  geom_density() +
  geom_boxplot(width = 1/250) +
  labs(x = "Score on WEMWBS (range 14-70)", y = "Probability\ndensity")

outdoortime_plot <- 
  ggplot(data = mwdata, aes(x = outdoor_time)) +
  geom_density() +
  geom_boxplot(width = 1/200) +
  labs(x = "Time spent outdoors per week (hours)", y = "Probability\ndensity")

social_plot <- 
  ggplot(data = mwdata, aes(x = social_int)) +
  geom_density() +
  geom_boxplot(width = 1/150) +
  labs(x = "Number of social interactions per week", y = "Probability\ndensity")

# the "patchwork" library allows us to arrange multiple plots
wellbeing_plot / outdoortime_plot / social_plot
```

:::int  

+ The marginal distribution of scores on the WEMWBS is unimodal with a mean of approximately `r round(mean(mwdata$wellbeing),1)`. There is variation in scores (SD = `r round(sd(mwdata$wellbeing),1)`).   
+ The marginal distribution of weekly hours spend outdoors is unimodal with a mean of approximately `r round(mean(mwdata$outdoor_time),1)` hours. There is variation in outdoor time (SD = `r round(sd(mwdata$outdoor_time),1)` hours).  
+ The marginal distribution of numbers of social interactions per week is unimodal with a mean of approximately `r round(mean(mwdata$social_int),1)`. There is variation in in numbers of social interactions per week (SD = `r round(sd(mwdata$social_int),1)`).  

:::

```{r}
#| label: fig-mwdata-mlr-rels
#| fig-cap: 'Scatterplots displaying the relationships between scores on the WEMWBS and a) weekly outdoor time (hours), and b) weekly number of social interactions'


wellbeing_outdoor <- 
  ggplot(data = mwdata, aes(x = outdoor_time, y = wellbeing)) +
  geom_point(alpha = 0.5) +
  labs(x = "Time spent outdoors per week (hours)", y = "Wellbeing score (WEMWBS)")

wellbeing_social <- 
  ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +
  geom_point(alpha = 0.5) +
  labs(x = "Number of social interactions per week", y = "Wellbeing score (WEMWBS)")

wellbeing_outdoor | wellbeing_social
```

We can either use:
```{r}
#| eval: false

# correlation matrix of the first 3 columns
cor(mwdata[,1:3])
```
or:
```{r}
# select only the columns we want by name, and pass this to cor()
mwdata %>% 
  select(wellbeing, outdoor_time, social_int) %>%
  cor()
```


:::int
There is a moderate, positive, linear relationship between weekly outdoor time and WEMWBS scores for the participants in the sample.
Participants' wellbeing scores tend to increase, on average, with the number of hours spent outdoors each week.  
There is a moderate, positive, linear relationship between the weekly number of social interactions and WEMWBS scores for the participants in the sample.
Participants' wellbeing scores tend to increase, on average, with the weekly number of social interactions. 
There is also a weak positive correlation between weekly outdoor time and the weekly number of social interactions.  
::: 

<br>
Note that there is a weak correlation between our two explanatory variables (outdoor_time and social_int). We will return to how this might affect our model when later on we look at the assumptions of multiple regression.  


## Fitting the Model

As we did for simple linear regression, we can fit our multiple regression model using the `lm()` function. We can add as many explanatory variables as we like, separating them with a `+`.  
```
[model name] <- lm([response variable] ~ 1 + [explanatory variable 1] + [explanatory variable 2] + ... , data = [dataframe])
```


$$
Wellbeing = b_0 \ + \ b_1 \cdot Social Interactions \ + \ b_2 \cdot Outdoor Time \ + \ \epsilon
$$
```{r}
wbmodel <- lm(wellbeing ~ 1 + social_int + outdoor_time, data = mwdata)
```


## Interpreting Coefficients


The parameters of a multiple regression model are:

+ $b_0$ (The intercept);
+ $b_1$ (The slope across values of $x_1$);
+ ...  
+ ...
+ $b_k$ (The slope across values of $x_k$);
+ $\sigma$ (The standard deviation of the errors).

<br>
You'll hear a lot of different ways that people explain multiple regression coefficients.  
For the model $y = b_0 + b_1 x_1 + b_2 x_2 + \epsilon$, the estimate $\hat b_1$ will often be reported as:  
  
the increase in $y$ for a one unit increase in $x_1$ when...

- holding the effect of $x_2$ constant.
- controlling for differences in $x_2$.
- partialling out the effects of $x_2$.
- holding $x_2$ equal. 
- accounting for effects of $x_2$. 


:::int
```{r}
#| echo: false
summary(wbmodel)$coefficients
```

The coefficient `r round(coef(wbmodel)[3],2)` of weekly outdoor time for predicting wellbeing score says that among those with the same number of social interactions per week, those who have one additional hour of outdoor time tend to, on average, score `r round(coef(wbmodel)[3],2)` higher on the WEMWBS wellbeing scale. The multiple regression coefficient measures that average _conditional_ relationship.
:::

One by one, the parameter estimates are: 
```{r}
coef(wbmodel)
```

- $\hat \b_0$ = `r round(coef(wbmodel)[1],2)`, the estimated average wellbeing score associated with zero hours of outdoor time and zero social interactions per week.  
- $\hat \b_2$ = `r round(coef(wbmodel)[2],2)`, the estimated increase in average wellbeing score associated with an additional social interaction per week (an increase of one), _holding weekly outdoor time constant_ (i.e., when the remaining explanatory variables are held at the same value or are fixed).  
- $\hat \b_1$ = `r round(coef(wbmodel)[3],2)`, the estimated increase in average wellbeing score associated with one hour increase in weekly outdoor time, _holding the number of social interactions constant_.

## $\sigma$

Just as we had with simple linear regression, we have errors around the a line, here we have error around a 3-dimensional surface. It's harder to visualise (but see @fig-regsurf), but we can still get an idea of how far away observations are from our fitted model (the surface).  
The estimated standard deviation of the errors is $\hat \sigma$ = `r round(sigma(wbmodel),2)`. We would expect 95% of wellbeing scores to be within about `r round(sigma(wbmodel)*2,2)` ($2 \hat \sigma$) from the model fit.  

```{r}
sigma(wbmodel)
```

## Inference  

Much like for simple linear regression, we have the tests of the coefficients being zero, which are provided in the summary: 
```{r}
summary(wbmodel)$coefficients
```

We can also obtain confidence intervals for our estimates (we saw confidence intervals back in [Reading 2B](02b_sampling.html){target="_blank"}. These provide a means of quantifying the uncertainty (or precision) of our estimates.  

The function `confint()` can do this for us. 

```{r}
confint(wbmodel, level = 0.95)
```

:::int 

+ The average wellbeing score for all those with zero hours of outdoor time and zero social interactions per week is between `r round(confint(wbmodel, level=.95)[1,1],2)` and `r round(confint(wbmodel, level=.95)[1,2],2)`.  
+ When _holding weekly outdoor time constant_, each increase of one social interaction per week is associated with a difference in wellbeing scores between `r round(confint(wbmodel, level=.95)[2,1],2)` and `r round(confint(wbmodel, level=.95)[2,2],2)`, on average. 
+ When _holding the number of social interactions per week constant_, each one hour increase in weekly outdoor time is associated with a difference in wellbeing scores between `r round(confint(wbmodel, level=.95)[3,1],2)` and `r round(confint(wbmodel, level=.95)[3,2],2)`, on average. 

:::

## More Model Evaluation

:::statbox
__Adjusted $R^2$__  

We know from our work on simple linear regression that the R-squared can be obtained as:
$$
R^2 = \frac{SS_{Model}}{SS_{Total}} = 1 - \frac{SS_{Residual}}{SS_{Total}}
$$

However, when we add more and more predictors into a multiple regression model, $SS_{Residual}$ cannot increase, and may decrease by pure chance alone, even if the predictors are unrelated to the outcome variable. Because $SS_{Total}$ is constant, the calculation $1-\frac{SS_{Residual}}{SS_{Total}}$ will increase by chance alone. 

An alternative, the Adjusted-$R^2$, does not necessarily increase with the addition of more explanatory variables, by including a penalty according to the number of explanatory variables in the model. It is not by itself meaningful, but can be useful in determining what predictors to include in a model. 
$$
Adjusted{-}R^2=1-\frac{(1-R^2)(n-1)}{n-k-1} \\
\quad \\
\begin{align}
& \text{Where:} \\
& n = \text{sample size} \\
& k = \text{number of explanatory variables} \\
\end{align}
$$

---

**In R,** you can view the mutiple and adjusted $R^2$ at the bottom of the output of `summary(<modelname>)`:

```{r}
#| label: fig-mlroutputrsq
#| fig-cap: "Multiple regression output in R, summary.lm(). R-squared highlighted"
#| echo: false
knitr::include_graphics("images/mlr/mlroutputrsq.png")
```

:::  

:::statbox
__F-ratio__  

As in simple linear regression, the F-ratio is used to test the null hypothesis that __all__ regression slopes are zero (it is just that now that we have multiple predictors, "all" is more than 1).  

$$
\begin{aligned}
H_0: & \text{the model is ineffective, } \\
& b_1, ..., b_k = 0 \\
H_1: &\text{the model is effective, } \\
& \text{any of }b_1, ..., b_k \neq 0
\end{aligned}
$$

It is called the F-ratio because it is the ratio of the how much of the variation is explained by the model (per parameter) versus how much of the variation is unexplained (per remaining degrees of freedom). 

$$
\begin{align}
& F_{df_{model},df_{residual}} = \frac{MS_{Model}}{MS_{Residual}} = \frac{SS_{Model}/df_{Model}}{SS_{Residual}/df_{Residual}} \\
& \quad \\
& \text{Where:} \\
& df_{model} = k \\
& df_{error} = n-k-1 \\
& n = \text{sample size} \\
& k  = \text{number of explanatory variables} \\
\end{align}
$$

---

**In R,** at the bottom of the output of `summary(<modelname>)`, you can view the F ratio, along with an hypothesis test against the alternative hypothesis that the at least one of the coefficients $\neq 0$ (under the null hypothesis that all coefficients = 0, the ratio of explained:unexplained variance should be approximately 1):




```{r}
#| label: fig-mlroutputrf
#| fig-cap: "Multiple regression output in R, summary.lm(). F statistic highlighted"
#| fig-align: "left"
#| echo: false
knitr::include_graphics("images/mlr/mlroutputf.png")
```
  
:::


:::int
```{r echo=FALSE}
mdl1<-wbmodel
```
Weekly social interactions and outdoor time explained `r paste0(round(summary(mdl1)$adj.r.squared*100,1),"%")` of the variance in well-being scores (adjusted $R^2$ =`r round(summary(mdl1)$adj.r.squared,3)`, $F$(`r paste(summary(mdl1)$fstatistic[2:3],collapse=",")`)=`r round(summary(mdl1)$fstatistic,1)[1]`, p`r map_chr(pf(summary(mdl1)$fstatistic[1],summary(mdl1)$fstatistic[2],summary(mdl1)$fstatistic[3], lower.tail = FALSE), ~ifelse(.<001,"<.001",paste0("=",round(.,2))))`)
:::
  

# Model Comparison

The F-ratio we see at the bottom of `summary(model)` is actually a comparison between two models: our model (with some explanatory variables in predicting $y$) and __the null model.__ In regression, the null model can be thought of as the model in which all explanatory variables have zero regression coefficients. It is also referred to as the __intercept-only model__, because if all predictor variable coefficients are zero, then the only we are only estimating $y$ via an intercept (which will be the mean: $\bar y$).  

But we don't always have to compare our model to the null model. We can compare it to all the intermediate models which vary in the complexity, from the null model to our full model.  

:::imp
If (*and only if*) two models are __nested__ (one model contains all the predictors of the other and is fitted to the same data), we can compare them using an __incremental F-test.__  
:::

:::statbox
__Incremental F-test__  

This is a formal test of whether the additional predictors provide a better fitting model.  
Formally this is the test of:  

+ $H_0:$ coefficients for the added/ommitted variables are all zero.
+ $H_1:$ at least one of the added/ommitted variables has a coefficient that is not zero. 

:::rtip

**In R,** we can conduct an incremental F-test by constructing two models, and passing them to the `anova()` function: `anova(model1, model2)`. 

:::

`r optbegin("Optional: F-ratio written for model comparison", olabel=FALSE, toggle=params$TOGGLE)`
The F-ratio for comparing the residual sums of squares between two models can be written as:

$$
\begin{align}
& F_{(df_R-df_F),df_F} = \frac{(SSR_R-SSR_F)/(df_R-df_F)}{SSR_F / df_F} \\
& \quad \\
& \text{Where:} \\
& SSR_R = \text{residual sums of squares for the restricted model} \\
& SSR_F = \text{residual sums of squares for the full model} \\
& df_R = \text{residual degrees of freedom from the restricted model} \\
& df_F = \text{residual degrees of freedom from the full model} \\
\end{align}
$$
`r optend()`

:::

To fit the 'null model', we simply fit the model with only an intercept term, and no predictors. We can use the `anova()` function to compare this model with ours, and we will see that it matches the $F$-statistic at the bottom of the full model output.  

Here are both models fitted: 
```{r}
null_model <- lm(wellbeing ~ 1, data = mwdata)
wbmodel <- lm(wellbeing ~ 1 + social_int + outdoor_time, data = mwdata)
```


And the comparison between them, a test of the reduction in residual sums of squares:
```{r}
anova(null_model, wbmodel)
```


And from our full model, we can get that same $F$-statistic:
```{r}
summary(wbmodel)$fstatistic
```
And we can retrieve the p-value:  
```{r}
fstat = summary(wbmodel)$fstatistic[1]
df_1 = summary(wbmodel)$fstatistic[2]
df_2 = summary(wbmodel)$fstatistic[3]
pf(fstat, df_1, df_2, lower.tail = FALSE)
```

We can also see quickly all the F-ratios at the addition of each explanatory variable incrementally, by just using `anova(model)`.  

```{r}
anova(wbmodel)
```
This is the same as building each incremental model:  
```{r}
null_model <- lm(wellbeing ~ 1, data = mwdata)
model1 <- lm(wellbeing ~ 1 + social_int, data = mwdata)
model2 <- lm(wellbeing ~ 1 + social_int + outdoor_time , data = mwdata)
```
And comparing them in increasing complexity:  
```{r}
anova(null_model, model1, model2)
```


TODO upto here



__Using either of the outputs from the above two lines of code, does weekly outdoor time explain a significant amount of variance in wellbeing scores over and above weekly social interactions?__

```{r}
null_model <- lm(wellbeing ~ 1, data = mwdata)
model1 <- lm(wellbeing ~ 1 + social_int, data = mwdata)
model2 <- lm(wellbeing ~ 1 + social_int + outdoor_time , data = mwdata)
summary(model1)$adj.r.sq
summary(model2)$adj.r.sq
```

:::int
The model *with* outdoor time as a predictor explains `r round(summary(model2)$adj.r.sq*100)`\% of the variance, and the model *without* explains `r round(summary(model1)$adj.r.sq*100)`\%.  
:::

```{r}
anova(model1, model2)
```
```{r include=FALSE}
mc <- anova(model1, model2)
names(mc)[6]<-"p"
```

:::int
Time spent outdoors was found to explain a significant amount of variance in wellbeing scores over and above weekly social interactions   
$F$(`r paste(c(mc$Df[2],mc$Res.Df[2]),collapse=",")`)=`r round(mc$F[2],2)`, p`r map_chr(mc$p[2], ~ifelse(.<001,"<.001",paste0("=",round(.,2))))`.
:::


`r qbegin("C4")`
Play around with changing the _order_ of the explanatory variables in our model. This will __not__ change the `summary()` output, but it __will__ change the `anova(model)` output. 
```{r eval=F}
model2 <- lm(wellbeing ~ 1 + outdoor_time + social_int, data = mwdata)
model2a <- lm(wellbeing ~ 1 + social_int + outdoor_time, data = mwdata)
summary(model2)
summary(model2a)
anova(model2)
anova(model2a)
```
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

The `summary()` output for these two models will be the same numbers, but just in a different order.
```{r}
model2 <- lm(wellbeing ~ 1 + outdoor_time + social_int, data = mwdata)
model2a <- lm(wellbeing ~ 1 + social_int + outdoor_time, data = mwdata)
summary(model2)$coefficients
summary(model2a)$coefficients
```

The `anova()` output will be _different_ for these two models, because it tests the __incremental__ addition of each explanatory variable in the order in which they are inputted into the model. 
```{r}
anova(model2)
anova(model2a)
```
`r solend()`


:::lo
We should be careful when we conduct research and take the time to think about _what_ exactly we are measuring, and _how._  

The notion of performing the "incremental tests" that we have just seen provides a good example of when we can fall foul of "measurement error".   
If you're interested, we have written up a fun little example on incremental validity, which you can [find here.](https://uoepsy.github.io/usmr/labs/zz_incrementalvalidity.html)

:::
`r qbegin("C5")`
Does the addition of routine provide significant improvement to model fit, after accounting for the effects of outdoor time and social interactions?  
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
We can do this with one: 
```{r eval=F}
model3 <- lm(wellbeing ~ 1 + outdoor_time + social_int + routine, data = mwdata)
anova(model3)
```

Or the same thing with two models:
```{r eval=F}
model2 <- lm(wellbeing ~ 1 + outdoor_time + social_int, data = mwdata)
model3 <- lm(wellbeing ~ 1 + outdoor_time + social_int + routine, data = mwdata)
anova(model2, model3)
```
`r solend()`




<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
