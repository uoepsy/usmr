---
title: "Week 7 Exercises: Linear Regression"
link-citations: yes
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---


```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(tidyverse)
library(patchwork)
set.seed(017)
survey_data <- read_csv("https://uoepsy.github.io/data/surveydata_allcourse.csv") 
```

Our data for these exercises is from an hypothetical study into income disparity for employees in a local authority. We're interested in investigating the link between the level of education and an employeeâ€™s income. Those with more formal education seem to be better paid. 

:::frame
__Data: riverview.csv__  

The riverview data, which come from [Lewis-Beck, 2015](https://methods.sagepub.com/book/applied-regression-an-introduction-second-edition), contain five attributes collected from a random sample of $n=32$ employees working for the city of Riverview, a hypothetical midwestern city in the US. The attributes include:  

- `education`: Years of formal education
- `income`: Annual income (in thousands of U.S. dollars)
- `seniority`: Years of seniority
- `gender`: Employee's gender
- `male`: Dummy coded gender variable (0 = Female, 1 = Male)
- `party`: Political party affiliation

The first six rows of the data are:

```{r echo=FALSE}
library(tidyverse)
library(kableExtra)

riverview <- read_csv('https://uoepsy.github.io/data/riverview.csv')
kable(head(riverview), align='c') %>% kable_styling(full_width = FALSE)
```

The data is available at [https://uoepsy.github.io/data/riverview.csv.](https://uoepsy.github.io/data/riverview.csv){target="_blank"}

:::


`r qbegin("A1")` 
Load the required libraries (probably just __tidyverse__ for now), and read in the riverview data to your R session.  
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r, warning=FALSE, message=FALSE}
library(tidyverse)

riverview <- read_csv("https://uoepsy.github.io/data/riverview.csv")
head(riverview)
```
`r solend()`

`r qbegin("A2")`  
Let us first visualise and describe the *marginal distributions* of those variables which are of interest to us. 
These are the distribution of each variable (employee incomes and education levels) *without* reference to the values of the other variables.

:::hints
__Hints:__  

- You could use, for example, `geom_density()` for a density plot or `geom_histogram()` for a histogram.
- Look at the shape, center and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal? 
- Do you notice any extreme observations?

:::
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
We can plot the marginal distribution of employee incomes as a density curve, and add a boxplot underneath to check for the presence of outliers. The `width` of the geom_boxplot() is always quite wide, so I want to make it narrower so that we can see it at the same time as the density plot. Deciding on the exact value for the width here is just trial and error:

```{r}
#| label: fig-incomeplot
#| fig.cap: "Density plot and boxplot of employee incomes and education levels"

library(patchwork)
# the patchwork library allows us to combine plots together
ggplot(data = riverview, aes(x = income)) +
  geom_density() +
  geom_boxplot(width = 1/300) +
  labs(x = "Income (in thousands of U.S. dollars)", 
       y = "Probability density") +

ggplot(data = riverview, aes(x = education)) +
  geom_density() +
  geom_boxplot(width = 1/100) +
  labs(x = "Education (in years)", 
       y = "Probability density")

```

The plots suggests that the distributions of employee incomes and education levels are both unimodal. Most of the incomes are between roughly \$45,000 and \$70,000, and most people have between 12 and 20 years of education. Furthermore, the boxplot does not highlight any outliers in either variable.  

To further summarize a distribution, it is typical to compute and report numerical summary statistics such as the mean and standard deviation. One way to compute these values is to use the `summarise()/summarize()` function from the `tidyverse` library:

```{r}
riverview %>% 
  summarize(
    e = mean(income), 
    sd_income = sd(income),
    mean_edu = mean(education),
    sd_edu = sd(education)
    )
```

:::int
The marginal distribution of income is unimodal with a mean of approximately \$53,700. There is variation in employees' salaries (SD = \$14,553).  
The marginal distribution of education is unimodal with a mean of 16 years. There is variation in employees' level of education (SD = 4.4 years).  
:::
`r solend()`

`r qbegin("A3")`  
After we've looked at the marginal distributions of the variables of interest in the analysis, we typically move on to examining *relationships* between the variables.  
  
Visualise and describe the relationship between income and level of education among the employees in the sample.  


:::hints
Think about:  

- *Direction* of association
- *Form* of association (can it be summarised well with a straight line?)  
- *Strength* of association (how closely do points fall to a recognizable pattern such as a line?)
- *Unusual observations* that do not fit the pattern of the rest of the observations and which are worth examining in more detail.  
:::
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
Because we are investigating how income varies when varying years of formal education, income here is the dependent variable (on the y-axis), and education is the independent variable (on the x-axis).

```{r}
#| label: fig-riverview-scatterplot
#| fig.cap: 'The relationship between employees education level and income.'
ggplot(data = riverview, aes(x = education, y = income)) +
  geom_point(alpha = 0.5) +
  labs(x = "Education (in years)", 
       y = "Income (in thousands of U.S. dollars)")
```

:::int
There is a strong positive linear relationship between education level and income for the employees in the sample.
High incomes tend to be observed, on average, with more years of formal education.
The scatterplot does not highlight any outliers.
:::

To comment numerically on the strength of the linear association we might compute the correlation coefficient that we were introduced to in [Reading 5A](05a_covcor.html)
```{r}
riverview %>%
  select(education, income) %>%
  cor()
```

that is, $r_{\text{education, income}} = 0.79$

`r solend()`

`r qbegin("A4")`
Using the `lm()` function, fit a linear model to the sample data, in which employee income is explained by education level. Assign it to a name to store it in your environment.
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
As the variables are in the `riverview` dataframe, we would write:  
```{r}
model1 <- lm(income ~ 1 + education, data = riverview)
```
`r solend()`

`r qbegin("A5")`
Interpret the estimated intercept and slope in the context of the question of interest.  

:::hints
Let's suppose we assigned our linear model object to the name "model1" in R. To obtain the estimated regression coefficients we can use it's name in various ways and with various functions. 

- type `model1`, i.e. simply invoke the name of the fitted model;
- type `model1$coefficients`;
- use the `coef(model1)` function;
- use the `coefficients(model1)` function;
- use the `summary(model1)` function and look under the "Estimate" column.

The estimated parameters returned by the above methods are all equivalent. However, `summary()` returns more information and you need to look under the column "Estimate".
:::
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r}
coef(model1)
```
From this, we get that the fitted line is:
$$
\widehat{Income} = 11.32 + 2.65 \ Education \\
$$

We can interpret the estimated intercept as:

:::int
The estimated average income associated with zero years of formal education is \$11,321.
:::

For the estimated slope we get:

:::int
The estimated increase in average income associated with a one year increase in education is \$2,651.
:::
`r solend()`

`r qbegin("A6")`
Consider the following:  

1. In fitting a linear regression model, we make the assumption that the errors around the line are normally distributed around zero (this is the $\epsilon \sim N(0, \sigma)$ bit.)  
2. About 95\% of values from a normal distribution fall within two standard deviations of the centre.  

We can obtain the estimated standard deviation of the errors ($\hat \sigma$) from the fitted model using `sigma()` and giving it the name of our model.  
What does this tell us?  

`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
The estimated standard deviation of the errors can be obtained by:

```{r}
sigma(model1)
```

:::int
For any particular level of education, employee incomes should be distributed above and below the regression line with standard deviation estimated to be $\hat \sigma = 8.98$. 
Since $2 \hat \sigma = 2 (8.98) = 17.96$, we expect most (about 95\%) of the employee incomes to be within about \$18,000 from the regression line.
:::  

`r solend()`

`r qbegin("A7")`
Compute the model-predicted income for someone with 1 year of education.  

Given that you know the intercept and slope, you can calculate this algebraically. However, try to also use the `predict()` function.  
`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
Using `predict()`, we need to give it our model, plus some new data which contains a person with only 1 year of education.  First we make a new dataframe with an education variable, with one entry which has the value 1, and then we give that to `predict()`:  
```{r}
education_query <- data.frame(education = c(1))
predict(model1, newdata = education_query)
```

Given that our fitted model takes the form: 

$$
Income = 11.32 + 2.65\cdot Education
$$

We are asking what the predicted income is for someone with 1 year of education. So we can substitute in "1" for the Education variable:
$$
\begin{align}
Income &= 11.32 + 2.65\cdot Education \\
Income &= 11.32 + 2.65\cdot 1 \\
Income &= 11.32 + 2.65\\
Income &= 13.97 \\
\end{align}
$$

`r solend()`

`r qbegin("A9")`
Test the hypothesis that the population slope is zero --- that is, that there is no linear association between income and education level in the population.  

:::hints
__Hint:__ you don't need to *do* anything for this, you can find all the necessary information in `summary()` of your model
:::
`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
The information is already contained in the row corresponding to the variable "education" in the output of `summary()`, which reports the t-statistic under `t value` and the p-value under `Pr(>|t|)`:
```{r}
summary(model1)
```

Recall that the p-value `5.56e-08` in the `Pr(>|t|)` column simply means $5.56 \times 10^{-8}$. This is a very small value, hence we will report it as <.001 following the APA guidelines.

:::int
A significant association was found between level of education (in years) and income ($t(30) = 7.173,\ p < .001$, two-sided). 
:::

`r solend()`

`r qbegin("A10")`
What is the proportion of the total variability in incomes explained by the linear relationship with education level?

:::hints
**Hint:** The question asks to compute the value of $R^2$, but you might be able to find it already computed somewhere (so much stuff is already in `summary()` of the model.
:::
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
For the moment, ignore "Adjusted R-squared". We will come back to this later on. 
```{r}
summary(model1)
```

:::int
Approximately 63\% of the total variability in employee incomes is explained by the linear association with education level.
:::

`r solend()`

`r qbegin("A11")`
Look at the output of `summary()` of your model. Identify the relevant information to conduct an F-test against the null hypothesis that the model is ineffective at predicting income using education level.
`r qend()`
`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r}
summary(model1)
```

From the `summary(model1`), the relevant row is just below the $R^2$, where it states: 

```
F-statistic: 51.45 on 1 and 30 DF,  p-value: 5.562e-08
```

:::int
The overall test of model utility was significant $F(1, 30) = 51.45, p < .001$, indicating evidence against the null hypothesis that the model is ineffective (that education is not a useful predictor of income). 
:::

`r solend()`



`r qbegin()`
TODO binary predictor
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

`r solend()`


`r qbegin()`
t.test. does it match
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

`r solend()`





<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
